{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c99ae02-cb8f-48df-b5f0-f61d99ff3cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from job_search_application.minsearch import Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6367e372-d37f-4c66-bef4-bddc249867a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai21 import AI21Client\n",
    "from ai21.models.chat import ChatMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5caa444-ae42-4515-8710-f9d6d270e980",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AI21Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d5e213c-478b-442b-bc4c-0310676627f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/job_data.json', 'r') as json_file:\n",
    "    job_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60ef7102-04b2-47d5-8a48-a63ec5e67604",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/retrival_evaluation_data.json', 'r') as json_file:\n",
    "    evaluation_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "babc3148-fa0a-4b25-8392-9b20232ea195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<job_search_application.minsearch.Index at 0x7fa451ff58b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = Index(\n",
    "    text_fields=[\n",
    "        \"title\",\n",
    "        \"company\",\n",
    "        \"locations\",\n",
    "        \"skills\",\n",
    "        \"posted_at\",\n",
    "        \"is_remote\",\n",
    "        \"snippet_fragments\",\n",
    "        \"description\"\n",
    "    ],\n",
    "    keyword_fields=[\"id\"]\n",
    ")\n",
    "\n",
    "index.fit(job_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d682cca-47ad-478f-810e-9350eff73495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={},\n",
    "        boost_dict=boost,\n",
    "        num_results=3\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67160110-0372-4520-affb-245be75c351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You're an expert application coach. Answer the QUESTION based on the CONTEXT from the job database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "entry_template = \"\"\"\n",
    "job_title: {title}\n",
    "company_name: {company}\n",
    "work locations: {locations}\n",
    "highlighted skills: {skills}\n",
    "date of posting: {posted_at}\n",
    "short job summary: {snippet_fragments}\n",
    "detailed job description: {description}\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + entry_template.format(**doc) + \"\\n\\n\"\n",
    "\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fbfffc7-9c37-443c-a320-64b968faf5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt, model='jamba-1.5-mini'):\n",
    "    response = client.chat.completions.create(\n",
    "    model=model,  \n",
    "    messages=[ChatMessage(   \n",
    "        role=\"user\",\n",
    "        content=prompt\n",
    "    )],\n",
    "        temperature=0.8,\n",
    "        max_tokens=200\n",
    "    )    \n",
    "    return response.choices[0].message.content, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54f3934c-5924-479e-b60d-2864daf1ef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, model='jamba-1.5-mini'):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer, resp = llm(prompt, model=model)\n",
    "    return answer, resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75f97016-bafe-4ecc-99e7-2af75cf2cad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_prompt_template = \"\"\"\n",
    "You are an expert evaluator for a RAG system.\n",
    "Your task is to analyze the relevance of the generated response to the given queries.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Query: {query}\n",
    "Response: {response}\n",
    "\n",
    "Please analyze the content and context of the generated response in relation to the query\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a very brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97dd06da-2baa-471e-ba1c-194359e79eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rag(query):\n",
    "    response_llm = rag(query) \n",
    "\n",
    "    evaluation_prompt = evaluation_prompt_template.format(\n",
    "        query=query,\n",
    "        response=response_llm\n",
    "    )\n",
    "\n",
    "    evaluation_llm, a21_resp = llm(evaluation_prompt)\n",
    "    evaluation_llm = json.loads(evaluation_llm)\n",
    "\n",
    "    return query, response_llm, evaluation_llm, a21_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da6d7f72-5c48-436b-96c7-db2e6553ba1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('{\\n  \"Relevance\": \"RELEVANT\",\\n  \"Explanation\": \"The response provides detailed information about the qualifications and experience required for the Mechatroniker/Elektroniker position at Novapax Kunststofftechnik, directly addressing the query.\"\\n}', ChatCompletionResponse(id='chat-e04523b5151a4a91b166ce76ab932659', choices=[ChatCompletionResponseChoice(index=0, message=AssistantMessage(role='assistant', content='{\\n  \"Relevance\": \"RELEVANT\",\\n  \"Explanation\": \"The response provides detailed information about the qualifications and experience required for the Mechatroniker/Elektroniker position at Novapax Kunststofftechnik, directly addressing the query.\"\\n}', tool_calls=None), logprobs=None, finish_reason='stop')], usage=UsageInfo(prompt_tokens=593, completion_tokens=63, total_tokens=656)))\n"
     ]
    }
   ],
   "source": [
    "for record in eval_data[:1]:\n",
    "    query = record['question']\n",
    "    id_ = record['id']\n",
    "    response_llm = rag(query) \n",
    "    \n",
    "    evaluation_prompt = evaluation_prompt_template.format(\n",
    "        query=query,\n",
    "        response=response_llm\n",
    "    )\n",
    "    \n",
    "    evaluation_llm, a21_resp = llm(evaluation_prompt)\n",
    "    print(evaluation_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad842fb0-d18d-4fed-b289-b1cb3e56f907",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_queries = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9939fe71-deaa-435b-8e73-65b612895205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compare two different approaches\n",
    "# TODO: only take a sample\n",
    "\n",
    "a21_resps = []\n",
    "evaluations = []\n",
    "\n",
    "for record in eval_data[:1]:\n",
    "    query = record['question']\n",
    "    id_ = record['id']\n",
    "    identifier = f'{id_}_{query}'\n",
    "\n",
    "    if f'{id_}_{query}' not in processed_queries:\n",
    "        _, response_llm, evaluation_llm, a21_resp = evaluate_rag(query)\n",
    "    \n",
    "        temp_eval_dict = {'id': id_, 'query': query, 'response': response_llm, 'relevance': evaluation_llm[\"Relevance\"], 'explanation': evaluation_llm[\"Explanation\"]}\n",
    "        evaluations.append(temp_eval_dict)\n",
    "        a21_resps.append(a21_resp)\n",
    "        processed_queries.add(identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162aea3f-d5d3-400b-bbf7-3972bf964350",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "job-search-application",
   "language": "python",
   "name": "job-search-application"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
