[
  {
    "id": 1,
    "title": "Mechatroniker / Elektroniker (m/w/d) Automatisierungstechnik f\u00fcr Spritzgussfertigung",
    "company": "Novapax Kunststofftechnik",
    "locations": "Berlin",
    "skills": "Microsoft Office, Elektronik, Formenbau, Kunststofftechnik, Medizin, Massenspektrometrie",
    "posted_at": "2024-10-02",
    "is_remote": "False",
    "snippet_fragments": "Abgeschlossene Ausbildung als Mechatroniker (m/w/d), Industrieelektriker (m/w/d) oder Elektroniker(m/w/d) f\u00fcr Automatisierungs- und Systemtechnik bzw,         Idealerweise praktische Erfahrung in der Kunststoffspritzgussproduktion , Mehrj\u00e4hrige Berufserfahrung in der Installation, Wartung und Reparatur elektrischer Anlagen und mechatronischer Systeme,         Know-how in der Fehleranalyse und -behebung sowie Grundkenntnisse in der Programmierung von Steuerungssystemen ,         Routinierter Umgang mit MES- und ERP-Systemen sowie MS Office ,         Gute Deutsch- und Englischkenntnisse in Wort und Schrift ,         Bereitschaft zur Weiterbildung in den Bereichen Elektrotechnik, Teamf\u00e4higkeit, Zuverl\u00e4ssigkeit, Flexibilit\u00e4t und Anpassungsf\u00e4higkeit in einem dynamischen Arbeitsumfeld,         Hohe Lernbereitschaft und Engagement zur Verbesserung von Prozessen und Systemen ,         Freude an der Weitergabe von Wissen an Ihre Kollegen (m/w/d) und der \u00dcbernahme neuer Aufgaben und Projekte ,         Kostenfreie Mitarbeiterparkpl\u00e4tze sowie Zuschuss zum Deutschlandticket ",
    "description": "<div id=\"jobtempl\" itemscope itemtype=\"http://schema.org/JobPosting\"> \n   <div id=\"wrapper\"> \n     \n     <p class=\"logo\"><a href=\"https://anzeigenvorschau.net/bestmedia/img/1064226/2056378/cl/2178a78eac4bca4bac7ca98a88afd24d452e6954/L3933903/JeyJvbGRsaW5rIjoiaHR0cHM6Ly93d3cubm92YXBheC5kZSIsInpsIjoiam9idGVuc29yLmNvbSJ9\" target=\"_blank\"></a></p> \n      \n     \n     \n     <div class=\"inner verticalspace\"> \n      <div data-ker=\"wysiwyg\" data-ker-id=\"u_beschreibung\" itemprop=\"description\"> \n       <p><b>NOVAPAX</b> ist ein mittelst\u00e4ndisches Unter\u00adnehmen der Kunststoff verarbeitenden Industrie mit ca. 190 Mitarbeitenden\u00a0mit Sitz in Berlin. Schwer\u00adpunkt ist die Her\u00adstellung komplexer technischer Komponenten und Bau\u00adgruppen im Kunst\u00adstoff\u00adspritzguss f\u00fcr Kunden aus den Branchen Automobil, Elektronik, Bau, Medizin und Sanit\u00e4r. Basis f\u00fcr die Realisierung der pr\u00e4zisen Komponenten ist der eigene Formen\u00adbau mit 75 Jahren Erfahrung. Der Maschinen\u00adpark der Spritzerei umfasst \u00fcber 75 Einheiten von 35 bis 400 Tonnen Schlie\u00df\u00adkraft der Marken Arburg, Engel und Demag. Die Fertigungs\u00adkonzepte werden im Team von Projekt\u00admanagement, Konstruktion, Formenbau, Fertigung, Betriebs- und Verfahrens\u00adtechnik sowie Quali\u00adt\u00e4ts\u00adsicherung entwickelt.</p> \n      </div> \n      <div data-ker=\"wysiwyg\" data-ker-id=\"titel_einleitung\" itemprop=\"description\"> \n       <p>Werden Sie Teil unseres Teams am Standort\u00a0<b>Berlin</b> als</p> \n      </div> \n      <h2 itemprop=\"description\"> <strong data-ker-id=\"titel\" data-ker=\"input\" class=\"hgross\"><strong>Mechatroniker / Elektroniker (m/w/d)\u00a0</strong></strong> <strong data-ker-id=\"untertitel\" data-ker=\"input\"><br> <strong data-ker=\"input\" data-ker-id=\"titel\"><strong>Mechatroniker / Elektroniker (m/w/d)\u00a0</strong></strong></strong> </h2> \n       \n      <h4 data-ker=\"input\" data-ker-id=\"label_aufgaben\">Freuen Sie sich auf Ihre neuen Aufgaben:</h4> \n      <div data-ker=\"wysiwyg\" data-ker-id=\"aufgaben\" itemprop=\"responsibilities\"> \n       <ul> \n        <li>Mitwirkung bei der Konzeption, Anfrage und Beauftragung von Auto\u00admations\u00adprozessen in Verbindung mit Spritz\u00adguss\u00admaschinen f\u00fcr robuste Serien\u00adprozesse</li> \n        <li>Begleitung ausgew\u00e4hlter\u00a0L\u00f6sungsanbieter f\u00fcr Auto\u00admatisierungs\u00adtechnik w\u00e4hrend der Projek\u00adtierungs\u00adphasen bis hin zu einer effi\u00adzienten Serien\u00adfertigung</li> \n        <li>Organisation von Vorabnahmen, Installationen, Inbetrieb\u00adnahmen und Abnahmen neuer Automations\u00adanlagen f\u00fcr die Serien\u00adproduktion</li> \n        <li>Schulung der Mitarbeitenden zur Handhabung komplexer Anlagen und Maschinen</li> \n        <li>Optimierung der Prozesse in Fertigungs\u00adanlagen, einschlie\u00dflich Spritz\u00adguss\u00admaschinen und Peripherie\u00adanlagen</li> \n        <li>Sicherstellung der Anlagen\u00adverf\u00fcg\u00adbarkeit durch Behebung von St\u00f6rungen und Fehlfunktionen</li> \n        <li>Installation, Montage, Reparatur und Instand\u00adhaltung mecha\u00adtronischer Systeme</li> \n        <li>Parametrier- und Programmier\u00adarbeiten an Anlagen und Maschinen</li> \n        <li>Dokumentation durchgef\u00fchrter Arbeiten, Erstellung von Wartungs\u00adprotokollen sowie Aktualisierung technischer Unterlagen und Pl\u00e4ne\u00a0im MES- bzw. ERP-System</li> \n       </ul> \n      </div> \n      <h4 data-ker=\"input\" data-ker-id=\"label_profil\">\u00dcberzeugen Sie uns mit Ihrem Profil:</h4> \n      <div data-ker=\"wysiwyg\" data-ker-id=\"profil\" itemprop=\"qualifications\"> \n       <ul> \n        <li>Abgeschlossene Ausbildung als Mechatroniker (m/w/d), Industrie\u00adelektriker (m/w/d) oder Elektroniker\u00a0(m/w/d) f\u00fcr Automatisierungs- und System\u00adtechnik bzw. eine vergleichbare Quali\u00adfikation</li> \n        <li>Idealerweise praktische Erfahrung in der Kunst\u00adstoff\u00adspritz\u00adguss\u00adproduktion</li> \n        <li>Mehrj\u00e4hrige Berufserfahrung in der Installation, Wartung und Reparatur elektrischer Anlagen und mecha\u00adtronischer Systeme</li> \n        <li>Know-how in der Fehleranalyse und -behebung sowie Grundkenntnisse in der Programmierung von Steuerungs\u00adsystemen</li> \n        <li>Routinierter Umgang mit MES- und ERP-Systemen sowie MS Office</li> \n        <li>Gute Deutsch- und Englischkenntnisse in Wort und Schrift</li> \n        <li>Bereitschaft zur Weiterbildung in den Bereichen Elektro\u00adtechnik, Mechanik und Automation</li> \n        <li>Teamf\u00e4higkeit, Zuverl\u00e4ssig\u00adkeit, Flexibilit\u00e4t und Anpassungs\u00adf\u00e4hig\u00adkeit in einem dynamischen Arbeits\u00adumfeld</li> \n        <li>Hohe Lernbereitschaft und Engagement zur Verbesserung von Prozessen und Systemen</li> \n        <li>Freude an der Weitergabe von Wissen an Ihre Kollegen (m/w/d) und der \u00dcber\u00adnahme neuer Aufgaben und Projekte</li> \n        <li>Bereitschaft zur Arbeit im Mehr\u00adschicht\u00adsystem</li> \n       </ul> \n      </div> \n      <h4 data-ker=\"input\" data-ker-id=\"label_wir_bieten\">Unser Angebot f\u00fcr Sie:</h4> \n      <div data-ker=\"wysiwyg\" data-ker-id=\"wir_bieten\" itemprop=\"jobBenefits\"> \n       <ul> \n        <li>Ein erfolgreiches Familienunternehmen mit Wachstumspotenzial</li> \n        <li>Interessante Aufgaben in einem\u00a0innovativen\u00a0Umfeld</li> \n        <li>Ein umfassendes Einarbeitungsprogramm</li> \n        <li>Eine leistungsgerechte, attraktive Verg\u00fctung</li> \n        <li>30 Tage Urlaub</li> \n        <li>Fort- und Weiterbildungsangebote</li> \n        <li>Kostenfreie Mitarbeiterparkpl\u00e4tze sowie Zuschuss zum Deutschlandticket</li> \n        <li>Arbeitgeberunterst\u00fctzte Altersvorsorge und verm\u00f6genswirksame Leistungen</li> \n       </ul> \n      </div> \n      <h4 data-ker=\"input\" data-ker-id=\"label_firmenkontakt\">Bereit f\u00fcr neue Wege?</h4> \n      <div data-ker=\"wysiwyg\" data-ker-id=\"firmenkontakt\" itemprop=\"contact\"> \n       <p>Dann freuen wir uns auf Ihre aussagekr\u00e4ftige Bewerbung unter Angabe Ihrer Gehaltsvorstellung und des fr\u00fchestm\u00f6glichen Eintrittstermins per E-Mail an\u00a0<a href=\"mailto:jobs@novapax.de?subject=Bewerbung%20als%20Mechatroniker%20%2F%20Elektroniker%20%28m%2Fw%2Fd%29%20Automatisierungstechnik%20f%C3%BCr%20Spritzgussfertigung\">jobs@novapax.de</a>.</p> \n       <p>Diese Position betreut unsere Kollegin Frau Bu\u00dfmann. Gerne beantwortet sie Ihre Fragen vorab telefonisch unter\u00a0<span class=\"no-wrap\">030 70191443</span>.</p> \n      </div> \n     </div> \n     \n     \n     <div data-ker=\"wysiwyg\" data-ker-id=\"adresse\" itemprop=\"contact\"> \n      <p><b>NOVAPAX Kunststofftechnik </b><strong>Steiner GmbH & Co. KG</strong><br> Sch\u00e4tzelbergstra\u00dfe 4\u201310, 12099 Berlin | <a href=\"https://anzeigenvorschau.net/bestmedia/img/1064226/2056378/cl/d96443e9b63fd35bc59558ceda6522d6f4113989/L3933905/JeyJvbGRsaW5rIjoiaHR0cHM6Ly93d3cubm92YXBheC5kZSIsInpsIjoiam9idGVuc29yLmNvbSJ9\" target=\"_blank\">www.novapax.de</a></p> \n     </div> \n     \n   </div> \n    \n  </div>"
  },
  {
    "id": 2,
    "title": "CRM Lead (m/w/d)",
    "company": "FORMEL SKIN",
    "locations": "Berlin",
    "skills": "Data Science, Mailchimp, SendGrid, CRM, Dermatologie",
    "posted_at": "2024-09-30",
    "is_remote": "False",
    "snippet_fragments": "Sendgrid, Mailchimp); Kenntnisse in Data Science und Datenbanken sind ein Plus.,  Bei FORMEL SKIN hast du die M\u00f6glichkeit, direkt Einfluss darauf zu nehmen, wie wir mit unseren Kunden interagieren und sie unterst\u00fctzen, Durch die Leitung innovativer CRM-Strategien spielst du eine entscheidende Rolle bei der F\u00f6rderung des Kundenengagements und der Kundentreue,  Vorteile, die perfekt zu dir passen, Um dies zu unterst\u00fctzen, bieten wir ein vielf\u00e4ltiges Leistungspaket an, darunter 28 Tage Urlaub, eine Mitgliedschaft bei NAVIT oder dem Urban Sports Club, Mitarbeiterrabatte auf unsere Produkte, ein Budget f\u00fcr berufliche Weiterentwicklung, flexible Arbeitszeiten und ein Remote Work M\u00f6glichkeit.",
    "description": "<p><strong>WER SIND WIR?</strong></p><br><p>Bei FORMEL SKIN sind wir Vorreiter bei der Revolutionierung der Dermatologie und der Neugestaltung des Gesundheitswesens. Unsere Mission besteht darin, eine weltweit f\u00fchrende Online-Dermatologieklinik zu schaffen, die hochwirksame dermatologische Behandlungen f\u00fcr jeden einfach zug\u00e4nglich macht. Wir haben bedeutende Fortschritte erzielt und die Unterst\u00fctzung einiger der prominentesten Gesundheits- und Consumer-Tech Investoren Europas erhalten. Im Dezember 2021 haben wir einen bedeutenden Erfolg erzielt, indem wir in der gr\u00f6\u00dften Serie-A-Finanzierungsrunde f\u00fcr Gesundheitstechnologie in Deutschland insgesamt 30 Millionen Euro gesammelt haben.</p><br><p>Bis heute haben wir fast eine Million Behandlungen f\u00fcr unsere Patienten erfolgreich durchgef\u00fchrt. Unser dynamisches Team ist leidenschaftlich, ehrgeizig und bringt eine F\u00fclle von Erfahrungen aus erfolgreichen Gesundheits- und Verbraucher-Tech-Unternehmen mit. Mit Sitz in Berlin, einer Stadt bekannt f\u00fcr ihre Lebendigkeit, sind wir entschlossen, unsere Reichweite und unseren Einfluss zu erweitern und bieten Ihnen die M\u00f6glichkeit, Teil unserer spannenden Reise zu sein.</p><br><p>Als <strong>CRM Lead (m/w/d)</strong> bei FORMEL SKIN spielst du eine zentrale Rolle bei der Skalierung unserer Customer Relationship Management (CRM) Initiativen. Du treibst das Engagement und Wachstum voran, indem du innovative Multi-Channel-CRM-Programme entwickelst, die auf die Bed\u00fcrfnisse der Kunden und die verschiedenen Phasen des Kundenlebenszyklus abgestimmt sind.</p><br><p><strong>WAS SIND DEINE AUFGABEN?</strong></p><ul><li><br><strong>Leitung der CRM-Strategieentwicklung</strong>: Du leitest die Ideenfindung und Entwicklung von Multi-Channel-CRM-Programmen, die auf unsere Wachstumsstrategien und Schl\u00fcsselinvestitionen abgestimmt sind.</li><li><br><strong>Management des Kundenlebenszyklus</strong>: Du planst und f\u00fchrst strategische Kommunikations- und Lebenszyklusprogramme durch und stellst sicher, dass qualitativ hochwertige Ergebnisse rechtzeitig geliefert werden.</li><li><br><strong>Kundensegmentierung</strong>: Du erstellst Personas und definierst Kundensegmente, um Kunden zur richtigen Zeit mit der richtigen Nachricht \u00fcber die verschiedenen Phasen des Kundenlebenszyklus anzusprechen.</li><li><br><strong>Innovation im CRM</strong>: Du entwickelst kontinuierlich personalisierte CRM-Programme weiter und richtest Kampagnen und Journeys ein, um den Customer Lifetime Value zu erh\u00f6hen.</li><li><br><strong>Kampagnenoptimierung</strong>: Du strukturierst A/B- und Multivariate-Tests, um CRM-Kampagnen zu optimieren und deren Leistung kontinuierlich zu verbessern.</li><li><br><strong>Berichterstattung und Analyse</strong>: Du erstellst regelm\u00e4\u00dfige Berichte zur Kampagnenleistung und f\u00fchrst Post-Mortem-Analysen durch, um die CRM-Unterst\u00fctzung zu verbessern und zuk\u00fcnftige Strategien zu informieren.</li><li><br><strong>Teamf\u00fchrung</strong>: Du leitest und unterst\u00fctzt dein Team und stellst sicher, dass es sich selbstst\u00e4ndig weiterentwickelt und Ziele erreicht.</li></ul><p><strong>WAS SOLLTEST DU MITBRINGEN?</strong></p><ul><li><br><strong>Erfahrung im CRM</strong>: Du hast mindestens 5 Jahre Erfahrung im Lifecycle-Marketing und hast erfolgreich CRM-Prozesse und -Tools implementiert und optimiert.</li><li><br><strong>Abonnementgesch\u00e4ft</strong>: Erfahrung in einem abonnementbasierten Unternehmen ist ein starkes Plus.</li><li><br><strong>Ganzheitlicher Ansatz</strong>: Du hast bewiesen, dass du komplexe CRM-Kampagnen mit einer Ownership-Mentalit\u00e4t aufsetzen, managen und optimieren kannst.</li><li><br><strong>Kundenfokus</strong>: Du hast eine starke Empathie und kennst die verschiedenen Phasen des Kundenlebenszyklus.</li><li><br><strong>Wachstumsmentalit\u00e4t</strong>: Eine Leidenschaft f\u00fcr Growth Marketing und eine proaktive, l\u00f6sungsorientierte Einstellung zeichnen dich aus.</li><li><br><strong>Technisches Know-how</strong>: Du bist vertraut mit E-Mail-Marketing-Tools (z. B. Sendgrid, Mailchimp); Kenntnisse in Data Science und Datenbanken sind ein Plus.</li><li><br><strong>Kommunikationsst\u00e4rke</strong>: Du verf\u00fcgst \u00fcber ausgezeichnete zwischenmenschliche und strategische Kommunikationsf\u00e4higkeiten.</li><li><br><strong>Sprachkenntnisse</strong>: Flie\u00dfende Englischkenntnisse sind erforderlich, flie\u00dfende Deutschkenntnisse sind ein Plus.</li></ul><p><strong>WARUM WIR?</strong></p><ul><li><br><strong>Eine gro\u00dfartige Gelegenheit, die Zukunft des CRM mitzugestalten:</strong> Bei FORMEL SKIN hast du die M\u00f6glichkeit, direkt Einfluss darauf zu nehmen, wie wir mit unseren Kunden interagieren und sie unterst\u00fctzen. Durch die Leitung innovativer CRM-Strategien spielst du eine entscheidende Rolle bei der F\u00f6rderung des Kundenengagements und der Kundentreue, w\u00e4hrend du mit einem leidenschaftlichen Team die Dermatologiebranche revolutionierst.</li><li><br><strong>Vorteile, die perfekt zu dir passen</strong>: Jeder Kandidat ist einzigartig, und wir engagieren uns daf\u00fcr, deine spezifischen Bed\u00fcrfnisse und W\u00fcnsche zu unterst\u00fctzen. Um dies zu unterst\u00fctzen, bieten wir ein vielf\u00e4ltiges Leistungspaket an, darunter 28 Tage Urlaub, eine Mitgliedschaft bei NAVIT oder dem Urban Sports Club, Mitarbeiterrabatte auf unsere Produkte, ein Budget f\u00fcr berufliche Weiterentwicklung, flexible Arbeitszeiten und ein Remote Work M\u00f6glichkeit.</li><li><br><strong>Gemeinsam ein gro\u00dfartiges Team aufbauen</strong>: Wir glauben, dass der Aufbau eines gro\u00dfartigen Teams und die F\u00f6rderung starker zwischenmenschlicher Beziehungen f\u00fcr unseren Erfolg grundlegend sind. Deshalb bieten wir folgendes an: regelm\u00e4\u00dfige Firmenveranstaltungen, ein Budget f\u00fcr Teamevents und Pr\u00e4mien f\u00fcr Mitarbeiterempfehlungen.</li></ul><p><strong>\u00dcBER UNS</strong></p><br><p>Mit FORMEL SKIN bauen wir Deutschlands f\u00fchrende dermatologische Plattform auf, um Patienten mit allen Hautproblemen einen sofortigen Zugang zu personalisierten medizinischen Behandlungen zu erm\u00f6glichen. Unser Team aus erfahrenen \u00c4rzt:innen, Apotheker:innen und Innovator:innen arbeitet hart daran, Patient:innen auf ihrer Hautgesundheitsjourney zu behandeln, zu beraten und zu unterst\u00fctzen. Als Marke im Gesundheitswesen konzentrieren wir uns auf eine klare und schnelle Kommunikation mit unseren Patient:innen, auf Vertrauen, das durch unsere medizinische Expertise und unsere umfassende Erfahrung untermauert wird, und auf unser Engagement f\u00fcr alles, was wir tun. Unser Ziel ist es, dermatologische Versorgung f\u00fcr alle zug\u00e4nglich zu machen - unabh\u00e4ngig davon, wie gro\u00df oder klein das Hautproblem sein mag.</p><br><p>Genau wie wir einen inklusiven Dermatologie-Service aufbauen wollen, m\u00f6chten wir auch einen inklusiven Arbeitsplatz mit au\u00dfergew\u00f6hnlichen Menschen schaffen, die sich einer gemeinsamen Mission verschrieben haben. FORMEL SKIN ist ein Arbeitgeber, der Chancengleichheit f\u00f6rdert. Daher begr\u00fc\u00dfen wir alle Bewerbungen: Menschen jeder Rasse, Ethnizit\u00e4t, Nationalit\u00e4t und Religion, LGBTQAI+-Menschen, Menschen mit Behinderungen (sichtbar und unsichtbar), Menschen jeden Alters oder Familienstands.</p><br>"
  },
  {
    "id": 3,
    "title": "Principal Product Manager - First, Middle and Last Mile (all genders)",
    "company": "Zalando",
    "locations": "Berlin",
    "skills": "",
    "posted_at": "2024-09-17",
    "is_remote": "False",
    "snippet_fragments": "  As a Principal Product Manager in the Transport team, You will join a team that owns the transportation platform for Zalando working with 30 carriers across 23 Zalando markets, You would own the problem statement of how we use different network configurations to increase the speed of delivery to customers through approaches such as Direct Injection, At Zalando, our vision is to be inclusive by design, And this vision starts with our hiring - we do not discriminate on the basis of gender identity, You are welcome to leave out your picture, We only assess candidates on their qualifications and merit,   We want to provide you with a great candidate experience, Feel free to inform us of any accommodations you may need,    WHAT WE'D LOVE YOU TO DO (AND LOVE DOING), You will collaborate with product, engineering and commercial teams across the organization (Fulfillment Core, Logistics Algorithms, Warehouse Management and Automation to name a few) to develop new sorting and injection solutions.,    You will own the long term multi year roadmap for Carrier Network Configurations,    You will spend a significant amount of time initially in the problem space, This will be followed by a technical solution proposal and implementation of desired feature and capability sets,    You will become a trusted partner and subject matter expert by diving deep into Zalandos complex technology & solution space,    WE'D LOVE TO MEET YOU IF",
    "description": "<p>Location</p><br><p>Berlin</p><br><p>Contract</p><br><p>Full time</p><br><p>Job Category</p><br><p>Product Management</p><br><p><strong>THE ROLE &amp; THE TEAM</strong></p><br><p>As a <strong>Principal Product Manager</strong> in the Transport team, you will have end-to-end ownership of discovering, defining, launching, and improving world-class transport network and configuration experiences for Zalando's 40MM+ customers. You will join a team that owns the transportation platform for Zalando working with 30+ carriers across 23 Zalando markets.</p><br><p>This role is specifically focused on expanding network capabilities for Zalando transportation. You would own the problem statement of how we use different network configurations to increase the speed of delivery to customers through approaches such as Direct Injection, sorting and selection techniques among others.</p><br><p><strong>INCLUSIVE BY DESIGN</strong></p><br><p>At Zalando, our vision is to be inclusive by design. And this vision starts with our hiring - we do not discriminate on the basis of gender identity, sexual orientation, personal expression, ethnicity, religious belief, or disability status. You are welcome to leave out your picture, age, or marital status from your application. We only assess candidates on their qualifications and merit.</p><br><p>We want to provide you with a great candidate experience. Feel free to inform us of any accommodations you may need, so we can best support you throughout the hiring process.</p><br><p>do.BETTER - our diversity &amp; inclusion strategy: https://corporate.zalando.com/en/our-impact/dobetter-our-diversity-and-inclusion-strategy</p><br><p>Our employee resource groups: https://corporate.zalando.com/en/our-impact/our-employee-resource-groups</p><br><p><strong>WHAT WE'D LOVE YOU TO DO (AND LOVE DOING)</strong></p><ul><li>You will collaborate with product, engineering and commercial teams across the organization (Fulfillment Core, Logistics Algorithms, Warehouse Management and Automation to name a few) to develop new sorting and injection solutions.</li><li>You will own the long term multi year roadmap for Carrier Network Configurations, creating iterative solutions over time to increase delivery speed, reduce network capacity risk, and delivery flexibility.</li><li>You will spend a significant amount of time initially in the problem space, in the operations as well as technical domain, teasing out and creating a common understanding of current process and technical constraints inhibiting us to achieve our business objectives in this domain. This will be followed by a technical solution proposal and implementation of desired feature and capability sets.</li><li>You will become a trusted partner and subject matter expert by diving deep into Zalando's complex technology &amp; solution space, to discover, define, and deliver remarkable solutions.</li></ul><p><strong>WE'D LOVE TO ME</strong>ET YOU IF...</p><ul><li>You are an experienced, data-driven, and highly collaborative Product Management leader with a strong customer focus.</li><li>You have a track record of end-to-end ownership and experience shipping products that scale (millions of users).</li><li>You have experience with fulfillment, logistics, last mile, delivery, and/or returns products and a solid understanding of their possibilities and limitations.</li><li>You have experience in defining and delivering on a product vision and strategy, and the patience to work with competing priorities to deliver customer value. You can maximize the medium-to-long-term impact of your work with your partner teams.</li><li>You showcase excellent verbal and written communication skills and ability to work across multiple teams, align goals and deliverables, and drive overall success independently of organizational boundaries.</li><li>Ability to break down complex problems by</li></ul><br>"
  },
  {
    "id": 4,
    "title": "Process Integration Lead",
    "company": "ardo",
    "locations": "Berlin",
    "skills": "Enterprise Architect, SAP, SAP S/4HANA, FICO, BPM, Wirtschaftsingenieurwesen",
    "posted_at": "2024-09-17",
    "is_remote": "False",
    "snippet_fragments": "As part of the deployment activities, You will help to resolve system and process design issues, You will safeguard the Template via the Change Approval Board, You will ensure that the necessary scenarios for testing cycles become available and are validated, You manage the process flow mapping and guarantee up-to-date documentation of process flows and scenarios within the foreseen BPM tool, You will be an evangelist of standard SAP best practice processes and a defender of the Ardo SAP Golden Template, As Process Integration Lead, you are expected to be an experienced integration and change agent who builds a new ERP environment while converting legacy systems to SAP to achieve substantial synergy savings, You will secure alignment with the Master Data team regarding setup, You will contribute from an SAP Process Integration perspective to defining the IT digital roadmap for the future for the different products in the SAP ecosystem and the various applications in the group linked to SAP, Your profile Bachelors or masters degree in a relevant discipline such as computer science, Minimum 10 years of experience as SAP Functional Stream Lead, Strong collaborative Information Technology leader with a proven record of implementing multiple end-to-end projects in diverse and challenging environments on an SAP platform, Strong analytical, planning, problem-solving, and project management skills coupled with the ability to understand the processes and quality related to a system, Functional expertise in all aspects of the system development life cycle involving business process analysis, Comfortable in interacting with people across hierarchical levels, Cross-Functional knowledge of SAP ERP in the modules MM, Experience in S/4HANA is a plus",
    "description": "<p>BE - Ardo Headquarters</p><br><p>IT</p><br><p>Permanent contract</p><br><p>Ardo supplies its continuously growing markets around the world with high quality frozen vegetables, herbs, and fruit with 4000 employees and 17 production sites in 8 countries. The family business sells in more than 100 countries and has a turnover of more than 1.4 billion euros. Ardo's mission is to preserve the gift of nature as pure as possible. Ardo achieves this goal thanks to an integrated network of growing areas, production units, freezing units, packaging equipment, appropriate logistics and thorough quality control. The group's know-how and flexible structure ensure that it can respond quickly to new trends and that innovative products can be brought onto the market quickly. More info on www.ardo.com.</p><br><p>Your Scope</p><br><p>As Process Integration Lead, you will be crucial in implementing SAP in the Ardo Group. You will be responsible for safeguarding and further enriching the Ardo SAP Golden Template. Based on your large cross-functional SAP knowledge, you will guide the Ardo SAP teams (partner and internal teams), both for Template and Deploy, to make the right process integration decisions about priorities, impact, effort, functional and technical design, and cost.</p><br><p>You will work closely with multiple stakeholders, including the SAP Program Manager and Project Sponsors, to analyze, discuss, and coordinate system design changes. As Process Integration Lead, you will report to the Group IT Director.</p><br><p><strong>Your key responsibilities are:</strong></p><br><p>You will take the lead in multiple SAP design activities, as part of the further deployment of the SAP system in de different Ardo sites, migrating the business processes from the existing local legacy ERP systems towards one integrated SAP S/4HANA environment. As part of the deployment activities, you will also validate the Show &amp; Tell content.</p><br><p>You will help to resolve system and process design issues, together with the Business Process Owners, internal and external Business Analysts, developers, and IT Enterprise Architect.</p><br><p>You will safeguard the Template via the Change Approval Board, which you organize, and discuss upfront all change requests, coming from fit gaps of further SAP Deploys, Continuous Improvement requests, and Support Tickets, with the Business Process Owners in preparation for the CAB.</p><br><p>You will ensure that the necessary scenarios for testing cycles become available and are validated. You manage the process flow mapping and guarantee up-to-date documentation of process flows and scenarios within the foreseen BPM tool.</p><br><p>You will be an evangelist of standard SAP best practice processes and a defender of the Ardo SAP Golden Template, both for our Sales entities track and our Plant Operations track, to limit the number of change requests to the must-have minimum, allowing Ardo to become more cost-efficient, reduce complexity and be compliant with local legislation.</p><br><p>As Process Integration Lead, you are expected to be an experienced integration and change agent who builds a new ERP environment while converting legacy systems to SAP to achieve substantial synergy savings.</p><br><p>You will secure alignment with the Master Data team regarding setup, defect solving, and continuous improvement.</p><br><p>You will contribute from an SAP Process Integration perspective to defining the IT digital roadmap for the future for the different products in the SAP ecosystem and the various applications in the group linked to SAP.</p><br><p>Your profile</p><br><p>Bachelor's or master's degree in a relevant discipline such as computer science, commercial engineering, civil/industrial engineering, or an equivalent.</p><br><p>Minimum 10 years of experience as SAP Functional Stream Lead, Process Integration Lead, or similar.</p><br><p>Strong collaborative Information Technology leader with a proven record of implementing multiple end-to-end projects in diverse and challenging environments on an SAP platform.</p><br><p>Strong analytical, planning, problem-solving, and project management skills coupled with the ability to understand the processes and quality related to a system.</p><br><p>Functional expertise in all aspects of the system development life cycle involving business process analysis, business requirements analysis, process re-engineering, project scoping, budgeting, risk analysis, and quality management.</p><br><p>Experience working with cross-cultural teams. Comfortable in interacting with people across hierarchical levels.</p><br><p>Cross-Functional knowledge of SAP ERP in the modules MM, PP, SD, FICO, and QM. Experience in S/4HANA is a plus.</p><br><p>Strong communication skills and the ability to clearly convey technical information to non-technical stakeholders.</p><br><p>Strong team player with good collaboration skills.</p><br><p><strong>Language skills:</strong> English is a must; Dutch and French are an asset.</p><br><p>We offer</p><br><p>We offer you the opportunity to be part of an authentic and sustainable international company, with real growth opportunities and the freedom to actively participate in shaping the business and the opportunity to develop professionally. You will receive a full remuneration package in line with the level of this position. We care for our people and create family-friendly surroundings by offering you the flexibility to work 2 days/week from home.</p><br><p>Interested? Contact our recruitment partner for this role, KABAS, via email katrijn.degrieck@kabasrecruit.be.</p><br>"
  },
  {
    "id": 5,
    "title": "Lead Analytics Engineer, Marketing",
    "company": "Vinted",
    "locations": "Berlin",
    "skills": "Data Analysis, Python, SQL, Continuous Integration, Java, CD, Data Science, BigQuery, Data Modeling, Git, ETL",
    "posted_at": "2024-08-30",
    "is_remote": "True",
    "snippet_fragments": "  Experience in roles like Analytics Engineer, Proficient in SQL, Git, and at least one programming language (e.g., Python, Java)., Expert in data modelling, access, and storage techniques.,   Proven experience in marketing data analytics and reporting across various digital and offline marketing channels, Familiar with testing, build, deployment, and CI/CD practices., Strong communication skills, attention to detail, and cross-functional collaboration.,   The opportunity to benefit from our share options programme,   30 days of paid annual leave,   Mental and emotional health support through the Mindletic app,   A personal monthly budget for shopping on Vinted,   A subsidised gym membership with ClassPass or Urban Sports Card,   A subsidised pension plan provided by Vinted,   The opportunity to spend up to 90 days per year - 21 of which can be spent working outside of the EU - on workation",
    "description": "<p>BRIEF INFO ABOUT VINTED</p><br><p>Vinted Marketplace is the largest online international C2C marketplace in Europe dedicated to second-hand fashion, with millions of registered members spanning 22 markets in Europe and North America. With a mission to make second-hand the first choice worldwide, Vinted enables people to sell and buy second-hand clothes and lifestyle items from each other, helping give those items a second or even third life.</p><br><p>Vinted Go launched in 2022, with a focus on developing products and solutions for more seamless shipping and delivery across Europe. Vinted Go has connected more than 40 carriers and more than 200,000 PUDO points across Europe to support the delivery of millions of parcels per year.</p><br><p>The Vinted Group, composed of Vinted Marketplace and Vinted Go, is headquartered in Vilnius, with workplaces in Germany, Lithuania, France, the United Kingdom, the Netherlands and over 2,000 employees. It is backed by six leading venture capital firms: Accel, Burda Principal Investments, EQT Growth, Insight Partners, Lightspeed Venture Partners, and Sprints Capital.</p><br><p>INFORMATION ABOUT THE POSITION</p><br><p>Vinted's Marketing Analytics Engineering team is taking a leap! We're excited to announce the creation of a new role: Lead Analytics Engineer, Marketing. This role is pivotal for ensuring the quality, reliability, and efficiency of our Marketing and Shipping Pricing data models. As a part of this dynamic, talented and committed team, you'll advocate for and implement best analytics engineering practices, manage broad and cross-domain technical projects, coordinate with external tech teams, and continuously strive to raise the bar for data practices in the Marketing Data Science &amp; Analytics domain. Join us on our mission to make Vinted Marketing data obvious and help second hand to become first choice worldwide faster.</p><br><p>IN THIS POSITION, YOU'LL</p><ul><li>Drive Domain Objectives: Lead technical projects in Marketing DSA, focusing on future outcomes and strategic initiatives.</li><li>Lead and Innovate: Suggest and implement technical changes to enhance Marketing data modelling.</li><li>Ensure Collaboration: Align the Marketing domain's technical vision through effective cross-team partnerships.</li><li>Raise the Bar: Develop and refine Marketing data models, enforcing best practices for quality and efficiency.</li><li>Unlock Impact: Guide the creation of data models for personalised Member Engagement Marketing campaigns.</li><li>Coordinate Across Teams: Manage technical collaborations with external partners for smooth project execution.</li><li>Continuously Improve: Stay updated on best practices in Dataverse and Analytics Engineering, sharing insights with the team.</li></ul><p>ABOUT YOU</p><ul><li>Experience in roles like Analytics Engineer, ETL Developer, or Data Engineer.</li><li>Proficient in SQL, Git, and at least one programming language (e.g., Python, Java).</li><li>Expert in data modelling, access, and storage techniques.</li><li>Proven experience in marketing data analytics and reporting across various digital and offline marketing channels.</li><li>Familiar with testing, build, deployment, and CI/CD practices.</li><li>Strong communication skills, attention to detail, and cross-functional collaboration.</li><li>Excellent written and spoken English.</li><li>Bonus: Experience with DBT and Google Cloud Platform (e.g. BigQuery).</li></ul><p>WORK PERKS</p><ul><li>The opportunity to benefit from our share options programme</li><li>30 days of paid annual leave</li><li>Newest MacBook models</li><li>Mental and emotional health support through the Mindletic app</li><li>Home office support: we provide IT workstation equipment and a personal budget of up to \u20ac540 for home workplace furniture</li><li>A daily lunch allowance</li><li>Frequent team-building events</li><li>A personal monthly budget for shopping on Vinted</li><li>A subsidised gym membership with ClassPass or Urban Sports Card</li><li>A subsidised pension plan provided by Vinted</li><li>Hallesche Supplemental health insurance</li><li>Life and disability insurance provided</li><li>A subsidised Deutschlandticket</li><li>The opportunity to spend up to 90 days per year - 21 of which can be spent working outside of the EU - on workation</li><li>A dog-friendly office</li></ul><p>WORKING AT VINTED</p><br><p><strong>Individual Learning Budget</strong></p><br><p>Vinted will set aside a yearly sum equal to 10-13.2% of your annual salary to be invested in your continuous professional development. You'll be able to take the initiative to use it for covering relevant learning activities that benefit your role.</p><br><p><strong>Hybrid Work</strong></p><br><p>We've adopted a hybrid workplace model where 2 days in the office are recommended but not enforced. It's up to you and your team to decide on the exact days you'll spend working together in person.</p><br><p><strong>Equal Opportunity</strong></p><br><p>The Vinted Group is committed to building an inclusive workplace where people from all walks of life feel a sense of belonging. We welcome applications from people of all backgrounds, identities and life experiences. At Vinted, all applicants are treated fairly without regard to their race, age, religion or belief, sex, national origin, citizenship, gender identity, sexual orientation, disability, or any other protected characteristic.</p><br><p>The salary range for this position is <strong>\u20ac</strong>83,600 - \u20ac113,200 gross per year.</p><br>"
  },
  {
    "id": 6,
    "title": "Lead Data Scientist - Machine Learning",
    "company": "Almedia",
    "locations": "Berlin",
    "skills": "Cloud, Python, SQL, Machine Learning, A/B testing",
    "posted_at": "2024-08-28",
    "is_remote": "False",
    "snippet_fragments": "  Deeply understand the data and customer and business problems, Collaborate effectively with cross-functional teams, including product managers, engineers, business developers, and user acquisition channel managers., Extensive work experience, with industry experience in developing machine-learning models, and ideally leading projects and small teams., Expertise in building, deploying, measuring, and maintaining machine learning models to address real-world problems., Strong statistical knowledge (A/B tests, probability, regression)., A combination of Python, SQL, and cloud experience is essential., Excellent communication skills, with the ability to present complex findings in a clear and concise manner, Preference for candidates with backgrounds in ad tech,   An opportunity to work in an innovative,   A fast-paced and inclusive work environment in a team of highly motivated professionals",
    "description": "<p>Almedia helps leading brands in the digital space to acquire new customers. Users can find and test the latest games, apps, and products for rewards via our platforms.</p><br><p>With more than 25 million users since our launch in 2020, Almedia's Freecash.com is one of the fastest-growing providers and a leader in our industry. Our mission is to provide a win-win experience for both users and advertisers.</p><br><p>We are looking for a Lead Data Scientist to join our rapidly growing team in Berlin</p><br><p><strong>You Will</strong></p><ul><li>Identify high-value ML business opportunities and work with both business and technical stakeholders to realize business benefit.</li><li>Deliver and deploy end-to-end machine-learning models, build measurement plans, learn and iterate to drive results.</li><li>Apply a solid statistical mindset and best practices, in the process of model development, deployment, and evolution.</li><li>Deeply understand the data and customer and business problems, in order to more closely align machine-learning model objectives and develop the best features and models to predict them.</li><li>Collaborate effectively with cross-functional teams, including product managers, engineers, business developers, and user acquisition channel managers.</li></ul><p><strong>You Have:</strong></p><ul><li>Extensive work experience, with industry experience in developing machine-learning models, and ideally leading projects and small teams.</li><li>Expertise in building, deploying, measuring, and maintaining machine learning models to address real-world problems.</li><li>Strong statistical knowledge (A/B tests, probability, regression).</li><li>A combination of Python, SQL, and cloud experience is essential.</li><li>Excellent communication skills, with the ability to present complex findings in a clear and concise manner. Preference for candidates with backgrounds in ad tech, gaming, or marketing.</li></ul><p><strong>Benefits:</strong></p><ul><li>An opportunity to work in an innovative, high-growth startup that has been profitable from day one.</li><li>A fast-paced and inclusive work environment in a team of highly motivated professionals.</li><li>Continuous learning and development opportunities.</li><li>Flexible work arrangements and a modern office space in the heart of Berlin.</li><li>Work from abroad policy</li></ul><p>Almedia is an equal opportunity employer, we embrace and celebrate diversity and encourage individuals from all backgrounds to apply.</p><br>"
  },
  {
    "id": 7,
    "title": "Lead Workforce Management",
    "company": "SumUp",
    "locations": "Berlin",
    "skills": "Statistik, Mathematik",
    "posted_at": "2024-08-13",
    "is_remote": "False",
    "snippet_fragments": "If you are a proactive, data-driven leader who is passionate about workforce management and customer service, we encourage you to apply for this exciting opportunity,    Opportunity to work with SumUppers globally on large-scale fintech products used by millions of businesses worldwide,    A dedicated annual L&D budget of 2,000 for attending conferences and/or advancing your career through further education  ,    A corporate pension scheme where we match up to 20% of your contributions  ,     \ufe0f Numerous other benefits such as Urban Sports Club subsidy",
    "description": "<p><strong>Lead Workforce Management</strong></p><br><p>Summary: SumUp is looking for a Head of Workforce Management to join our team and lead the development and implementation of workforce management strategies across our customer service organization. The ideal candidate will have experience in managing workforce management teams (internal and outsourced across multiple geographies), be data-driven, and possess excellent communication skills.</p><br><p>Responsibilities:</p><ul><li>Develop and implement workforce management strategies that drive operational efficiencies, increase productivity, and improve customer experience</li><li>Manage and mentor a team of workforce management analysts responsible for forecasting staffing needs, scheduling, and real-time monitoring of service levels</li><li>Analyze data and trends to identify opportunities to optimize staffing levels, improve service levels, and reduce costs</li><li>Work cross-functionally with other teams to ensure alignment of workforce management strategies with business goals</li><li>Develop and maintain key performance indicators (KPIs) to track performance across the workforce management team and customer service organization</li><li>Collaborate with senior leadership to develop and implement long-term workforce management strategies that support the growth and success of the business</li><li>Develop and maintain relationships with external vendors and partners to ensure the delivery of workforce management services that meet business needs</li></ul><p><strong>THIS ROLE WILL BE GREAT IF YOU HAVE THE FOLLOWING:</strong></p><ul><li>Bachelor's degree in Business Administration, Mathematics, Statistics, or related field</li><li>7+ years of experience in workforce management, with at least 3 years in a management role</li><li>Strong analytical and problem-solving skills with experience in data analysis and forecasting</li><li>Experience with workforce management software and tools, such as Verint, IEX, or NICE</li><li>Excellent communication skills, with the ability to present complex data and insights to senior leadership</li><li>Ability to work collaboratively with cross-functional teams and stakeholders to achieve business goals</li><li>Demonstrated experience in developing and implementing workforce management strategies that drive operational efficiencies, increase productivity, and improve customer experience</li><li>If you are a proactive, data-driven leader who is passionate about workforce management and customer service, we encourage you to apply for this exciting opportunity</li></ul><p><strong>WHY YOU SHOULD JOIN SUMUP</strong></p><ul><li>Opportunity to work with SumUppers globally on large-scale fintech products used by millions of businesses worldwide, from our Berlin office. This involves an office-first setup</li><li>Commitment to Diversity and Inclusion: Be part of a workplace that values and promotes diversity, fostering an inclusive environment where everyone's perspectives are respected and embraced</li><li>A dedicated annual L&amp;D budget of \u20ac2,000 for attending conferences and/or advancing your career through further education</li><li>Enrolment onto our VSOP program: You will own a stake in SumUp's future success</li><li>A corporate pension scheme where we match up to 20% of your contributions</li><li>30 Days Sabbatical: Enjoy the unique opportunity to take a well-deserved break with our 30 days sabbatical benefit after completing 3 years of employment with SumUp</li><li>Referral Bonus: Earn additional rewards by referring talented individuals to join the SumUp team</li><li>\u200d</li><li>\ufe0f Numerous other benefits such as Urban Sports Club subsidy, Kita placement assistance, relocation assistance, subsidised office lunches</li></ul><p><strong>Job Application Tip</strong></p><br><p>We recognise that candidates feel they need to meet 100% of the job criteria in order to apply for a job. Please note that this is only a guide. If you don't tick every box, it's ok too because it means you have room to learn and develop your career at SumUp.</p><br>"
  },
  {
    "id": 8,
    "title": "Social Media Lead - Lounge by Zalando (all genders)",
    "company": "Zalando",
    "locations": "Berlin",
    "skills": "Algorithms, Paid Social",
    "posted_at": "2024-08-09",
    "is_remote": "False",
    "snippet_fragments": "You are welcome to leave out your picture, We only assess candidates on their qualifications and merit,    We want to provide you with a great candidate experience, Feel free to inform us of any accommodations you may need,    WHAT WED LOVE YOU TO DO (AND LOVE DOING),    WE'D LOVE TO MEET YOU IF,     You have 5 years of experience in social media management",
    "description": "<p>Location</p><br><p>Berlin</p><br><p>Contract</p><br><p>Full time</p><br><p>Job Category</p><br><p>Marketing &amp; Communications</p><br><p><strong>THE ROLE &amp; THE TEAM</strong></p><br><p>As our Social Media Lead, you'll be at the forefront of shaping and growing our brand's organic presence on Instagram and TikTok. You will work closely with an external agency to craft and execute compelling social media strategies that resonate with our audience. Your creativity and strategic thinking will drive engagement and brand loyalty, while your analytical skills will ensure our content continuously evolves and improves. You'll be joining a dynamic and innovative team committed to pushing the boundaries of online fashion retail.</p><br><p><strong>INCLUSIVE BY DESIGN</strong></p><br><p>At Zalando, our vision is to be inclusive by design. And this vision starts with our hiring - we do not discriminate on the basis of gender identity, sexual orientation, personal expression, ethnicity, religious belief, or disability status. You are welcome to leave out your picture, age, or marital status from your application. We only assess candidates on their qualifications and merit.</p><br><p>We want to provide you with a great candidate experience. Feel free to inform us of any accommodations you may need, so we can best support you throughout the hiring process.</p><br><p>do.BETTER - our diversity &amp; inclusion strategy: https://corporate.zalando.com/en/our-impact/dobetter-our-diversity-and-inclusion-strategy</p><br><p>Our employee resource groups: https://corporate.zalando.com/en/our-impact/our-employee-resource-groups</p><br><p><strong>WHAT WE'D LOVE YOU TO DO (AND LOVE DOING)</strong></p><ul><li><br><strong>Develop and Execute Strategy:</strong> Collaborate with our external agency to create and implement a robust social media strategy for Instagram and TikTok that aligns with our brand's goals.</li><li><br><strong>Create Engaging Content:</strong> Oversee the creation and curation of visually appealing and brand-consistent content that captivates our audience.</li><li><br><strong>Audit and Improve Channels:</strong> Regularly audit our social media channels to identify areas for improvement and ensure we are on the cutting edge of social media trends.</li><li><br><strong>Drive Campaign Success:</strong> Plan and manage innovative social media campaigns that drive engagement, brand awareness, and conversions.</li><li><br><strong>Monitor and Optimise KPIs:</strong> Track and analyse performance metrics to ensure we are meeting and exceeding our engagement, reach, and follower growth targets.</li><li><br><strong>Drive Community Management:</strong> Collaborate with our agency to foster a vibrant and interactive community by ensuring timely and engaging responses to comments and messages.</li><li><br><strong>Enhance Workflows:</strong> Continuously review and refine workflows for content planning, creation, approval, and posting to enhance efficiency.</li><li><br><strong>Collaborate Across Teams:</strong> Work closely with our Influencer Marketing and Paid Social teams to ensure cohesive and complementary social media strategies, and with Retail to ensure we're capturing all the key commercial moments with our content plan</li><li><br><strong>I</strong>nnovate Continuously: Stay ahead of the latest social media trends and platform updates, experimenting with new content formats and strategies.</li><li><br><strong>Report Insights:</strong> Develop comprehensive reports on social media performance and provide strategic recommendations for ongoing improvement.</li></ul><p><strong>WE'D LOVE TO MEET YOU IF</strong></p><ul><li>You have 5+ years of experience in social media management, preferably within the fashion or retail industry.</li><li>You live and breathe social media and have a deep understanding of Instagram and TikTok algorithms and best practices. You always stay ahead of industry trends.</li><li>You are creative and have a proven track record of creating engaging and high-quality content.</li><li>You are analytical and proficient in using social media analytics tools to drive strategy based on data.</li><li>You love collaboration and have experience working with external agencies and cross-functional teams.</li><li>You are adaptable and thrive in a fast-paced environment, managing multiple projects with ease.</li><li>You have excellent written and oral communication skills in English.</li></ul><p>If you have what it takes, we encourage you to</p><br>"
  },
  {
    "id": 9,
    "title": "Go-to-Market Lead Life Sciences (w/m/d)",
    "company": "Capgemini Deutschland",
    "locations": "Berlin",
    "skills": "",
    "posted_at": "2024-07-24",
    "is_remote": "False",
    "snippet_fragments": "  Du bist zust\u00e4ndig f\u00fcr die Zusammenarbeit mit Partnern zur Gestaltung weiterer Gesch\u00e4ftsm\u00f6glichkeiten und die Beratung von Kunden zu komplexen Daten- und Analytik-Fragen im eigenen Fachgebiet,   Als Botschafter*in f\u00fcr Capgemini bist du sowohl intern als auch extern t\u00e4tig,   Du tr\u00e4gst mit Wissen und Erfahrung zu kommerziellen Angeboten (RFPs) bei; bist vertriebsorientiert und somit in der Lage, Erfolgreich abgeschlossenes Studium der (Wirtschafts-)Informatik, einem anderen MINT Studiengang oder ein vergleichbarer Abschluss.,   Du verf\u00fcgst \u00fcber Erfahrung im Bereich Daten,   Erfahrung in einer Beratungst\u00e4tigkeit ist von Vorteil,   Du bist eine Expertin oder ein Experte im Stakeholder-Management,   Du verf\u00fcgst \u00fcber gute Kommunikations- und Schreibf\u00e4higkeiten in Deutsch und Englisch und \u00fcber projektbezogene Reisebereitschaft,   Get the future you want  f\u00fcr den ersten Schritt in Richtung Zukunft brauchst du nur drei Minuten Zeit und deinen aktuellen Lebenslauf, Du m\u00f6chtest weitere Dokumente mit uns teilen? Mit wenigen Klicks kannst du sie deiner Bewerbung optional hinzuf\u00fcgen,   Bei Fragen steht dir Miriam Schleicher unter career,  Diese Anzeige ist online, solange die Stelle verf\u00fcgbar ist, Wir freuen uns auf deine aussagekr\u00e4ftige Online-Bewerbung, Bitte habe Verst\u00e4ndnis, dass wir keine postalischen Bewerbungen ber\u00fccksichtigen und Originalunterlagen nicht zur\u00fcckgeschickt werden k\u00f6nnen.,   Wir legen gro\u00dfen Wert auf die Vereinbarkeit von Arbeit und Privatleben, Deshalb hast du bei uns die M\u00f6glichkeit, Diversit\u00e4t sorgt in unserem Unternehmen f\u00fcr Inspiration und Innovation, Wir freuen uns besonders \u00fcber Bewerbungen von qualifizierten Talenten,   Erfahre hier mehr zu unserem Bewerbungsprozess und erhalte Tipps f\u00fcr deine Bewerbung",
    "description": "<p><strong>JOB DESCRIPTION</strong></p><br><p>Capgemini Global Insights &amp; Data ist eine f\u00fchrende Gesch\u00e4ftseinheit auf dem Markt f\u00fcr Daten, Plattformen und Analytik in allen Regionen und Branchen, einschlie\u00dflich Finanzdienstleistungen, Konsumg\u00fcter, Fertigung und Life Sciences. Unser Angebot umfasst die End-to-End Datenintegration zur Cloud-Plattform, ein komplettes Sortiment an KI-Engineering-F\u00e4higkeiten sowie eine Reihe von branchenspezifischen fortgeschrittenen Analytik- und KI-L\u00f6sungen. Diese Position im Bereich Insights &amp; Data bietet eine einzigartige Gelegenheit, das Gesch\u00e4ft im Bereich Life Sciences in Deutschland weiterzuentwickeln. Als Go-to-Market Lead (w/m/d) wirst du dabei helfen, wichtige Gro\u00dfprojekte im Bereich Life Sciences innerhalb der Gesch\u00e4ftseinheit zu formen und unser Kundenverst\u00e4ndnis zu vertiefen, um maximalen Wert, Einfluss und Innovation auf den Markt zu bringen.</p><br><p><strong>Dein neuer Job</strong></p><ul><li>Du bist verantwortlich f\u00fcr die Entwicklung und Umsetzung von Vertriebs- und Gesch\u00e4ftsentwicklungsstrategien.</li><li>Du arbeitest an verschiedenen Life-Science-Projekten und entwickelst neue Daten- und Analytik-M\u00f6glichkeiten bei unseren Life-Science-Kunden in Zusammenarbeit mit den Vertriebs- und Account-Teams von Capgemini und F\u00fchrung dieser Projekte.</li><li>Du bist zust\u00e4ndig f\u00fcr die Zusammenarbeit mit Partnern zur Gestaltung weiterer Gesch\u00e4ftsm\u00f6glichkeiten und die Beratung von Kunden zu komplexen Daten- und Analytik-Fragen im eigenen Fachgebiet.</li><li>Als Botschafter*in f\u00fcr Capgemini bist du sowohl intern als auch extern t\u00e4tig, Kunden dabei unterst\u00fctzen, datengesteuerter zu werden und unterst\u00fctzt dabei, Mehrwert aus Daten und Analytik zu ziehen.</li><li>Du tr\u00e4gst mit Wissen und Erfahrung zu kommerziellen Angeboten (RFPs) bei; bist vertriebsorientiert und somit in der Lage, in Zusammenarbeit mit unserer Vertriebsorganisation, Chancen zu erkennen und zu nutzen.</li></ul><p><strong>Dein Profil</strong></p><ul><li>Erfolgreich abgeschlossenes Studium der (Wirtschafts-)Informatik, einem anderen MINT Studiengang oder ein vergleichbarer Abschluss.</li><li>Du verf\u00fcgst \u00fcber Erfahrung im Bereich Daten, Analytik und KI-Problematiken sowie \u00fcber einen Hintergrund im Vertrieb und/oder Gesch\u00e4ftsentwicklung und hast Erfahrung in der Unterst\u00fctzung von Datengesch\u00e4ften in der Life-Science-Branche.</li><li>Erfahrung in einer Beratungst\u00e4tigkeit ist von Vorteil.</li><li>Du bist eine Expertin oder ein Experte im Stakeholder-Management.</li><li>Du verf\u00fcgst \u00fcber gute Kommunikations- und Schreibf\u00e4higkeiten in Deutsch und Englisch und \u00fcber projektbezogene Reisebereitschaft.</li></ul><p><strong>Bewirb dich jetzt</strong></p><br><p>Get the future you want - f\u00fcr den ersten Schritt in Richtung Zukunft brauchst du nur drei Minuten Zeit und deinen aktuellen Lebenslauf. Du m\u00f6chtest weitere Dokumente mit uns teilen? Mit wenigen Klicks kannst du sie deiner Bewerbung optional hinzuf\u00fcgen.</p><br><p>Bei Fragen steht dir <strong>Miriam Schleicher</strong> unter <strong>career.de@capgemini.com</strong> zur Seite.</p><br><p>Diese Anzeige ist online, solange die Stelle verf\u00fcgbar ist. Wir freuen uns auf deine aussagekr\u00e4ftige Online-Bewerbung. Bitte habe Verst\u00e4ndnis, dass wir keine postalischen Bewerbungen ber\u00fccksichtigen und Originalunterlagen nicht zur\u00fcckgeschickt werden k\u00f6nnen.</p><br><p>Wir legen gro\u00dfen Wert auf die Vereinbarkeit von Arbeit und Privatleben. Deshalb hast du bei uns die M\u00f6glichkeit, <strong>hybrid</strong> aus dem Office, von zu Hause oder an anderen Capgemini Standorten in Deutschland zu arbeiten.</p><br><p>Capgemini lebt Vielfalt am Arbeitsplatz. Diversit\u00e4t sorgt in unserem Unternehmen f\u00fcr Inspiration und Innovation. Wir freuen uns besonders \u00fcber Bewerbungen von qualifizierten Talenten, unabh\u00e4ngig von Herkunft, Nationalit\u00e4t, Geschlecht, Hautfarbe, ethnischer und sozialer Herkunft, Religion, Alter, Behinderung, sexueller Orientierung und Lebensphase.</p><br><p><strong>Mehr Infos</strong></p><br><p>Erfahre hier mehr zu unserem <strong>Bewerbungsprozess</strong> und erhalte Tipps f\u00fcr deine Bewerbung. Steig jetzt bei Capgemini ein und profitiere von unseren <strong>zahlreichen Benefits</strong>. Mehr Informationen zu den <strong>IT-Berufsfeldern</strong> bei Capgemini und unseren <strong>Standorten in Deutschland</strong> findest du auf unserer Karriereseite: <strong>capgemini.de/karrier</strong></p><br><p>S\u00e4mtliche in der Anzeige genannten Nebenleistungen geben lediglich einen ersten \u00dcberblick ohne Anerkennung einer Rechtspflicht. Sie richten sich nach den jeweils g\u00fcltigen Betriebsvereinbarungen, Policies, betrieblichen Regelungen und Anspruchsvoraussetzungen zum Zeitpunkt des Eintritts in das Unternehmen.</p><br><p><strong>Informiere dich auf</strong> <strong>glassdoor</strong> <strong>und</strong> <strong>kununu</strong>, wie unsere Mitarbeiter*innen Capgemini als Arbeitgeber bewerten.</p><br><p><strong>COMPANY DESCRIPTION</strong></p><br><p>Capgemini ist einer der weltweit f\u00fchrenden Anbieter von Management- und IT-Beratung, digitaler Transformation sowie Technologie- und Ingenieursdienstleistungen. Wir bieten dir ein inspirierendes Team, flexible Karrierem\u00f6glichkeiten sowie die Freiheit, mit deiner Arbeit f\u00fcr dich und andere Perspektiven zu schaffen.</p><br>"
  },
  {
    "id": 10,
    "title": "Sales Team Leader B2B for Italy - Circular Tech IT Infrastructure (m/w/d)",
    "company": "Tonitrus GmbH",
    "locations": "Berlin",
    "skills": "",
    "posted_at": "2024-07-24",
    "is_remote": "True",
    "snippet_fragments": " Fluent Italian language skills and good English skills for our internal communication,  Great team spirit within our comany and our multi-national Berlin sales team including regular company events throughout the year,  Exciting customer projects in the Circular Economy,  Structured onboarding process and ongoing trainings,  Lots of room for personal and professional development,  Modern workspace with latest technology and equipment,  Performance-oriented salaray scheme and further sales incentives,  Office location (Friedrichstra\u00dfe 68, Berlin) in a modern & spacious office building with lots of amenities such as a caf\u00e9 and a rooftop terrace, We are looking forward meeting you!",
    "description": "<p>Tonitrus is an international IT company engaged in the Circular Economy. Our focus lies on offering IT infrastructure products in the area of Servers, Storage, Networking and Computing. We help companies and public institutions across Europe and worldwide by not only delivering first class IT hardware to them, but also by helping our customers to reduce their carbon footprint &amp; to save their IT budget at the same time by supplying refurbished \u201eas good as new&quot; IT products. We round up our offerings by also providing various IT services such as Third-Party-Maintenance &amp; Certified Data Erasure. We keep available over 50,000 SKUs to our valued customers in more than 20 countries across Europe with same-day-shipment options via marketplaces and via our multi-language webshops (tonitrus.com), supported by our dedicated account managers.</p><br><p>For our international sales office located in Berlin (Friedrichstra\u00dfe 68), we are hiring a Sales Team Leader Italy for supporting our Italian Sales Team with further growth.</p><br><p><strong>Your tasks:</strong></p><ul><li>Understanding, embracing and executing our well structured sales process</li><li>Supporting and giving guidance to Italian sales team member for reaching &amp; outperforming our mutual goals</li><li>Data-driven and analytical Sales Controlling including weekly sales management meetings</li><li>Managing your own sales funnel &amp; your team's sales funnel</li><li>Understanding and identifying customer growth potential</li><li>Developing accounts to key accounts with recurring business opportunities &amp; excellent account management</li><li>Embracing the powerful features of our CRM system and share input for further improvements</li></ul><p><strong>Your profile:</strong></p><ul><li>Any Bachelor and/or Master degree</li><li>Minimum of 7 years work experience in B2B sales</li><li>Minimum of 3 years experience in leading a B2B sales team</li><li>Excellent communication skills</li><li>Proven track record for helping sales people to grow and develope to new heights</li><li>Analytical and data-driven management capabilities</li><li>Customer-centric thinking</li><li>Enthusiasm for sales and the circular economy/ circular IT</li><li>Fluent Italian language skills and good English skills for our internal communication</li></ul><p><strong>We offer:</strong></p><ul><li>Great team spirit within our comany and our multi-national Berlin sales team including regular company events throughout the year</li><li>Exciting customer projects in the Circular Economy</li><li>Structured onboarding process and ongoing trainings</li><li>Lots of room for personal and professional development</li><li>Modern workspace with latest technology and equipment</li><li>Performance-oriented salaray scheme and further sales incentives</li><li>Office location (Friedrichstra\u00dfe 68, Berlin) in a modern &amp; spacious office building with lots of amenities such as a caf\u00e9 and a rooftop terrace</li><li>Home Office options available</li></ul><p><strong>We are looking forward meeting you!</strong></p><br><p>Your Tonitrus-Team</p><br><p>www.tonitrus.com</p><br><p>Job Types: Full-time, Permanent</p><br><p>Pay: 72.000,00\u20ac - 115.000,00\u20ac per year</p><br><p>Experience:</p><ul><li>Leading a B2B sales team: 3 years (Required)</li><li>B2B Sales: 7 years (Required)</li></ul><p>Language:</p><ul><li>flie\u00dfend Italienisch (Wort und Schrift) (Required)</li></ul><p>Work Location: In person</p><br>"
  },
  {
    "id": 11,
    "title": "Revenue Strategy Lead Analyst",
    "company": "Remerge",
    "locations": "Berlin",
    "skills": "Data Analysis, Excel, Power BI, Salesforce",
    "posted_at": "2024-07-10",
    "is_remote": "True",
    "snippet_fragments": "Prepare a status report on what regions may require to achieve the appointed board goals ,   Define KPIs for productivity measurement of sales, Develop monthly productivity reports and share key insights with stakeholders ,   Select key KPIs for revenue strategy planning and provide preliminary analysis of data every quarter ,   Ensure accurate forecasting and anecdotal insight population during our quarterly business reviews, Prepare quarterly business reports summarising key highlights and action items ,   Manage and mentor a CRM specialist,   Innate interest in understanding the business context ,   Ability to create precise business narratives based on data analysis ,   Strong project management and organisational skills ,   Advanced qualitative and quantitative research skills ,   Proven practices for effective internal communication ,   Proficiency in data analysis tools such as Excel",
    "description": "<p>Remerge helps leading mobile app marketers increase revenue and retention by activating, re-engaging and retaining high-value users through programmatic in-app ads. Founded in 2014, Remerge has established itself as a leading app retargeting player globally, with offices spanning Berlin, New York, Singapore, Seoul and Tokyo. Our international team of experts has contributed to the growth of hundreds of apps across all major verticals, including gaming, on-demand delivery, e-commerce, and finance.</p><br><p><strong>Job mission</strong></p><br><p>We're seeking a highly organised Revenue Strategy Lead Analyst to join our team. In this role, you'll redesign how data is presented within the revenue department and lead the definition and implementation of a collective, data-driven and decision-making culture.</p><br><p><strong>Job responsibilities</strong></p><ul><li>Assist with formulating and communicating annual board goals to the revenue team. Prepare a status report on what regions may require to achieve the appointed board goals</li><li>Define KPIs for productivity measurement of sales, account management, and marketing. Develop monthly productivity reports and share key insights with stakeholders</li><li>Select key KPIs for revenue strategy planning and provide preliminary analysis of data every quarter</li><li>Ensure accurate forecasting and anecdotal insight population during our quarterly business reviews. Prepare quarterly business reports summarising key highlights and action items</li><li>Manage and mentor a CRM specialist, guiding their professional development and ensuring best practices in CRM management</li></ul><p><strong>Job requirements</strong></p><ul><li>Innate interest in understanding the business context</li><li>Ability to create precise business narratives based on data analysis</li><li>Strong project management and organisational skills</li><li>Advanced qualitative and quantitative research skills</li><li>Proven practices for effective internal communication</li><li>Proficiency in data analysis tools such as Excel, PowerBI, or other data visualisation tools</li><li>Proficiency in Salesforce</li></ul><p><strong>Our promise</strong></p><ul><li>Direct Impact: Accelerate your career in a fast-paced environment with a high degree of responsibility.</li><li>Competitive Remuneration: Enjoy a top-tier package including stock option awards in a profitable company.</li><li>Personal Growth: Take advantage of our budget for books, conferences, and other training materials.</li><li>Flexible Schedule: We offer flexible working hours, unlimited home office days, and the ability to take as much time off as you need.</li><li>Office Exchange: Travel to our global offices for short-term assignments.</li><li>Team Events: Celebrate achievements and enjoy team off-sites with an amazing team.</li></ul><p>Remerge is an Equal Opportunity Employer: all qualified applicants are considered for positions regardless of race, ethnic origin, gender, age, religion or belief, marital status, gender identification, sexual orientation, veteran status or disability. We're looking forward to your application!</p><br><p>Important notice: Protect yourself from scammers representing Remerge</p><br><p>Do not respond to job offers from third parties claiming to recruit on behalf of Remerge, or individuals impersonating as Remerge employees offering freelance or remote work opportunities. We do not ask job applicants for personal information like bank account numbers, address, money transfer requests, or other confidential details on any messaging platform. If someone reaches out to you to offer you a job, make sure that they are a verified Remerge employee by checking their identity on official Remerge channels.</p><br><p>Please note that the only job openings we offer are listed on our official website: remerge.io/careers</p><br><p>Stay vigilant and protect yourself from potential scams.</p><br>"
  },
  {
    "id": 12,
    "title": "Lead Game Product Manager - Casual Games (all genders)",
    "company": "Justplay GmbH",
    "locations": "Berlin",
    "skills": "Data Analysis, A/B testing, Unity",
    "posted_at": "2024-07-10",
    "is_remote": "False",
    "snippet_fragments": "    Lead initiatives to optimize the overall quality of the entire JustPlay Casual Games portfolio,      Identify and implement strategic improvement and fixes within our game design processes,      Proactively scout and evaluate new titles with the potential to add value to our portfolio,      Design and execute A/B testing strategies to assess and leverage new opportunities,      Drive retention and improve in app advertising revenue opportunities,   The experience we hope you bring to JustPlay ,     5 years of experience as a game producer or product manager or portfolio manager in the mobile gaming industry (casual and hyper-casual games),  Excellent command of English, both in writing and speaking,,      Structured approach and ability to coordinate between different teams,      Comprehensive understanding of what makes casual games successful and knowledge of casual game genres and their target audiences,      Proven experience in contributing to the success of a casual or hyper-casual game,      Ideally previous experience from a game publishing company and/or background in game design,      Concrete experience in casual or hyper casual gaming and/or in-app advertisement would be considered a great advantage, Global (coaching, language courses) and local (gym membership, monthly public transportation ticket, etc.) benefits tailored to our distributed team,,      A lot of responsibility with complete ownership of tasks and freedom in choosing the best path to reach your goals,      Training Budget - we believe in learning and growing together, We support that by offering a generous personal learning budget that can be used for books,      Health and Fitness - active breaks,      Highly Competitive Salary - we believe that top performers should receive top payment,      Flexible working hours and flexibility  we believe in a good work-life balance and in giving employees the choice of which setup works best for them,      State-of-the-art technical equipment - this includes the latest laptops and phones, A spirited, inspiring, international, and enthusiastic team,,      An International team that is currently working from 8 locations around the world,      An organization with a high level of trust and sense of belonging among employees,      An opportunity to be a part of a company thats breaking with traditional ideas and taking a new approach thats shattering how the games industry works",
    "description": "<p><strong>YOUR MISSION</strong></p><br><p><strong>Location:</strong> Berlin or Remote (+/- 3hrs from CET)</p><br><p>We are a worldwide gaming loyalty platform operator and publisher. Our purpose is to enable free-to-play mobile game players to get rewarded for their hobby. We launched JustPlay in the US in 2020, and now our product is one of the leading loyalty rewards apps in the world. Our team is based in 8+ countries and our headquarters are in Berlin, Germany. While serving our 500,000 daily active players, developing our loyalty app and awesome games, we value fairness, having fun together, creativity and focusing on the things that matter.</p><br><p>As a Lead Game Product Manager, you will play a pivotal role in enhancing our casual games portfolio by merging your game design expertise with effective product management skills. You'll manage the entire process of making our games more enjoyable and profitable, both for titles we produce internally and those developed in collaboration with external studios. While this role does not include direct reports from the get-go, it will oversee various external teams (designers, game developers, etc.) and has the opportunity of taking over the whole games domain in the future, including building and leading their own team.</p><br><p>Join one of the largest casual games publishers in the market, where our games are enjoyed by millions of players. This is a unique opportunity to make a significant impact in a both rapidly growing and already massively scaled business.</p><br><p><strong>JOB RESPONSIBILITIES</strong></p><ul><li>Lead initiatives to optimize the overall quality of the entire JustPlay Casual Games portfolio, focusing on enhancing player satisfaction, boosting retention and increasing engagement across all titles,</li><li>Identify and implement strategic improvement and fixes within our game design processes, coordinating the collaboration with several casual game development teams and ensuring a smooth execution of future developments and enhancements,</li><li>Proactively scout and evaluate new titles with the potential to add value to our portfolio,</li><li>Design and execute A/B testing strategies to assess and leverage new opportunities, optimizing game performance and diversifying our portfolio genres,</li><li>Drive retention and improve in app advertising revenue opportunities.</li></ul><p><strong>THE EXPERIENCE WE HOPE YOU BRING TO JUSTPLAY</strong></p><ul><li>5+ years of experience as a game producer or product manager or portfolio manager in the mobile gaming industry (casual and hyper-casual games),</li><li>Excellent command of English, both in writing and speaking,</li><li>Proficient in data analysis,</li><li>Structured approach and ability to coordinate between different teams,</li><li>Comprehensive understanding of what makes casual games successful and knowledge of casual game genres and their target audiences,</li><li>Proven experience in contributing to the success of a casual or hyper-casual game,</li><li>Ideally experience with unity,</li><li>Ideally previous experience from a game publishing company and/or background in game design,</li><li>Concrete experience in casual or hyper casual gaming and/or in-app advertisement would be considered a great advantage.</li></ul><p><strong>OUR BENEFITS PACKAGE:</strong></p><ul><li>Global (coaching, language courses) and local (gym membership, monthly public transportation ticket, etc.) benefits tailored to our distributed team,</li><li>A lot of responsibility with complete ownership of tasks and freedom in choosing the best path to reach your goals,</li><li>Training Budget - we believe in learning and growing together. We support that by offering a generous personal learning budget that can be used for books, workshops, conferences, coaching etc.,</li><li>Health and Fitness - active breaks, sponsored healthy lunches and a company which is deeply interested in your well-being,</li><li>Highly Competitive Salary - we believe that top performers should receive top payment,</li><li>Flexible working hours and flexibility - we believe in a good work-life balance and in giving employees the choice of which setup works best for them, it doesn't matter if you are a digital nomad, the type that comes to the office once a month or an office-goer,</li><li>State-of-the-art technical equipment - this includes the latest laptops and phones, which may also be used in your free time.</li></ul><p><strong>WHY US?</strong></p><ul><li>A spirited, inspiring, international, and enthusiastic team,</li><li>An International team that is currently working from 8+ locations around the world,</li><li>An organization with a high level of trust and sense of belonging among employees, that prioritizes employee quality of life, job satisfaction and professional development,</li><li>An opportunity to be a part of a company that's breaking with traditional ideas and taking a new approach that's shattering how the games industry works.</li></ul><p>Apply for this job</p><br><p><strong>ABOUT US</strong></p><br><p>We are a worldwide gaming loyalty platform operator and publisher. Our purpose is to enable free-to-play mobile game players to get rewarded for their hobby. We launched JustPlay in the US in 2020, and now our product is one of the leading loyalty rewards apps in the world. Our team is based in 8+ countries and our headquarters are in Berlin, Germany. While serving our 500,000 daily active players, developing our loyalty app and awesome games, we value fairness, having fun together, creativity and focusing on the things that matter.</p><br>"
  },
  {
    "id": 13,
    "title": "Senior / Lead Data Engineer (f/m/d)",
    "company": "Hive Technologies GmbH",
    "locations": "Berlin",
    "skills": "Python, SQL, AWS, Redshift, Flink, Dashboards, PostgreSQL, Terraform, Database Design, Tableau, Data Warehouse, Cloud Platforms, Shopify, Data Pipelines, Metabase, Hive, ETL, Business Intelligence, IaC, ELT",
    "posted_at": "2024-06-27",
    "is_remote": "False",
    "snippet_fragments": "Experience with (near) real-time data use-cases a plus, Proficiency in a programming language such as Python, Solid understanding of data warehousing concepts and best practices, Excellent problem-solving skills and high attention to detail, Strong communication skills and the ability to work collaboratively in a team environment, You will work with a highly driven team of exceptional and experienced people in all domains, People at Hive have worked at organizations such as McKinsey, We believe in a culture of trust,  Join a young company with an entrepreneurial culture operating at lightning speed  we want you to grow with us, We offer attractive compensation, including virtual employee stock options for all full-time team members plus your choice of hardware according to your preference",
    "description": "<p><strong>THE POSITION</strong></p><br><p>If you are excited about growing with Hive and love operations, this might be the right position for you!</p><br><p>You'll join as our first full-time data engineer, helping power our business, serve our customers better, and drive our data infrastructure.</p><br><p><strong>What you'll be responsible for:</strong></p><br><p>Some exemplary topics of what we expect a data engineer to cover is below - an important note is that we're not looking for someone that purely optimizes the technical aspects of what they're doing, but that they're doing it with their users (engineers, data analysts, PMs, ...) and our customers in mind.</p><ul><li>Design, develop, and maintain scalable ETL/ELT processes to support data ingestion, transformation, and storage using dbt, Python, and Redshift.</li><li>Optimize and manage our data warehouse (Redshift) to ensure high performance, reliability, and low latency.</li><li>Architect, create, and maintain data models that reflect the needs of the business.</li><li>Develop data products to be integrated across our entire operations platform, such as:</li><li>Merchant-facing analytics for dashboards and different views in our customer-facing applications</li><li>Operational analytics for data-driven decision making in our Warehouse Management Software</li><li>Delivery time prediction models to power our &quot;Delivery Promise&quot; functionality across applications, from the merchant's storefront to their tracking emails and customer-facing tracking portal.</li></ul><p>Hive is building the leading operations platform for independent commerce. It's time for us to take the next step and deeply invest in our data platform foundations as a key enabler to enhance the value of our multi-product offering. Better commerce operations for merchants, consumers, and our fulfillment network.</p><br><p><strong>What you'll be doing:</strong></p><ul><li><br><strong>Data pipeline optimization:</strong> Redesign, build, and optimize ETL processes to reduce latency and improve performance for real-time analytics use cases.</li><li><br><strong>Scalable Data Warehouse setup</strong>: Help shape and implement a scalable data warehousing solution (e.g., in Redshift) to handle increasing data volumes and complex queries efficiently.</li><li><br><strong>BI enhancement:</strong> Guide data analysts to develop new dashboards and reporting solutions in Metabase, providing actionable insights.</li><li><br><strong>Data quality and consistency:</strong> Ensure comprehensive data quality and accuracy across all pipelines.</li><li><br><strong>Integration with product infrastructure:</strong> Work with engineering teams to integrate data solutions with our product stack, enabling seamless data flow and enhancing our capabilities across the entire platform.<br> Collaboration across the business: Assess stakeholder needs across the Hive organization to drive decision-making and technical approaches proactively, ensuring different use cases are covered properly and thoroughly<br><strong>YOUR PROFILE</strong><br></li></ul><p>We know - sometimes, you can't tick every box. We would still love to hear from you if you think you're a good fit!</p><ul><li><br><strong>You have the skills.</strong> Strong proficiency in SQL and significant experience with relational databases and data warehouse (e.g. Postgres and Redshift). Experience with (near) real-time data use-cases a plus.</li><li><br><strong>You get into the details.</strong> Hands-on experience with ETL/ELT tools and processes, BI tools like Mode/Metabase/Tableau, and cloud platforms like AWS.</li><li><br><strong>You write code.</strong> Proficiency in a programming language such as Python, and are experienced in managing data infrastructure via IaC tools like Terraform</li><li><br><strong>You know the theory, and the practice.</strong> Solid understanding of data warehousing concepts and best practices.</li><li><br><strong>You care about the craft</strong>. Excellent problem-solving skills and high attention to detail.</li><li><br><strong>You bring people along.</strong> Strong communication skills and the ability to work collaboratively in a team environment.</li></ul><p><strong>OUR OFFERING</strong></p><ul><li><br><strong>Be part of the Hive</strong>. You will work with a highly driven team of exceptional and experienced people in all domains. People at Hive have worked at organizations such as McKinsey, Amazon, Shopify, Google, Flink, Blackstone, J.P. Morgan &amp; DHL before. We believe in a culture of trust, collaboration, empowerment and constructive feedback in a positive and inspiring work atmosphere</li><li><br><strong>Make an impact.</strong> Join a young company with an entrepreneurial culture operating at lightning speed - we want you to grow with us</li><li><br><strong>You will be valued</strong>. We offer attractive compensation, including virtual employee stock options for all full-time team members plus your choice of hardware according to your preference</li><li><br><strong>We support your well-being.</strong> Benefit from 30 vacation days annually, with the opportunity for a sabbatical after three years with us, alongside a dedicated monthly wellness and productivity budget.</li><li><br><strong>We will get you set up.</strong> Operating system and hardware of your choice, additional tech equipment that you need, screens, you name it - we want to enable you to do your best work</li><li><br><strong>There's more!</strong> Enjoy flexible working hours, free drinks and snacks in our office in Berlin, Paris, Milan &amp; Madrid and join regular team events such as off-sites and workcations</li></ul><p><strong>ABOUT US</strong></p><br><p><strong>We make better commerce operations for everyone.</strong></p><br><p>Hive's mission is to make commerce operations better - for brands, consumers and ops partners. Hive seamlessly combines powerful technology with a network of leading operations providers, saving commerce brands on average 17% on costs and generating up to 24% revenue uplift. All-in-one, through our Hive App. The Hive ecosystem spans the full operational chain. Started just in 2020, Hive already works with hundreds of the leading brands across Europe such as HOLY, mybacs and Inkster and has become the leading operations platform in Europe. Backed by acclaimed global investors including Tiger Global, Earlybird, Picus Capital, we are rapidly expanding our pan-European network with our newly opened fulfillment centers and offices in Berlin, Paris, Milan, Madrid and London.</p><br><p>At Hive, we believe fostering diversity in every team makes us a stronger company overall. We do not discriminate based on religion, skin color, nationality, gender, sexual orientation, age, marital status, or disability, and encourage applications from all backgrounds. We strive to create an inclusive workplace where everyone feels encouraged to be their true self and to grow professionally.</p><br>"
  },
  {
    "id": 14,
    "title": "Team Lead Technical Support (f/m/d)*",
    "company": "Parloa",
    "locations": "Berlin",
    "skills": "AI, Machine Learning, JavaScript, TypeScript, Telephony, SaaS, NLP",
    "posted_at": "2024-06-24",
    "is_remote": "False",
    "snippet_fragments": "  Bring 3-5 years of experience in a customer-facing technical support role in the tech industry, This experience is crucial for navigating the complexities of technical support leadership,   Demonstrate proven experience in a software environment, Your technical background is essential for understanding and resolving complex issues, German language skills are a nice to have but not mandatory,   Exhibit exceptional leadership and team management skills, Your ability to inspire and guide your team is vital,   Highlight your strong problem-solving abilities and a track record of resolving complex technical issues, Your analytical skills are key to troubleshooting effectively, Demonstrate excellent communication skills, capable of articulating complex solutions in a clear and concise manner, Your communication abilities are crucial for interacting with both your team and customers, Thrive in a fast-paced environment, learn quickly, and adapt to product changes, Your agility and adaptability are essential for success in this role,   Possess a basic understanding of Javascript and/or Typescript, Be part of a dynamic, driven team of 35 nationalities with flat hierarchies and collaborative company culture,   Hybrid work environment - we believe in hiring the best talent, However, we love to build real connections and want to welcome everyone in the office on certain days, (Job specific, it could be also on-site work),   Training and development budget which can be used for conferences and attending development courses to ensure continuous professional growth, Gym Memberships, Mental Health Support, etc., Flexible working hours, 28 vacation days and workation opportunities, Regular team events, game nights, and other social activities,   Is something missing here? Reach out and let's talk about what else you need for your ideal next growth opportunity,   Recruiter video call Meet your manager Challenge Task  Expert interview(s) Meeting the team Founder interview,    Parloa is one of the fastest growing startups in the world of Generative AI and customer service, Parloa's voice-first GenAI platform for contact centers is built on the best AI technology to automate customer service with natural-sounding conversations for outstanding experiences on all communication channels, Leveraging natural language processing (NLP) and machine learning",
    "description": "<p><strong>YOUR MISSION:</strong></p><br><p>As the <strong>Team Lead Technical Support (f/m/d)</strong>* at Parloa, your mission is to ensure our customers receive exceptional technical support. Your strategic leadership and hands-on approach will be key to guiding a team of skilled engineers in troubleshooting, problem-solving, and enhancing the overall customer experience.</p><br><p><strong>IN THIS ROLE YOU WILL:</strong></p><ul><li>Lead and mentor a team of on- and off-site Technical Support Engineers, fostering a culture of excellence and continuous improvement.</li><li>Conduct regular team meetings, check-ins, and provide constructive feedback.</li><li>Set clear goals and expectations, ensuring alignment with company objectives and customer satisfaction metrics.</li><li>Oversee the team's response to customer queries, ensuring timely and effective resolution of issues related to the Parloa platform and telephony problems.</li><li>Act as an escalation point for complex technical issues, providing advanced troubleshooting and problem resolution.</li><li>Identify opportunities to enhance customer support processes and implement best practices.</li><li>Collaborate with Solution Engineering, CX Design, Product &amp; Engineering teams to drive product improvements based on customer feedback.</li><li>Provide insights and feedback to the documentation team to improve user guides and technical documentation.</li><li>Become a Parloa expert and advanced &quot;Bot Builder,&quot; capable of navigating logs and diagnosing customer-reported issues.<br> Maintain up-to-date knowledge of the Parloa platform, industry trends, and emerging technologies.</li></ul><p><strong>WHAT YOU BRING TO THE TABLE:</strong></p><ul><li>Bring 3-5 years of experience in a customer-facing technical support role in the tech industry, with at least 1-2 years in a leadership position. This experience is crucial for navigating the complexities of technical support leadership.</li><li>Demonstrate proven experience in a software environment, with SaaS experience being a strong plus. Your technical background is essential for understanding and resolving complex issues.</li><li>Showcase your fluency in English. German language skills are a nice to have but not mandatory.</li><li>Exhibit exceptional leadership and team management skills, with a passion for mentoring and developing talent. Your ability to inspire and guide your team is vital.</li><li>Highlight your strong problem-solving abilities and a track record of resolving complex technical issues. Your analytical skills are key to troubleshooting effectively.</li><li>Demonstrate excellent communication skills, capable of articulating complex solutions in a clear and concise manner. Your communication abilities are crucial for interacting with both your team and customers.</li><li>Thrive in a fast-paced environment, learn quickly, and adapt to product changes. Your agility and adaptability are essential for success in this role.</li></ul><p><strong>NICE TO HAVE:</strong></p><ul><li>Possess a basic understanding of Javascript and/or Typescript.</li></ul><p><strong>WHAT'S IN IT FOR YOU?</strong></p><ul><li>Be part of a dynamic, driven team of +35 nationalities with flat hierarchies and collaborative company culture</li><li>Hybrid work environment - we believe in hiring the best talent, no matter where they are based. However, we love to build real connections and want to welcome everyone in the office on certain days. (Job specific, it could be also on-site work)</li><li>Training and development budget which can be used for conferences and attending development courses to ensure continuous professional growth.</li><li>Gym Memberships, Mental Health Support, etc.</li><li>Flexible working hours, 28 vacation days and workation opportunities</li><li>Regular team events, game nights, and other social activities</li><li>And last but not least: a beautiful office with flair in the heart of Berlin or Munich with all the conveniences, such as adjustable desks, social area, fresh fruits, cereals and drinks.</li><li>Is something missing here? Reach out and let's talk about what else you need for your ideal next growth opportunity.</li></ul><p><strong>YOUR RECRUITING PROCESS AT PARLOA:</strong></p><br><p>Recruiter video call Meet your manager Challenge Task + Expert interview(s) Meeting the team Founder interview</p><br><p><strong>WHY PARLOA?</strong></p><br><p>Parloa is one of the fastest growing startups in the world of Generative AI and customer service. Parloa's voice-first GenAI platform for contact centers is built on the best AI technology to automate customer service with natural-sounding conversations for outstanding experiences on all communication channels. Leveraging natural language processing (NLP) and machine learning, Parloa creates intelligent phone and chat solutions for businesses that turn contact centers into value centers by boosting customer service efficiency. The Parloa platform resolves the majority of customer queries quickly and automatically, allowing human agents to focus on complex issues and relationships. Parloa was founded in 2018 by Malte Kosub and Stefan Ostwald and today employs over 250 people in Berlin, Munich, and New York.</p><br><p>When you join Parloa, you become part of a dynamic and innovative team made up of over 34 nationalities that's revolutionizing an entire industry. We're passionate about growing together and creating opportunities for personal and professional development. With our recent $66 million Series B investment, we're expanding globally and looking for talented individuals to join us on this exciting journey.</p><br><p>Do you have questions about Parloa, the role, or our team before you apply? Please feel free to get in touch with our Hiring Team.</p><br><p>Parloa is committed to upholding the highest data protection standards for our clients' and employees' data. All our employees are instrumental in ensuring the utmost care, GDPR, and ISO compliance, including ISO 27001, in handling sensitive information.</p><ul><li><br><strong>We provide equal opportunities to all qualified applicants regardless race, gender, sexual orientation, age, religion, national origin, disability status, socioeconomic background and other characteristics.</strong><br></li></ul><br>"
  },
  {
    "id": 15,
    "title": "CoE Lead Manufacturing & Quality (m/w/d)",
    "company": "All for One Group SE",
    "locations": "Berlin",
    "skills": "Big Data, SAP S/4HANA, Cybersecurity, SAP, IoT",
    "posted_at": "2024-06-14",
    "is_remote": "True",
    "snippet_fragments": "Spannende Projekte bei erfolgreichen Top-Unternehmen, Weltmarktf\u00fchrern und Hidden Champions, Organisierter Wissensaustausch mit erfahrenen Kollegen, Weiterbildungsm\u00f6glichkeiten zu Themen wie S/4HANA,         Interessante Benefits und die M\u00f6glichkeit auf einen Dienstwagen ,         Eine tolle Arbeitsatmosph\u00e4re mit viel Gestaltungsfreiraum , Abgeschlossenes Studium im Bereich Betriebswirtschaft, Informatik oder einer vergleichbaren Qualifikation,         In der Vergangenheit hast du bereits mehrj\u00e4hrige Erfahrung in der SAP-Beratung sammeln k\u00f6nnen ,         Idealerweise kannst du tiefes Fachwissen in den SAP Modulen PP,         Du verf\u00fcgst \u00fcber Erfahrung im Aufbau und der Leitung von Teams ,         Du besitzt hervorragende soziale und kommunikative F\u00e4higkeiten und trittst stets selbstbewusst auf ,         Verhandlungssichere Deutsch- und Englischkenntnisse runden dein Profil ab ,             Flexible Arbeitszeiten, mobiles Arbeiten und ein hohes Ma\u00df an Eigenverantwortung & Gestaltungsspielraum  so bekommst du Raum f\u00fcr deine Pers\u00f6nlichkeit, deinen Rhythmus und deine Ideen,             Nimm dir die Zeit f\u00fcr das, Profitiere von unserer digitalen Lernplattform \"One Academy\",             Profitiere von Boni f\u00fcr Sonderprojekte, Pr\u00e4mien f\u00fcr Mitarbeiterempfehlungen und Firmenjubil\u00e4en, Mitarbeiterrabatten f\u00fcr privates Online Shopping, verg\u00fcnstigten Freizeit & Fitnessangeboten (EGYM Wellpass) und Rad Leasing (JobRad), Angebote f\u00fcr Stresspr\u00e4vention & Konfliktbew\u00e4ltigung, Unterst\u00fctzung f\u00fcr Kinder- & Pflegebetreuung, Gesundheitschecks & Vorsorgeuntersuchungen, Modelle f\u00fcr betriebliche Altersvorsorge & Berufsunf\u00e4higkeit und eine ergonomische Arbeitsplatzausstattung,             Zusammenhalt, Vertrauen & Wertsch\u00e4tzung  die Basis f\u00fcr deinen und unseren Erfolg und f\u00fcr ein respektvolles Miteinander auf Augenh\u00f6he, Dieser besondere Spirit ist ab dem ersten Tag erlebbar durch unser bereichs\u00fcbergreifendes Group-Starter Training,     \u00dcBER DIE ALL FOR ONE GROUP SE ,       Wir! Eine eingeschworene Gemeinschaft von \u00fcber 2.800 Transformations- & Integrationsexperten, Als f\u00fchrende Consulting- und IT-Gruppe vereinen wir Strategie- und Managementberatung, Wir begleiten und unterst\u00fctzen mehr als 3.000 Kunden aus Deutschland,  Aus Deutschland, \u00d6sterreich, Schweiz und Polen ",
    "description": "<p><strong>FACHBEREICH</strong></p><br><p>SAP Consulting</p><br><p><strong>STANDORT</strong></p><br><p>Berlin, Bielefeld, Dortmund, D\u00fcsseldorf, Ettlingen bei Karlsruhe, Filderstadt bei Stuttgart, Frankfurt am Main, Hamburg, Heidelberg, Heilbronn, Karlsruhe, Leipzig, M\u00fcnchen, Oldenburg, Ratingen, Rosenheim, Weingarten</p><br><p><strong>JOBLEVEL</strong></p><br><p>Professionals</p><br><p><strong>DAS MACHT DEINEN JOB SPANNEND</strong></p><ul><li>Als CoE Lead bist du f\u00fcr die Sicherstellung der Lieferf\u00e4higkeit verantwortlich. Du managst das Portfolio und entwickelst neue Strategien. Dar\u00fcber hinaus koordinierst du die Schnittstelle zu 4Business und betreibst Trend Scouting</li><li>Du \u00fcbernimmst die Budgetplanung und -verantwortung und erstellst Personalpl\u00e4ne. Die Abstimmung mit der HR-Abteilung und die Organisation und Durchf\u00fchrung von Schulungen und Ausbildungen geh\u00f6rt ebenfalls zu deinem Aufgabenbereich</li><li>Du f\u00fchrst und unterst\u00fctzt die Cluster Leads und entwickelst sowie implementierst Rollenmodelle. Du definierst und ordnest Aufgabenbereiche zu und bist f\u00fcr die Ressourcenplanung verantwortlich. Die F\u00f6rderung der Weiterentwicklung und Karriereplanung der Mitarbeitenden ist ebenfalls ein wesentlicher Bestandteil deiner T\u00e4tigkeit</li><li>Du repr\u00e4sentierst das Unternehmen gegen\u00fcber Kunden und setzt die Anforderungen um</li></ul><p><strong>DAS ERWARTET DICH</strong></p><ul><li>Spannende Projekte bei erfolgreichen Top-Unternehmen, Weltmarktf\u00fchrern und Hidden Champions</li><li>Organisierter Wissensaustausch mit erfahrenen Kollegen, Weiterbildungsm\u00f6glichkeiten zu Themen wie S/4HANA</li><li>Flexible Arbeitszeiten inklusive Homeoffice</li><li>30+1 Tage Urlaub</li><li>Weiterentwicklungsm\u00f6glichkeiten mit Laufbahnmodellen</li><li>Interessante Benefits und die M\u00f6glichkeit auf einen Dienstwagen</li><li>Eine tolle Arbeitsatmosph\u00e4re mit viel Gestaltungsfreiraum</li></ul><p><strong>DAS ZEICHNET DICH AUS</strong></p><ul><li>Abgeschlossenes Studium im Bereich Betriebswirtschaft, Informatik oder einer vergleichbaren Qualifikation</li><li>In der Vergangenheit hast du bereits mehrj\u00e4hrige Erfahrung in der SAP-Beratung sammeln k\u00f6nnen</li><li>Idealerweise kannst du tiefes Fachwissen in den SAP Modulen PP, PP/DS, IBP und DM vorweisen</li><li>Du verf\u00fcgst \u00fcber Erfahrung im Aufbau und der Leitung von Teams</li><li>Du besitzt hervorragende soziale und kommunikative F\u00e4higkeiten und trittst stets selbstbewusst auf</li><li>Verhandlungssichere Deutsch- und Englischkenntnisse runden dein Profil ab</li></ul><p><strong>DARAUF KANNST DU DICH FREUEN</strong></p><br><p>WERTVOLLER FREIRAUM</p><br><p>Flexible Arbeitszeiten, mobiles Arbeiten und ein hohes Ma\u00df an Eigenverantwortung &amp; Gestaltungsspielraum - so bekommst du Raum f\u00fcr deine Pers\u00f6nlichkeit, deinen Rhythmus und deine Ideen.</p><br><p>30+1 TAGE URLAUB</p><br><p>Nimm dir die Zeit f\u00fcr das, was dir wichtig ist.</p><br><p>GL\u00c4NZENDE PERSPEKTIVEN</p><br><p>Gestalte Karriere nach deinen W\u00fcnschen. Profitiere von unserer digitalen Lernplattform &quot;One Academy&quot;, individuellen Laufbahnmodellen, systematischem Wissensaustausch &amp; -aufbau mit erfahrenen Kollegen und gezielten F\u00f6rderprogrammen.</p><br><p>ATTRAKTIVE PR\u00c4MIEN &amp; RABATTE</p><br><p>Profitiere von Boni f\u00fcr Sonderprojekte, Pr\u00e4mien f\u00fcr Mitarbeiterempfehlungen und Firmenjubil\u00e4en, Mitarbeiterrabatten f\u00fcr privates Online Shopping, verg\u00fcnstigten Freizeit &amp; Fitnessangeboten (EGYM Wellpass) und Rad Leasing (JobRad).</p><br><p>WORK LIFE BALANCE &amp; GESUNDHEIT</p><br><p>Wir bieten dir u. a. Angebote f\u00fcr Stresspr\u00e4vention &amp; Konfliktbew\u00e4ltigung, Unterst\u00fctzung f\u00fcr Kinder- &amp; Pflegebetreuung, Gesundheitschecks &amp; Vorsorgeuntersuchungen, Modelle f\u00fcr betriebliche Altersvorsorge &amp; Berufsunf\u00e4higkeit und eine ergonomische Arbeitsplatzausstattung.</p><br><p>WE ARE ONE</p><br><p>Zusammenhalt, Vertrauen &amp; Wertsch\u00e4tzung - die Basis f\u00fcr deinen und unseren Erfolg und f\u00fcr ein respektvolles Miteinander auf Augenh\u00f6he. Dieser besondere Spirit ist ab dem ersten Tag erlebbar durch unser bereichs\u00fcbergreifendes Group-Starter Training.</p><br><p><strong>\u00dcBER DIE ALL FOR ONE GROUP SE</strong></p><br><p>Wir! Eine eingeschworene Gemeinschaft von \u00fcber 2.800 Transformations- &amp; Integrationsexperten, New Work Verfechtern, Cybersecurity Spezialisten, Big Data &amp; Business Analysten, IoT Engineers und Consultants rund um Business-IT von SAP, Microsoft und IBM. Als f\u00fchrende Consulting- und IT-Gruppe vereinen wir Strategie- und Managementberatung, Prozessberatung, Branchen-Expertise und Technologie-Know-how in Kombination mit IT-Beratung und -Services unter einem Dach. Wir begleiten und unterst\u00fctzen mehr als 3.000 Kunden aus Deutschland, \u00d6sterreich und der Schweiz bei der Unternehmenstransformation und dem Ausbau ihrer Wettbewerbsf\u00e4higkeit.</p><br><p><strong>3.000 KUNDEN</strong></p><br><p>Aus Deutschland, \u00d6sterreich, Schweiz und Polen</p><br><p><strong>2.800 KOLLEGINNEN &amp; KOLLEGEN</strong></p><br><p>Weltweit</p><br><p><strong>30 STANDORTE</strong></p><br><p>Auch in deiner N\u00e4he</p><br><p><strong>AUSGEZEICHNET</strong></p><br><p>SAP Platinum Partner und Gewinner des SAP Digital Supply Chain-Appreciation Award 2024 I Diamant-Initiative Partner mit 6 Awards 2024 I kununu Top Company 2024 I brandeins - Beste IT Dienstleister 2024 I</p><br><p><strong>DEIN ANSPRECHPARTNER F\u00dcR FRAGEN</strong></p><br><p><strong>MARKUS HELL</strong></p><br><p>TALENT ACQUISITION MANAGER</p><br>"
  },
  {
    "id": 16,
    "title": "Senior Expert, Tech Lead Solution Delivery",
    "company": "Fresenius Medical Care",
    "locations": "Berlin",
    "skills": "Cloud, Python, SQL, Agile, Azure, Big Data, DevOps, Java, C#, C++, Code Reviews, Scala, Scrum, Software Design, Terraform, Database Design, Data Lake, Azure Synapse, Spark, C, Julia, R, Business Intelligence, Physik, Mathematik, Medizin",
    "posted_at": "2024-06-13",
    "is_remote": "True",
    "snippet_fragments": "    Ensure compliance with data privacy regulations and company policies,     Collaborate with system and enterprise architects on the strategy and integration of the data management platform,  Diagram technical decompositions, describe technical processes and data components, and design exception handling and controls,     Work with colleagues to document and promote best practices and standards in software design and development,     Assign tasks and provide technical guidance, Mentor developers in integration techniques and tools,  Stay up-to-date with industry trends, emerging technologies, and best practices in data management,     Propose and implement innovative solutions to enhance the platform's capabilities,     Monitor the performance of implemented solutions,     Foster a collaborative and productive work environment,     Serve as a technical point of contact for any issues or challenges related to the Data Management platform,     Successfully completed degree with an analytical focus (Mathematics,     At least 6 years of directly related work experience as a data engineer,  Quick thinking, high level of initiative, and strong analytical and problem-solving skills to address technical challenges and drive innovation,     Strong interpersonal skills and ability to work effectively in a cross-functional team environment,     Willingness to learn and adapt to new technologies and methodologies,     Ability to explain technical concepts to non-technical stakeholders,     Experience in agile working methods (e,     Excellent communication and writing skills in English,     Proficiency in at least one general-purpose programming language (C#,     Strong knowledge of relational database systems or SQL,     Proficient in handling complex BI stacks (Microsoft SQL Server,  Good understanding of operating systems, IT security requirements, and implementation options,     Experience with programming environments like Python,     Good Azure cloud and Terraform DevOps experience,     Demonstrable knowledge and experience of the software development lifecycle and methodologies spanning development,     Strong technical development and relational platform design experience",
    "description": "<p><strong>Senior Expert, Tech Lead Solution Delivery</strong> <strong>(m/f/d)</strong></p><br><p>Become part of a team that is passionate and enthusiastic about developing data-based solutions to advance services, products and business processes across Fresenius Medical Care MedTech business.</p><br><p><strong>Your Responsibilities:</strong></p><ul><li>Manage the integration of a virtual data management platform with various shared services and other systems</li><li>Lead architectural decisions and technical design choices, ensuring the platform is scalable, reliable, secure, and optimized for performance</li><li>Work closely with cross-functional teams, including product management, business analysts, and data scientists, to understand and address their data needs and to define data management strategies aligned with business goals</li><li>Transform business-oriented functional specifications into detailed technical specifications</li><li>Ensure compliance with data privacy regulations and company policies</li><li>Collaborate with system and enterprise architects on the strategy and integration of the data management platform</li><li>Diagram technical decompositions, describe technical processes and data components, and design exception handling and controls</li><li>Work with colleagues to document and promote best practices and standards in software design and development</li><li>Assign tasks and provide technical guidance, code reviews, knowledge transfer, and feedback to team members. Mentor developers in integration techniques and tools</li><li>Stay up-to-date with industry trends, emerging technologies, and best practices in data management</li><li>Propose and implement innovative solutions to enhance the platform's capabilities</li><li>Monitor the performance of implemented solutions</li><li>Foster a collaborative and productive work environment</li><li>Serve as a technical point of contact for any issues or challenges related to the Data Management platform</li></ul><p><strong>Your Profile:</strong></p><ul><li>Successfully completed degree with an analytical focus (Mathematics, (Business) Computer Science, Physics, or similar) or comparable qualification with relevant professional experience</li><li>At least 6 years of directly related work experience as a data engineer, data architect, or DevOps support, or in a comparable function</li><li>Quick thinking, high level of initiative, and strong analytical and problem-solving skills to address technical challenges and drive innovation</li><li>Strong interpersonal skills and ability to work effectively in a cross-functional team environment</li><li>Willingness to learn and adapt to new technologies and methodologies</li><li>Ability to explain technical concepts to non-technical stakeholders</li><li>Experience in agile working methods (e.g., Scrum, SAFe), certification preferred</li><li>Excellent communication and writing skills in English, German optional</li></ul><p><strong>Technical Skills:</strong></p><ul><li>Proficiency in at least one general-purpose programming language (C#, Java, Python, C/C++)</li><li>Strong knowledge of relational database systems or SQL, as well as Big Data infrastructures (Spark, Data Lakes)</li><li>Proficient in handling complex BI stacks (Microsoft SQL Server, Synapse, Azure Data Service)</li><li>Good understanding of operating systems, IT security requirements, and implementation options</li><li>Experience with programming environments like Python, R, Scala, or Julia</li><li>Good Azure cloud and Terraform DevOps experience</li><li>Demonstrable knowledge and experience of the software development lifecycle and methodologies spanning development, testing, release, and deployment management</li><li>Strong technical development and relational platform design experience, especially with systems integration and interface development</li></ul><p><strong>Our offer for you:</strong></p><br><p>There is a lot you can discover at Fresenius Medical Care, because we have a lot to offer. No matter in which field you are an expert (m/f/d) and how much experience you have - for your professional future with meaning:</p><ul><li>The opportunity to work remotely</li><li>Whether in front of or behind the scenes - you will help to make better medicine accessible to more and more people around the world</li><li>Individual opportunities for self-determined career planning and professional development</li><li>A corporate culture in which there is enough room for innovative thinking - to find the best solution together, not the quickest one</li><li>A large number of committed people with a wide range of skills, talents and experience</li><li>The benefits of a successful global corporation with the collegial culture of a medium-sized company</li></ul><br>"
  },
  {
    "id": 17,
    "title": "Customer Engineering Improvement Project Lead",
    "company": "Air Products PLC",
    "locations": "Berlin",
    "skills": "Microsoft Office, Replication, FMEA, Dashboards, SAP, APM",
    "posted_at": "2024-06-07",
    "is_remote": "True",
    "snippet_fragments": "   KPIs Scorecard Performance reviews  support reviews as required as Cust Eng SME,      Instrumental in creating and formalising Cust Eng KPIs and dashboard,      Undertake detailed analysis of Gaps or trends identified with Supply Chain Performance reviews for Cust Eng,    Process Design  Support technical project teams where new technology is being deployed,      Act as Cust Eng SME with operational knowledge and advice from an analytical statistical data driven point of view to development teams,    Safety Quality & Environment  Always act as champion for safety in all that we do,      Ensure that Safety is considered within all projects and use data driven tools to assist with mitigating solutions,      Drive compliance within Cust Eng on completion of overdue for review procedures,      Support Operational Discipline initiatives within Cust Eng,    COP  Support Cust Eng CoPs,      Reporting out on improvement projects  with emphasis on Best-Practice replication,    Minimum bachelors degree or HND in Engineering or industrial related context,    Ideally Certified Lean Six Sigma Black Belt  Can be obtained during first year in role,    Ideally Project Management experience or Qualification, (APM, Prince 2 or Kepner Tregoe) can be obtained within role.,    Ability to work remotely and able to travel frequently  circa 40%,  Good communicator, team player comfortable with working in Matrix Org.,    Ability to report upwards to SLT level and downwards to end users and technicians,    IT literate with experience of SAP",
    "description": "<p>At Air Products, our purpose is to bring people together to reimagine what's possible, collaborate and innovate solutions to the world's most significant energy and environmental sustainability challenges. Grow with us as we embark on building tomorrow together by being the safest, most diverse and most profitable industrial gas company in the world.</p><br><p><strong>Reimagine What's Possible</strong></p><br><p>We are seeking a fulltime project lead, candidate to fill a vacancy within the European Merchant business improvement team, specifically for Customer Engineering Operations.</p><br><p>The role is principally Leading Projects and Programmes aimed at improving overall business performance by providing productivity, improving service, quality, and safety.</p><br><p>The position is part of the European Central supply chain support structure and in addition to project management will require some technical subject matter expert support to personnel within the European Customer Engineering operations.</p><br><p>The position will also require supporting coaching and training Lean Six Sigma throughout the EU Supply Chain as a technical expert.</p><br><p>Due to the nature of the role and geographical remit the position can likely require up to 40% business travel.</p><br><p><strong>Your main responsibilities will involve:</strong></p><ul><li>Project leadership - combination of leading projects and coaching/advising Cust Eng personnel within Key Projects &amp; Initiatives.</li><li>Driving and supporting projects through to completion as agreed by steering team.</li><li>Policing DMAIC Toll Gate or Stage Gate reviews on projects to ensure projects meet success criteria and quality statement.</li><li>Process Mapping to facilitate optimisation of existing processes and tools.</li><li>Undertaking detailed analysis using LSS tools and recommending appropriate tool use throughout project lifecycles.</li><li>Coaching &amp; mentoring Lean Six Sigma Green Belts.</li><li>Harnessing project resources, by engaging personnel &amp; SMEs through influence.</li><li>Budget &amp; Productivity Planning - Coordinate and execute annual Budget planning.</li><li>Cross pollination &amp; Exchange of ideas, initiatives, &amp; smaller projects.</li><li>Use of data (Entitlement / opportunity / gap analysis) to identify material project opportunities and develop / maintain a healthy pipeline for engineering.</li><li>Leading Coaching Mentoring project team or personnel responsible for project delivery, identified through budget planning &amp; objectives regionally.</li><li>KPIs Scorecard Performance reviews - support reviews as required as Cust Eng SME.</li><li>Instrumental in creating and formalising Cust Eng KPIs and dashboard, working with technical managers and Stakeholders to agree KPI tree hierarchy.</li><li>Undertake detailed analysis of Gaps or trends identified with Supply Chain Performance reviews for Cust Eng, to ascertain the level of opportunity, report back on viability and results.</li><li>Process Design - Support technical project teams where new technology is being deployed.</li><li>Act as Cust Eng SME with operational knowledge and advice from an analytical statistical data driven point of view to development teams.</li><li>Safety Quality &amp; Environment - Always act as champion for safety in all that we do.</li><li>Ensure that Safety is considered within all projects and use data driven tools to assist with mitigating solutions, (Power Scales, FMEA etc.)</li><li>Drive compliance within Cust Eng on completion of overdue for review procedures, act as progress chaser with technical SMEs, support the entry to EMOC.</li><li>Support Operational Discipline initiatives within Cust Eng.</li><li>COP - Support Cust Eng CoPs.</li><li>Reporting out on improvement projects - with emphasis on Best-Practice replication.</li><li>Highlighting Improvement opportunities.</li></ul><p><strong>You will have:</strong></p><ul><li>Minimum bachelor's degree or HND in Engineering or industrial related context.</li><li>Ideally Certified Lean Six Sigma Black Belt - Can be obtained during first year in role.</li><li>Ideally Project Management experience or Qualification. (APM, Prince 2 or Kepner Tregoe) can be obtained within role.</li><li>Valid driver's licence.</li><li>Ability to work remotely and able to travel frequently - circa 40%</li><li>Self-motivated independent worker</li><li>Lead through Influence.</li><li>Good communicator, team player comfortable with working in Matrix Org.</li><li>Ability to report upwards to SLT level and downwards to end users and technicians.</li><li>IT literate with experience of SAP, Microsoft Office programmes.</li><li>Experience in Manufacturing operational industry</li><li>Ideally working within CI, Optimisation or Project Management Experience.</li><li>Change Agent &amp; ability to drive change.</li><li>Ability to multi-task in a very fast-paced environment</li><li>Must be solutions oriented with analytical thinking and problem-solving.</li><li>Excellent project management and organization skills.</li></ul><p><strong>What We Offer:</strong></p><br><p>At Air Products, we work in an environment where diversity is essential, inclusion is our culture, and each person knows they belong and matter</p><br><p>We offer a competitive salary and benefits package, a culture of respect, challenge and innovation - with excellent opportunities for growth and development.</p><br><p>If that sounds interesting, then come and discover, care and accomplish by clicking APPLY now</p><br><p>#LI-MN1</p><br><p>We are the world's largest hydrogen producer with over 80 years of industrial gas experience. We are hydrogen and industrial gas experts delivering safe, end-to-end solutions, investing in real, clean energy projects at scale, and driving the industry forward to generate a cleaner future.</p><br><p>At Air Products, we work in an environment where we put safety first, diversity is essential, inclusion is our culture, and each person knows they belong and matter. To learn more, visit About Air Products.</p><br>"
  },
    {
    "id": 18,
    "title": "Lead Data Engineer",
    "company": "Almedia",
    "locations": "Berlin",
    "skills": "Python, SQL, Data Science, Data Analysis, Data Pipelines, GCP, Data Warehouse, BigQuery, APIs, Orchestration, Scripting Language, Data Lake",
    "posted_at": "2024-09-27",
    "is_remote": "False",
    "snippet_fragments": "  Collaborate across teams to integrate data-driven insights into daily operations,   Handle the operational aspects of the data warehouse,   Experience in data engineering (4 years),   Expertise in SQL and experience with scripting languages (e,   Experience in building and optimising data pipelines,   Knowledge and competence within Data Science & Data Analytics,   Strong analytical skills related to working with unstructured datasets,   Ability to lead projects and collaborate effectively with diverse teams,   An opportunity to work in an innovative",
    "description": "<p>Almedia helps leading brands in the digital space to acquire new customers. Users can find and test the latest games, apps, and products for rewards via our platforms.</p><br><p>With more than 25 million users since our launch in 2020, Almedia's Freecash.com is one of the fastest-growing providers and a leader in our industry. Our mission is to provide a win-win experience for both users and advertisers.</p><br><p>We are seeking a a <strong>Lead Data Engineer</strong> to spearhead the development of our data warehouse in the Google Cloud Platform (GCP). This is a unique opportunity to join a forward-thinking company that is dedicated to revolutionising the way brands engage with their audience.</p><br><p>Collaborating with data scientists, analysts, and backend developers, you will drive the evolution of our data-driven culture, ensuring our infrastructure scales with our growth.</p><br><p><strong>Responsibilities:</strong></p><ul><li>Architect and maintain our BigQuery data warehouse and data lakes, aligning with both current and future business needs.</li><li>Manage the ingestion of data from diverse sources, optimizing for efficiency and reliability.</li><li>Lead complex data transformations and implement orchestration tools, turning raw data into refined datasets ready for analysis and operational use.</li><li>Create and maintain APIs for internal use, facilitating real-time data interactions that support critical business processes.</li><li>Implement robust data cataloging and quality frameworks, ensuring the warehouse remains a trusted source for insightful decision-making.</li><li>Provide guidance to junior engineers, promoting a culture of excellence in data management practices.</li><li>Collaborate across teams to integrate data-driven insights into daily operations.</li><li>Handle the operational aspects of the data warehouse, including performance tuning, disaster recovery planning, and capacity management, to support scalability and reliability.</li></ul><p><strong>Requirements:</strong></p><ul><li>Experience in data engineering (4 years+), with a strong understanding of data warehousing concepts.</li><li>Expertise in SQL and experience with scripting languages (e.g. Python).</li><li>Experience in building and optimising data pipelines, architectures, and data sets.</li><li>Knowledge and competence within Data Science &amp; Data Analytics.</li><li>Strong analytical skills related to working with unstructured datasets.</li><li>Ability to lead projects and collaborate effectively with diverse teams.</li><li>Excellent problem-solving and communication skills.</li></ul><p><strong>Benefits:</strong></p><ul><li>An opportunity to work in an innovative, high-growth startup that has been profitable from day one.</li><li>A fast-paced and inclusive work environment in a team of highly motivated professionals.</li><li>Continuous learning and development opportunities.</li><li>Flexible work arrangements and a modern office space in the heart of Berlin.</li><li>Work from abroad policy</li></ul><p>Almedia is an equal opportunity employer, we embrace and celebrate diversity and encourage individuals from all backgrounds to apply.</p><br>"
  },
  {
    "id": 19,
    "title": "(Senior) Fraud Data Scientist / Data Analyst (f/d/m)",
    "company": "Digital Charging Solutions GmbH",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Data Analysis, Algorithms, Julia, R, Statistik",
    "posted_at": "2024-09-26",
    "is_remote": "True",
    "snippet_fragments": "    Take care of fraud expert knowledge management and education in the company,       You have a quantitative background in math,       You have experience in a quantitative role,       You have a strong interest in learning and personal development, You want more than the 3-days bootcamp,       You have programming experience in SQL and at least one analytical programming language like Python,       You have first experience in statistics and/or machine learning,       Developed and implemented (fraud) scoring models before,       Have experience in a senior level of a forensic department of consulting company (e,       Have experience as a Fraud Analyst at a public authority like police,         A unique opportunity combining the energy of a start-up with the power of BMW,         Working on products & services with a high social impact,         An international team of talented people who love what they do and live a collaborative spirit,         An open minded culture with room for growth and the freedom to bring in own ideas, Subsidized gym membership, subsidized office lunch benefit, a personal development budget for your professional growth, monthly mobility budget, offsite/ team events & much more, Modern, sunny offices in Berlin & Munich,         up to 3 days of home office in a week,         At DCS we acknowledge the value of diversity, We strive to create an inclusive work environment, We have the clear goal of driving diversity and inclusion across all dimensions and treat each applicant with the same respect and consideration",
    "description": "<p>We believe the future of mobility is electric. With the backing of BMW Group, Mercedes-Benz Mobility AG &amp; BP we are one of the leading global drivers of the change to e-mobility. DCS was founded on a simple idea: charging an EV should be as easy as it gets. Together, we are developing digital solutions that help connect the drivers with a broad network of charging stations and thereby enable our users a seamless charging experience.</p><br><p>Join our Financial Risk Management team and have a real impact on the success and safety of the company. You will take care of keeping DCS fraud-resistant and stay up-to-date with the ever-changing challenges of a digital company. You will take end-to-end ownership including project work and operational analytics.</p><br><p>You have an analytical mind set and a quantitative background. You come with programming experience and know about statistics and machine learning. But most importantly, you love to learn. May it be math, statistics, programming languages, model types, or algorithms - you are keen on gathering and applying knowledge. You do not need to bring vast fraud expertise, but you need to be willing to build it. If this sounds like you, then go ahead and apply. We are looking forward to your application.</p><br><p><strong>YOUR MISSION:</strong></p><ul><li>Build and maintain fraud detection models using supervised machine learning and anomaly detection.</li><li>Build and maintain a fraud detection monitoring and alerting system.</li><li>Operational and deep-dive data analysis.</li><li>Develop and improve regular reports and inform the management of the company.</li><li>Build a historic fraud case database.</li><li>Take care of fraud expert knowledge management and education in the company.</li></ul><p><strong>YOUR PROFILE:</strong></p><ul><li>You have a quantitative background in math, natural sciences, economics or similar.</li><li>You have experience in a quantitative role.</li><li>You have a strong interest in learning and personal development. You want more than the 3-days bootcamp.</li><li>You have programming experience in SQL and at least one analytical programming language like Python, R or Julia.</li><li>You have first experience in statistics and/or machine learning.</li><li>You have experience in a fraud prevention role in the line organization of a company (optional but beneficial: in a FinTech company)</li><li>Developed and implemented (fraud) scoring models before</li><li>Have experience in a senior level of a forensic department of consulting company (e.g. BIG 4 company)</li><li>Have experience as a Fraud Analyst at a public authority like police, Federal Criminal Police Office (BKA)</li></ul><p><strong>WE OFFER</strong></p><ul><li>A unique opportunity combining the energy of a start-up with the power of BMW, Mercedes Benz Mobility &amp; bp</li><li>Working on products &amp; services with a high social impact</li><li>An international team of talented people who love what they do and live a collaborative spirit</li><li>An open minded culture with room for growth and the freedom to bring in own ideas</li><li>Subsidized gym membership, subsidized office lunch benefit, a personal development budget for your professional growth, monthly mobility budget, offsite/ team events &amp; much more</li><li>Modern, sunny offices in Berlin &amp; Munich</li><li>up to 3 days of home office in a week</li></ul><p>... and of course the classics: delicious coffee &amp; tea, fresh fruits and an office dog friendly environment</p><br><p>At DCS we acknowledge the value of diversity, promote equality and challenge unfair discrimination. We strive to create an inclusive work environment, safe for anyone regardless of their gender identity, sexual orientation, abilities, ethnicity or race. We have the clear goal of driving diversity and inclusion across all dimensions and treat each applicant with the same respect and consideration.</p><br><p><strong>GET IN TOUCH!</strong></p><br><p>Excited about being a part of the transition to e-mobility?</p><br><p>Then send us your application with your CV and motivational statement including your earliest starting date and salary expectations.</p><br><p>Don't worry if you don't think you meet all requirements for this position. First and foremost, we value like-minded, passionate people who want to make an impact in shaping the future of e-mobility. We encourage you to apply and convince us why you would be a good fit in a cover letter.</p><br><p>We are looking forward to hearin</p><br>"
  },
  {
    "id": 20,
    "title": "Data Engineer",
    "company": "unybrands",
    "locations": "Berlin",
    "skills": "Python, SQL, Data Pipelines, GCP, Data Modeling, Data Warehouse, ETL, Airflow, DynamoDB, Cassandra, BigQuery, DevOps, MySQL, NoSQL, PostgreSQL, Terraform, CloudFormation, Looker, OLAP, Encryption, Software Development Lifecycle, IaC, Snowflake, Scripting Language, CD, Continuous Integration, APIs, Architektur",
    "posted_at": "2024-09-24",
    "is_remote": "False",
    "snippet_fragments": "  Experience working with data architectures for scalable and performant systems, Experience with dimensional data modeling, OLAP systems, and data warehousing concepts (star/snowflake schema, etc.).,  pipelines for efficient data movement and transformation.,   Hands-on experience with workflow management tools such as Apache Airflow,   Proficiency in Python and other relevant programming scripting languages for data processing,   Strong SQL expertise for querying large datasets,   Knowledge of API integration for extracting data from multiple sources (internal and external systems such as Amazon's API for FBA, Experience with CI/CD pipelines, automation scripts, and infrastructure-as-code tools (e.g., ,   Ability to implement data versioning and data quality checks,   Strong understanding of data privacy and compliance regulations like GDPR or CCPA, Ensure data governance best practices, including encryption, access controls, and audit trails.,   Expertise in implementing data quality checks,   Proficiency with monitoring tools for real-time visibility of data flows,   Experience with ecommerce/retail/supply chain data modeling is a big plus,   Experience with Amazon seller ecosystem is a big plus,   Ability to solve complex data challenges",
    "description": "<p>unybrands was founded in 2020 by a group of partners who shared a common vision to create the leading next-generation e-commerce platform for micro-brands. The company operates globally, with our headquarters located in Miami and additional teams based in Berlin, London, New York, Seattle and Shanghai.</p><br><p>unybrands acquires e-commerce brands that operate on and off Amazon. unybrands integrates the brands into its platform, optimizes the business operations and economics, and expands to new product lines and geographies. With us, e-commerce brands reach new heights with expert operators and infrastructure.</p><br><p><strong>About the role:</strong></p><br><p>The Data Engineer will collaborate closely with other Data Engineers, Software Development Engineers (SDEs), Analytics Engineers (AEs), Data Scientists (DSs) and Infrastructure Engineers (IEs) in the unybrands' technology team. This role will report directly to the Director of Data Engineering of the company.</p><br><p><strong>Responsibilities include - but not limited to:</strong></p><ul><li>Collaborate closely with other Data Engineers, Software Development Engineers (SDEs), Analytics Engineers (AEs), Data Scientists (DSs) and Infrastructure Engineers (IEs) in the Unybrands' technology team.</li><li>Focus on building a modular, flexible data engineering infrastructure that we can iteratively improve on continuously. Your customers will include eCommerce, marketing, supply chain, finance.</li><li>Business development, and legal (i.e., essentially every part of Unybrands).</li><li>Understand that our data is a strategic resource, and will build data products to support every aspect of our business.</li><li>Build Unybrands' data model(s) in addition to our data infrastructure (in collaboration with the Director of Analytics and Head of Infrastructure Engineering.</li></ul><p><strong>Requirements</strong></p><br><p><strong>Technical Expertise</strong></p><br><p><strong>Data Architecture and Modeling</strong>:</p><ul><li>Experience working with data architectures for scalable and performant systems.</li><li>Experience with dimensional data modeling, OLAP systems, and data warehousing concepts (star/snowflake schema, etc.).</li><li>Strong experience with <strong>GCP</strong></li><li>Experience with <strong>Big Query, Looker Studio</strong></li><li>Experience with <strong>NoSQL</strong> databases (e.g., DynamoDB, Cassandra) and <strong>SQL</strong> databases (e.g., PostgreSQL, MySQL).</li><li>Design, implement, and optimize <strong>ETL</strong> pipelines for efficient data movement and transformation.</li><li>Hands-on experience with workflow management tools such as <strong>Apache Airflow</strong></li><li>Proficiency in <strong>Python</strong> and other relevant programming scripting languages for data processing.</li><li>Strong SQL expertise for querying large datasets</li><li>Knowledge of API integration for extracting data from multiple sources (internal and external systems such as Amazon's API for FBA, sales data, etc.).</li></ul><p><strong>DevOps and Automation</strong>:</p><ul><li>Experience with CI/CD pipelines, automation scripts, and infrastructure-as-code tools (e.g., <strong>Terraform</strong>, <strong>CloudFormation</strong>).</li><li>Ability to implement <strong>data versioning</strong> and <strong>data quality checks</strong>.</li></ul><p><strong>Data Privacy</strong>:</p><ul><li>Strong understanding of data privacy and compliance regulations like <strong>GDPR</strong> or <strong>CCPA</strong>.</li><li>Ensure data governance best practices, including encryption, access controls, and audit trails.</li></ul><p><strong>Monitoring and Observability</strong>:</p><ul><li>Expertise in implementing data quality checks, monitoring data pipelines, and ensuring that systems are reliable and efficient.</li><li>Proficiency with monitoring tools for real-time visibility of data flows.</li><li>Experience with ecommerce/retail/supply chain data modeling is a big plus.</li><li>Experience with Amazon seller ecosystem is a big plus.</li></ul><p><strong>Communication Skills</strong></p><ul><li>Ability to solve complex data challenges, propose innovative solutions for scaling and optimizing data architecture, and proactively drive improvements.</li><li>Ability to adapt to fast-paced, constantly evolving scale-up environment</li><li>Capable of handling well defined projects and prioritizing based on business impact.</li><li>Proficient in English</li></ul><p>unybrands is an equal opportunity employer and considers all applicants for employment without any regard to race, skin color, religion, gender identity, sexual orientation, and age. Nor are applicants discriminated against based on disability or protected classes.</p><br>"
  },
  {
    "id": 21,
    "title": "Data Scientist - Startup Berlin",
    "company": "Cherry Ventures",
    "locations": "Berlin",
    "skills": "Python, Machine Learning, Data Science, AWS, Data Pipelines, AI, Spark, Jenkins, Algorithms, Cloud Platforms, PySpark, Databricks, Recommender Systems, CD, Continuous Integration, Empower, Git, NLP, Klimatechnik",
    "posted_at": "2024-09-24",
    "is_remote": "False",
    "snippet_fragments": "  2 technical 1 hour long interviews, Before sending the offer, we ask you to provide 2-3 contacts for us to do some reference checks.,   Congratulations! We are convinced by your skills and personality and see a great fit! You will get an offer from us including an appropriate share package, We are moving fast, and we also want to grow our team fast  that is why we are trying to conclude the whole process within a short time (2-4 weeks).,  We work from our beautiful and centrally-located Berlin office ,     We believe working on-site is crucial in our stage to foster ideas and communication,  once a year to escape the Berlin winter,  Top of the range tech setup,  Competitive comp and meaningful equity in rapidly growing startup,   you'd like to be part of a rocket ship backed by top-tier investors from day one,   digitize an old economy with cutting-edge AI technology,   while enjoying the adventurous and demanding road of venture building,   in a team of motivated A-players who push hard to make this a reality,   We go the extra mile to leave a dent,  We work hard to make our vision become reality.,  We are here to enjoy the ride and raise the bar.,  We persevere during challenges and stay optimistic.,  We are results-oriented and take end-to-end responsibility.,  We initiate new ideas and don't stay idle.,  We prioritise action over processes and processes over chaos.,   We are obsessed with our customer,  We care about our customers and prioritise their needs.,  We underpromise and overdeliver on customer needs.,  We understand the problem before we seek solutions.",
    "description": "<p><strong>DATA SCIENTIST</strong></p><br><p><strong>CHERRY VENTURES IS SUPPORTING OUR PORTFOLIO WITH THIS HIRE</strong></p><br><p><strong>BERLIN BASED - M/F/D - FULL-TIME</strong></p><br><p><strong>WHAT WE DO AT PLATO</strong></p><br><p>Plato is building the digital backbone of the global trade economy. Starting with the $48T wholesale industry, we empower the modern wholesaler to connect their people and data in a single analytics and workflow hub. By leveraging data science and AI, we automate workflows and combat labor shortages, making SMB wholesalers competitive with large corporations.</p><br><p><strong>WHY WE DO WHAT WE DO</strong></p><br><p><strong>The future of wholesale is data-driven.</strong> Unlike popular opinion, Industrial SMEs are ready to make the step to become more proactive in their processes but lack the technology to steer them to success. Our founders come from a wholesale family and gathered a rock star team of ex-Big Tech, VC, and top-tier consulting companies to reshape the operations of this $48tn industry. Our initial product leverages cutting-edge data science to provide customized demand forecasts and product recommendations combined with intelligent workflow automation.</p><br><p><strong>We are about to create category-defining software.</strong> Our primary customers are C-suite executives within large-scale wholesale and distribution businesses. We are committed to helping them enhance their decision-making processes and optimize their operations through the smart use of their data - bringing their operations into the 21st century! But don't just hear it from us! We are supported by a list of top-tier EU &amp; US VCs, advisors, and angels providing insights from some of the best SME tech companies such as Miro, Celonis, Personio, Workday, Forto, and Microsoft.</p><br><p><strong>WHAT WE'RE LOOKING FOR</strong></p><br><p>As a Data Scientist at Plato you will be tackling the complex challenge of building versatile models that serve multiple industries, ranging from construction and steel to technical and HVAC wholesalers. Each industry presents unique data sets and requires a tailored approach.</p><br><p>You will have the opportunity to develop a variety of models, such as recommendation engines, dynamic pricing systems, churn prediction models, and customer segmentation algorithms. You will be responsible for the entire lifecycle of these models, from creation to deployment, and ensuring they scale across different industries.</p><br><p>Our platform generates a wealth of data from user interactions, and a key part of your role will be feeding this data back into the models to continuously improve their performance. You'll collaborate closely with our data engineering and product teams to ensure our portfolio of data products provide value to our users.</p><br><p><strong>WHAT YOU'D BE WORKING ON</strong></p><ul><li>Develop, test, and deploy a wide range of machine learning models, including recommendation systems, dynamic pricing models, churn prediction algorithms, and customer categorisation systems.</li><li>Tackle the challenge of building adaptable models that can be customized across various industries, such as construction, technical, and HVAC wholesale, ensuring that industry-specific needs are met.</li><li>Continuously refine and update models based on real-time platform data and customer feedback to ensure they evolve with our users' needs.</li><li>Collaborate with data engineers and ML engineers to build efficient data pipelines that feed into and optimise machine learning models.</li><li>Recommendations System knowledge</li><li>Design experiments to assess model performance and iteratively improve accuracy and scalability.</li><li>Implement automated model retraining and monitoring systems to ensure that models remain relevant and continue to perform in production environments.</li><li>Work closely with the product and engineering teams to align model outputs with business goals and deliver actionable insights to customers.</li><li>Build processes to efficiently manage the lifecycle of machine learning models, including versioning, experimentation, and reproducibility across different deployments.</li></ul><p><strong>WHAT YOU BRING ALONG</strong></p><ul><li>3+ years of experience in data science, with a strong emphasis on machine learning model development and deployment.</li><li><br><strong>Hands-on experience with recommender systems is highly valued-this will be a core component of the role.</strong><br></li><li>A strong generalist mindset, capable of owning the full product lifecycle-from translating business problems into data science solutions to building and maintaining models in production.</li><li>Experience in building and running machine learning models end-to-end; you will own your models, ensuring they run smoothly in production and are continuously optimised.</li><li>Experience with MLFlow for model tracking and lifecycle management is desirable.</li><li>Hands-on experience with data engineering tools and platforms; a background in Databricks is highly valued.</li><li>Familiarity with NLP techniques is a plus, especially for customer segmentation and categorisation tasks.</li><li>Ability to wear multiple hats and thrive in a startup environment where flexibility and initiative are key.</li><li>Proficiency in German is plus.</li><li>Based in Germany/EU: <strong>We are unfortunately not able to sponsor visas - for this role, you will need to possess an existing EU/German work permit.</strong><br></li></ul><p><strong>\ufe0f</strong> <strong>THE TOOLS YOU WILL BE USING</strong></p><ul><li>Python</li><li>PySpark</li><li>Databricks</li><li>MLFlow</li><li>Model Serving Technologies</li><li>CI/CD Tools (e.g., Jenkins, Git)</li><li>Cloud Platforms (AWS)</li><li>Data Engineering Tools (Apache Spark, DBT)</li></ul><p><strong>HIRING PROCESS</strong></p><br><p><strong>Step 1: Intro call (30 min.) - Oliver</strong></p><ul><li>Intro call with one of the founders to get to know each other and introduce Plato.</li></ul><p><strong>Step 2: System design call - Oliver + Nikolai</strong></p><ul><li>Technical interview with Nikolai, Backend Lead</li></ul><p><strong>Step 3: Technical fit - in office</strong></p><ul><li>2 technical 1 hour long interviews</li></ul><p><strong>Step 4: Meet the founders</strong></p><ul><li>Meet the other co-founders</li></ul><p><strong>Step 5: Reference checks</strong></p><ul><li>Before sending the offer, we ask you to provide 2-3 contacts for us to do some reference checks.</li></ul><p><strong>Step 6: Offer</strong></p><ul><li>Congratulations! We are convinced by your skills and personality and see a great fit! You will get an offer from us including an appropriate share package.</li></ul><p>We are moving fast, and we also want to grow our team fast - that is why we are trying to conclude the whole process within a short time (2-4 weeks).</p><br><p><strong>\ufe0f OUR WAY OF WORKING</strong></p><ul><li><strong>Office:</strong> We work from our beautiful and centrally-located Berlin office</li><li>We believe working <strong>on-site</strong> is crucial in our stage to foster ideas and communication</li><li>We are, however, open to <strong>remote work</strong> once a year to escape the Berlin winter</li><li><strong>Team:</strong> Regular team events and lunches</li><li><strong>Tech:</strong> Top of the range tech setup</li><li><strong>Package:</strong> Competitive comp and meaningful equity in rapidly growing startup</li></ul><p><strong>YOU SHOULD JOIN PLATO IF,</strong></p><ul><li>you'd like to be part of a rocket ship backed by top-tier investors from day one,</li><li>digitize an old economy with cutting-edge AI technology,</li><li>while enjoying the adventurous and demanding road of venture building,</li><li>in a team of motivated A-players who push hard to make this a reality</li></ul><p><strong>OUR VALUES</strong></p><ul><li><strong>We go the extra mile to leave a dent.</strong></li><li><strong>Hustle:</strong> We work hard to make our vision become reality.</li><li><strong>Purpose:</strong> We are here to enjoy the ride and raise the bar.</li><li><strong>Resilience:</strong> We persevere during challenges and stay optimistic.</li><li><strong>We are drivers, not the passengers.</strong></li><li><strong>Ownership:</strong> We are results-oriented and take end-to-end responsibility.</li><li><strong>Proactivity:</strong> We initiate new ideas and don't stay idle.</li><li><strong>Velocity:</strong> We prioritise action over processes and processes over chaos.</li><li><strong>We are obsessed with our customer.</strong></li><li><strong>Empathy:</strong> We care about our customers and prioritise their needs.</li><li><strong>Reliability:</strong> We underpromise and overdeliver on customer needs.</li><li><strong>Humility:</strong> We understand the problem before we seek solutions.</li><li><strong>We shoot for the moon no matter if we fail.</strong></li><li><strong>Boldness:</strong> We dare to push the boundaries of what is possible.</li><li><strong>Agility:</strong> We think critically and quickly adjust to changing circumstances.</li><li><strong>Growth:</strong> We stay curious and learn from our mistakes.</li><li><strong>We count on everybody's voice.</strong></li><li><strong>Respect:</strong> We act with empathy, encourage new ideas and keep a low ego.</li><li><strong>Transparency:</strong> We adopt an honest, direct yet polite communication style.</li><li><strong>Trust:</strong> We assume every team member acts with best intentions.</li></ul><p>Cherry Ventures is an equal opportunity employer and values diversity. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, or disability status.</p><br>"
  },
  {
    "id": 22,
    "title": "Data Scientist - Startup Berlin",
    "company": "Cherry Ventures",
    "locations": "Berlin",
    "skills": "Python, Machine Learning, Data Science, AWS, Data Pipelines, AI, Spark, Jenkins, Algorithms, Cloud Platforms, PySpark, Databricks, Recommender Systems, CD, Continuous Integration, Empower, Git, NLP, Klimatechnik",
    "posted_at": "2024-09-24",
    "is_remote": "False",
    "snippet_fragments": "Data Engineering Tools (Apache Spark, DBT),  Intro call with one of the founders to get to know each other and introduce Plato,  System design call - Oliver  Nikolai , Technical interview with Nikolai, Backend Lead,  2 technical 1 hour long interviews, Before sending the offer, we ask you to provide 2-3 contacts for us to do some reference checks.,  Congratulations! We are convinced by your skills and personality and see a great fit! You will get an offer from us including an appropriate share package,  We are moving fast, and we also want to grow our team fast  that is why we are trying to conclude the whole process within a short time (2-4 weeks),  We believe working on-site is crucial in our stage to foster ideas and communication, We are, however, open to remote work once a year to escape the Berlin winter,  youd like to be part of a rocket ship backed by top-tier investors from day one,  digitize an old economy with cutting-edge AI technology,  while enjoying the adventurous and demanding road of venture building,  in a team of motivated A-players who push hard to make this a reality,  We go the extra mile to leave a dent,  We work hard to make our vision become reality,  We are here to enjoy the ride and raise the bar,  We persevere during challenges and stay optimistic, We are drivers, not the passengers.,  We are results-oriented and take end-to-end responsibility,  We initiate new ideas and dont stay idle,  We prioritise action over processes and processes over chaos,  We are obsessed with our customer",
    "description": "<p>Data Scientist</p><br><p>Cherry Ventures is supporting our portfolio with this hire</p><br><p>Berlin based - m/f/d - full-time</p><br><p>What we do at Plato</p><br><p>Plato is building the digital backbone of the global trade economy. Starting with the $48T wholesale industry, we empower the modern wholesaler to connect their people and data in a single analytics and workflow hub. By leveraging data science and AI, we automate workflows and combat labor shortages, making SMB wholesalers competitive with large corporations.</p><br><p>Why we do what we do</p><br><p>The future of wholesale is data-driven. Unlike popular opinion, Industrial SMEs are ready to make the step to become more proactive in their processes but lack the technology to steer them to success. Our founders come from a wholesale family and gathered a rock star team of ex-Big Tech, VC, and top-tier consulting companies to reshape the operations of this $48tn industry. Our initial product leverages cutting-edge data science to provide customized demand forecasts and product recommendations combined with intelligent workflow automation.</p><br><p>We are about to create category-defining software. Our primary customers are C-suite executives within large-scale wholesale and distribution businesses. We are committed to helping them enhance their decision-making processes and optimize their operations through the smart use of their data - bringing their operations into the 21st century! But don't just hear it from us! We are supported by a list of top-tier EU &amp; US VCs, advisors, and angels providing insights from some of the best SME tech companies such as Miro, Celonis, Personio, Workday, Forto, and Microsoft.</p><br><p>What we're looking for</p><br><p>As a Data Scientist at Plato you will be tackling the complex challenge of building versatile models that serve multiple industries, ranging from construction and steel to technical and HVAC wholesalers. Each industry presents unique data sets and requires a tailored approach.</p><br><p>You will have the opportunity to develop a variety of models, such as recommendation engines, dynamic pricing systems, churn prediction models, and customer segmentation algorithms. You will be responsible for the entire lifecycle of these models, from creation to deployment, and ensuring they scale across different industries.</p><br><p>Our platform generates a wealth of data from user interactions, and a key part of your role will be feeding this data back into the models to continuously improve their performance. You'll collaborate closely with our data engineering and product teams to ensure our portfolio of data products provide value to our users.</p><br><p>What you'd be working on</p><ul><li>Develop, test, and deploy a wide range of machine learning models, including recommendation systems, dynamic pricing models, churn prediction algorithms, and customer categorisation systems.</li><li>Tackle the challenge of building adaptable models that can be customized across various industries, such as construction, technical, and HVAC wholesale, ensuring that industry-specific needs are met.</li><li>Continuously refine and update models based on real-time platform data and customer feedback to ensure they evolve with our users' needs.</li><li>Collaborate with data engineers and ML engineers to build efficient data pipelines that feed into and optimise machine learning models.</li><li>Recommendations System knowledge</li><li>Design experiments to assess model performance and iteratively improve accuracy and scalability.</li><li>Implement automated model retraining and monitoring systems to ensure that models remain relevant and continue to perform in production environments.</li><li>Work closely with the product and engineering teams to align model outputs with business goals and deliver actionable insights to customers.</li><li>Build processes to efficiently manage the lifecycle of machine learning models, including versioning, experimentation, and reproducibility across different deployments.<br> What you bring along</li><li>3+ years of experience in data science, with a strong emphasis on machine learning model development and deployment.</li><li>Hands-on experience with recommender systems is highly valued-this will be a core component of the role.</li><li>A strong generalist mindset, capable of owning the full product lifecycle-from translating business problems into data science solutions to building and maintaining models in production.</li><li>Experience in building and running machine learning models end-to-end; you will own your models, ensuring they run smoothly in production and are continuously optimised.</li><li>Experience with MLFlow for model tracking and lifecycle management is desirable.</li><li>Hands-on experience with data engineering tools and platforms; a background in Databricks is highly valued.</li><li>Familiarity with NLP techniques is a plus, especially for customer segmentation and categorisation tasks.</li><li>Ability to wear multiple hats and thrive in a startup environment where flexibility and initiative are key.</li><li>Proficiency in German is plus.</li><li>Based in Germany/EU: We are unfortunately not able to sponsor visas - for this role, you will need to possess an existing EU/German work permit.<br> \ufe0f The tools you will be using</li><li>Python</li><li>PySpark</li><li>Databricks</li><li>MLFlow</li><li>Model Serving Technologies</li><li>CI/CD Tools (e.g., Jenkins, Git)</li><li>Cloud Platforms (AWS)</li><li>Data Engineering Tools (Apache Spark, DBT)<br> Hiring Process</li></ul><p><strong>Step 1:</strong> Intro call (30 min.) - Oliver</p><ul><li>Intro call with one of the founders to get to know each other and introduce Plato.<br><strong>Step 2:</strong> System design call - Oliver + Nikolai</li><li>Technical interview with Nikolai, Backend Lead<br><strong>Step 3:</strong> Technical fit - in office</li><li>2 technical 1 hour long interviews<br><strong>Step 4:</strong> Meet the founders</li><li>Meet the other co-founders<br><strong>Step 5:</strong> Reference checks</li><li>Before sending the offer, we ask you to provide 2-3 contacts for us to do some reference checks.<br><strong>Step 6:</strong> Offer</li><li>Congratulations! We are convinced by your skills and personality and see a great fit! You will get an offer from us including an appropriate share package.<br> We are moving fast, and we also want to grow our team fast - that is why we are trying to conclude the whole process within a short time (2-4 weeks).</li></ul><p>\ufe0f Our way of working</p><ul><li>Office: We work from our beautiful and centrally-located Berlin office</li><li>We believe working on-site is crucial in our stage to foster ideas and communication</li><li>We are, however, open to remote work once a year to escape the Berlin winter</li><li>Team: Regular team events and lunches</li><li>Tech: Top of the range tech setup</li><li>Package: Competitive comp and meaningful equity in rapidly growing startup<br> You should join Plato if,</li><li>you'd like to be part of a rocket ship backed by top-tier investors from day one,</li><li>digitize an old economy with cutting-edge AI technology,</li><li>while enjoying the adventurous and demanding road of venture building,</li><li>in a team of motivated A-players who push hard to make this a reality<br> Our Values</li><li>We go the extra mile to leave a dent.<br><strong>1. Hustle:</strong> We work hard to make our vision become reality.</li></ul><p><strong>2. Purpose:</strong> We are here to enjoy the ride and raise the bar.</p><br><p><strong>3. Resilience:</strong> We persevere during challenges and stay optimistic.</p><ul><li>We are drivers, not the passengers.<br><strong>1. Ownership:</strong> We are results-oriented and take end-to-end responsibility.</li></ul><p><strong>2. Proactivity:</strong> We initiate new ideas and don't stay idle.</p><br><p><strong>3. Velocity:</strong> We prioritise action over processes and processes over chaos.</p><ul><li>We are obsessed with our customer.<br><strong>1. Empathy:</strong> We care about our customers and prioritise their needs.</li></ul><p><strong>2. Reliability:</strong> We underpromise and overdeliver on customer needs.</p><br><p><strong>3. Humility:</strong> We understand the problem before we seek solutions.</p><ul><li>We shoot for the moon no matter if we fail.<br><strong>1. Boldness:</strong> We dare to push the boundaries of what is possible.</li></ul><p><strong>2. Agility:</strong> We think critically and quickly adjust to changing circumstances.</p><br><p><strong>3. Growth:</strong> We stay curious and learn from our mistakes.</p><ul><li>We count on everybody's voice.<br><strong>1. Respect:</strong> We act with empathy, encourage new ideas and keep a low ego.</li></ul><p><strong>2. Transparency:</strong> We adopt an honest, direct yet polite communication style.</p><br><p><strong>3. Trust:</strong> We assume every team member acts with best intentions.</p><br><p>Cherry Ventures is an equal opportunity employer and values diversity. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, or disability status.</p><br>"
  },
  {
    "id": 23,
    "title": "Data Engineer Microsoft (all genders)",
    "company": "EXXETA",
    "locations": "Berlin",
    "skills": "Cloud, Azure, Data Modeling, Data Warehouse, Power BI, OLAP, Kimball, Databricks, Data Lake, Vault",
    "posted_at": "2024-09-24",
    "is_remote": "True",
    "snippet_fragments": "Du bringst fundierte Berufserfahrung in der Beratungsbranche oder In-house-Position sowie ein abgeschlossenes IT-Studium oder eine vergleichbare Qualifikation mit,  Von der Anforderungsanalyse, \u00fcber die Konzeption, hin zur Datenmodellierung, bis zur fertigen Anwendung  du kannst uns mit deinen bisherigen Projekterfolgen in der Gestaltung von modernen Data Warehouse Systemen \u00fcberzeugen., Du hast Erfahrungen im Bereich MS SQL-Server, MS Azure Cloud Technologien, bringst Projekterfahrung in den Komponenten Azure Data Factory, Azure Databricks und Azure Datalake mit und das Dashboarding mittels MS Power BI ist dir auch nicht fremd? Perfekt! Das klingt nach einem Match.,  Modernen Datenlandschaften (Data Lake, Data Warehouse, OLAP Modelle) & Modellierungsans\u00e4tzen (Data Vault, Kimball, Inmon) geh\u00f6ren zu deinem daily business genauso wie eine stakeholderorientierte Kommunikation.,     Echte Challenges f\u00fcr dein Wachstum  Weiterbildungsbudget inklusive,     Mobiles Arbeiten? Nachteule oder fr\u00fcher Vogel? F\u00fcr deine optimale Work-Life-Balance gibt es genug Gestaltungsraum,     Bleib gesund - neben betrieblicher Krankenversicherung gibt es ein Gesundheitsbudget f\u00fcr individuelle Leistungen, Wer legt die meisten Kilometer zur\u00fcck?, Herkunft, Alter, Vorlieben  spielt bei uns keine Rolle., Wir m\u00f6chten ein diverses Team sein, Deshalb ermutigen wir dich, dich auch dann zu bewerben, wenn du glaubst, nicht alle Anforderungen zu erf\u00fcllen.",
    "description": "<p><strong>Bei Exxeta fordern wir das traditionelle Konzept von Beratung und Tech heraus. \u00dcber 1200 Kolleg:innen an verschiedenen Standorten schaffen jeden Tag gemeinsam digitale L\u00f6sungen, ver\u00e4ndern M\u00e4rkte und Mindsets - angetrieben von unserer Leidenschaft f\u00fcr Technologie, unserem Teamspirit und dem Drang, echten Impact zu schaffen. Hightech with a heartbeat eben.</strong></p><br><p><strong>Dein Herz schl\u00e4gt Data. Egal welche cloudbasierten Technologien im Microsoft Data &amp; Analytics-Umfeld - du brennst daf\u00fcr unsere Kunden auf dem Weg von Microsoft on-premise L\u00f6sungen in die modernen Azure Cloud Services zu begleiten. \u00dcberf\u00fchre mit uns Datawarehouse Architekturen in state-of-the-art Cloud-Technologien der Microsoft Azure Cloud Plattform und schaffe mit uns L\u00f6sungen, die etwas bewegen.</strong></p><br><p><strong>WAS ERWARTET DICH</strong></p><ul><li>Du liebst es Kunden bei der Gestaltung &amp; Migration ihrer Microsoft Datenplattform strategische und konzeptionelle zu beraten? Dann bist du bei uns genau richtig.</li><li>Beweise dein Talent beim Designen von hybriden Datenarchitekturen mit MS SQL Server und MS Azure Cloud Technologien.</li><li>\u00dcbernimm die technische F\u00fchrung und bringe monolithischen Data Warehouse Architekturen in moderne cloudbasierte Datenplattformen.</li><li>Wir packen gemeinsam an - zusammen mit einem Team aus Top-Managementberater:innen, innovativen Entwickler:innen und exzellenten Informatiker:innen arbeiten wir an neuen L\u00f6sungen.</li></ul><p><strong>WAS ERWARTEN WIR VON DIR</strong></p><ul><li><br><strong>Pers\u00f6nlicher Background:</strong> Du bringst fundierte Berufserfahrung in der Beratungsbranche oder In-house-Position sowie ein abgeschlossenes IT-Studium oder eine vergleichbare Qualifikation mit</li><li><br><strong>Fachkompetenz:</strong> Von der Anforderungsanalyse, \u00fcber die Konzeption, hin zur Datenmodellierung, bis zur fertigen Anwendung - du kannst uns mit deinen bisherigen Projekterfolgen in der Gestaltung von modernen Data Warehouse Systemen \u00fcberzeugen.</li><li><br><strong>Technische Vielseitigkeit:</strong> Du hast Erfahrungen im Bereich MS SQL-Server, MS Azure Cloud Technologien, bringst Projekterfahrung in den Komponenten Azure Data Factory, Azure Databricks und Azure Datalake mit und das Dashboarding mittels MS Power BI ist dir auch nicht fremd? Perfekt! Das klingt nach einem Match.</li><li><br><strong>Landschaftsexpertise:</strong> Modernen Datenlandschaften (Data Lake, Data Warehouse, OLAP Modelle) &amp; Modellierungsans\u00e4tzen (Data Vault, Kimball, Inmon) geh\u00f6ren zu deinem daily business genauso wie eine stakeholderorientierte Kommunikation.</li><li><br><strong>Let's talk</strong>: Du sprichst flie\u00dfend Deutsch und Englisch - super, dann findest du dich bei Exxeta bestens zurecht.</li></ul><p><strong>WARUM EXXETA</strong></p><ul><li>Echte Challenges f\u00fcr dein Wachstum - Weiterbildungsbudget inklusive</li><li>F\u00fcr deinen perfekten Start setzen wir auf unser Mentor:innenprogramm</li><li>Mobiles Arbeiten? Nachteule oder fr\u00fcher Vogel? F\u00fcr deine optimale Work-Life-Balance gibt es genug Gestaltungsraum.</li><li>Bleib gesund - neben betrieblicher Krankenversicherung gibt es ein Gesundheitsbudget f\u00fcr individuelle Leistungen</li><li>Mit dem XX-Bike ins B\u00fcro: Wir bezuschussen Fahrrad- und E-Bike-Leasing. Wer legt die meisten Kilometer zur\u00fcck?</li></ul><p><strong>Wir sind ein Zuhause f\u00fcr Tech-Lover:innen und Macher:innen. Herkunft, Alter, Vorlieben - spielt bei uns keine Rolle.</strong></p><br><p><strong>Du glaubst, nicht alle Punkte zu 100 % zu erf\u00fcllen? Studien zeigen, dass sich Angeh\u00f6rige historisch unterrepr\u00e4sentierter Gruppen in der Regel nur dann auf Stellen bewerben, wenn sie meinen, 100% aller Anforderungen zu erf\u00fcllen. Wir m\u00f6chten ein diverses Team sein, sch\u00e4tzen eine Vielfalt an Perspektiven. Deshalb ermutigen wir dich, dich auch dann zu bewerben, wenn du glaubst, nicht alle Anforderungen zu erf\u00fcllen.</strong></p><br><p><strong>Wir m\u00f6chten dich kennenlernen und erfahren, was du mitbringst.</strong></p><br><p>Jessica Nikolow</p><br><p>Senior Recruiting Expert</p><br><p>+49 172 7254796</p><br>"
  },
  {
    "id": 24,
    "title": "Senior Data Engineer (all genders)",
    "company": "diconium group",
    "locations": "Berlin",
    "skills": "Python, Machine Learning, Data Science, AWS, Data Pipelines, GCP, AI, Azure, Data Modeling, Big Data, Flink, Hadoop, Kafka, Spark, Java, Kanban, Scala, Scrum, Databricks",
    "posted_at": "2024-09-21",
    "is_remote": "False",
    "snippet_fragments": "    Praktische Erfahrung mit Cloud-basierten Datenplattformen (Azure,     Erfahrung in der fachlichen F\u00fchrung und der Beratung von Kunden zu technischen Konzepten,     Kenntnisse in der Entwicklung von Machine Learning Pipelines und Modellen,     Erfahrung im Projektmanagement mit agilen Methoden wie SAFe,     Erfahrung in der Implementierung von Data Quality- und Data Governance-Frameworks, Volkswagen, Bosch, Kodak Alaris oder SICK,      In einem modernen und flexiblen Arbeitsumfeld leben wir unsere 4 Kernwerte #courage, Innovation & Strategy, Customer Experience, Data & AI, Commerce Solutions, Technology Solutions, Digital Transformation",
    "description": "<p>Berlin</p><br><p>Diconium ist Spezialist in den Gebieten Daten und K\u00fcnstliche Intelligenz. Ob in den Bereichen Search, Social und Content, Personalisierung und Analytics, Data Engineering oder Data Science - unsere Expertise hilft unseren Kunden, die richtigen Daten zum richtigen Zeitpunkt zu erheben, Services und Angebote zu prognostizieren und somit datengetriebene Entscheidungen zu f\u00e4llen. Werde Teil der diconium data-Familie und unterst\u00fctze uns auf unserer Data &amp; AI-Reise!</p><br><p><strong>DAS ERWARTET DICH</strong></p><ul><li>Du entwirfst und entwickelst skalierbare Data Pipelines, um gro\u00dfe Mengen an Daten effizient zu verarbeiten und zu analysieren.</li><li>Du bewertest und implementierst neue Technologien und Tools im Bereich Data Engineering, um die Effizienz und Leistung unserer Datenverarbeitungsprozesse kontinuierlich zu verbessern.</li><li>Du unterst\u00fctzt unsere Kunden bei der einfachen und transparenten Beschaffung der notwendigen Daten, um intelligente Data-Produkte in verschiedenen Bereichen (Mobilit\u00e4t, Automobil, Industrie, Consumer, Finanzwesen und Non-Profit-Organisationen) zu entwickeln.</li><li>Du arbeitest eng mit Data Scientists und Analysten zusammen, identifizierst potenzielle Datenquellen und evaluierst deren Nutzen, um die Anforderungen an die Daten zu verstehen und geeignete L\u00f6sungen zu entwickeln.</li><li>Du teilst dein Fachwissen und deine Erfahrungen mit anderen Teammitgliedern, tr\u00e4gst zum Wissensaustausch und zur Weiterentwicklung des Teams bei und \u00fcbernimmst eine fachliche F\u00fchrungsrolle innerhalb des Teams.</li><li>Du entwickelst und pflegst Dokumentationen zu Data Engineering-Prozessen, Best Practices und Technologien.</li></ul><p><strong>DAS BRINGST DU MIT</strong></p><br><p><strong>Must haves:</strong></p><ul><li>Relevante Berufserfahrung von mindestens 5 Jahren im Bereich Data Engineering</li><li>Fundierte Kenntnisse in mindestens einer Programmiersprache (wie Python, Java oder Scala) und Erfahrung mit Big Data Technologien (wie Hadoop, Spark oder Kafka)</li><li>Fundierte Kenntnisse in Batch- und Real-Time Data Processing Frameworks wie z.B. Apache Spark, Apache Flink oder \u00c4hnlichen</li><li>Praktische Erfahrung mit Cloud-basierten Datenplattformen (Azure, AWS oder GCP), Verst\u00e4ndnis von Datenmodellierung &amp; Datenarchitektur und Erfahrung mit Databricks</li><li>Erfahrung in der fachlichen F\u00fchrung und der Beratung von Kunden zu technischen Konzepten</li></ul><p><strong>Nice to have:</strong></p><ul><li>Kenntnisse in der Entwicklung von Machine Learning Pipelines und Modellen</li><li>Erfahrung im Projektmanagement mit agilen Methoden wie SAFe, Scrum oder Kanban</li><li>Vertrautheit mit DataOps-Praktiken und DevOps-Konzepten</li><li>Erfahrung in der Implementierung von Data Quality- und Data Governance-Frameworks</li></ul><p><strong>DICONIUM AUF EINEN BLICK</strong></p><br><p><strong>KUNDEN</strong></p><br><p>u.a. Volkswagen, Bosch, Kodak Alaris oder SICK</p><br><p><strong>WERTE</strong></p><br><p>In einem modernen und flexiblen Arbeitsumfeld leben wir unsere 4 Kernwerte #courage, #mindfulness, #collaboration und #impact.</p><br><p><strong>PORTFOLIO</strong></p><br><p>Innovation &amp; Strategy, Customer Experience, Data &amp; AI, Commerce Solutions, Technology Solutions, Digital Transformation</p><br><p><strong>STANDORTE</strong></p><br><p>In diversen, interdisziplin\u00e4ren Teams arbeiten wir auf vielf\u00e4ltige Weise zusammen - ob remote oder vor Ort in einem unserer weltweiten B\u00fcros in Europa, Nordamerika und Asien.</p><br><p><strong>MITARBEITENDE</strong></p><br><p>\u00fcber 2.000 Menschen aus \u00fcber 70 Nationen</p><br>"
  },
  {
    "id": 25,
    "title": "Data Engineer (m/w/d)",
    "company": "admi",
    "locations": "Berlin",
    "skills": "Python, AWS, Cloud, GCP, ETL, Airflow, Kafka, BigQuery, Dashboards, PostgreSQL, Jupyter, Data Lake, AWS S3, Photovoltaik",
    "posted_at": "2024-09-21",
    "is_remote": "False",
    "snippet_fragments": "  You have experience in designing and building ETL pipelines and familiarity with multiple technologies in this area,   You have extensive experience in building and maintaining Data Lakes and Data Warehouses,   You are familiar with cloud providers such as GCP and AWS,   You have proficiency in storage solutions like BigQuery,   You are experienced in working with Kafka,   You know all about data governance,   You have a high degree of self-motivation and self-organization,   Broad network of mentors that we make available to you,   Flexible working from our office or mobile,  admi Kommunal GmbH - Gemeinsam mit St\u00e4dten und Gemeinden treiben wir die kommunale Energiewende voran,  Wir unterst\u00fctzen Kommunen bei der Planung und Umsetzung ihrer energiepolitischen Ambitionen kompetent und zielgerichtet, den Photovoltaikausbau auf allen kommunalen Liegenschaften, Dank unserer technologiegetriebenen Herangehensweise, Prozessexzellenz und Erfahrung in der Zusammenarbeit mit staatlichen Institutionen, bringen wir Kommunen innerhalb weniger Wochen ihrer autonomen Energieversorgung und CO2-Neutralit\u00e4t n\u00e4her",
    "description": "<p><strong>IHRE AUFGABEN</strong></p><ul><li>You design a robust and simple data platform</li><li>You build ETL pipelines to import, clean, and process data</li><li>You build dashboards to support business decisions and operations</li><li>You host and use ML Models (when necessary) for performing tasks such as Image-to-Text conversion, Predictions, etc...</li><li>You take care of our data aggregation</li></ul><p><strong>IHR PROFIL</strong></p><ul><li>You have experience in designing and building ETL pipelines and familiarity with multiple technologies in this area</li><li>You have extensive experience in building and maintaining Data Lakes and Data Warehouses</li><li>You are familiar with cloud providers such as GCP and AWS</li><li>You have proficiency in storage solutions like BigQuery, PostgreSQL, and object storage solutions (S3 or GCS)</li><li>You are experienced in working with Kafka, Python, Jupyter Notebooks, and Airflow</li><li>You know all about data governance, security, and privacy regulations</li><li>You have a high degree of self-motivation and self-organization</li></ul><p><strong>WARUM WIR?</strong></p><ul><li>Attractive remuneration package</li><li>30 vacation days</li><li>Flexible further training opportunities</li><li>Broad network of mentors that we make available to you</li><li>Team offsites</li><li>Flexible working from our office or mobile</li><li>More impact is not possible: through your work you contribute to saving millions of tons of CO2 in the world and also help the state to live up to its role as a role model again and save money in the process</li></ul><p><strong>\u00dcBER UNS</strong></p><br><p>admi Kommunal GmbH - Gemeinsam mit St\u00e4dten und Gemeinden treiben wir die kommunale Energiewende voran.</p><br><p>Wir unterst\u00fctzen Kommunen bei der Planung und Umsetzung ihrer energiepolitischen Ambitionen kompetent und zielgerichtet. Damit beschleunigen wir u.a. den Photovoltaikausbau auf allen kommunalen Liegenschaften. Dank unserer technologiegetriebenen Herangehensweise, Prozessexzellenz und Erfahrung in der Zusammenarbeit mit staatlichen Institutionen, bringen wir Kommunen innerhalb weniger Wochen ihrer autonomen Energieversorgung und CO2-Neutralit\u00e4t n\u00e4her. Davon profitiert langfristig nicht nur der Klimaschutz, sondern auch alle Steuerzahler. Dabei agieren wir als echte Partner der modernen, effektiven Verwaltung in Deutschland.</p><br><p>Mit hunderten von erfolgreich realisierten Projekten haben wir uns schon nach wenigen Monaten erfolgreich am Markt etabliert und dabei tausende Tonnen CO2 eingespart.</p><br><p>Aber die Zeit rennt: Heute entfallen noch rund 38% aller CO2-Emissionen in Deutschland auf die Kommunen. Gleichzeitig verpflichtet die Europ\u00e4ische Union ihre Mitgliedsstaaten, alle geeigneten \u00f6ffentlichen D\u00e4cher bis 2030 mit Photovoltaik auszustatten, um die Klimaneutralit\u00e4t voranzutreiben. Dieses Ziel k\u00f6nnen wir nur erreichen, wenn wir in den n\u00e4chsten Jahren weiter so viele Kommunen wie m\u00f6glich auf dem Weg in die komplette Klimaneutralit\u00e4t unterst\u00fctzen. Und daf\u00fcr brauchen wir Dich!</p><br><p>Wenn Du uns auf unserer Mission mit Deinem Talent, deiner Passion und Deiner Tatkraft unterst\u00fctzen m\u00f6chtest, freuen wir uns auf Deine Bewerbung.</p><br>"
  },
  {
    "id": 26,
    "title": "Data Scientist",
    "company": "Vay",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Mathematik, Data Analysis, scikit-learn, TensorFlow, Predictive modelling, Foundation, SOLID, Statistik",
    "posted_at": "2024-09-21",
    "is_remote": "False",
    "snippet_fragments": "  You have a solid foundation in mathematics,   You're comfortable working with Python and SQL,   You're excited to work with large datasets and eager to learn more about data preprocessing,   You have a basic understanding of predictive modeling and data analysis,   You're a fast learner who's motivated to grow in a dynamic,   You enjoy solving problems and work well under guidance and mentorship, This comes with challenges, frustrations and failures along the way, We embrace these challenges through perseverance and innovation, We celebrate diversity and encourage different opinions, Our teams and partners communicate and collaborate openly, Together we build, improve, and grow., We are biassed towards action and get behind the steering wheel, We are empowered to take initiative and drive it to completion, We understand their expectations and always respond in a way that feels human and respectful, We always put safety first and safety second, We create unexpected and delightful moments for our riders, We design end-to-end experiences that leave a lasting expression,   You'll be joining a highly committed, The team has previously worked at companies such as Tesla",
    "description": "<p>Vay has developed an alternative approach to autonomous driving called teledriving (remote driving) - to solve transportation in metropolitan areas.</p><br><p>Vay is the first company that has driven a car on European public roads with no one inside. Vay is the leading teledriving company setting the global standard for remotely driven vehicles. Vay aims to launch a safe, affordable, and sustainable door-to-door mobility service in the US, Germany and beyond. With its first service, Vay plans to remotely deliver and return electric cars for its customers.</p><br><p>This is very ambitious. And we can't do it alone. So we'd love to meet you!</p><br><p><strong>The responsibilities:</strong></p><ul><li>You'll assist in developing, testing, and deploying machine learning models for analyzing Cellular Network Performance, predicting fleet behavior, and forecasting demand in the deep tech startup working on remote driving technology</li><li>You'll integrate these models into existing systems and fine-tune them for real-time performance.</li><li>You'll monitor how the models perform, gather data, and contribute to their improvement over time.</li></ul><p><strong>The profile:</strong></p><ul><li>You have a solid foundation in mathematics, statistics.</li><li>You're comfortable working with Python and SQL, and if you've dabbled with machine learning libraries like Scikit-learn or TensorFlow, that's a bonus!</li><li>You're excited to work with large datasets and eager to learn more about data preprocessing, model training, and deployment.</li><li>You have a basic understanding of predictive modeling and data analysis, and you're ready to develop those skills further.</li><li>You're a fast learner who's motivated to grow in a dynamic, fast-paced startup environment.</li><li>You enjoy solving problems and work well under guidance and mentorship, but you're also not afraid to take initiative.</li></ul><p><strong>Our values:</strong></p><ul><li>We pioneer change: At Vay, we're doing work that has never been done before. This comes with challenges, frustrations and failures along the way. We embrace these challenges through perseverance and innovation, delivering creative solutions to overcome them.</li><li>We fuel collaboration: At Vay, we work as a team and strive for a common goal. We celebrate diversity and encourage different opinions. Our teams and partners communicate and collaborate openly. Together we build, improve, and grow.</li><li>We drive action: At Vay, everyone takes pride and commitment in their role for every task and every challenge. We are biassed towards action and get behind the steering wheel, even when there is none. We are empowered to take initiative and drive it to completion.</li><li>We build trust: At Vay, we consistently do the right thing, and follow through on our commitments to stakeholders, users and society. We understand their expectations and always respond in a way that feels human and respectful. We always put safety first and safety second.</li><li>We create magic: At Vay, we don't just make things that work, we build products people love. We create unexpected and delightful moments for our riders. We design end-to-end experiences that leave a lasting expression.</li></ul><p><strong>Additional benefits:</strong></p><ul><li>You'll be joining a highly committed, experienced, fun, and international team from over 30 countries. The team has previously worked at companies such as Tesla, Google, Waymo, Zoox, Byton, Argo, Amazon, Uber as well as Audi, BMW, and Daimler and has founded various companies before</li><li>You would be a part of solving transportation in metropolitan areas all over the world - from Europe</li><li>We organise thoughtful &amp; fun team events throughout the year</li><li>We provide healthy snacks, drinks, and coffee at our waterfront office in Berlin</li><li>Company ESOP (stock options)</li><li>Free German classes</li></ul><p>Vay is committed to building an inclusive, supportive place for you to do the best and most rewarding work of your career.</p><br><p>Come join the future!</p><br>"
  },
  {
    "id": 27,
    "title": "(Senior) DevOps Engineer - Data Analytics & Management Plattform (m/w/d)",
    "company": "Bundesdruckerei GmbH",
    "locations": "Berlin",
    "skills": "Python, Data Analysis, Ansible, Ceph, DevOps, GitLab, Kanban, OpenShift, OpenStack, Scrum, Unit Testing, Terraform, Red Hat Linux, IaC",
    "posted_at": "2024-09-21",
    "is_remote": "False",
    "snippet_fragments": "  \u00dcbernahme von Testaktivit\u00e4ten in Form von beispielsweise Unit Tests in einem BDD- Set-up,   Erfolgreich abgeschlossenes Studium der Informatik bzw, einer vergleichbaren Fachrichtung oder eine IT Ausbildung mit einschl\u00e4giger Berufspraxis in vergleichbarer Position,   Expertise im Aufbau und Betrieb von OpenStack und OpenShift, Python, Shell, Ansible, Terraform) und im Umgang mit agilen Methoden (Scrum, Kanban)",
    "description": "<p>Als (Senior) DevOps Engineer - Data Analytics &amp; Management Plattform (m/w/d) arbeiten Sie an PLAIN, einer Datenanalyse- und KI-Plattform mit, welche die Basis f\u00fcr Data-Engineering-Projekte in einem Multi-Mandanten-Setup bildet. Hierzu geh\u00f6ren der Aufbau der technischen Infrastruktur als On-Premise L\u00f6sung im Rechenzentrum und die Entwicklung bzw. Integration von bestehenden Softwaresystemen f\u00fcr die Dienste Virtualisierung, Containerisierung, Automation und \u00dcberwachung.</p><br><p>PLAIN steht f\u00fcr \u201ePlatform Analysis and Information System&quot;. Mit PLAIN bef\u00e4higen wir unsere Kunden, Daten f\u00fcr die politische Entscheidungsfindung zu nutzen und das effiziente Arbeiten mit Daten zu professionalisieren. In unserem Arbeitsalltag arbeiten wir eng mit allen Bundesministerien und deren Datenlaboren zusammen und legen Wert auf Pers\u00f6nlichkeiten mit Eigenverantwortung und Teamgeist. Mehr Informationen unter https://www.bundesdruckerei.de/de/innovation-hub/plain.<br><strong>Ihr Aufgabenbereich</strong></p><ul><li>Konzeption, Aufbau und Wartung von Red Hat OpenStack (RHOSP) und von Multicluster-L\u00f6sungen mit Red Hat OpenShift (ab Version 4)</li><li>Anlage, Verwaltung und Optimierung von OpenShift- Ressourcen und von der virtuellen Netzwerkinfrastruktur</li><li>Implementierung und Konzeption von Automation als IaC (Terraform oder Ansible)</li><li>Planung und Implementierung von Storagel\u00f6sungen mit Red Hat Ceph und Data Foundation, sowie dem Betrieb eines Zero-Trust- Networks</li><li>\u00dcbernahme von Testaktivit\u00e4ten in Form von beispielsweise Unit Tests in einem BDD- Set-up<br><strong>Ihr Profil</strong><br></li><li>Erfolgreich abgeschlossenes Studium der Informatik bzw. einer vergleichbaren Fachrichtung oder eine IT Ausbildung mit einschl\u00e4giger Berufspraxis in vergleichbarer Position</li><li>Expertise im Aufbau und Betrieb von OpenStack und OpenShift</li><li>Know-how im Bereich allgemeine Programmierung/Skripting/IaC (z.B. Python, Shell, Ansible, Terraform) und im Umgang mit agilen Methoden (Scrum, Kanban)</li><li>Kenntnisse in der Automatisierung und Verwaltung von Linux-Systemadministrationsaufgaben sowie verteilten Versionierungssystemen (insbesondere GitLab)</li><li>Praktisches Wissen in Infrastructure Automation, Confiuguration Management, Log Management und Monitoring</li><li>Erfahrung in der Sicherung von IT-Infrastrukturen nach ISO 27001 oder BSI- Grundschutz sowie im Betrieb von Softwarel\u00f6sungen bei externen Cloud-Anbietern</li></ul><br>"
  },
  {
    "id": 28,
    "title": "Senior Data Scientist (all genders)",
    "company": "Justplay GmbH",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Data Science, AWS, Data Analysis, GCP, A/B testing, Google Adwords, NumPy, Pandas, scikit-learn, TensorFlow, Cloud Platforms, Looker, Predictive Analytics, Firebase, Deep Learning, Reinforcement Learning, Data Visualization, UX, PyTorch, Statistical Analysis",
    "posted_at": "2024-09-20",
    "is_remote": "False",
    "snippet_fragments": "    Hands-on experience with Looker for data visualization and reporting,     Familiarity with ad tech tools and platforms (e,     Knowledge of reinforcement learning and its applications in gaming or ad optimization,     Benefits may vary depending on location and contract type, Do not hesitate to ask us about more details on our benefits offer, A spirited, inspiring, international, and enthusiastic team,,     An International team that is currently working from 8 locations around the world,     An organization with a high level of trust and sense of belonging among employees,     An opportunity to be a part of a company thats breaking with traditional ideas and taking a new approach thats shattering how the games industry works",
    "description": "<p><strong>YOUR MISSION</strong></p><br><p>We are seeking a highly skilled and experienced Senior Data Scientist to join our team. The ideal candidate will have a strong background in Machine Learning, Statistical Analysis, and Deep Learning, with over 5 years of professional experience. This role requires an expert in creating and optimizing User Acquisition models, LTV predictions, Ad Monetization strategies, and performing in-depth Product Analytics. The candidate should also be proficient in A/B testing and possess excellent project management skills. Familiarity with Python is essential, and experience in the mobile gaming industry is highly preferred.</p><br><p><strong>JOB RESPONSIBILITIES</strong></p><ul><li>User Acquisition Modeling: You will build and optimize machine learning models to enhance user acquisition, predict user behavior, and improve campaign performance. You will collaborate with marketing and product teams to refine audience targeting and maximize ROI</li><li>Product Analytics: You will be responsible for conducting in-depth product analysis to identify key metrics and areas for improvement, using data insights to guide product development and enhance user experience. Additionally, you will collaborate with product managers to steer data-driven features and improvements</li><li>A/B Testing: You will collaborate closely with the product team to design, implement, and analyze A/B and multivariate tests to optimize product features and marketing strategies. During those initiatives, you will be responsible for ensuring scientific rigor and proper statistical methods. Finally, you will support interpreting the results and providing actionable insights to stakeholders</li><li>Machine Learning &amp; Statistical Analysis: You will develop and deploy machine learning models for predictive analytics, user segmentation, and personalization, while applying deep learning techniques for complex data analysis tasks (image recognition, natural language processing, etc.) to drive user acquisition and monetization of our JustPlay app</li><li>Project Management: Lead data science projects from concept to delivery, coordinating with cross-functional teams (including Engineering, Product, and marketing) and managing timelines, deliverables, and stakeholder communication</li></ul><p><strong>THE EXPERIENCE WE HOPE YOU BRING TO JUSTPLAY</strong></p><ul><li>6+ years of professional experience in data science, focusing on machine learning, statistical analysis, and deep learning. Ideally paired with experience in the mobile gaming industry</li><li>Proven expertise in user acquisition modeling, product analytics, and A/B testing methodologies and tools</li><li>Proficiency in Python (Pandas, NumPy, Scikit-learn, TensorFlow, PyTorch)</li><li>Familiarity with SQL for database querying and data manipulation</li><li>Strong knowledge of statistical methods and their application in business</li><li>Experience with cloud platforms (AWS, GCP) is a plus</li><li>Strong project management skills, with a track record of leading data science projects</li><li>Excellent communication skills and the ability to translate data into insights</li><li>Strong problem-solving skills and the ability to work collaboratively in a cross-functional team environment<br><strong>Nice-to haves:</strong><br></li><li>Experience with mobile gaming analytics</li><li>Hands-on experience with Looker for data visualization and reporting</li><li>Familiarity with ad tech tools and platforms (e.g., Google Ads, Facebook Audience Network, Firebase)</li><li>Knowledge of reinforcement learning and its applications in gaming or ad optimization</li></ul><p><strong>OUR BENEFITS PACKAGE:</strong></p><ul><li>State-of-the-Art Equipment: Doesn't matter if you are a macbook or windows user, we will provide you with the technical gear you need to succeed</li><li>Engaging and diverse work environment: Join a diverse team, with over 19 nationalities and working from 13 different locations</li><li>Training &amp; Development: Free language Courses with Chatterbug</li><li>Education allowance: Enjoy a personal development budget of up to 2000\u20ac/year for training, conferences, workshops etc.</li><li>Mental Health Support: Free personal coaching through our partner nilo.health to support our team members to live fulfilled lives at home and at work</li><li>Work-Life Balance and Flexibility: Flexible working hours and options for digital nomads, occasional office visitors, or regular office-goers</li><li>Germany-based benefits: 25 vacation days, free Gympass gold subscription, free monthly Deutschland-Ticket, and a monthly \u20ac50 tax-free internet contribution</li><li>Berlin Office Perks: Ergonomic setup, free lunch on a daily basis, and dog-friendly environment</li><li>Benefits may vary depending on location and contract type. Do not hesitate to ask us about more details on our benefits offer.</li></ul><p><strong>WHY US?</strong></p><ul><li>A spirited, inspiring, international, and enthusiastic team,</li><li>An International team that is currently working from 8+ locations around the world,</li><li>An organization with a high level of trust and sense of belonging among employees, that prioritizes employee quality of life, job satisfaction and professional development,</li><li>An opportunity to be a part of a company that's breaking with traditional ideas and taking a new approach that's shattering how the games industry works.</li></ul><p>Apply for this job</p><br><p><strong>ABOUT US</strong></p><br><p>JustPlay is a worldwide gaming loyalty platform operator and publisher. Our purpose is to enable free-to-play mobile game players to get rewarded for their hobby. We launched JustPlay in the US in 2020, and now our product is one of the leading loyalty rewards apps in the world and our games are enjoyed by millions of players (our solitaire game is one of the top 5 most downloaded card games in the US). Our team is based in 13+ countries and our headquarters are in Berlin, Germany. While developing our loyalty app and awesome games, we value fairness, having fun together, creativity and focusing on the things that matter.</p><br>"
  },
  {
    "id": 29,
    "title": "Junior Data Scientist (m/f/d)",
    "company": "Flink",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Mathematik, Data Science, Cloud, GCP, Airflow, Flink, BigQuery, Kubernetes, Routing",
    "posted_at": "2024-09-20",
    "is_remote": "False",
    "snippet_fragments": "  You are proficient in reading and writing SQL (experience in Google BigQuery dialect is a plus);,   You have very good (spoken & written) communication skills in English (our main company language),   Experience developing recommender or forecasting systems is a plus;, Experience with Kubernetes, Airflow and cloud infrastructure (e.g, MLflow / VertexAI) is a plus,   A 1000 annual L&D budget as well as individual coaching options to ensure you have plenty of opportunities to learn, 26 days of vacation, 1 day every year up to a maximum of 30 days,   A mobility budget of 30 EUR per month with NAVIT",
    "description": "<p><strong>Company Description</strong></p><br><p>Flink is the leading quick commerce player in Europe. We are on a mission to give people back time: You can order your groceries through our app and we deliver to your doorstep in minutes. We carry 3,000 products with a focus on the leading brands in each category. We aim for sustainability by making deliveries on electric bikes and utilizing recyclable packaging.</p><br><p>Flink launched in February 2021 and already operates in more than 90 cities in Germany, and the Netherlands. The business generated more than EUR 400m in revenues in 2022 and is operationally profitable. Flink is backed by the world's most renowned tech investors, including Prosus, Mubadala, and Bond, and strategic investors like Doordash and REWE. We take great pride in being an inclusive employer that offers equal opportunities, and we celebrate the diversity and multiculturalism of our team. We're growing fast and always pushing ourselves to do better - we play for #1.</p><br><p>In your role as a <strong>Junior Data Scientist (m/f/d)</strong>, you will get the chance to work in a cross-functional team and have a direct impact on the business by building state-of-the-art ML models. Some of the business problems we solve in our team are Flink's Product Recommenders which help our customers find the products most relevant to them, or our Last Mile Data Products which match demand and supply to help us steer our operations more efficiently.</p><br><p>You can expect therefore to work on business-critical projects in close collaboration with various Flink stakeholders as well as with our Engineering teams. Get ready to be immersed in the fast-paced environment of quick commerce where data is a first-class citizen.<br><strong>Job Description</strong></p><ul><li>Develop models that generate insightful predictions and allow to steer day-to-day business decisions with a focus on rider routing and dispatching;</li><li>Work with internal stakeholders to identify the best ways to integrate our Data Science products in our quick grocery and workforce apps;</li><li>Collaborate within a cross-functional team to build relevant Data Science products that reliably predict/help the business and Flink's customers with their needs;</li><li>Analyse experiments and AB tests to evaluate the effectiveness of those Data Science products.</li></ul><p><strong>Qualifications</strong></p><ul><li>You hold a bachelor degree or higher in data science, computer science, mathematics, or related field;</li><li>You have practical experience in using different data science and statistical methodologies and you have experience doing this with Python;</li><li>You are proficient in reading and writing SQL (experience in Google BigQuery dialect is a plus);</li><li>You have very good (spoken &amp; written) communication skills in English (our main company language).</li></ul><p><strong>Additional Qualifications:</strong></p><ul><li>Experience developing recommender or forecasting systems is a plus;</li><li>Experience with Kubernetes, Airflow and cloud infrastructure (e.g. GCP) is a plus;</li><li>Experience with ML platforms (e.g. MLflow / VertexAI) is a plus.</li></ul><p><strong>Additional Information</strong></p><ul><li>A \u20ac1000 annual L&amp;D budget as well as individual coaching options to ensure you have plenty of opportunities to learn, grow and achieve your goals</li><li>26 days of vacation, +1 day every year up to a maximum of 30 days</li><li>A mobility budget of 30 EUR per month with NAVIT, which you can use individually for Uber, BVG and many other providers</li><li>A cool discount on your Urban Sports Club membership</li><li>Attractive company pension options</li><li>Unlimited access to an e-learning and development platform, MyAcademy, including online German courses</li><li>Online discounts with Corporate Benefits and Future Bens</li><li>A cool discount off your personal Flink orders; be the first to test out new products!</li><li>A modern and dog-friendly office in the heart of Berlin - lots of delicious lunch spots available within short walking distance</li></ul><p>It is our commitment that every applicant will be evaluated according to their skills regardless of age, gender identity, ethnicity, sexual orientation, disability status, or religion.</p><br>"
  },
  {
    "id": 30,
    "title": "Senior Data Scientist (Commercial) (x/f/m)",
    "company": "SellerX",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Data Science, AWS, Data Analysis, Data Modeling, Airflow, Kubernetes, Power BI, Deep Learning, Snowflake, Genetik",
    "posted_at": "2024-09-20",
    "is_remote": "False",
    "snippet_fragments": "  Strong stakeholder management skills to translate business needs into data-driven solutions,  Sounds exciting but you're not sure if you tick all the boxes? We are always happy to read your application and hear your story, At SellerX, we embark on an ambitious journey to establish ourselves as the global leader in acquiring and operating a new generation of eCommerce businesses, As one of Europe's fastest-growing startups,   Since November 2020, our dynamic team has expanded to over 800 talented individuals,   Founded by visionary serial entrepreneurs and Harvard Business School graduates, Our senior management comprises distinguished professionals from Amazon,   We take pride in our diverse portfolio, As SellerX continues to evolve, we recognize the need to tell a compelling story that reflects our current standing in the industry, With a solid foundation and a team of dedicated individuals,   We're not just building a company; we're crafting a legacy",
    "description": "<p><strong>Please note that the role is hybrid in Berlin (twice per week at the office).</strong></p><br><p><strong>The role</strong></p><br><p>At SellerX, we are expanding our <strong>Data Analytics Department</strong> and we are currently seeking a <strong>Senior</strong> <strong>Data Scientist (x/f/m)</strong> to join our dynamic team. In this role, you will play a pivotal part in building and refining data models, as well as devising effective methodologies to drive precise pricing and demand planning for thousands of products sold globally under our SellerX brands.</p><br><p>Ready for an exciting challenge? Apply today!</p><br><p><strong>Your Responsibilities in Detail</strong></p><ul><li>Apply advanced data modelling techniques using Python and SQL to develop and enhance our existing planning and pricing models across our comprehensive portfolio</li><li>Take our pricing and forecasting methodologies to the next level by improving accuracy, refining rules and processes, and optimizing our current toolset</li><li>Challenge existing assumptions and propose innovative solutions to scale and automate our planning and pricing processes</li><li>Initiate and conduct real-time tests to gauge the impact of pricing and promotion strategies on sales, profitability, and product rankings</li><li>Collaborate closely with cross-functional teams in commercial, supply chain, operations, and finance to identify constraints and objectives that will inform and enhance our modeling efforts</li><li>Lead one-off analyses for our leadership team, including the Chief Commercial Officer (CCO) and Chief Executive Officer (CEO)</li></ul><p><strong>Your Background</strong></p><br><p>To join our team, you bring along</p><ul><li>5+ years hands-on experience in at least one of the following areas: Demand forecasting, pricing, or marketing</li><li>End-to-end Data Science experience in Machine Learning: from development to deployment of models with real business impact using Python, AWS, Kubernetes, Airflow</li><li>Proficiency in ML modeling using Python (Time Series models, Tree-based models or Deep Learning)</li><li>SQL is a must (preferably in a Snowflake)</li><li>Experience in taking ML use cases from concept to production.</li><li>Experience in building and managing MLOps frameworks would be a big plus</li><li>Familiarity in visualization or building reports in Power BI would be nice to have</li><li>Degree in Engineering, Computer Science, Data Science, Operations Research, or equivalent</li><li>Strong stakeholder management skills to translate business needs into data-driven solutions</li></ul><p><strong>Sounds exciting but you're not sure if you tick all the boxes? We are always happy to read your application and hear your story. Everyone's talent is unique!</strong></p><br><p><strong>About SellerX:</strong></p><br><p>At SellerX, we embark on an ambitious journey to establish ourselves as the global leader in acquiring and operating a new generation of eCommerce businesses. As one of Europe's fastest-growing startups, we've secured $750M in funding from renowned VC and PE firms such as L Catterton, 83North, Cherry Ventures, Felix Capital, Sofina, Victory Park Capital, and BlackRock.</p><br><p>Since November 2020, our dynamic team has expanded to over 800 talented individuals, shaping our presence across 6 offices spanning Europe, APAC, and the US.</p><br><p><strong>Our Distinctive Journey:</strong></p><br><p>Founded by visionary serial entrepreneurs and Harvard Business School graduates, our leaders bring over 12 years of invaluable experience in eCommerce and private equity. Our senior management comprises distinguished professionals from Amazon, eCommerce, and investment sectors, each contributing to our collective success.</p><br><p><strong>A Portfolio of Excellence:</strong></p><br><p>We take pride in our diverse portfolio, boasting a panel of 80+ brands that showcase our commitment to excellence and innovation in the eCommerce space.</p><br><p><strong>Evolving Beyond Boundaries:</strong></p><br><p>As SellerX continues to evolve, we recognize the need to tell a compelling story that reflects our current standing in the industry. With a solid foundation and a team of dedicated individuals, we are charting new territories and redefining the eCommerce landscape.</p><br><p><strong>Why Join SellerX:</strong></p><br><p>We're not just building a company; we're crafting a legacy. Your role at SellerX is pivotal because we firmly believe that our company is only as exceptional as the team we assemble. Join us in shaping the future of eCommerce and be a part of a company that values innovation, collaboration, and continuous growth.</p><br><p>SellerX is an Equal Opportunity Employer. We value diversity and strive to create an inclusive workplace for everyone. We do not discriminate based on race, color, religion, gender, sexual orientation, national origin, genetics, disability, age, or veteran status. We actively encourage individuals from all backgrounds to apply.</p><br><p>We are dedicated to providing equal opportunities in recruitment, training, promotion, and compensation. SellerX is proud to foster a diverse and talented team, reflecting the global nature of our business. Join us in building a workplace where innovation and creativity thrive.</p><br>"
  },
  {
    "id": 31,
    "title": "(Senior) Data Engineer / DevOps Engineer (m/f/d)",
    "company": "Wetter.com GmbH",
    "locations": "Berlin",
    "skills": "Python, Machine Learning, Data Science, AWS, Cloud, Data Pipelines, AI, Confluence, DevOps, Jira, Terraform, APIs, Serverless, Databricks, API Gateway, Spark, CD, Continuous Integration, IAM, Prototyping, Architektur",
    "posted_at": "2024-09-20",
    "is_remote": "True",
    "snippet_fragments": "     You are well versed in setup and operations of cloud infrastructure and data pipelines,      You have good Python programming skills and work experience with AWS Serverless,      You are natural with JIRA and Confluence and are interested to learn Spark,      An own area of responsibility with space to develop your own ideas and concepts,      Our corporate culture is characterized by team spirit,      We work in a hybrid model with home office and office presence,      A variety of additional perks and employee services in a leading Media Company,      Promotion is very important to us,     Looking forward to a conversation with your new colleagues? Then apply via our job portal,     With up to 20 million visitors a month, At our locations in Munich, Berlin and Constance, more than 70 meteorologists, editors, developers, technicians, designers, sales managers and data professionals, among others, work on our products with a lot of passion and fun, In addition to the wetter.com offerings for desktop, mobile and TV, these include our winter sports portal snowthority, We also offer weather data-driven business solutions that help companies optimize processes and leverage new business potential, We are a wholly owned subsidiary of ProSiebenSat.1 Media SE",
    "description": "<p><strong>INTRODUCTION SENTENCE</strong></p><br><p>To further strengthen our Data Team, we are seeking talented individuals to join us at one of our locations in Munich, Berlin, or Constance.</p><br><p><strong>WHAT YOU CAN EXPECT IN THIS ROLE</strong></p><ul><li>You develop and build innovative B2B data-as-a-service products together with our data scientists and backend team (e.g. public and private APIs, webhooks, ML pipelines, AI pipelines)</li><li>You define set-up and maintain CI/CD pipelines using modern cloud infrastructure (our stack uses AWS + Databricks)</li><li>You develop and implement scalable applications for automated data processing and predictions - from conception to prototyping to production</li><li>You actively shape the evolution of our data architecture including DevOps processes and evaluate necessary tools and technologies</li></ul><p><strong>YOUR ESSENTIAL EXPERIENCE AND EDUCATION</strong></p><ul><li>You have a degree in Computer Science, Data Science or an equivalent qualification</li><li>You are well versed in setup and operations of cloud infrastructure and data pipelines, especially on AWS</li><li>You have good Python programming skills and work experience with AWS Serverless, IAM, API Gateway, Stepfunction and Lamda</li><li>You are natural with JIRA and Confluence and are interested to learn Spark, Terraform and Databricks</li></ul><p><strong>WHAT'S IN IT FOR YOU?</strong></p><ul><li>An own area of responsibility with space to develop your own ideas and concepts</li><li>Our corporate culture is characterized by team spirit, open communication and dynamic atmosphere, flat hierarchies and short decision-making paths</li><li>We work in a hybrid model with home office and office presence</li><li>Uncomplicated cooperation: We have a You culture with no Mr uns Mrs and are detached from dress codes</li><li>A variety of additional perks and employee services in a leading Media Company</li><li>Promotion is very important to us</li></ul><p><strong>CLOSURE</strong></p><br><p>Looking forward to a conversation with your new colleagues? Then apply via our job portal.</p><br><p>With up to 20 million visitors a month, wetter.com is one of the most popular online weather portals in Germany, Austria and Switzerland. At our locations in Munich, Berlin and Constance, more than 70 meteorologists, editors, developers, technicians, designers, sales managers and data professionals, among others, work on our products with a lot of passion and fun. In addition to the wetter.com offerings for desktop, mobile and TV, these include our winter sports portal snowthority. We also offer weather data-driven business solutions that help companies optimize processes and leverage new business potential. We are a wholly owned subsidiary of ProSiebenSat.1 Media SE.</p><br><p><strong>COMPANY TEXT</strong></p><br><p>Click here to learn more about the ProSiebenSat.1 Group and our diverse portfolio.</p><br><p>Although we refer to one gender in the text, all genders may be implied.</p><ul><li>Training and Education</li><li>Flexible Working Hours</li><li>No dress code</li><li>Open corporate culture</li></ul><br>"
  },
  {
    "id": 32,
    "title": "Senior Data Scientist",
    "company": "Contiamo",
    "locations": "Berlin",
    "skills": "Machine Learning, Mathematik, Data Science, Cloud, Data Pipelines, AI, Data Warehouse, Big Data, Excel, scikit-learn, Algorithms, Architektur",
    "posted_at": "2024-09-18",
    "is_remote": "True",
    "snippet_fragments": " Identify essential requirements and priorities, balancing project limitations and success, and thoroughly document projects and processes.,  Explore varied data landscapes in search for relevant insights and meaningful relations.,  Propose state-of-the-art and/or innovative ML approaches, establish testing and evaluation frameworks, and obtain clear and interpretable results.,  Develop and maintain projects as they mature into an application, Establish monitoring, pipelining, and packaging of the software.,  Present the results to both technical and non-technical stakeholders, answer their questions and address possible doubts.,   You are a good fit if,   you have strong analytical skills and are ready to understand clients businesses and help them tackle their challenges,   you have strong problem-solving abilities and the ability to work independently,   you are interested and/or have experience developing Generative AI use cases with related technologies, you enjoy open communication, appreciate teamwork and are ready to help and ask for help when needed.,   you match 80% of the above list and are ready to dive into the other items,    you currently live in Germany or you are considering a move, You must already have an EU work visa,   A dynamic environment with the exciting opportunity to work with a broad spectrum of interlocutors,   The chance to be part of a talented team in data science,   A role that demands not only technical proficiency but also strong problem-solving abilities and collaboration skills,   The opportunity to tackle challenging problems with cutting-edge technology and the freedom to grow your skill set",
    "description": "<p><strong>ABOUT US</strong></p><br><p>Contiamo is a premier consulting firm that brings together an interdisciplinary team of senior experts in data science, data engineering, mathematics, business consulting, and change management. Our extensive experience allows us to deliver high-quality data solutions, seamlessly integrating deep business know-how.</p><br><p>We collaborate with industry leaders such as Mercedes Benz, CBRE, and Deutsche Telekom to tackle their most pressing business challenges with technology. As a trusted partner, we pride ourselves on delivering scalable cloud applications and leveraging open-source tools to find elegant solutions to complex problems.</p><br><p>At Contiamo, our culture thrives on fast iterations and a high-trust environment where everyone is given significant responsibility. We believe in the power of a supportive atmosphere, valuing both individual contributions and the joy of teamwork.</p><br><p>In the last years, Generative AI has become a core focus for us and we have delivered many high value projects using cutting edge developments for our customers. <strong>Besides Gen AI, our projects span a wide range of exciting data use cases, including:</strong></p><ul><li>Advanced Data Science and Machine Learning</li><li>Data and AI Strategy</li><li>Data Architecture and Cloud Data Warehouse Setup</li><li>Building Data-intensive Applications and Algorithms</li></ul><p><strong>ABOUT THE ROLE</strong></p><br><p><strong>We are seeking a highly skilled and experienced Senior Data Scientist to join our team. You will play a pivotal role in developing and delivering innovative solutions for our clients in various industries.</strong></p><br><p><strong>KEY RESPONSIBILITIES</strong></p><ul><li><br><strong>Design and Build</strong>: Develop client-oriented, data-intensive ML solutions and robust data pipelines.</li><li><br><strong>Ownership:</strong> Identify essential requirements and priorities, balancing project limitations and success, and thoroughly document projects and processes.</li><li><br><strong>Collaboration</strong>: Work closely with data engineers to deploy our ML-based applications, ensuring seamless integration and performance.</li><li><br><strong>Project Management</strong>: Collaborate with project management leads and engage with clients, effectively communicating with both technical and non-technical audiences.</li></ul><p><strong>WHAT YOU'LL DO</strong></p><ul><li><br><strong>Analyse and Understand:</strong> Explore varied data landscapes in search for relevant insights and meaningful relations.</li><li><br><strong>Build and Test Models:</strong> Propose state-of-the-art and/or innovative ML approaches, establish testing and evaluation frameworks, and obtain clear and interpretable results.</li><li><br><strong>Productionize:</strong> Develop and maintain projects as they mature into an application. Establish monitoring, pipelining, and packaging of the software.</li><li><br><strong>Present and Interpret:</strong> Present the results to both technical and non-technical stakeholders, answer their questions and address possible doubts.</li></ul><p><strong>YOU ARE A GOOD FIT IF</strong></p><ul><li>you have strong analytical skills and are ready to understand clients businesses and help them tackle their challenges.</li><li>you have strong problem-solving abilities and the ability to work independently, take ownership of projects, and deliver high-quality results.</li><li>you have experience with a scope of ML-related libraries: sklearn, catboost, prophet, mlflow, kedro.</li><li>you are interested and/or have experience developing Generative AI use cases with related technologies.</li><li>you enjoy open communication, appreciate teamwork and are ready to help and ask for help when needed.</li><li>you match 80% of the above list and are ready to dive into the other items.</li><li><br><strong>you currently live in Germany or you are considering a move. You must already have an EU work visa.</strong><br></li></ul><p><strong>WHAT WE OFFER</strong></p><ul><li>A dynamic environment with the exciting opportunity to work with a broad spectrum of interlocutors, from clients to software engineers.</li><li>The chance to be part of a talented team in data science, AI, and big data.</li><li>A role that demands not only technical proficiency but also strong problem-solving abilities and collaboration skills.</li><li>The opportunity to tackle challenging problems with cutting-edge technology and the freedom to grow your skill set.</li></ul><p><strong>BENEFITS</strong></p><ul><li>Flexible working hours (really!)</li><li>A senior and highly qualified team to work with and learn from</li><li>A competitive salary</li><li>Vacation up to 30 days, can be taken independently and flexible according to your own wishes</li><li>Home office budget and choose the equipment you want to work on</li><li>Remote work possible (also in other EU countries for a limited amount of time)</li><li>Beautiful office in the heart of Berlin, team lunches and events, paid train ticket and more...</li></ul><p>We value diversity and encourage applications from individuals of all backgrounds. If you have the skills and passion to excel in this role, we would love to hear from you.</p><br><p>Please note that this is a senior-level position, and we expect candidates to demonstrate their ability to be independent problem solvers and collaborate effectively with the team and clients. We highly value clear communication, both written and spoken.</p><br>"
  },
  {
    "id": 33,
    "title": "Senior Data Scientist (m/w/d) Pricing Finance & Steering",
    "company": "Deutsche Telekom Gesch\u00e4ftskunden GmbH",
    "locations": "Berlin",
    "skills": "Python, Data Science, Data Analysis, Big Data, Dashboards, Power BI, scikit-learn, Tableau, Spark, CRM, \u00d6konometrie",
    "posted_at": "2024-09-17",
    "is_remote": "False",
    "snippet_fragments": " Du lebst in der GenAI-Welt und sch\u00e4tzt die M\u00f6glichkeiten eines Gro\u00dfunternehmens? Daten und Finance sind deine Leidenschaft?,   Sehr gute Kenntnisse der relevanten Data-Science Tools (Python,   Nachgewiesene praktische Erfahrung im Kontext von Data Science Projekten,   Sehr gute Kenntnisse der ML-Ans\u00e4tze im Bereich Kundensegmentierung und Pricing,   Sehr gute Kenntnisse in der Datenvisualisierung und -kommunikation,   Hervorragende Kenntnisse in komplexen Big Data Architekturen,   Sehr gute Erfahrungen in klassischen und agilen Kooperationsformen",
    "description": "<p><strong>IHRE AUFGABE</strong></p><br><p>Als Data Scientist (m/w/d) Finance Pricing &amp; Steering designst und entwickelst du in einem dynamischen Team die Price Recommendation Engine (pricing econometric methods). Deine Zielsetzung sind Preis- und Handlungsempfehlungen auf Kundenebene f\u00fcr den Vertrieb.</p><br><p>Daf\u00fcr sollen aus den Bestandsdaten-f\u00fchrenden Systemen (Mobilfunk-, TK- und IT-Produktwelten) Datenmodelle erstellt und miteinander verkn\u00fcpft werden. F\u00fcr die Anwender muss die Integration im Pricing/CRM Tool sowie die Visualisierung von Dashboards erfolgen.</p><br><p>Folgende Aufgaben werden von Dir \u00fcbernommen:</p><ul><li>Du entwickelst Auswerte- und Steuerungstools f\u00fcr unterschiedliche Datenquellen zur Bereitstellung erforderlicher Datens\u00e4tze.</li><li>Du f\u00fchrst Datenanalysen durch und integrierst die Ergebnisse in bestehende L\u00f6sungen und Gesch\u00e4ftsprozesse.</li><li>Du ermittelst Muster, Vorhersagemodelle und k\u00fcmmerst dich um die Evaluation und Nutzbarmachung neuer KI-Innovationstrends.</li><li>Du erstellst Cost-Cases und techno-\u00f6konomische Bewertungen.</li><li>Du tr\u00e4gst E2E-Verantwortung f\u00fcr strategisch ausgerichtete Data-Science-Projekte.</li><li>Du \u00fcbernimmst Aufgaben aus dem Bereich Data - und Softwareengineering.</li></ul><p><strong>IHR PROFIL</strong></p><br><p>Du lebst in der GenAI-Welt und sch\u00e4tzt die M\u00f6glichkeiten eines Gro\u00dfunternehmens? Daten und Finance sind deine Leidenschaft?</p><br><p>Wir w\u00fcnschen uns von dir:</p><ul><li>Sehr gute Kenntnisse der relevanten Data-Science Tools (Python, scikit-learn, Spark oder \u00e4hnliche)</li><li>Nachgewiesene praktische Erfahrung im Kontext von Data Science Projekten</li><li>Sehr gute Kenntnisse der ML-Ans\u00e4tze im Bereich Kundensegmentierung und Pricing</li><li>Sehr gute Kenntnisse in der Datenvisualisierung und -kommunikation, einschlie\u00dflich Tools wie Tableau, Power BI oder \u00e4hnliche</li><li>Hervorragende Kenntnisse in komplexen Big Data Architekturen</li><li>Sehr gute Erfahrungen in klassischen und agilen Kooperationsformen</li></ul><p><strong>\u00dcBER UNS</strong></p><br><p><strong>Deutsche Telekom Gesch\u00e4ftskunden GmbH</strong></p><br><p>Ob Handwerksbetrieb, Gro\u00dfkonzern oder Beh\u00f6rde - wir begleiten alle bei den entscheidenden Schritten der DIGITALISIERUNG. Mit Leidenschaft machen wir das Business unserer Kunden zu unserem Business und entwickeln GEMEINSAM mit ihnen zukunftssichere L\u00f6sungen. Was uns auszeichnet? Wir krempeln die \u00c4rmel hoch, packen an und MACHEN es m\u00f6glich.</p><br><p>Werden Sie Teil unseres Teams!</p><br><p>Wir sch\u00e4tzen Vielfalt und Gleichberechtigung, gehen gemeinsam voran und f\u00f6rdern Wachstum- mit dem klaren Ziel: Becoming the Leading Digital B2B Telco!</p><br>"
  },
  {
    "id": 34,
    "title": "Senior Data Platform Engineer (f/m/d)*",
    "company": "Parloa",
    "locations": "Berlin",
    "skills": "Python, Machine Learning, Cloud, AI, Azure, Airflow, Kafka, Docker, Kubernetes, MongoDB, Redis, Terraform, Orchestration, Databricks, Data Lake, NLP, Architektur",
    "posted_at": "2024-09-16",
    "is_remote": "False",
    "snippet_fragments": "Be part of a dynamic, driven team of 20 nationalities with flat hierarchies and collaborative company culture.,   Hybrid work environment - we believe in hiring the best talent, However, we love to build real connections and want to welcome everyone in the office on certain days.,   Training and development budget which can be used for conferences and attending development courses to ensure continuous professional growth, Flexible working hours, 28 vacation days and workation opportunities.,   Enjoy unlimited access to a variety of fitness,   Leverage exclusive offers with our corporate benefits portal, Regular team events, game nights, and other social activities.,   Is something missing here? Reach out and let's talk about what else you need for your ideal next growth opportunity,  Recruiter video call Hiring Manager Interview Coding Challenge Technical Interview (Systems Design  Coding Challenge Review) Meeting the team,   Parloa is one of the fastest growing startups in the world of Generative AI and customer service, Parloa's voice-first GenAI platform for contact centers is built on the best AI technology to automate customer service with natural-sounding conversations for outstanding experiences on all communication channels, Leveraging natural language processing (NLP) and machine learning, The Parloa platform resolves the majority of customer queries quickly and automatically, Parloa was founded in 2018 by Malte Kosub and Stefan Ostwald and today employs over 250 people in Berlin",
    "description": "<p><strong>YOUR MISSION:</strong></p><br><p>As a Senior Data Platform Engineer (f/m/d)*, you will design and develop Parloa's data platform. The data platform will power Parloa's data and machine learning products as well as analytics for decision intelligence and needs to be ready for petabyte scale. The infrastructure you build will make an impact to transform the entire customer service industry leveraging data and AI.</p><br><p><strong>IN THIS ROLE YOU WILL:</strong></p><ul><li>Together with your team, take ownership of building and improving the data platform at Parloa, including data ingestion, data lake/house, tooling for building data products, orchestration, data catalog &amp; lineage, streaming infrastructure, serving layer</li><li>Take the lead in systems design for parts of the data platform</li><li>Take ownership executing technical projects end-to-end for parts of the data platform: understanding user requirements, systems design, vendor evaluation, proof of concept, implementation, maintenance and support, continuous improvement</li><li>Work directly with data engineers, ML engineers and analytics engineers to provide internal user support (first responder system) and understand user needs for improving the data platform</li></ul><p><strong>OUR</strong> <strong>DATA STACK:</strong></p><br><p>Microsoft Azure, Python, Databricks, Kafka, Kubernetes, Docker, Terraform, Preset, MongoDB, Redis (more technologies to be added as we build our data platform, like e.g. Airflow)</p><br><p><strong>WHAT YOU BRING TO THE TABLE:</strong></p><ul><li>7+ years of experience as a data engineer</li><li>Thereof 2+ years of experience in developing data platforms</li><li>Experience with cloud data platforms and Terraform, proficiency in Python</li><li>Track record of building data platforms in accordance with legal requirements with a clear focus on data quality and observability</li><li>Experience in designing systems and leading medium-sized technical projects (3-9 months roadmap)</li><li>Strong spoken and written communication skills in English</li></ul><p><strong>NICE TO HAVE:</strong></p><ul><li>Experience with events-driven architecture and related tooling (Kafka etc.) is a plus</li><li>Experience with Azure based data services/products</li></ul><p><strong>WHAT'S IN IT FOR YOU?</strong></p><ul><li>Be part of a dynamic, driven team of +20 nationalities with flat hierarchies and collaborative company culture.</li><li>Hybrid work environment - we believe in hiring the best talent, no matter where they are based. However, we love to build real connections and want to welcome everyone in the office on certain days.</li><li>Attractive compensation package.</li><li>Training and development budget which can be used for conferences and attending development courses to ensure continuous professional growth.</li><li>Flexible working hours, 28 vacation days and workation opportunities.</li><li>Enjoy unlimited access to a variety of fitness, yoga, and leisure activities via Wellpass.</li><li>Leverage exclusive offers with our corporate benefits portal, giving you access to compelling deals from leading brands.</li><li>Regular team events, game nights, and other social activities.</li><li>And last but not least: a beautiful office with flair in the heart of Berlin with all the conveniences, such as adjustable desks, social area, fresh fruits, cereals and drinks.</li><li>Is something missing here? Reach out and let's talk about what else you need for your ideal next growth opportunity.</li></ul><p><strong>YOUR RECRUITING PROCESS AT PARLOA:</strong></p><br><p>Recruiter video call Hiring Manager Interview Coding Challenge Technical Interview (Systems Design + Coding Challenge Review) Meeting the team</p><br><p><strong>WHY PARLOA?</strong></p><br><p>Parloa is one of the fastest growing startups in the world of Generative AI and customer service. Parloa's voice-first GenAI platform for contact centers is built on the best AI technology to automate customer service with natural-sounding conversations for outstanding experiences on all communication channels. Leveraging natural language processing (NLP) and machine learning, Parloa creates intelligent phone and chat solutions for businesses that turn contact centers into value centers by boosting customer service efficiency. The Parloa platform resolves the majority of customer queries quickly and automatically, allowing human agents to focus on complex issues and relationships. Parloa was founded in 2018 by Malte Kosub and Stefan Ostwald and today employs over 250 people in Berlin, Munich, and New York.</p><br><p>When you join Parloa, you become part of a dynamic and innovative team made up of over 34 nationalities that's revolutionizing an entire industry. We're passionate about growing together and creating opportunities for personal and professional development. With our recent $66 million Series B investment, we're expanding globally and looking for talented individuals to join us on this exciting journey.</p><br><p>Do you have questions about Parloa, the role, or our team before you apply? Please feel free to get in touch with our Hiring Team.</p><br><p>Parloa is committed to upholding the highest data protection standards for our clients' and employees' data. All our employees are instrumental in ensuring the utmost care, GDPR, and ISO compliance, including ISO 27001, in handling sensitive information.</p><ul><li><br><strong>We provide equal opportunities to all qualified applicants regardless race, gender, sexual orientation, age, religion, national origin, disability status, socioeconomic background and other characteristics.</strong><br></li></ul><br>"
  },
  {
    "id": 35,
    "title": "Data Scientist - 24 month contract",
    "company": "Amazon.com",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Data Science, Data Analysis, Agile, MATLAB, Perl, Deep Learning, Causal Inference, Statistical modeling, Scripting Language, Empower, R, SAS, NLP, Statistik, Applied Mathematics",
    "posted_at": "2024-09-12",
    "is_remote": "True",
    "snippet_fragments": "  Imagine and invent before the business asks, Open the Science black-box, use causal inference and develop compelling data visualizations,   Work closely with other data scientists,   ABOUT AUDIBLE Audible is the leading producer and provider of audio storytelling, We spark listeners imaginations, offering immersive, cinematic experiences full of inspiration and insight to enrich our customers daily lives, Our HubHome hybrid workplace model gives employees the flexibility between gathering in a common office space (work from hub) and remote work (work from home), For more information, please visit adbl.co/hybrid,    Experience with data scripting languages (e,    Experience with machine learning/statistical modeling data analysis tools and techniques, 3 yrs relevant experience; or, PhD 1 yr relevant experience, Experience in Python, Perl, or another scripting language,    Experience in a ML or data scientist role with a large technology company",
    "description": "<p>At Audible, we believe stories have the power to transform lives. It's why we work with some of the world's leading creators to produce and share audio storytelling with our millions of global listeners. We are dreamers and inventors who come from a wide range of backgrounds and experiences to empower and inspire each other. Imagine your future with us.</p><br><p>ABOUT THIS ROLE</p><br><p>In this role, you will build scalable solutions and models to support our business functions (Content, Marketing, Product). Leveraging a range of methods including machine learning and simulation, you will explain, quantify, predict and prescribe in support of informing critical business decisions. You will translate business goals into agile, insightful analytics. You will seek to create value for both stakeholders and customers and inform findings in a clear, actionable way to managers and senior leaders.</p><br><p>This position is for a 24 month contract.</p><br><p>ABOUT THE TEAM</p><br><p>Audible's Data Science team partners with marketing, content, product, and technology partners to solve business and technology problems using scientific approaches to build product and services that surprise and delight our customers. We employ scalable cutting-edge Data Science (DS), machine learning (ML), deep learning (DL), and Natural Language Processing (NLP) knowledge to better target customers and prospects, understand and personalize the content, and context needed to optimize their book-listening experience. We operate in an agile environment in which we own and collaborate on the life cycle of research, design, and model development of relevant projects.</p><br><p>As a Data Scientist, you will...</p><ul><li>Develop and validate models to optimize the Who, When, Where and How of all our interactions with customers</li><li>Develop Audible-wide data engineering pipelines</li><li>Imagine and invent before the business asks, and create groundbreaking applications using cutting-edge approaches</li><li>Open the Science black-box, use causal inference and develop compelling data visualizations</li><li>Work closely with other data scientists, ML experts, engineers and on cross-disciplinary efforts with other scientists within Amazon</li></ul><p>ABOUT AUDIBLE</p><br><p>Audible is the leading producer and provider of audio storytelling. We spark listeners' imaginations, offering immersive, cinematic experiences full of inspiration and insight to enrich our customers daily lives. Our Hub+Home hybrid workplace model gives employees the flexibility between gathering in a common office space (work from hub) and remote work (work from home). For more information, please visit adbl.co/hybrid.<br><strong>BASIC QUALIFICATIONS</strong></p><ul><li>Experience with data scripting languages (e.g., SQL, Python, R, or equivalent) or statistical/mathematical software (e.g., R, SAS, Matlab, or equivalent)</li><li>Experience with machine learning/statistical modeling data analysis tools and techniques, and parameters that affect their performance</li><li>3 yrs relevant experience; or, PhD +1 yr relevant experience</li><li>MS in one of the following disciplines: Computer Science, Statistics, Data Science, Economics, Applied Mathematics, Operational Research or a related quantitative field</li><li>Experience in modeling, research design</li></ul><p><strong>PREFERRED QUALIFICATIONS</strong></p><ul><li>Experience in Python, Perl, or another scripting language</li><li>Experience in a ML or data scientist role with a large technology company</li></ul><p>Amazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success. We make recruiting decisions based on your experience and skills. We value your passion to discover, invent, simplify and build. Protecting your privacy and the security of your data is a longstanding top priority for Amazon. Please consult our Privacy Notice (https://www.amazon.jobs/en/privacy_page) to know more about how we collect, use and transfer the personal data of our candidates.</p><br><p>m/w/d</p><br>"
  },
  {
    "id": 36,
    "title": "Data Scientist (m/f/d)",
    "company": "ZDF Sparks GmbH",
    "locations": "Berlin",
    "skills": "Python, Machine Learning, Data Analysis, AI, Data Modeling, Agile, Feature Engineering, Matplotlib, NumPy, Pandas, scikit-learn, TensorFlow, Algorithms, Deep Learning, Data Visualization, Seaborn, PyTorch",
    "posted_at": "2024-09-12",
    "is_remote": "False",
    "snippet_fragments": "  ZDF Sparks is a workplace for curious, We proudly embrace diversity and enjoy working in fast-paced cross-functional and multicultural teams, We offer flexible working hours and a hybrid setup to accommodate any personal circumstances, In our centrally located Berlin top-floor office,  for conferences, certifications, or external courses, The 30-day vacation rounds up the year to relax off the job, Your insights and knowledge will be valued and shared to drive collective success, At ZDF Sparks, we maintain a light-hearted atmosphere with humor and a relaxed communication style among colleagues, This fosters a positive environment where everyone feels comfortable and motivated to contribute their best, Our strength lies in our diverse team, Different perspectives and backgrounds drive our creativity and innovation, By integrating different points of view,  We live and breathe innovation, continuously learning and pushing boundaries to deliver cutting-edge AI solutions.",
    "description": "<p><strong>EXCITED ABOUT AI?</strong></p><br><p>Join us at <strong>ZDF Sparks</strong> and be part of an exciting journey in AI innovation! We are looking for a full-time <strong>Data Scientist (m/f/d)</strong> for our location in <strong>Berlin in a hybrid set-up</strong> at the earliest possible starting date.</p><br><p><strong>YOUR ROLE</strong></p><ul><li>Design, review, implementation and modernization of data systems, solutions and algorithms from data analytics to advanced AI/ML solutions</li><li>Work with structured and unstructured data, their preprocessing and visualization</li><li>Help to train new models for various use cases from POC to production</li><li>Work on solutions across multiple media formats such as text, image, audio and video</li><li>Open source algorithms and make AI explainable for larger audiences</li><li>Consume and fine-tune generative AI models (e.g., text generation, image generation, etc.) for various real-world applications.</li><li>Collaborate with cross-functional teams to integrate AI solutions in business processes.</li></ul><p><strong>YOUR PROFILE</strong></p><ul><li>Strong proficiency in Python, including data manipulation and analysis with pandas and NumPy, and data visualization using Matplotlib and Seaborn.</li><li>Expertise in libraries and tools like scikit-learn, Hugging Face, TensorFlow/PyTorch for machine learning and deep learning tasks and LangChain, or other generative AI frameworks.</li><li>Hands-on experience in data analytics, feature engineering, and model evaluation with a focus on performance optimization.</li><li>Strong interest in designing and implementing algorithms and building generative AI applications.</li><li>Strong interest in working at the intersection of consultancy business and technology, and in learning advanced data modeling skills.</li><li>Able to identify key challenges, and independently explore solutions without relying on pre-defined or structured tasks.</li><li>Excellent communication skills in English and preferably in German, to effectively interact with team members, stakeholders, and clients.</li></ul><p><strong>OUR COMMITMENT TO YOU</strong></p><br><p><strong>ZDF Sparks</strong> is a workplace for <strong>curious, ambitious, and collaborative AI trendsetters</strong> who are excited about working on new and continuously changing customer challenges. We proudly <strong>embrace diversity</strong> and enjoy working <strong>in fast-paced cross-functional and multicultural teams.</strong></p><br><p>Our <strong>hybrid office and mobile work model</strong> is designed to support <strong>personal flexibility and creativity</strong>, enabling a <strong>healthy work-life balance</strong>. We offer flexible working hours and a hybrid setup to accommodate any personal circumstances. In our centrally located <strong>Berlin top-floor office</strong>, we enjoy modern spaces with <strong>ergonomic workstations</strong> grouped to facilitate personal exchange and knowledge sharing, as well as closed rooms for larger meetings and quiet work.</p><br><p>We network with our ZDF office partners and visitors over <strong>lunches, talks, and afterwork get-together events</strong>; and engage in <strong>f</strong>un team activities during regular company events.</p><br><p>To support your professional growth, we offer opportunities for further education through <strong>external regular workshops and hackathons</strong>, and networking events. Additionally, we provide a <strong>professional development budget</strong> for conferences, certifications, or external courses. The <strong>30-day vacation</strong> rounds up the year to relax off the job.</p><br><p><strong>OUR VALUES</strong></p><br><p>At ZDF Sparks, our values are the cornerstone of everything we do:</p><ul><li><br><strong>Transparent:</strong> We believe in clear, open communication both within our team and with our clients. Your insights and knowledge will be valued and shared to drive collective success.</li><li><br><strong>Fun</strong>: We believe that work should be enjoyable and fulfilling. At ZDF Sparks, we maintain a light-hearted atmosphere with humor and a relaxed communication style among colleagues. This fosters a positive environment where everyone feels comfortable and motivated to contribute their best, ensuring our collaborative efforts are both productive and enjoyable.</li><li><br><strong>Diverse:</strong> Our strength lies in our diverse team. Different perspectives and backgrounds drive our creativity and innovation, ensuring that our AI solutions are comprehensive and inclusive. By integrating different points of view, our collaborative team develops AI that reflects various experiences and meets the diverse needs of our clients.</li><li><br><strong>Innovative:</strong> We live and breathe innovation, continuously learning and pushing boundaries to deliver cutting-edge AI solutions.</li></ul><p><strong>ANY QUESTIONS?</strong></p><br><p>Your contact person is: <strong>Nilofer Qayumi (Senior Technical Recruiter)</strong></p><br><p>For any questions about the job advertisement and the application process, please contact career@zdf-sparks.com.</p><br><p><strong>We look forward to getting to know you!</strong></p><br><p>At ZDF Sparks, diversity drives our innovation and strengthens our team. We are committed to creating an inclusive environment where every individual feels valued and respected. We welcome applications from all qualified candidates, regardless of race, color, religion, gender, sexual orientation, age, national origin, disability, or any other legally protected status.</p><br><p><strong>ABOUT US</strong></p><br><p>ZDF Sparks was founded in 2024 - our data experts are an agile team dedicated to the development of AI solutions and algorithms for the media industry. We are focused on consulting, design and implementation of AI services, especially in the areas of algorithms, machine learning and data platforms for planning, communication, distribution and personalization of data and audiovisual content.</p><br><p>We are the perfect place for curious, ambitious and collaborative AI trendsetters who are excited about working on new and changing challenges. We enjoy working in our fast-paced, cross-functional and diverse team where everyone feels comfortable and can fulfill their full potential.</p><br>"
  },
  {
    "id": 37,
    "title": "Data Centre Engineer",
    "company": "EOS",
    "locations": "Berlin",
    "skills": "CCNA, CISSP, Network Management, CompTIA, Architektur",
    "posted_at": "2024-09-12",
    "is_remote": "False",
    "snippet_fragments": "The individual will also be responsible for applying security patches to protect systems from vulnerabilities and maintaining an up-to-date inventory of all data center assets, This position requires a solid technical background and network administration,   The position involves overseeing the daily operations of server infrastructure, Monitoring server performance, ensuring consistent uptime, and promptly addressing technical issues.,   Performing regular checks on hardware and software,   Applying patches and updates to safeguard servers against potential vulnerabilities,   Maintaining a detailed inventory of server hardware and software,   3-5 years of experience in Data Centre/Network Administration",
    "description": "<p>WHO WE ARE:</p><br><p>EOS IT Solutions is a global technology and logistics company that provides collaboration and business IT support services to some of the world's most prominent industry leaders, delivering forward-thinking solutions based on multi-domain architecture. Customer satisfaction and commitment to superior quality of service are our top business priorities, along with investing in and supporting our partners and employees.</p><br><p>We are a genuine International IT provider and are proud to deliver our services through global simplicity with trusted transparency.</p><br><p>JOB OVERVIEW:</p><br><p>The Network Systems Administrator/Data Centre Operations Engineer ensures the seamless operation, security, and maintenance of the organization's server infrastructure. This role involves monitoring server performance, addressing issues, and implementing regular hardware and software maintenance. The individual will also be responsible for applying security patches to protect systems from vulnerabilities and maintaining an up-to-date inventory of all data center assets. This position requires a solid technical background and network administration, security, and system management expertise.</p><br><p>JOB RESPONSIBILITIES:</p><ul><li>The position involves overseeing the daily operations of server infrastructure, ensuring the smooth performance, security, and maintenance of data center systems.</li><li>Monitoring server performance, ensuring consistent uptime, and promptly addressing technical issues.</li><li>Performing regular checks on hardware and software, handling upgrades, and replacing or repairing faulty equipment as necessary.</li><li>Applying patches and updates to safeguard servers against potential vulnerabilities.</li><li>Maintaining a detailed inventory of server hardware and software, ensuring compliance with company policies and licensing requirements.</li></ul><p>SKILLS</p><ul><li>3-5 years of experience in Data Centre/Network Administration</li><li>CCNA (Cisco Certified Network Associate)</li><li>CISSP (Certified Information Systems Security Professional)</li><li>CompTIA Network+ Certification</li><li>CompTIA A+ Certification</li></ul><br>"
  },
  {
    "id": 38,
    "title": "Data Centre Engineer",
    "company": "EOS",
    "locations": "Berlin",
    "skills": "CCNA, CISSP, Network Management, CompTIA, Architektur",
    "posted_at": "2024-09-12",
    "is_remote": "False",
    "snippet_fragments": "The individual will also be responsible for applying security patches to protect systems from vulnerabilities and maintaining an up-to-date inventory of all data center assets, This position requires a solid technical background and network administration,   The position involves overseeing the daily operations of server infrastructure, Monitoring server performance, ensuring consistent uptime, and promptly addressing technical issues.,   Performing regular checks on hardware and software,   Applying patches and updates to safeguard servers against potential vulnerabilities,   Maintaining a detailed inventory of server hardware and software,   3-5 years of experience in Data Centre/Network Administration",
    "description": "<p>WHO WE ARE:</p><br><p>EOS IT Solutions is a global technology and logistics company that provides collaboration and business IT support services to some of the world's most prominent industry leaders, delivering forward-thinking solutions based on multi-domain architecture. Customer satisfaction and commitment to superior quality of service are our top business priorities, along with investing in and supporting our partners and employees.</p><br><p>We are a genuine International IT provider and are proud to deliver our services through global simplicity with trusted transparency.</p><br><p>JOB OVERVIEW:</p><br><p>The Network Systems Administrator/Data Centre Operations Engineer ensures the seamless operation, security, and maintenance of the organization's server infrastructure. This role involves monitoring server performance, addressing issues, and implementing regular hardware and software maintenance. The individual will also be responsible for applying security patches to protect systems from vulnerabilities and maintaining an up-to-date inventory of all data center assets. This position requires a solid technical background and network administration, security, and system management expertise.</p><br><p>JOB RESPONSIBILITIES:</p><ul><li>The position involves overseeing the daily operations of server infrastructure, ensuring the smooth performance, security, and maintenance of data center systems.</li><li>Monitoring server performance, ensuring consistent uptime, and promptly addressing technical issues.</li><li>Performing regular checks on hardware and software, handling upgrades, and replacing or repairing faulty equipment as necessary.</li><li>Applying patches and updates to safeguard servers against potential vulnerabilities.</li><li>Maintaining a detailed inventory of server hardware and software, ensuring compliance with company policies and licensing requirements.</li></ul><p>SKILLS</p><ul><li>3-5 years of experience in Data Centre/Network Administration</li><li>CCNA (Cisco Certified Network Associate)</li><li>CISSP (Certified Information Systems Security Professional)</li><li>CompTIA Network+ Certification</li><li>CompTIA A+ Certification</li></ul><br>"
  },
  {
    "id": 39,
    "title": "Working Student Data Engineer (m/w/d) Berlin, Hamburg, Munich",
    "company": "1Komma5\u00b0 GmbH",
    "locations": "Berlin",
    "skills": "Python, SQL, Cloud, Data Pipelines, GCP, Agile, BigQuery, PubSub, Terraform, GitHub, Datadog, UX, CloudSQL, Firestore",
    "posted_at": "2024-09-12",
    "is_remote": "True",
    "snippet_fragments": "  Write audit SQL queries to maintain high data quality standards, Collaborate with product managers, engineers, designers, and developers to deliver data-driven solutions, Build, implement, and maintain data pipelines on Google Cloud Platform (GCP),   Take full ownership of data flows across our systems,   You are enrolled at a university and can commit to 15-20 hours per week, Youre studying Computer Science, Data Engineering, or a similar field,   You have experience writing SQL queries and working with Python, You enjoy problem-solving, analyzing data, and deriving insights, You enjoy writing clean, maintainable, and reusable code thats easy to test,   You are excited to contribute to improving user experience, You have a team-oriented mindset, like working in agile environments, and value close collaboration with your teammates,   Strong English communication skills (both written and spoken) are required; German is a plus, Google Cloud Platform (e.g., Cloud Run, PubSub, CloudSQL, Firestore, BigQuery),   You are part of a dynamic and highly motivated team with people who have proven that they can make things happen and move companies forward, With your work, you accelerate the \"energy and mobility transition\" and make a concrete contribution to the sustainable transformation of our energy infrastructure,   You move in flat hierarchies and have direct contact with the managing directors as well as short decision-making paths,   Work with and learn from other skilled engineers",
    "description": "<p><strong>1KOMMA5\u00b0</strong></p><br><p>We are looking for you to join our tech team in Berlin, Munich, or Hamburg. 1KOMMA5\u00b0 is creating Germany's largest one-stop-shop for the sale, installation, and servicing of solar panels, heat pumps, electricity solutions, and charging infrastructure. And the best part? They are all interconnected! One of our key tech products, our energy manager &quot;Heartbeat,&quot; is central to our mission. It enhances the user experience through our app and ensures the cheapest and cleanest energy for our customers. Additionally, it serves as a core component of our vision to build a virtual power plant.</p><br><p>Become a part of our mission!</p><br><p><strong>YOUR MISSION</strong></p><br><p>As a Working Student Data Engineer in our cross-functional B2C team, you'll play an important role in shaping data solutions that enhance our Heartbeat App and its underlying backend services. You'll collaborate with engineers, product owners, designers, and QA specialists to help address critical business and customer questions using data. Your day-to-day will involve creating robust data ingestion pipelines in Python, writing advanced SQL queries for analysis, and ensuring smooth data flow throughout our systems. You will contribute to empowering our users by delivering transparent, actionable data insights that support smooth operations.</p><br><p>Key responsibilities include but are not limited to:</p><ul><li>Analyze measurements, pricing, and system data to calculate meaningful insights</li><li>Write audit SQL queries to maintain high data quality standards</li><li>Collaborate with product managers, engineers, designers, and developers to deliver data-driven solutions</li><li>Build, implement, and maintain data pipelines on Google Cloud Platform (GCP)</li><li>Take full ownership of data flows across our systems, ensuring reliability and performance</li></ul><p>Technologies you'll work with:</p><ul><li>Python</li><li>SQL</li></ul><p><strong>YOUR PROFILE</strong></p><ul><li>You are enrolled at a university and can commit to 15-20 hours per week</li><li>You're studying Computer Science, Data Engineering, or a similar field</li><li>You have experience writing SQL queries and working with Python</li><li>You enjoy problem-solving, analyzing data, and deriving insights</li><li>You enjoy writing clean, maintainable, and reusable code that's easy to test</li><li>You are excited to contribute to improving user experience</li><li>You have a team-oriented mindset, like working in agile environments, and value close collaboration with your teammates</li><li>Strong English communication skills (both written and spoken) are required; German is a plus</li></ul><p>Bonus points for:</p><ul><li>Google Cloud Platform (e.g., Cloud Run, PubSub, CloudSQL, Firestore, BigQuery)</li><li>Datadog</li><li>Terraform</li><li>GitHub Actions</li></ul><p><strong>BENEFITS</strong></p><ul><li>You are part of a dynamic and highly motivated team with people who have proven that they can make things happen and move companies forward</li><li>With your work, you accelerate the &quot;energy and mobility transition&quot; and make a concrete contribution to the sustainable transformation of our energy infrastructure</li><li>You move in flat hierarchies and have direct contact with the managing directors as well as short decision-making paths</li><li>Work with and learn from other skilled engineers</li><li>You work remotely (Germany-wide), with offices in are Hamburg, Berlin or Munich</li><li>See the direct impact of your work on a rapid-scaling user base</li><li>Create a healthy balance alongside your work and enjoy all the benefits of the EGYM Wellpass</li></ul><p><strong>ABOUT US</strong></p><br><p>&quot;At 1KOMMA5\u00b0, our vision is to accelerate CO2 neutral life for all! We created an easy one-stop-shop to buy and install solar, charging stations and heat pumps, with the purpose of liberating all European homes from the shackles of fossil fuels. With Heartbeat, we make clean energy smarter. Connecting our customers into one powerful clean energy operating system to enable flexible tariffs and to ultimately follow the rhythm of wind and sun!&quot; - Philipp Schr\u00f6der (CEO 1KOMMA5\u00b0)</p><br>"
  },
  {
    "id": 40,
    "title": "Data Engineer - Working Student (f/m/d)",
    "company": "onu.energy GmbH",
    "locations": "Berlin",
    "skills": "Python, SQL, APIs",
    "posted_at": "2024-09-12",
    "is_remote": "False",
    "snippet_fragments": "  Feel comfortable supporting with tasks such as database development,  Yet, if your toolkit isn't a perfect match for our list, but you have a willingness to adapt and learn, you might just be the spark we're looking for,   That's how working with us will be ,  We Celebrate Work-Life Synergy  At onu, Our founders lead by example, working diligently while juggling parental responsibilities and sometimes working from abroad, We are committed to giving everyone the flexibility they need to thrive in our inclusive and supportive culture, We are committed to a hiring process that is inclusive by design, We encourage all applicants to omit personal information such as pictures",
    "description": "<p><strong>YOUR MISSION / THE OPPORTUNITY</strong></p><br><p>You will be an early member of onu.energy's tech team, putting you at the forefront of our product development. Working directly with our founding team members, you'll have the chance to shape our team and build services from the ground up.</p><br><p><strong>Who we're looking for</strong></p><br><p>At Onu Energy, Data Engineering activities are at the heart of nearly everything we do. As we continue to grow, so do the demands on our data systems. Our lead Data Engineer is handling a broad range of tasks, and we're looking for someone to join him as a tandem partner. Your role will be crucial in supporting him and offers a unique opportunity to grow alongside the company, with the potential to transition into a full-time role.</p><br><p><strong>WHAT YOU BRING TO THE TABLE</strong></p><ul><li>Be a student studying ideally computer science at Master's degree level or a very closely related degree.</li><li>Be proficient with SQL and have a working knowledge of python.</li><li>Feel comfortable supporting with tasks such as database development, query design, pipeline development, data cleaning and analysis, API integration, etc.<br> Yet, if your toolkit isn't a perfect match for our list, but you have a willingness to adapt and learn, you might just be the spark we're looking for.<br><strong>THAT'S HOW WORKING WITH US WILL BE</strong><br></li></ul><p><strong>We Celebrate Work-Life Synergy</strong></p><br><p>At onu.energy, we understand that everyone's journey is different, and we are passionate about diversity, family friendliness, and flexible work arrangements and a hybrid model (office &amp; remote). Our founders lead by example, working diligently while juggling parental responsibilities and sometimes working from abroad. We are committed to giving everyone the flexibility they need to thrive in our inclusive and supportive culture.</p><br><p><strong>Join the onu.energy Revolution</strong></p><br><p>Are you ready to power up your career while igniting positive change in the world of energy? Apply now to be part of onu's vibrant, driven team and let's make a sustainable difference, one kilowatt-hour at a time!</p><br><p><strong>EQUAL OPPORTUNITIES &amp; DIVERSITY STATEMENT</strong></p><br><p><strong>onu.energy</strong> is an equal opportunity employer. Our commitment to inclusivity is woven into the fabric of our culture: We believe in fostering a workplace that celebrates diversity and respects each individual's unique journey. We are committed to a hiring process that is inclusive by design, ensuring that no candidate is discriminated against based on gender identity, sexual orientation, personal expression, ethnicity, religious beliefs, or disability status. We encourage all applicants to omit personal information such as pictures, age, or marital status from their applications, as we focus solely on evaluating candidates based on their qualifications and merit. Our goal is to provide a positive candidate experience, and we welcome candidates to communicate any accommodations they may need during the hiring process.</p><br><p><strong>ABOUT US</strong></p><br><p><strong>onu.energy</strong> works at the intersection of energy and technology: we are on a mission to combat climate change by giving medium and large energy consumers the tools to move away from fossil fuels. To achieve this, we are developing a B2B software solution that enables our customers to make smarter energy decisions, increase the speed of green transformation and achieve significant cost savings at the same time.</p><br>"
  },
  {
    "id": 41,
    "title": "ML Researcher / Data Scientist (f/m/d)",
    "company": "onu.energy GmbH",
    "locations": "Berlin",
    "skills": "Python, Machine Learning, AI, Reinforcement Learning, SOLID",
    "posted_at": "2024-09-12",
    "is_remote": "False",
    "snippet_fragments": "  Minimum MSc in a relevant field, Your academic journey should have included significant exposure to machine learning research, Proven experience in Python programming, with a solid understanding of production-level coding standards.,   Demonstrated experience in conducting ML research,   You have the ability to lead and mentor a team, You are proactive, innovative, and always looking for ways to push the boundaries of what's possible with AI in the energy sector.,  Yet, if your toolkit isn't a perfect match for our list, but you have a willingness to adapt and learn, you might just be the spark we're looking for,   That's how working with us will be ,  We Celebrate Work-Life Synergy  At onu",
    "description": "<p><strong>YOUR MISSION / THE OPPORTUNITY</strong></p><br><p>You will be one of the first to join onu.energy's tech team. This will put you at the forefront of our product development. You will be working directly with our founders and have the opportunity to shape our team in its early stages.</p><br><p><strong>You will</strong></p><ul><li>Develop and implement cutting-edge machine learning models for hedging suggestions and load forecasts.</li><li>Collaborate with cross-functional teams to integrate AI solutions into our energy trading and forecasting platforms.</li><li>Conduct advanced ML research with a focus on reinforcement learning (RL) and time series problems.</li><li>Write and maintain production-level code in Python, ensuring scalability and reliability.</li><li>In time, lead and mentor junior data scientists and AI researchers, fostering a culture of innovation and continuous learning.</li><li>Contribute to the strategic direction of AI initiatives within the company.</li></ul><p><strong>WHAT YOU BRING TO THE TABLE</strong></p><br><p><strong>What You Bring to the Table</strong></p><ul><li>Minimum MSc in a relevant field, with a strong preference for candidates holding a PhD. Your academic journey should have included significant exposure to machine learning research, particularly in reinforcement learning and/or time series analysis.</li><li>Proven experience in Python programming, with a solid understanding of production-level coding standards.</li><li>Demonstrated experience in conducting ML research, with a portfolio of projects or publications that showcase your ability to tackle complex problems.</li><li>You have the ability to lead and mentor a team, with a passion for guiding others and driving collaborative success.</li><li>You are proactive, innovative, and always looking for ways to push the boundaries of what's possible with AI in the energy sector.<br> Yet, if your toolkit isn't a perfect match for our list, but you have a willingness to adapt and learn, you might just be the spark we're looking for.<br><strong>THAT'S HOW WORKING WITH US WILL BE</strong><br></li></ul><p><strong>We Celebrate Work-Life Synergy</strong></p><br><p>At onu.energy, we understand that everyone's journey is different, and we are passionate about diversity, family friendliness, flexible work arrangements and a hybrid model (office &amp; remote). Our founders lead by example, working diligently while juggling parental responsibilities and sometimes working from abroad. We are committed to giving everyone the flexibility they need to thrive in our inclusive and supportive culture.</p><br><p><strong>Join the onu.energy Revolution</strong></p><br><p>Are you ready to power up your career while igniting positive change in the world of energy? Apply now to be part of onu's vibrant, driven team and let's make a sustainable difference, one kilowatt-hour at a time!</p><br><p><strong>ABOUT US</strong></p><br><p><strong>onu.energy</strong> works at the intersection of energy and technology: we are on a mission to combat climate change by giving medium and large energy consumers the tools to move away from fossil fuels. To achieve this, we are developing a B2B software solution that enables our customers to make smarter energy decisions, increase the speed of green transformation and achieve significant cost savings at the same time.</p><br>"
  },
  {
    "id": 42,
    "title": "Senior Data Scientist - Fraud & Credit Risk (m/f/d)",
    "company": "RatePAY GmbH",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Data Science, AWS, Cloud, Data Pipelines, ETL, Code Reviews, Unit Testing, PyTest, Algorithms, Codebase, MyPy, Integrity, Prototyping",
    "posted_at": "2024-09-10",
    "is_remote": "True",
    "snippet_fragments": "       Learning and development (Access to various self-development platforms such as language learning and skills enhancement,        Monthly lunches as well as Beets & Roots discounts, We take certain days off to give back to the community as a unit, (Animal shelters, homeless aids, and various charities), So, bring your pawsome pet to work when needed.,           The first call with our recruiter is meant to be an introduction to ratepay,           We want to get to know you better,           This step is designed to get to know your future manager and the role better,           During this conversation we will dive deeper into your experience and share more about the team you would work with and share expectations from both sides",
    "description": "<ul><li>Full-time</li></ul><p>Berlin</p><br><p>from today</p><br><p><strong>HERE'S WHAT YOU'LL BE DOING</strong></p><br><p>Risk management is at the core of Ratepay's business strategy. Our cutting-edge risk management platform processes hundreds of thousands of transactions daily, ensuring secure payments for our merchants and their customers while minimizing risk and maximizing profitability.</p><br><p>We are seeking a highly skilled and experienced Senior Full-Stack Data Scientist to take a leading role in enhancing our fraud prevention and credit risk assessment capabilities. This role involves researching, developing, and deploying advanced machine learning algorithms into production. You will be responsible for every aspect of the data science process, from data collection and pre-processing to building and deploying machine learning models, as well as developing and maintaining production-level codebases.</p><br><p>In this role, you will collaborate with cross-functional teams to drive innovation and ensure that our solutions are scalable and reliable in a fast-paced environment.</p><br><p><strong>Your tasks at Ratepay, among others</strong></p><ul><li>Lead the research, development and implementation of advanced machine learning models for credit risk assessment and fraud prevention.</li><li>Own data science projects end-to-end, i.e. from ideation and proof of concept to bringing it into production.</li><li>Write clean, efficient, and maintainable code adhering to best engineering practices for data processing, model development, and deployment, ensuring scalability and reliability.</li><li>Pre-process complex financial data and create ETL pipelines to support machine learning models.</li><li>Continuously improve our machine learning workflows, research, and deployment pipelines, ensuring best practices and innovation.</li><li>Collaborate closely with team members and cross-functional teams, utilizing strong communication skills to develop robust machine learning solutions.</li><li>Take ownership of subcomponents of the machine learning infrastructure, ensuring their performance and scalability as the platform evolves.</li></ul><p><strong>YOUR PROFILE</strong></p><ul><li>5 + years of experience working with the whole data science product cycle: conception, research, prototyping, modelling, deployment to production</li><li>Master's degree in STEM field</li><li>Very good engineering skills in Python and familiarity with clean code (pre-commit, black, code reviews etc.), unit testing (pytest) and type hints (mypy).</li><li>General understanding of SQL and SQL databases. Ability to retrieve data and build data pipelines that feed models in research and (ideally) build pipelines for production.</li><li>Advanced knowledge of statistical learning theory and its application to solve real-world problems.</li><li>Strong stakeholder communication skills with the ability to clearly present ideas, solutions and findings.</li></ul><p><strong>Nice to have:</strong></p><ul><li>MLOps and experience on AWS Cloud</li><li>Experience in Fintech</li></ul><p><strong>EQUAL OPPORTUNITIES &amp; DIVERSITY</strong></p><br><p>We value our diversity and welcome everyone to our team. Regardless of ethnic and social background, religious views, worldview, gender, sexual orientation, physical and mental limitations, age, marital status, educational background and nationality. With over 250 employees and 40 different nationalities, we take our values seriously. These include; ownership, growth, integrity, collaboration, customer centricity and inclusion (4/6 of our C-Level Board members are female).</p><br><p><strong>THE SWEET SPOT! LET'S TALK PERKS.</strong></p><br><p>We're more than just a workplace - we're a vibrant community of innovators, collaborators, and visionaries who love what we do and reward those who work with us. Here, your career isn't just a job. It's an opportunity to thrive, learn, and make a difference. Take a look at these great personalised benefits of working at Ratepay On a monthly basis, you can choose between mobility, fitness, food, training and much more.</p><br><p><strong>FLEXIBLE WORKING HOURS</strong></p><br><p><strong>WORK REMOTELY (EU FOR UP TO 4 WEEKS A YEAR)</strong></p><br><p><strong>28 VACATION DAYS PER ANNUM</strong></p><br><p><strong>FINANCIAL SECURITY INCLUDING PENSION PLAN</strong></p><br><p><strong>MEDICAL EXTRAS (FLU VACCINATIONS ETC.)</strong></p><br><p><strong>LEARNING AND DEVELOPMENT (ACCESS TO VARIOUS SELF-DEVELOPMENT PLATFORMS SUCH AS LANGUAGE LEARNING AND SKILLS ENHANCEMENT.</strong></p><br><p><strong>MONTHLY LUNCHES AS WELL AS BEETS &amp; ROOTS DISCOUNTS</strong></p><br><p><strong>COMMUNITY CONNECT. WE TAKE CERTAIN DAYS OFF TO GIVE BACK TO THE COMMUNITY AS A UNIT. (ANIMAL SHELTERS, HOMELESS AIDS, AND VARIOUS CHARITIES)</strong></p><br><p><strong>RATEPAW COMMUNITY: OUR OFFICE HAS A FLOOR WHICH IS DOG-FRIENDLY. SO, BRING YOUR PAWSOME PET TO WORK WHEN NEEDED.</strong></p><br><p><strong>GYM MEMBERSHIPS AND FITNESS</strong></p><br><p><strong>HEALTH &amp; WELLBEING</strong></p><br><p><strong>OUR RECRUITMENT PROCESS</strong></p><br><p>Step 1: Intro Call with a Senior Talent Partner</p><br><p>The first call with our recruiter is meant to be an introduction to ratepay, our culture and recruitment process.</p><br><p>We want to get to know you better, understand who you are beyond your CV and find out what excites you.</p><br><p>Step 2: Meet your future Manager</p><br><p>This step is designed to get to know your future manager and the role better.</p><br><p>During this conversation we will dive deeper into your experience and share more about the team you would work with and share expectations from both sides.</p><br><p>Step 3: Team interview &amp; skill assessment</p><br><p>This step looks slightly different in different business areas but is to assess technical and culture add.</p><br><p>It usually consists of a role-specific case study or technical assessment as well as assessing values alignment with some senior members of the team you would be joining.</p><br><p>Step 4: Coffee chat (optional)</p><br><p>This step doesn't occur in every process, it depends on the role.</p><br><p>The coffee chat would generally take place with either a senior stakeholder from the business area you are joining such as a C-level leader or Head of department, or in some cases with a Senior HRBP.</p><br><p><strong>READY TO SHAPE THE FUTURE OF DIGITAL PAYMENTS? JOIN OUR TEAM</strong></p><br>"
  },
  {
    "id": 43,
    "title": "Data Engineer - Klinisches Datenzentrum (m/w/d)",
    "company": "Vivantes \u2013 Netzwerk f\u00fcr Gesundheit GmbH",
    "locations": "Berlin",
    "skills": "Python, SQL, ETL, NoSQL, FHIR, ELT",
    "posted_at": "2024-09-09",
    "is_remote": "False",
    "snippet_fragments": "",
    "description": "<p>Referenz-Nr. ZVI1244</p><br><p><strong>DATA ENGINEER - KLINISCHES DATENZENTRUM (M/W/D)</strong></p><br><p>Mittendrin. Mitarbeiten. Gemeinsam mit angesehenen Expertinnen und Experten. Wir sind der gr\u00f6\u00dfte kommunale Klinikbetreiber Deutschlands mit \u00fcber 100 Fachkliniken, Pflegeeinrichtungen und Instituten. Gestalten Sie die Gesundheitsversorgung von morgen in unserer pulsierenden Hauptstadt.</p><br><p>F\u00fcr das Klinische Datenzentrum (Datenintegrationszentrum) in der Abteilung Klinische Applikationen im Ressort IT und Digitalisierung suchen wir Sie zum n\u00e4chstm\u00f6glichen Termin als</p><br><p><strong>DATA ENGINEER - KLINISCHES DATENZENTRUM (M/W/D)</strong></p><br><p>Das Ressort IT und Digitalisierung hat sich die vollst\u00e4ndige Digitalisierung der klinischen Prozesse zum Ziel gesetzt. Im Rahmen der Vivantes Strategie 2030 arbeiten wir Hand in Hand mit dem Klinikmanagement und Fachanwendern/Fachanwenderinnen an Optimierung, Standardisierung und Digitalisierung unserer Abl\u00e4ufe.</p><br><p><strong>IHRE AUFGABEN</strong></p><br><p>Zusammenarbeit mit (universit\u00e4ren) Projektpartnern/Projektpartnerinnen bei Konzeption und Planung von Schnittstellen, Datenausleitungen und Forschungsprojekten * Konzeption und Umsetzung der Datenintegration aus unseren Quellsystemen inkl. Entwicklung der Datenstrukturen und Ladeprozesse * \u00dcbernahme der Systemverantwortung und des Supports der vom Klinischen Datenzentrum betriebenen Infrastruktur * Mitwirkung im Second-Level-Support der Abteilung sowie Rufbereitschaften * Entwicklung von Datenbankabfragen zu Reportingzwecken * Dokumentation und Schulung laufender IT-Verfahren</p><br><p><strong>WIR W\u00dcNSCHEN UNS</strong></p><br><p>Fach-/Hochschulabschluss im Bereich Medizinische Informatik oder Informatik mit medizinischer Zusatzqualifikation, alternativ Abschluss Fachinformatik Systemintegration/Anwendungsentwicklung mit Projekterfahrungen * Fundiertes Knowhow zur Etablierung von Datenintegrationsprozessen (ETL/ELT/CDC) in DWHs * Programmierkenntnisse in Python oder \u00e4hnlichen Sprachen und profunde Kenntnisse g\u00e4ngiger Datenbanktechnologien (SQL/NoSQL) * Idealerweise erste Kenntnisse der Healthcare - IT Standards v.a. HL/7 V2 und FHIR * Sicheres Deutsch in Wort und Schrift f\u00fcr die Kommunikation im Unternehmen * Selbstorganisation, Eigenverantwortung und Engagement * Sicheres Auftreten gegen\u00fcber Forschern/Forscherinnen, Medizinern/Medizinerinnen und Analysten/Analystinnen</p><br><p><strong>FREUEN SIE SICH AUF</strong></p><br><p>Eine herausfordernde, vielseitige und verantwortungsvolle T\u00e4tigkeit mit der M\u00f6glichkeit, sich einzubringen und zu engagieren * Ein fachlich gut ausgebildetes Team mit hoher Leistungsmotivation * Fundierte Einarbeitung durch ein qualifiziertes Team * Attraktive leistungsgerechte Verg\u00fctung nach TV\u00f6D * Eine sehr g\u00fcnstige Lage mit guten Verkehrsanbindungen * Pr\u00e4miensystem bei Anwerbung von Personal * Mitarbeiter-Einkaufsvorteile bei namhaften Firmen * Entwicklungs- und Karrierechancen als Vorteil unseres gro\u00dfen Konzerns * Sehr gute Weiterentwicklungs- und Fortbildungsm\u00f6glichkeiten in einem eigenen innerbetrieblichen Lehrinstitut * Kostenlose betriebseigene Kinderbetreuung bei kurzfristigem Bedarf * Attraktive und vielf\u00e4ltige Gesundheits- und Freizeitangebote * Eine betriebliche Altersversorgung (VBL) * Bezuschusste Altersvorsorge durch Gehaltsumwandlung m\u00f6glich</p><br><p><strong>FORT- UND WEITERBILDUNG</strong></p><br><p><strong>BERUF UND FAMILIE</strong></p><br><p><strong>GEHALT</strong></p><br><p><strong>GESUNDHEITSF\u00d6RDERUNG</strong></p><br><p><strong>PODCAST</strong></p><br><p><strong>GASTRONOMIE</strong></p><br><p><strong>RAHMENBEDINGUNGEN</strong></p><br><p>Entgelt nach EG 12 TV\u00f6D, die Stufenzuordnung erfolgt je nach Berufserfahrung * Arbeitszeit 39 Wochenstunden * 30 Tage Urlaub * Einsatzort: Berlin Reinickendorf</p><br><p>Einstellungsvoraussetzung: vor Aufnahme der T\u00e4tigkeit - Nachweis der Masernimmunit\u00e4t / Masernschutzimpfung f\u00fcr nach 1970 Geborene.</p><br><p>Wenn Sie die Arbeit in einem dynamischen, motivierten und vor allem offenen und kollegialen Umfeld sch\u00e4tzen, freuen wir uns Sie kennenzulernen.</p><br><p><strong>BITTE BEWERBEN SIE SICH</strong></p><br><p>Referenz-Nr. ZVI1244</p><br><p>Vivantes hat sich die Chancengleichheit und berufliche F\u00f6rderung von Frauen zum Ziel gesetzt. Bewerbungen von Frauen sind uns besonders willkommen. Wir unterst\u00fctzen ausdr\u00fccklich Bewerbungen schwerbehinderter Menschen.</p><br>"
  },
  {
    "id": 44,
    "title": "(Senior) Cloud Engineer - Schwerpunkt Cloud Data Center, SaaS",
    "company": "BEW Berliner Energie und W\u00e4rme AG",
    "locations": "Berlin",
    "skills": "Cloud, Azure, Ansible, DevOps, GitLab, Jenkins, Terraform, VPN, Firewalls, IaC, SaaS, Continuous Integration, IAM",
    "posted_at": "2024-09-06",
    "is_remote": "True",
    "snippet_fragments": "  Du arbeitest mit anderen IT-Teams und externen Dienstleistern zusammen zur schnellen L\u00f6sung von Problemen und Sicherstellung eines reibungslosen Betriebs,   Du leitest und unterst\u00fctzt Projekte im Bereich Cloud-Infrastruktur und SaaS-Integration,   Du erstellst und pflegst technische Dokumentationen,   Du f\u00fchrst regelm\u00e4\u00dfige Berichterstattungen durch \u00fcber Projektstatus,   Abgeschlossenes (Fach-) Hochschulstudium in den Bereichen Informatik,   Tiefgehende Kenntnisse in der Verwaltung und Optimierung von Cloud-Infrastrukturen in Public Cloud-Umgebungen mit Schwerpunkt Microsoft Azure, Erfahrung mit SaaS-Integration, Verwaltung und Betrieb, einschlie\u00dflich Lizenzierung, Sicherheit und Compliance.,   Fundierte Kenntnisse in Infrastructure-as-Code (IaC)-Tools wie Terraform,   Erfahrung in der Implementierung und Verwaltung von Sicherheitsma\u00dfnahmen und Compliance-Vorgaben in der Cloud,   Kenntnisse in der Nutzung von DevOps-Tools und -Prozessen, Vertrautheit mit Netzwerkkonzepten und -sicherheitsprotokollen, einschlie\u00dflich VPNs, Firewalls, und Zero Trust-Architekturen.,   F\u00e4higkeit zur Implementierung und Verwaltung von Cloud-nativen Anwendungen und Microservices-Architekturen,   F\u00e4higkeit zur Analyse komplexer Anforderungen und zur Entwicklung von skalierbaren,   Proaktives Erkennen und Beheben von Performance-Engp\u00e4ssen und Sicherheitsrisiken in der Cloud-Umgebung,   F\u00e4higkeit zur Optimierung der Cloud-Kosten durch den Einsatz von geeigneten Tools und Strategien,   Ausgepr\u00e4gte Kommunikationsf\u00e4higkeiten zur effektiven Zusammenarbeit mit verschiedenen Teams und zur Pr\u00e4sentation von technischen Konzepten,   Projektmanagement-F\u00e4higkeiten zur erfolgreichen Durchf\u00fchrung von Cloud-Infrastruktur- und SaaS-Integrationsprojekten, Hohes Ma\u00df an Eigeninitiative, Verantwortungsbewusstsein und die F\u00e4higkeit, selbstst\u00e4ndig und teamorientiert zu arbeiten.,  Du erf\u00fcllst ungef\u00e4hr 70 Prozent der Anforderungen? Dann bewirb Dich! Zus\u00e4tzliche Informationen, Flexible Gestaltung des Arbeitsalltags (37-Stunden-Woche, Teilzeitm\u00f6glichkeiten, flexible Arbeitszeiten, F\u00fchren von Zeitkonten, mobiles Arbeiten), 30 Tage Urlaub, arbeitsfreie Tage am 24.12, durch kostenfreie Trainings und Unterst\u00fctzung bei berufsbegleitender Weiterqualifizierung,   13 Monatsgeh\u00e4lter f\u00fcr tariflich Angestellte und zus\u00e4tzliche Verg\u00fctungsbestandteile",
    "description": "<p><strong>Unternehmensbeschreibung</strong></p><br><p>W\u00e4rme und Energie sind unser Beitrag zur Lebensqualit\u00e4t - jeden Tag aufs Neue. In Berlin versorgen wir rund 1,4 Millionen Wohneinheiten zuverl\u00e4ssig und klimaschonend mit Fernw\u00e4rme. Mit dem Know How unserer rund 2000 Mitarbeitenden decken wir die gesamte Wertsch\u00f6pfungskette der Fernw\u00e4rme ab - von der Erzeugung \u00fcber den Netzbetrieb und -ausbau bis hin zum Vertrieb. Wir arbeiten bei der BEW Berliner Energie und W\u00e4rme AG jeden Tag in unserer Hauptstadt am Kohleausstieg bis 2030 und einer klimaneutralen Erzeugung ab 2040. Als landeseigenes Unternehmen mit dem gr\u00f6\u00dften Fernw\u00e4rmesystem Westeuropas leisten wir einen gro\u00dfen Beitrag zum Erreichen von Berlins Klimazielen. Auf unserem Weg zum Jahr 2030 integrieren wir verschiedene erneuerbare Energien und Abw\u00e4rmel\u00f6sungen in unsere Erzeugung, was eine umfassende Umgestaltung unserer Kraftwerksstandorte und Anlagen erfordert. F\u00fcr diese Herausforderungen und die damit verbundenen Aufgaben brauchen wir Menschen, die sich mit ganzer Kraft f\u00fcr unser gemeinsames Ziel der lokalen W\u00e4rmewende engagieren - Menschen wie Dich.<br><strong>Stellenbeschreibung</strong><br><strong>Werde Teil der W\u00e4rmewende!</strong></p><br><p>F\u00fcr die <strong>BEW Berliner Energie und W\u00e4rme AG</strong> suchen wir Dich <strong>zum</strong> <strong>n\u00e4chstm\u00f6glichen Zeitpunkt</strong> als <strong>(Senior) Cloud Engineer - Schwerpunkt Cloud Data Center, SaaS am Standort Berlin</strong> <strong>in</strong> <strong>unbefristeter</strong> <strong>Anstellung.</strong></p><br><p>Freitext zur Stelle (optional)</p><br><p><strong>Deine Aufgaben</strong></p><ul><li>Du verantwortest die Verwaltung und Optimierung von Cloud Data Center-Infrastrukturen in Public Cloud-Umgebungen.</li><li>Du bist f\u00fcr die Planung, Implementierung und den Betrieb von skalierbaren und hochverf\u00fcgbaren Cloud-Infrastrukturen f\u00fcr unternehmenskritische Anwendungen zust\u00e4ndig.</li><li>Du stellst die optimale Leistung und Verf\u00fcgbarkeit der Cloud-Ressourcen durch Monitoring, Kapazit\u00e4tsplanung und Performance-Tuning sicher.</li><li>Du implementierst und verwaltest Infrastructure-as-Code (IaC) f\u00fcr die automatisierte Bereitstellung und Verwaltung von Cloud-Ressourcen.</li><li>Du integrierst und verwaltest Software-as-a-Service (SaaS)-L\u00f6sungen in die bestehende Cloud-Umgebung des Unternehmens.</li><li>Du \u00fcbernimmst die Evaluierung, Auswahl und Implementierung von SaaS-L\u00f6sungen zur Unterst\u00fctzung der Gesch\u00e4ftsprozesse.</li><li>Du stellst die nahtlose Integration von SaaS-Anwendungen mit anderen Cloud-Diensten und On-Premises-Systemen sicher.</li><li>Du verwaltest SaaS-Anwendungen, einschlie\u00dflich Benutzerzugriff, Lizenzierung und Sicherheitskonfigurationen.</li><li>Du implementierst Sicherheitsrichtlinien und -ma\u00dfnahmen in der Cloud-Umgebung, einschlie\u00dflich IAM (Identity and Access Management), Netzwerksicherheit und Verschl\u00fcsselung.</li><li>Du stellst die Einhaltung von Compliance-Vorgaben und regulatorischen Anforderungen (z.B. DSGVO, ISO 27001) im Cloud- und SaaS-Bereich sicher.</li><li>Du f\u00fchrst regelm\u00e4\u00dfige Sicherheits\u00fcberpr\u00fcfungen und Risikobewertungen zur Identifizierung und Behebung von Schwachstellen durch.</li><li>Du \u00fcbernimmst den Entwurf und die Implementierung von Cloud-Architekturen f\u00fcr neue Projekte und Anwendungen unter Ber\u00fccksichtigung von Best Practices und Unternehmensrichtlinien.</li><li>Du ber\u00e4tst interne Teams und Stakeholder bei der Entwicklung von Cloud-nativen Anwendungen und der Migration bestehender Anwendungen in die Cloud.</li><li>Du stellst die Skalierbarkeit, Verf\u00fcgbarkeit und Sicherheit der Cloud-Architekturen durch den Einsatz von modernen Technologien und Ans\u00e4tzen sicher.</li><li>Du entwickelst und implementierst Automatisierungsl\u00f6sungen zur Effizienzsteigerung und Kostenoptimierung in der Cloud-Umgebung.</li><li>Du nutzt DevOps-Prinzipien und Tools (z.B. CI/CD-Pipelines) zur Automatisierung von Deployments, Tests und Monitoring.</li><li>Du bist f\u00fcr die kontinuierliche Optimierung der Cloud-Infrastruktur und SaaS-Anwendungen zur Verbesserung der Betriebsabl\u00e4ufe und Reduzierung von Kosten verantwortlich.</li><li>Du k\u00fcmmerst dich um die Bereitstellung von 2nd und 3rd Level Support f\u00fcr Cloud-Infrastrukturen und SaaS-Anwendungen, einschlie\u00dflich Fehlerbehebung und Performance-Optimierung.</li><li>Du f\u00fchrst Analyse durch und findest entsprechende L\u00f6sungen von komplexen technischen Problemen im Zusammenhang mit Cloud- und SaaS-Diensten.</li><li>Du arbeitest mit anderen IT-Teams und externen Dienstleistern zusammen zur schnellen L\u00f6sung von Problemen und Sicherstellung eines reibungslosen Betriebs.</li><li>Du leitest und unterst\u00fctzt Projekte im Bereich Cloud-Infrastruktur und SaaS-Integration, einschlie\u00dflich Planung, Implementierung und \u00dcbergabe.</li><li>Du erstellst und pflegst technische Dokumentationen, Architekturbeschreibungen und Betriebshandb\u00fccher f\u00fcr die Cloud-Umgebung.</li><li>Du f\u00fchrst regelm\u00e4\u00dfige Berichterstattungen durch \u00fcber Projektstatus, Betriebsergebnisse und Optimierungspotenziale an das Management.</li></ul><p><strong>Qualifikationen</strong><br><strong>Dein Profil</strong></p><ul><li>Abgeschlossenes (Fach-) Hochschulstudium in den Bereichen Informatik, Wirtschaftswissenschaften o.\u00e4. bzw. eine ad\u00e4quate Qualifikation</li><li>Tiefgehende Kenntnisse in der Verwaltung und Optimierung von Cloud-Infrastrukturen in Public Cloud-Umgebungen mit Schwerpunkt Microsoft Azure.</li><li>Erfahrung mit SaaS-Integration, Verwaltung und Betrieb, einschlie\u00dflich Lizenzierung, Sicherheit und Compliance.</li><li>Fundierte Kenntnisse in Infrastructure-as-Code (IaC)-Tools wie Terraform, Ansible oder ARM Templates.</li><li>Erfahrung in der Implementierung und Verwaltung von Sicherheitsma\u00dfnahmen und Compliance-Vorgaben in der Cloud.</li><li>Kenntnisse in der Nutzung von DevOps-Tools und -Prozessen, einschlie\u00dflich CI/CD-Pipelines, Jenkins, GitLab, oder Azure DevOps.</li><li>Vertrautheit mit Netzwerkkonzepten und -sicherheitsprotokollen, einschlie\u00dflich VPNs, Firewalls, und Zero Trust-Architekturen.</li><li>F\u00e4higkeit zur Implementierung und Verwaltung von Cloud-nativen Anwendungen und Microservices-Architekturen.</li><li>F\u00e4higkeit zur Analyse komplexer Anforderungen und zur Entwicklung von skalierbaren, sicheren und kosteneffizienten Cloud-L\u00f6sungen.</li><li>Proaktives Erkennen und Beheben von Performance-Engp\u00e4ssen und Sicherheitsrisiken in der Cloud-Umgebung.</li><li>F\u00e4higkeit zur Optimierung der Cloud-Kosten durch den Einsatz von geeigneten Tools und Strategien.</li><li>Ausgepr\u00e4gte Kommunikationsf\u00e4higkeiten zur effektiven Zusammenarbeit mit verschiedenen Teams und zur Pr\u00e4sentation von technischen Konzepten.</li><li>Projektmanagement-F\u00e4higkeiten zur erfolgreichen Durchf\u00fchrung von Cloud-Infrastruktur- und SaaS-Integrationsprojekten.</li><li>Hohes Ma\u00df an Eigeninitiative, Verantwortungsbewusstsein und die F\u00e4higkeit, selbstst\u00e4ndig und teamorientiert zu arbeiten.</li></ul><p>Du erf\u00fcllst ungef\u00e4hr 70 Prozent der Anforderungen? Dann bewirb Dich!<br><strong>Zus\u00e4tzliche Informationen</strong><br><strong>Deine Benefits</strong></p><ul><li>Flexible Gestaltung des Arbeitsalltags (37-Stunden-Woche, Teilzeitm\u00f6glichkeiten, flexible Arbeitszeiten, F\u00fchren von Zeitkonten, mobiles Arbeiten)</li><li>30 Tage Urlaub, arbeitsfreie Tage am 24.12. und 31.12. sowie Freistellungsm\u00f6glichkeiten</li><li>F\u00f6rderung der individuellen Entwicklung, u.a. durch kostenfreie Trainings und Unterst\u00fctzung bei berufsbegleitender Weiterqualifizierung</li><li>13 Monatsgeh\u00e4lter f\u00fcr tariflich Angestellte und zus\u00e4tzliche Verg\u00fctungsbestandteile</li><li>Betriebliche Altersversorgung</li><li>\u00d6PNV-Firmenticket bzw. Deutschlandticket (50% Arbeitgeberzuschuss) und Jobrad-Angebot</li><li>Mitarbeiterstromtarif nach 12 Monaten Betriebszugeh\u00f6rigkeit</li><li>Diverse Angebote zum Thema Gesundheit, u.a. Urban Sports Club Mitgliedschaft und PME-Familienservice</li></ul><p>Du m\u00f6chtest alle unsere Benefits kennenlernen? Dann sprich uns darauf an, was wir zu bieten haben!</p><br><p><strong>Deine Bewerbung</strong></p><br><p>Wir freuen uns \u00fcber Deine Bewerbung bis sp\u00e4testens <strong>04.10.2024</strong> <strong>in deutscher Sprache</strong>!</p><br><p>F\u00fcr weitere Informationen zu dieser Position kannst Du Dich an den einstellenden Manager <strong>Andreas Kohsiek</strong> unter der Emailadresse <strong>andreas.kohsiek@bew.berlin</strong> wenden. Fragen zum Bewerbungsprozess beantwortet Dir gern die zust\u00e4ndige Recruiterin <strong>Anja Blisch</strong> unter der Telefonnummer <strong>+49 30 81822001</strong>.</p><br><p>Du hast Interesse an unserem Angebot und m\u00f6chtest gemeinsam mit uns die Berliner W\u00e4rmewende gestalten? <strong>Dann freuen wir uns auf Deine Bewerbung \u00fcber unsere Website!</strong></p><br><p><strong>Hinweise</strong></p><br><p>Wir sind davon \u00fcberzeugt, dass Vielfalt dazu beitr\u00e4gt, unser Unternehmen leistungsf\u00e4higer und attraktiver zu machen. Bewerbungen zum Beispiel von Personen jeglichen Alters, geschlechtlicher Identit\u00e4t, sexueller Orientierung, ethnisch-kulturellen Hintergrunds sind herzlich willkommen. Schwerbehinderte Menschen werden bei gleicher fachlicher Eignung besonders ber\u00fccksichtigt.</p><br><p>Die Sicherheit von BEW Berliner Energie und W\u00e4rme AG und seinen Besch\u00e4ftigten ist von grundlegender Bedeutung. Aus diesem Grund ist ein Pre-Employment Screening Teil des Rekrutierungsprozesses. Der Umfang der \u00dcberpr\u00fcfung variiert je nach Funktion und Einsatzbereich. Das Screening wird von einem Drittanbieter, Validata, durchgef\u00fchrt.</p><br>"
  },
  {
    "id": 45,
    "title": "(Senior) Data Engineer (m/w/d) Data Mnagement & Analytics Plattform",
    "company": "Bundesdruckerei GmbH",
    "locations": "Berlin",
    "skills": "Mathematik, Linux, Data Modeling, Data Warehouse, ETL, Airflow, Big Data, Apache Beam, Hadoop, Kafka, Bash, Kubernetes, Scrum, Unit Testing, APIs, Orchestration, Kimball, Data Lake, Spark, SOAP, Vault, AWS S3, ELT, Statistik",
    "posted_at": "2024-09-04",
    "is_remote": "False",
    "snippet_fragments": "Erfolgreich abgeschlossenes Studium der (Wirtschafts-)Informatik, Mathematik, Statistik oder eines vergleichbaren Studiengangs, alternativ eine Ausbildung in einem entsprechenden IT-Bereich mit relevanter Berufserfahrung,   Umfassende Kenntnisse in der Python- und SQL-Entwicklung sowie in Software-Entwicklungsstandards, Airflow, Argo Workflows), in der Datenmodellierung/-architektur (3NF, Kimball, Inmon, Data Vault 2.0, Lambda-/Kappa-Architekturen) sowie in Schnittstellen/APIs (Rest, Soap, auch Crawler/Scraper), Know-how im Bereich analytische Datenbanken, Containerisierung, Kubernetes, Linux und Bash,   Sichere Kenntnisse in der Aufsetzung und Optimierung von Enterprise-Data-Warehouse-/Data-Lake-Strukturen sowie in den Bereichen Big Data (HDFS,   Breites Data Engineering Markt- und Technologiewissen im Bereich Tools (Query Engines), Delta Lake, Kafka) und Konzepte (Lakehouse, Data Mesh)",
    "description": "<p><strong>Ihr Aufgabenbereich</strong></p><ul><li>Verantwortung f\u00fcr den Entwurf und die (Weiter-)Entwicklung von anwendungsfallspezifischen Datenarchitekturen und Datenmodellen</li><li>Verantwortung f\u00fcr die Entwicklung und Optimierung von SQL-Abfragen und Prozeduren</li><li>Entwurf, Entwicklung, Test und Monitoring von Prozessen zur Extraktion, Transformation und Laden von Daten aus Quellsystemen in Data Warehouse und Data Lake (ETL/ELT-Pipelines),</li><li>Entwicklung, Orchestration und Monitoring von Airflow und ArgoWorkflows DAGs,</li><li>Gestaltung automatisierter Qualit\u00e4tsprozesse zur Sicherstellung der Software- und Datenqualit\u00e4t sowie der Datenverf\u00fcgbarkeit zur Einhaltung von Service Level Agreements</li><li>Analyse und Optimierung der aktuellen L\u00f6sungen, des physischen Modells sowie der Abfragen</li><li>Anleitung und Weiterentwicklung der technischen F\u00e4higkeiten, sowie Wissensweitergabe im Data Engineering Team<br><strong>Ihr Profil</strong><br></li><li>Erfolgreich abgeschlossenes Studium der (Wirtschafts-)Informatik, Mathematik, Statistik oder eines vergleichbaren Studiengangs, alternativ eine Ausbildung in einem entsprechenden IT-Bereich mit relevanter Berufserfahrung</li><li>Umfassende Kenntnisse in der Python- und SQL-Entwicklung sowie in Software-Entwicklungsstandards, Best Practices und Testing (Unit Tests, Test Frameworks, Mocking)</li><li>Fachwissen in einem oder mehreren ETL-Tools (z.B. Airflow, Argo Workflows), in der Datenmodellierung/-architektur (3NF, Kimball, Inmon, Data Vault 2.0, Lambda-/Kappa-Architekturen) sowie in Schnittstellen/APIs (Rest, Soap, auch Crawler/Scraper)</li><li>Know-how im Bereich analytische Datenbanken, Containerisierung, Kubernetes, Linux und Bash</li><li>Sichere Kenntnisse in der Aufsetzung und Optimierung von Enterprise-Data-Warehouse-/Data-Lake-Strukturen sowie in den Bereichen Big Data (HDFS, S3, Spark), Data Streaming (Kafka, Apache Beam) und ELT</li><li>Breites Data Engineering Markt- und Technologiewissen im Bereich Tools (Query Engines), Frameworks (z.B. Delta Lake, Kafka) und Konzepte (Lakehouse, Data Mesh)</li><li>Gutes Kommunikationsverm\u00f6gen und erfahren im agilen Softwareentwickeln nach SCRUM</li><li>Deutschkenntnisse mindestens auf B2-Niveau</li></ul><br>"
  },
  {
    "id": 46,
    "title": "(Senior) Data Engineer (m/w/d) Data Mnagement & Analytics Plattform",
    "company": "Bundesdruckerei GmbH",
    "locations": "Berlin",
    "skills": "Mathematik, Linux, Data Modeling, Data Warehouse, ETL, Airflow, Big Data, Apache Beam, Hadoop, Kafka, Bash, Kubernetes, Scrum, Unit Testing, APIs, Orchestration, Kimball, Data Lake, Spark, SOAP, Vault, AWS S3, ELT, Statistik",
    "posted_at": "2024-09-04",
    "is_remote": "False",
    "snippet_fragments": "Erfolgreich abgeschlossenes Studium der (Wirtschafts-)Informatik, Mathematik, Statistik oder eines vergleichbaren Studiengangs, alternativ eine Ausbildung in einem entsprechenden IT-Bereich mit relevanter Berufserfahrung,   Umfassende Kenntnisse in der Python- und SQL-Entwicklung sowie in Software-Entwicklungsstandards, Airflow, Argo Workflows), in der Datenmodellierung/-architektur (3NF, Kimball, Inmon, Data Vault 2.0, Lambda-/Kappa-Architekturen) sowie in Schnittstellen/APIs (Rest, Soap, auch Crawler/Scraper), Know-how im Bereich analytische Datenbanken, Containerisierung, Kubernetes, Linux und Bash,   Sichere Kenntnisse in der Aufsetzung und Optimierung von Enterprise-Data-Warehouse-/Data-Lake-Strukturen sowie in den Bereichen Big Data (HDFS,   Breites Data Engineering Markt- und Technologiewissen im Bereich Tools (Query Engines), Delta Lake, Kafka) und Konzepte (Lakehouse, Data Mesh)",
    "description": "<p><strong>Ihr Aufgabenbereich</strong></p><ul><li>Verantwortung f\u00fcr den Entwurf und die (Weiter-)Entwicklung von anwendungsfallspezifischen Datenarchitekturen und Datenmodellen</li><li>Verantwortung f\u00fcr die Entwicklung und Optimierung von SQL-Abfragen und Prozeduren</li><li>Entwurf, Entwicklung, Test und Monitoring von Prozessen zur Extraktion, Transformation und Laden von Daten aus Quellsystemen in Data Warehouse und Data Lake (ETL/ELT-Pipelines),</li><li>Entwicklung, Orchestration und Monitoring von Airflow und ArgoWorkflows DAGs,</li><li>Gestaltung automatisierter Qualit\u00e4tsprozesse zur Sicherstellung der Software- und Datenqualit\u00e4t sowie der Datenverf\u00fcgbarkeit zur Einhaltung von Service Level Agreements</li><li>Analyse und Optimierung der aktuellen L\u00f6sungen, des physischen Modells sowie der Abfragen</li><li>Anleitung und Weiterentwicklung der technischen F\u00e4higkeiten, sowie Wissensweitergabe im Data Engineering Team<br><strong>Ihr Profil</strong><br></li><li>Erfolgreich abgeschlossenes Studium der (Wirtschafts-)Informatik, Mathematik, Statistik oder eines vergleichbaren Studiengangs, alternativ eine Ausbildung in einem entsprechenden IT-Bereich mit relevanter Berufserfahrung</li><li>Umfassende Kenntnisse in der Python- und SQL-Entwicklung sowie in Software-Entwicklungsstandards, Best Practices und Testing (Unit Tests, Test Frameworks, Mocking)</li><li>Fachwissen in einem oder mehreren ETL-Tools (z.B. Airflow, Argo Workflows), in der Datenmodellierung/-architektur (3NF, Kimball, Inmon, Data Vault 2.0, Lambda-/Kappa-Architekturen) sowie in Schnittstellen/APIs (Rest, Soap, auch Crawler/Scraper)</li><li>Know-how im Bereich analytische Datenbanken, Containerisierung, Kubernetes, Linux und Bash</li><li>Sichere Kenntnisse in der Aufsetzung und Optimierung von Enterprise-Data-Warehouse-/Data-Lake-Strukturen sowie in den Bereichen Big Data (HDFS, S3, Spark), Data Streaming (Kafka, Apache Beam) und ELT</li><li>Breites Data Engineering Markt- und Technologiewissen im Bereich Tools (Query Engines), Frameworks (z.B. Delta Lake, Kafka) und Konzepte (Lakehouse, Data Mesh)</li><li>Gutes Kommunikationsverm\u00f6gen und erfahren im agilen Softwareentwickeln nach SCRUM</li><li>Deutschkenntnisse mindestens auf B2-Niveau</li></ul><br>"
  },
  {
    "id": 47,
    "title": "Data Engineer (m/w/d)",
    "company": "ista Express Service GmbH",
    "locations": "Berlin",
    "skills": "Python, SQL, Mathematik, AWS, Data Analysis, GCP, Azure, Business Intelligence, Data Modeling, BigQuery, Java, Scala, Looker, Mac",
    "posted_at": "2024-09-04",
    "is_remote": "False",
    "snippet_fragments": "  Einen unbefristeten Arbeitsvertrag mit einem attraktiven Gehalt in einem jungen, durch flache Hierarchien, kurze Entscheidungswege und Can-Do-Attitude, Wir arbeiten agil orientiert am Spotify-Modell,    Spannende und abwechslungsreiche Aufgaben mit viel Raum f\u00fcr eigenverantwortliches Arbeiten,    Work-Life Balance - flexible Arbeitszeiten und 30 Tage Urlaub,   Du bekommst von uns eine zugeschnittene Einarbeitung mit vielen Trainings- und Qualifizierungsma\u00dfnahmen,    Zahlreiche Weiterentwicklungsm\u00f6glichkeiten dank eines starken Expansionskurses und einem komplexen Umfeld,  Du arbeitest in modernen B\u00fcror\u00e4umlichkeiten im Herzen Berlins mit ergonomischen Arbeitspl\u00e4tzen und bester Hardware - Du w\u00e4hlst selbst zwischen Mac und PC.,    Mitarbeiterrabatte bei \u00fcber 800 Anbietern wie Zalando",
    "description": "<p><strong>WAS DU BEI UNS MACHST</strong></p><br><p><strong>PLEASE NOTE: THIS POSITION REQUIRES FLUENT GERMAN LANGUAGES SKILLS</strong></p><br><p>Du bist ein erfahrener Data Engineer und suchst nach einer neuen Herausforderung? Du hast eine Leidenschaft f\u00fcr Datenanalysen und m\u00f6chtest Dein Fachwissen nutzen, um bei der Optimierung die Gesch\u00e4ftsprozesse und -entscheidungen unseres Unternehmens zu unterst\u00fctzen? Dann komm in unser Team!</p><br><p><strong>Deine Aufgaben</strong></p><ul><li>Als Data Engineer entwickelst Du kontinuierliche unsere Business Intelligence L\u00f6sung und die Datenmodellen in der Google Cloud Platform weiter.</li><li>Du entwickelst und wartest Datenpipelines zur Verarbeitung gro\u00dfer Datenmengen.</li><li>Du verstehst Business Use Cases und \u00fcbersetzt diese in eine Datensprache, sodass der Use Cases durch die Daten interpretiert werden kann.</li><li>Du konzipierst und implementierst ETL-Prozesse f\u00fcr unterschiedliche Datenquellen.</li><li>Du arbeitest mit diversen Bereichen, wie z.B. Business Development und Softwareentwicklern zusammen, eng zusammen, um datengetriebene L\u00f6sungen zu entwickeln.</li><li>Du sorgst f\u00fcr die Datenqualit\u00e4t und -integrit\u00e4t in unseren Systemen.</li><li>Du unterst\u00fctzt bei der Optimierung und Skalierung unserer Datenarchitekturen.</li></ul><p><strong>WAS DU MITBRINGST</strong></p><ul><li>Du hast ein abgeschlossenes Studium in Informatik, Wirtschaftsinformatik, Mathematik, Ingenieurwissenschaften oder einem verwandten Bereich.</li><li>Du hast mindestens 3 Jahre fundierte Berufserfahrung in diesem Bereich.</li><li>Du verf\u00fcgst \u00fcber fundierte Kenntnisse in SQL vorzugsweise in BigQuery.</li><li>Du bist vertraut mit Programmiersprachen wie Python, Java oder Scala.</li><li>Erfahrungen mit Cloud-Plattformen wie AWS, Azure oder bevorzugt Google Cloud sind von Vorteil.</li><li>Du bringst Kenntnisse in der Datenmodellierung und -visualisierung vorzugsweise in Looker mit. Dateninterpretation ist f\u00fcr Dich ein Kinderspiel und mit Deinen Ideen kannst du im Team \u00fcberzeugen.</li><li>Du bist ein Teamplayer und hast Freude an der Zusammenarbeit in interdisziplin\u00e4ren Teams.</li><li>Du hast eine analytische Denkweise und ein hohes Ma\u00df an Probleml\u00f6sungskompetenz.</li></ul><p><strong>WAS WIR BIETEN</strong></p><ul><li>Einen <strong>unbefristeten Arbeitsvertrag mit einem attraktiven Gehalt</strong> in einem jungen, stabilen und zukunftsorientierten Unternehmen.</li><li><br><strong>Innovative Unternehmenskultur</strong>: Hier kannst Du unser Unternehmen kennenlernen: ista Express Service Mediathek (https://www.ista-express.de/videos/).</li><li><br><strong>Effiziente Teamarbeit</strong> durch flache Hierarchien, kurze Entscheidungswege und Can-Do-Attitude. Wir arbeiten agil orientiert am Spotify-Modell.</li><li><br><strong>Spannende und abwechslungsreiche Aufgaben</strong> mit viel Raum f\u00fcr eigenverantwortliches Arbeiten.</li><li><br><strong>Work-Life Balance</strong> - flexible Arbeitszeiten und 30 Tage Urlaub.</li><li>Zusatzleistungen: <strong>Eine betriebliche Krankenzusatzversicherung</strong> (z.B. f\u00fcr Brille, Zahnersatz, Heilpraktiker).</li><li>Du bekommst von uns eine <strong>zugeschnittene Einarbeitung mit vielen Trainings- und Qualifizierungsma\u00dfnahmen</strong>.</li><li><br><strong>Zahlreiche Weiterentwicklungsm\u00f6glichkeiten</strong> dank eines starken Expansionskurses und einem komplexen Umfeld, in dem sich immer wieder neue Themenfelder ergeben.</li><li><br><strong>Moderne Arbeitspl\u00e4tze:</strong> Du arbeitest in modernen B\u00fcror\u00e4umlichkeiten im Herzen Berlins mit ergonomischen Arbeitspl\u00e4tzen und bester Hardware - Du w\u00e4hlst selbst zwischen Mac und PC.</li><li><br><strong>Mitarbeiterrabatte</strong> bei \u00fcber 800 Anbietern wie Zalando, Adidas, Apple &amp; Co - da ist bestimmt auch f\u00fcr Dich etwas dabei!</li><li><br><strong>Mitarbeiter werben Mitarbeiter: Pr\u00e4mie</strong>.</li><li><br><strong>Extras</strong>: Auf Dich warten neben einem Siebtr\u00e4ger-Coffeemaker, Obstkorb und kostenlosen Getr\u00e4nken auch viele weitere Extras (z.B. Firmenevents, Gewinnspiele).</li></ul><p><strong>DU HAST NOCH FRAGEN?</strong></p><br><p>Wir beantworten Dir gerne Fragen zum Bewerbungsablauf f\u00fcr die Position als Data Engineer (m/w/d). Melde Dich einfach per Telefon unter +49 341 69700777.</p><br><p><strong>\u00dcBER UNS</strong></p><br><p>Seit 2020 sind wir als ista Express Service GmbH der professionelle Servicepartner f\u00fcr die zuverl\u00e4ssige Installation und Wartung von Messger\u00e4ten wie Hei\u00dfkostenverteiler, Wasserz\u00e4hler und Rauchwarnmelder in Privatr\u00e4umen und Gewerbeanlagen. Unser Ziel ist es, das perfekte Kundenerlebnis f\u00fcr Mieter:innen, Hausverwaltungen und Gro\u00dfkund:innen zu garantieren.</p><br><p>Mit aktuell 16 Standorten in ganz Deutschland (wie z.B. Berlin, Hamburg, Hannover, Leipzig, Mannheim, Osnabr\u00fcck, Frankfurt, Essen, Stuttgart, K\u00f6ln, D\u00fcsseldorf und Oldenburg) und weit \u00fcber 250 Mitarbeiter:innen werden wir unsere Unternehmensgr\u00f6\u00dfe auch in Zukunft nachhaltig erweitern.</p><br>"
  },
  {
    "id": 48,
    "title": "Data Engineer - Advanced Analytics / ETL / SQL (m/w/d)",
    "company": "BRL Risk Consulting GmbH & Co. KG",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Mathematik, Data Science, AWS, Data Pipelines, Azure, Business Intelligence, ETL, Big Data, CISA, Dashboards, SQL Server, MySQL, Predictive Analytics, Data mining, Snowflake, R, Amazon RDS, Statistik",
    "posted_at": "2024-09-04",
    "is_remote": "False",
    "snippet_fragments": "  Gute Anbindung an die \u00d6PNV sowie Innenstadtlage,   Gute Anbindung an die \u00d6PNV sowie Innenstadtlage und Fahrtkostenzuschuss,   Firmenhandy (iPhone) mit der M\u00f6glichkeit privater Nutzung,  Was erwartet Dich als Senior Data Engineer?,   Du implementierst relationale Datenbanken und extrahierst relevante Informationen aus diesen, Du analysierst Gesch\u00e4ftsprozesse, identifizierst Optimierungspotentiale und entwickelst entsprechende Ma\u00dfnahmen, Du entwirfst, implementierst und pflegst Data Pipelines und systeme, insbesondere f\u00fcr ETL-Prozesse,   Du evaluierst verschiedene Methoden und Tools f\u00fcr Data Science und Data-Mining,   Du unterst\u00fctzt bei der Konzeption und Aufbau von BI und Big Data Plattformen sowie der Auswahl von Speichertechnologien,   Du unterst\u00fctzt bei der Erstellung von Reports und Dashboards,   Du \u00fcbernimmst Projektmanagementt\u00e4tigkeiten und erstellst Statusberichte,  Wir bieten Dir einen vielf\u00e4ltigen Aufgabenbereich und ein unternehmerisch orientiertes Arbeitsumfeld mit Freiraum f\u00fcr die Umsetzung deiner L\u00f6sungsans\u00e4tze sowie \u00fcberdurchschnittliche Perspektiven f\u00fcr deinen weiteren beruflichen Aufstieg,   Du hast mindestens 4-5 Jahre Berufserfahrung im Bereich Data Engineering,   Du verf\u00fcgst \u00fcber ein abgeschlossenes Studium der Wirtschafts- (Informatik),   Du besitzt sehr gute Kenntnisse in der Programmierung f\u00fcr Advanced Analytics (SQL,   Du besitzt Kenntnisse zur Entwicklung und Verwaltung von Datenbanken,   Du hast Erfahrung mit Erstellung und Optimierung von ETL-Prozessen unter Ber\u00fccksichtigung der Datenplausibilit\u00e4t und Leistung,   Du kannst effiziente Data Pipelines und -systeme entwerfen, AWS RDS, Google Cloud SQL, Azure SQL-Datenbank)",
    "description": "<p><strong>\u00dcber BRL Risk Consulting GmbH &amp; Co. KG:</strong></p><br><p>Globale Expertise, lokale Pr\u00e4senz: Ihre verl\u00e4sslichen Partner f\u00fcr Rechts-, Wirtschafts- und Steuerfragen seit 2006.</p><br><p>Wir sind eine international ausgerichtete Partnerschaft von Rechtsanw\u00e4lten, Wirtschaftspr\u00fcfern und Steuerberatern, die im Jahr 2006 gegr\u00fcndet wurde. Heute sind wir mit rund 380 Mitarbeitern an den Standorten Hamburg, Berlin, Bochum, Hannover, Dortmund, M\u00fcnchen und Bielefeld vertreten.</p><br><p>Durch eine eigene Gesellschaft sowie \u00fcber Moore Global, ein globales Netzwerk unabh\u00e4ngiger WP/StB-Gesellschaften, sind wir bestens aufgestellt, um auch f\u00fcr l\u00e4nder\u00fcbergreifende Fragestellungen zuverl\u00e4ssige und effiziente L\u00f6sungen bereitzustellen. Heute sind in diesem Netzwerk weltweit rund 230 f\u00fchrende Wirtschaftspr\u00fcfungs- und Steuerberatungsgesellschaften zusammengeschlossen, mit Standorten in 522 St\u00e4dten und 112 L\u00e4ndern und mit mehr als 34.000 Mitarbeitern.</p><br><p>Wir sind ein interdisziplin\u00e4res Team, das sich leidenschaftlich daf\u00fcr einsetzt, unsere weltweit t\u00e4tigen Kunden bei der Identifikation, Steuerung und Vermeidung potenzieller Risiken in allen Gesch\u00e4ftsbereichen zu unterst\u00fctzen. Dabei betrachten wir finanzielle, technologische und gesch\u00e4ftsrelevante Risiken, um den Unternehmenserfolg langfristig zu sichern. Mit unseren breiten Pr\u00fcfungs- und Beratungsdienstleistungen bieten wir umfassende L\u00f6sungen f\u00fcr unsere Kunden an.</p><br><p>Unser Risk Advisory Services (RAS)-Team bietet umfassende Leistungen im Bereich Governance, Risk und Compliance an. Dabei wird ein einheitlicher und integrierter Ansatz verfolgt, um bestm\u00f6gliche Synergieeffekte zwischen den Bereichen Risikomanagement, interne Kontrollsystemen (IKS) und Interne Revision sowie Compliance Management und Corporate Governance zu erzielen.</p><br><p><strong>WAS BIETEN WIR DIR?</strong></p><ul><li>Unternehmen mit flachen Hierarchien, kurzen Entscheidungswegen und einer offenen Kommunikationspolitik</li><li>Ausgepr\u00e4gte Feedbackkultur</li><li>Gute Anbindung an die \u00d6PNV sowie Innenstadtlage</li><li>Regelm\u00e4\u00dfige Teamevents</li><li>Attraktive Corporate Benefits</li><li>Attraktive Weiterbildungsangebote sowie Unterst\u00fctzung beim Erwerb von beruflichen Zertifizierungen (z.B. CISA, CIA, CISA etc.)</li><li>Ein leistungsorientiertes Bonussystem</li><li>Gute Anbindung an die \u00d6PNV sowie Innenstadtlage und Fahrtkostenzuschuss</li><li>Betriebliche Altersvorsorge sowie Gesundheitsf\u00f6rderung</li><li>Firmenhandy (iPhone) mit der M\u00f6glichkeit privater Nutzung</li></ul><p><strong>WAS ERWARTET DICH ALS SENIOR DATA ENGINEER?</strong></p><ul><li>Du implementierst relationale Datenbanken und extrahierst relevante Informationen aus diesen</li><li>Du analysierst Gesch\u00e4ftsprozesse, identifizierst Optimierungspotentiale und entwickelst entsprechende Ma\u00dfnahmen</li><li>Du entwirfst, implementierst und pflegst Data Pipelines und -systeme, insbesondere f\u00fcr ETL-Prozesse</li><li>Du evaluierst verschiedene Methoden und Tools f\u00fcr Data Science und Data-Mining</li><li>Du unterst\u00fctzt bei der Konzeption und Aufbau von BI und Big Data Plattformen sowie der Auswahl von Speichertechnologien</li><li>Du unterst\u00fctzt bei der Erstellung von Reports und Dashboards</li><li>Du \u00fcbernimmst Projektmanagementt\u00e4tigkeiten und erstellst Statusberichte<br> Wir bieten Dir einen vielf\u00e4ltigen Aufgabenbereich und ein unternehmerisch orientiertes Arbeitsumfeld mit Freiraum f\u00fcr die Umsetzung deiner L\u00f6sungsans\u00e4tze sowie \u00fcberdurchschnittliche Perspektiven f\u00fcr deinen weiteren beruflichen Aufstieg.<br><strong>WAS SOLLTEST DU MITBRINGEN?</strong></li><li>Du hast mindestens 4-5 Jahre Berufserfahrung im Bereich Data Engineering</li><li>Du verf\u00fcgst \u00fcber ein abgeschlossenes Studium der Wirtschafts- (Informatik), Mathematik, Statistik oder in Data Science</li><li>Du besitzt sehr gute Kenntnisse in der Programmierung f\u00fcr Advanced Analytics (SQL, Python oder R f\u00fcr Data Mining, Predictive Analytics, Computational Statistics)</li><li>Du besitzt Kenntnisse zur Entwicklung und Verwaltung von Datenbanken, insbesondere mit einem Schwerpunkt auf relationalen Datenbanken wie MySQL oder SQL-Server</li><li>Du hast Erfahrung mit Erstellung und Optimierung von ETL-Prozessen unter Ber\u00fccksichtigung der Datenplausibilit\u00e4t und Leistung</li><li>Du kannst effiziente Data Pipelines und -systeme entwerfen, implementieren und warten, um eine hohe Skalierbarkeit, Zuverl\u00e4ssigkeit und Leistung sicherzustellen</li><li>Du hast bereits Erfahrungen mit der Implementierung von Cloud-basierten Datenbankservices gesammelt (z. B. AWS RDS, Google Cloud SQL, Azure SQL-Datenbank)</li><li>Erfahrungen mit Data-Warehouse-Technologien wie Snowflake sind von Vorteil</li><li>Ausgezeichnete Kommunikations- und Pr\u00e4sentationsf\u00e4higkeiten in Deutsch und Englisch, sowie F\u00e4higkeit, komplexe technische Konzepte verst\u00e4ndlich an nicht-technische Stakeholder zu vermitteln</li><li>Du konntest bereits Erfahrungen im Bereich Machine Learning und Big Data Technologien sammeln</li></ul><p>Unser Jobangebot Data Engineer - Advanced Analytics / ETL / SQL (m/w/d) klingt vielversprechend?</p><br><p>Bei unserem Partner <strong>Workwise</strong> ist eine Bewerbung f\u00fcr diesen Job <strong>in nur wenigen Minuten</strong> und <strong>ohne Anschreiben</strong> m\u00f6glich. Anschlie\u00dfend kann der Status der Bewerbung live verfolgt werden. Wir freuen wir uns auf eine <strong>Bewerbung \u00fcber Workwise</strong>.</p><br><p>Mehr Informationen zu uns und unseren Jobangeboten findet man auf unserem Unternehmensprofil bei Workwise.</p><br>"
  },
  {
    "id": 49,
    "title": "(Senior) Data Engineer (m/f/d)",
    "company": "Verivox GmbH",
    "locations": "Berlin",
    "skills": "Python, SQL, AWS, GCP, Data Modeling, Data Warehouse, ETL, Airflow, BigQuery, JSON, APIs, Data Structures, Salesforce, Snowflake, ELT",
    "posted_at": "2024-09-04",
    "is_remote": "True",
    "snippet_fragments": "     Extensive professional experience in data engineering,      Affinity for the Internet and a keen interest in e-commerce,      Practice know-how in relational and multidimensional data modeling,      Practice know-how in data warehouse solutions,      Fluent in spoken and written English,      Around 500 employees from over 35 nations as a collegial community,      Open and diverse corporate culture with flat hierarchies,      Generous Mobile office regulations enabling flexible work from home and within the EU,      Individual area of responsibility with space for the development of one's own ideas and concepts,      Exclusive employee benefits such as a job ticket, Company health management, including company pension schemes, Urban Sports Club, Crossfit, and Mental Health Days, Centrally located offices in Heidelberg, Berlin, Munich, and Leipzig with optimal transportation connections,     Are you up to meet these exciting challenges?   If so, Tell us how you will contribute to our success story! Please send your application (including your salary expectation and the earliest possible date of starting to work) via Apply now or to jobs@verivox,   Verivox is one of the leading online comparison portals in Germany, Since 1998, we have been making markets transparent in the areas of electricity & gas, We find the best offer for consumers from around 30,000 tariffs, With our help more than 8 million customers have already saved over 2 billion euros, Since 2015, Verivox has been part of the ProSiebenSat.1 Group",
    "description": "<p><strong>INTRODUCTION SENTENCE</strong></p><br><p><strong>Become part of the Verivox team!</strong></p><br><p>Are you highly motivated, creative and an independently working team player and want to take an active part in shaping the future of Verivox within the context of data-driven?</p><br><p>Than we are looking for you as a <strong>(Senior) Data Engineer (m/f/d)</strong> ! We offer a fulltime position (40h/week) in one of our locations in <strong>Heidelberg, Berlin or Munich</strong> . The offer includes the option of working several days per week in the mobile office.</p><br><p><strong>YOUR MISSION</strong></p><ul><li>Your focus is on modelling data, implementing ELT/ETL pipelines and on developing concepts of data warehouse solutions</li><li>You integrate a variety of data sources like Salesforce, Google Big Query, (rest) APIs</li><li>You mainly work with state-of-the-art technologies and concepts (e.g. AWS, Snowflake, message queues) and evaluate new technologies with regard to their appropriate use</li><li>You provide the complete data flow from the source to reporting for the end user</li><li>You design and ensure a uniform data model with its data structures, central lookup tables, central fact tables and important dimensions</li><li>You ensure data consistency and quality</li></ul><p><strong>YOUR ESSENTIAL EXPERIENCE AND EDUCATION</strong></p><ul><li>Extensive professional experience in data engineering</li><li>Affinity for the Internet and a keen interest in e-commerce</li><li>Practice know-how in relational and multidimensional data modeling</li><li>Practice know-how in data warehouse solutions</li><li>Technologies: SQL, Python, Rest, JSON, ETL-tools (Airflow), Amazon AWS, Google Cloud BigQuery, DBT</li><li>Fluent in spoken and written English, knowledge of the German Language is a plus</li></ul><p><strong>WHAT'S IN IT FOR YOU?</strong></p><ul><li>Around 500 employees from over 35 nations as a collegial community</li><li>Open and diverse corporate culture with flat hierarchies, as well as a modern and appreciative working environment</li><li>Generous Mobile office regulations enabling flexible work from home and within the EU</li><li>Individual area of responsibility with space for the development of one's own ideas and concepts</li><li>Uncomplicated cooperation: we are on first-name terms &amp; don't insist on dress codes</li><li>Exclusive employee benefits such as a job ticket, job bike, lunch subsidies via Sodexo, and employee discounts</li><li>Company health management, including company pension schemes, Urban Sports Club, Crossfit, and Mental Health Days</li><li>Centrally located offices in Heidelberg, Berlin, Munich, and Leipzig with optimal transportation connections</li></ul><p><strong>CLOSURE</strong></p><br><p><strong>Are you up to meet these exciting challenges?</strong></p><br><p>If so, then we would love to talk to you. Tell us how you will contribute to our success story! Please send your application (including your salary expectation and the earliest possible date of starting to work) via &quot;Apply now&quot; or to jobs@verivox.com .</p><br><p>Verivox is one of the leading online comparison portals in Germany. Since 1998, we have been making markets transparent in the areas of electricity &amp; gas, mobile phones &amp; internet and finance &amp; insurance. We find the best offer for consumers from around 30,000 tariffs, helping households to save time and money. With our help more than 8 million customers have already saved over 2 billion euros. Since 2015, Verivox has been part of the ProSiebenSat.1 Group.</p><br><p><strong>COMPANY TEXT</strong></p><br><p>Click here to learn more about the ProSiebenSat.1 Group and our diverse portfolio.</p><br><p>You have a disability and would like to apply? Then you are very welcome.</p><br><p>We know that we are not entirely accessible yet, but we are working on it. Let's talk about how we can eliminate any barrier together and find an individual solution if needed.</p><br><p>Although we refer to one gender in the text, all genders may be implied.</p><ul><li>Training and Education</li><li>Subsidized company pension plan</li><li>Flexible Working Hours</li><li>No dress code</li><li>Team Events</li><li>Open corporate culture</li><li>Exclusive employee benefits / discounts</li><li>Hybrid Work</li></ul><br>"
  },
  {
    "id": 50,
    "title": "(Senior) Consultant Data Engineer - Strategy and Transactions (w/m/d)",
    "company": "EY",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Mathematik, Data Analysis, Business Intelligence, Power BI, Databricks, Business Analytics, Azure Synapse, Datenanalytik",
    "posted_at": "2024-09-03",
    "is_remote": "False",
    "snippet_fragments": " Das bieten wir dir  ein inspirierendes Arbeitsumfeld,  Bei EY setzen wir alles daran, Daf\u00fcr hinterfragen wir t\u00e4glich den Status quo und suchen schon heute die Antworten von morgen, Wandel? Sehen wir als Chance und Treiber f\u00fcr Innovation,  Wenn du auch so tickst, dann bist du bei uns genau richtig, Das erfordert Zusammenarbeit auf Augenh\u00f6he und das Verlassen ausgetretener Pfade, Diese beschreitest du als Teil von interdisziplin\u00e4ren Teams  innovativ und multikulturell aufgestellt in Deutschland,   Damit auch du pers\u00f6nlich und beruflich \u00fcber dich hinausw\u00e4chst, Das Tempo und Ziel auf deinem Weg bestimmst du selbst",
    "description": "<p><strong>Das erwartet dich bei uns - Erfahrungen, von denen du ein Leben lang profitierst</strong></p><br><p>Als Teil unseres Data &amp; Analytics-Teams in Hamburg, Berlin, M\u00fcnchen, Stuttgart, D\u00fcsseldorf und Frankfurt/Main \u00fcbernimmst du relevante und zuverl\u00e4ssige Analysen w\u00e4hrend des gesamten Deal- und Transformationszyklus, sowie strategischer Fragestellungen und unterst\u00fctzt damit unsere Kund:innen bei den dringendsten Gesch\u00e4ftsfragen und Herausforderungen.Dabei \u00fcbernimmst du vielf\u00e4ltige Aufgaben:</p><ul><li>Du ber\u00e4tst unsere nationalen und internationalen Kunden:innen, um ihr Gesch\u00e4ftswachstum und die Unternehmensperformance zu verbessern</li><li>Du konzipierst und implementierst passgenaue BI und Analytics L\u00f6sungen unter Verwendung von Azure-Technologien wie Azure Synapse, MS Fabric, Power BI und Databricks</li><li>Du f\u00fchrst komplexe Datenanalysen durch, um Gesch\u00e4ftseinblicke, Trends zu extrahieren und klare strategische Anleitungen und Empfehlungen zu finanziellen und operativen Herausforderungen zu geben</li><li>Du nutzt dein Wissen im Bereich der K\u00fcnstlichen Intelligenz, einschlie\u00dflich GenAI und Machine Learning, um reale Probleme f\u00fcr unsere Kunden zu l\u00f6sen und eine Kultur der datengesteuerten Innovation in der Unternehmensteuerung zu f\u00f6rdern, die die Erforschung und \u00dcbernahme neuer analytischer Methoden und Werkzeuge ermutigt</li></ul><p><strong>Das bringst du mit - F\u00e4higkeiten, mit denen du die Zukunft gestaltest</strong></p><ul><li>Du hast dein Studium im Bereich der Datenwissenschaften/Business Analytics/Wirtschaftswissenschaften/Mathematik/Informatik oder einem verwandten Bereich mit \u00fcberdurchschnittlichem Erfolg abgeschlossen und verf\u00fcgst im besten Fall \u00fcber erste praktische Erfahrung in der Umsetzung datengesteuerter Projekte</li><li>Du hast starke Programmierkenntnisse, insbesondere in Python und SQL, verf\u00fcgst \u00fcber Erfahrung in Datenanalytik, Datenwissenschaft oder Datenengineering</li><li>Du hast erste Erfahrung im Aufbau und Management von ETL/ELT-Pipelines, vorzugsweise auf Cloud-Plattformen oder lokal</li><li>Du verf\u00fcgst \u00fcber zus\u00e4tzliches Wissen in einem der Bereiche BI, Corporate Finance, Accounting/Controlling/Marketing oder Operations</li><li>Du hast ausgezeichnete Kommunikations- und Pr\u00e4sentationsf\u00e4higkeiten in Englisch und Deutsch</li></ul><p><strong>Das bieten wir dir</strong> <strong>-</strong> <strong>ein inspirierendes Arbeitsumfeld</strong></p><br><p>Bei EY setzen wir alles daran, dass die Welt besser funktioniert. Daf\u00fcr hinterfragen wir t\u00e4glich den Status quo und suchen schon heute die Antworten von morgen. Stillstand? Keine Option. Wandel? Sehen wir als Chance und Treiber f\u00fcr Innovation.</p><br><p>Wenn du auch so tickst, dann bist du bei uns genau richtig. Wir suchen Macher:innen, die Unternehmen, Entrepreneuren, Privatpersonen und der \u00f6ffentlichen Hand helfen, \u00fcber sich hinaus zu wachsen. Das erfordert Zusammenarbeit auf Augenh\u00f6he und das Verlassen ausgetretener Pfade. Diese beschreitest du als Teil von interdisziplin\u00e4ren Teams - innovativ und multikulturell aufgestellt in Deutschland, Europa und der ganzen Welt.</p><br><p>Damit auch du pers\u00f6nlich und beruflich \u00fcber dich hinausw\u00e4chst, begleiten wir dich auf deinem Karriereweg mit auf dich zugeschnittenen Arbeitsmodellen sowie Trainings- und Entwicklungsm\u00f6glichkeiten on- und off-the-Job. Das Tempo und Ziel auf deinem Weg bestimmst du selbst.</p><br><p>Wir wissen: Erstklassiger Service f\u00fcr unsere Mandant:innen und Kund:innen beginnt bei zufriedenen und motivierten Mitarbeitenden. Deshalb reicht unser Angebot von flexiblen Arbeitsmodellen, Auslandeins\u00e4tzen und Weiterbildungen \u00fcber Sport- und Freizeitangeboten bis hin zu Rabatten bekannter Marken und Anbieter sowie Altersvorsorge. Erfahre mehr \u00fcber deine Benefits bei EY.</p><br><p><strong>Du hast Lust was zu bewegen? Dann werde Teil unseres Teams.</strong></p><br><p>Bewirb dich jetzt \u00fcber unser Jobportal: www.de.ey.com/karriere.</p><br><p>Mehr Informationen zum Bewerbungsprozess bei EY findest du auf unserer Karriereseite.</p><br><p>Deine Fragen beantwortet gerne unser Recruitment Center unter: +49 6196 996 10005.</p><br><p>Was andere \u00fcber uns sagen, findest du auf kununu und Glassdoor.</p><br>"
  },
  {
    "id": 51,
    "title": "Data Scientist",
    "company": "Amazon.com",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Data Science, Data Analysis, Agile, MATLAB, Perl, Deep Learning, Causal Inference, Statistical modeling, Scripting Language, Empower, R, SAS, NLP, Statistik, Applied Mathematics",
    "posted_at": "2024-08-30",
    "is_remote": "True",
    "snippet_fragments": "We operate in an agile environment in which we own and collaborate on the life cycle of research,   Develop and validate models to optimize the Who,   Imagine and invent before the business asks, Open the Science black-box, use causal inference and develop compelling data visualizations,   Work closely with other data scientists,   ABOUT AUDIBLE Audible is the leading producer and provider of audio storytelling, We spark listeners imaginations, offering immersive, cinematic experiences full of inspiration and insight to enrich our customers daily lives, Our HubHome hybrid workplace model gives employees the flexibility between gathering in a common office space (work from hub) and remote work (work from home), For more information, please visit adbl.co/hybrid,    Experience with data scripting languages (e,    Experience with machine learning/statistical modeling data analysis tools and techniques, 3 yrs relevant experience; or, PhD 1 yr relevant experience, Experience in Python, Perl, or another scripting language,    Experience in a ML or data scientist role with a large technology company",
    "description": "<p>At Audible, we believe stories have the power to transform lives. It's why we work with some of the world's leading creators to produce and share audio storytelling with our millions of global listeners. We are dreamers and inventors who come from a wide range of backgrounds and experiences to empower and inspire each other. Imagine your future with us.</p><br><p>ABOUT THIS ROLE</p><br><p>In this role, you will build scalable solutions and models to support our business functions (Content, Marketing, Product). Leveraging a range of methods including machine learning and simulation, you will explain, quantify, predict and prescribe in support of informing critical business decisions. You will translate business goals into agile, insightful analytics. You will seek to create value for both stakeholders and customers and inform findings in a clear, actionable way to managers and senior leaders.</p><br><p>ABOUT THE TEAM</p><br><p>Audible's Data Science team partners with marketing, content, product, and technology partners to solve business and technology problems using scientific approaches to build product and services that surprise and delight our customers. We employ scalable cutting-edge Data Science (DS), machine learning (ML), deep learning (DL), and Natural Language Processing (NLP) knowledge to better target customers and prospects, understand and personalize the content, and context needed to optimize their book-listening experience. We operate in an agile environment in which we own and collaborate on the life cycle of research, design, and model development of relevant projects.</p><br><p>As a Data Scientist, you will...</p><ul><li>Develop and validate models to optimize the Who, When, Where and How of all our interactions with customers</li><li>Develop Audible-wide data engineering pipelines</li><li>Imagine and invent before the business asks, and create groundbreaking applications using cutting-edge approaches</li><li>Open the Science black-box, use causal inference and develop compelling data visualizations</li><li>Work closely with other data scientists, ML experts, engineers and on cross-disciplinary efforts with other scientists within Amazon</li></ul><p>ABOUT AUDIBLE</p><br><p>Audible is the leading producer and provider of audio storytelling. We spark listeners' imaginations, offering immersive, cinematic experiences full of inspiration and insight to enrich our customers daily lives. Our Hub+Home hybrid workplace model gives employees the flexibility between gathering in a common office space (work from hub) and remote work (work from home). For more information, please visit adbl.co/hybrid.<br><strong>BASIC QUALIFICATIONS</strong></p><ul><li>Experience with data scripting languages (e.g., SQL, Python, R, or equivalent) or statistical/mathematical software (e.g., R, SAS, Matlab, or equivalent)</li><li>Experience with machine learning/statistical modeling data analysis tools and techniques, and parameters that affect their performance</li><li>3 yrs relevant experience; or, PhD +1 yr relevant experience</li><li>MS in one of the following disciplines: Computer Science, Statistics, Data Science, Economics, Applied Mathematics, Operational Research or a related quantitative field</li><li>Experience in modeling, research design</li></ul><p><strong>PREFERRED QUALIFICATIONS</strong></p><ul><li>Experience in Python, Perl, or another scripting language</li><li>Experience in a ML or data scientist role with a large technology company</li></ul><p>Amazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success. We make recruiting decisions based on your experience and skills. We value your passion to discover, invent, simplify and build. Protecting your privacy and the security of your data is a longstanding top priority for Amazon. Please consult our Privacy Notice (https://www.amazon.jobs/en/privacy_page) to know more about how we collect, use and transfer the personal data of our candidates.</p><br><p>m/w/d</p><br>"
  },
  {
    "id": 52,
    "title": "Data Scientist",
    "company": "Audible",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Data Science, Data Analysis, MATLAB, Perl, Deep Learning, Causal Inference, Statistical modeling, Scripting Language, Empower, R, SAS, NLP, Statistik, Applied Mathematics",
    "posted_at": "2024-08-30",
    "is_remote": "True",
    "snippet_fragments": "We operate in an agile environment in which we own and collaborate on the life cycle of research,   Develop and validate models to optimize the Who,   Imagine and invent before the business asks, Open the Science black-box, use causal inference and develop compelling data visualizations,   Work closely with other data scientists,   ABOUT AUDIBLE Audible is the leading producer and provider of audio storytelling, We spark listeners imaginations, offering immersive, cinematic experiences full of inspiration and insight to enrich our customers daily lives, Our HubHome hybrid workplace model gives employees the flexibility between gathering in a common office space (work from hub) and remote work (work from home), For more information, please visit adbl.co/hybrid.,   Experience with data scripting languages (e,   Experience with machine learning/statistical modeling data analysis tools and techniques, 3 yrs relevant experience; or, PhD 1 yr relevant experience, Experience in Python, Perl, or another scripting language,   Experience in a ML or data scientist role with a large technology company",
    "description": "<p>At Audible, we believe stories have the power to transform lives. It's why we work with some of the world's leading creators to produce and share audio storytelling with our millions of global listeners. We are dreamers and inventors who come from a wide range of backgrounds and experiences to empower and inspire each other. Imagine your future with us.</p><br><p>ABOUT THIS ROLE</p><br><p>In this role, you will build scalable solutions and models to support our business functions (Content, Marketing, Product). Leveraging a range of methods including machine learning and simulation, you will explain, quantify, predict and prescribe in support of informing critical business decisions. You will translate business goals into agile, insightful analytics. You will seek to create value for both stakeholders and customers and inform findings in a clear, actionable way to managers and senior leaders.</p><br><p>ABOUT THE TEAM</p><br><p>Audible's Data Science team partners with marketing, content, product, and technology partners to solve business and technology problems using scientific approaches to build product and services that surprise and delight our customers. We employ scalable cutting-edge Data Science (DS), machine learning (ML), deep learning (DL), and Natural Language Processing (NLP) knowledge to better target customers and prospects, understand and personalize the content, and context needed to optimize their book-listening experience. We operate in an agile environment in which we own and collaborate on the life cycle of research, design, and model development of relevant projects.</p><br><p>As a Data Scientist, you will...</p><ul><li>Develop and validate models to optimize the Who, When, Where and How of all our interactions with customers</li><li>Develop Audible-wide data engineering pipelines</li><li>Imagine and invent before the business asks, and create groundbreaking applications using cutting-edge approaches</li><li>Open the Science black-box, use causal inference and develop compelling data visualizations</li><li>Work closely with other data scientists, ML experts, engineers and on cross-disciplinary efforts with other scientists within Amazon</li></ul><p>ABOUT AUDIBLE</p><br><p>Audible is the leading producer and provider of audio storytelling. We spark listeners' imaginations, offering immersive, cinematic experiences full of inspiration and insight to enrich our customers daily lives. Our Hub+Home hybrid workplace model gives employees the flexibility between gathering in a common office space (work from hub) and remote work (work from home). For more information, please visit adbl.co/hybrid.</p><br><p>Basic Qualifications</p><ul><li>Experience with data scripting languages (e.g., SQL, Python, R, or equivalent) or statistical/mathematical software (e.g., R, SAS, Matlab, or equivalent)</li><li>Experience with machine learning/statistical modeling data analysis tools and techniques, and parameters that affect their performance</li><li>3 yrs relevant experience; or, PhD +1 yr relevant experience</li><li>MS in one of the following disciplines: Computer Science, Statistics, Data Science, Economics, Applied Mathematics, Operational Research or a related quantitative field</li><li>Experience in modeling, research design</li></ul><p>Preferred Qualifications</p><ul><li>Experience in Python, Perl, or another scripting language</li><li>Experience in a ML or data scientist role with a large technology company</li></ul><p>Amazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success. We make recruiting decisions based on your experience and skills. We value your passion to discover, invent, simplify and build. Protecting your privacy and the security of your data is a longstanding top priority for Amazon. Please consult our Privacy Notice (https://www.amazon.jobs/en/privacy_page) to know more about how we collect, use and transfer the personal data of our candidates.</p><br><p>m/w/d</p><br>"
  },
  {
    "id": 53,
    "title": "Solution Engineer Data Center Technologies (m/w/d) f\u00fcr AIRBUS",
    "company": "Orizon GmbH, Unit Aviation",
    "locations": "Berlin",
    "skills": "VMware, KVM, Nachrichtentechnik",
    "posted_at": "2024-08-29",
    "is_remote": "False",
    "snippet_fragments": "   Die Secure Land Communications ist die Programmlinie von Airbus Defence and Space f\u00fcr professionelle Mobilfunkl\u00f6sungen, Weltweit bieten sie Kunden eine umfassende Palette an Funk- und IT-L\u00f6sungen f\u00fcr mobile, Dies umfasst die Realisierung von landesweiten Sicherheitsfunknetzen,   Lieferung des globalen Design f\u00fcr Data Center L\u00f6sungen einschlie\u00dflich technischer Anforderungen,   Analyse und \u00dcbersetzung von Gesch\u00e4ftsanforderungen in IT Requirements und deren Anpassung an das Architektur-spezifische Blueprint,   Sicherstellung der \u00fcbergreifenden L\u00f6sungsanpassung \u00fcber Anwendungen,   Mitwirkung in allen Phasen des Entwicklungsablaufs der Anwendungen, Unterst\u00fctzung der Bereiche Vertrieb, Marketing und Bid Management in den Phasen Pre-Sales, Angebot, Projektabwicklung und technische Kundenpr\u00e4sentationen, Abgeschlossenes Studium der Fachrichtung Informatik, Ingenieurwesen, Nachrichtentechnik, Kommunikationstechnik oder eine vergleichbare Qualifikation,   Verhandlungssichere Deutsch- und Englischkenntnisse in Wort und Schrift",
    "description": "<p><strong>UNSER ANGEBOT:</strong></p><ul><li>Attraktives Arbeitsumfeld mit guten Perspektiven</li><li>Tarifliche Entlohnung nach iGZ/DGB Tarif zzgl. Branchenzuschl\u00e4gen</li><li>Pers\u00f6nliche Einsatzbegleitung und qualifizierte Beratung</li><li>Unser Mitarbeiter-Benefit-Programm Orizon PlusPunkte</li><li>Bis zu 30 Tage Jahresurlaub</li></ul><p><strong>IHRE ZUK\u00dcNFTIGE ARBEITSSTELLE:</strong><br> F\u00fcr unseren Kunden Airbus Secure Land Communications am Standort Ulm sind Sie als Solution Engineer (m/w/d) f\u00fcr Data Center Technologies t\u00e4tig.</p><ul><li>Die Secure Land Communications ist die Programmlinie von Airbus Defence and Space f\u00fcr professionelle Mobilfunkl\u00f6sungen. Weltweit bieten sie Kunden eine umfassende Palette an Funk- und IT-L\u00f6sungen f\u00fcr mobile, taktische Kommunikation an. Dies umfasst die Realisierung von landesweiten Sicherheitsfunknetzen, wie beispielsweise dem digitalen Beh\u00f6rdenfunk der Bundesrepublik Deutschland.</li></ul><p><strong>IHRE AUFGABEN:</strong></p><ul><li>Lieferung des globalen Design f\u00fcr Data Center L\u00f6sungen einschlie\u00dflich technischer Anforderungen, Prinzipien und Modelle in \u00dcbereinstimmung mit den Konzern- Architektur-Richtlinien</li><li>Analyse und \u00dcbersetzung von Gesch\u00e4ftsanforderungen in IT Requirements und deren Anpassung an das Architektur-spezifische Blueprint</li><li>Sicherstellung der \u00fcbergreifenden L\u00f6sungsanpassung \u00fcber Anwendungen, Systeme und Plattformen und Gew\u00e4hrleistung der Konsistenz der IT-Produkte</li><li>Mitwirkung in allen Phasen des Entwicklungsablaufs der Anwendungen, einschlie\u00dflich Forschung, Design, Entwicklung, Test, Implementierung und Support</li><li>Unterst\u00fctzung der Bereiche Vertrieb, Marketing und Bid Management in den Phasen Pre-Sales, Angebot, Projektabwicklung und technische Kundenpr\u00e4sentationen</li></ul><p><strong>IHR PROFIL:</strong></p><ul><li>Abgeschlossenes Studium der Fachrichtung Informatik, Ingenieurwesen, Nachrichtentechnik, Kommunikationstechnik oder eine vergleichbare Qualifikation</li><li>Berufserfahrung im System Engineering</li><li>Technische Kenntnisse von Virtualisierungstools (z. B. KVM oder VMware) erforderlich</li><li>Verhandlungssichere Deutsch- und Englischkenntnisse in Wort und Schrift</li></ul><p><strong>IHR PARTNER:</strong><br> Sie sind auf der Suche nach Ihrem Wunschjob? Orizon unterst\u00fctzt Sie dabei! Mit individueller Beratung und pers\u00f6nlicher Betreuung finden wir f\u00fcr Sie den Job, der am besten zu Ihnen passt.</p><br><p>Orizon geh\u00f6rt zu den f\u00fcnfzehn gr\u00f6\u00dften Personaldienstleistern in Deutschland. Als einer der Marktf\u00fchrer f\u00fcr den deutschen Mittelstand \u00fcberlassen und vermitteln wir Fach- und F\u00fchrungskr\u00e4fte aus allen Berufsfeldern an namhafte Unternehmen. Finden auch Sie mit uns Ihren Platz!<br><strong>NOCH FRAGEN ZU DIESER ANZEIGE?</strong></p><br><p><strong>PERS\u00d6NLICHER KONTAKT:</strong></p><br><p>Herr Kai Bachmann</p><br><p>T: +49 421 16037-72</p><br><p>E: IndeedBewerbung.aviation@orizon.de</p><br><p>Postanschrift:</p><br><p>Orizon GmbH, Unit Aviation</p><br><p>S\u00f6gestr. 59 - 61</p><br><p>28195 Bremen</p><br><p><strong>BEWERBUNG UND R\u00dcCKFRAGEN:</strong></p><br><p>Wir freuen uns auf Bewerbungen (unter Angabe von ID-Nummer 289398, Verf\u00fcgbarkeit und Gehaltsvorstellung) gerne per E-Mail an IndeedBewerbung.aviation@orizon.de oder \u00fcber den Bewerbungs-Button in dieser Anzeige.</p><br><p>F\u00fcr Fragen steht Herr Kai Bachmann gern unter der Telefonnummer +49 421 16037-72</p><br><p>zur Verf\u00fcgung.</p><br><p>Weitere Stellenangebote sind unter orizon.de zu finden.</p><br><p>Wir nehmen den Schutz personenbezogener Daten ernst: www.orizon.de/de/datenschutzvereinbarungen</p><br>"
  },
  {
    "id": 54,
    "title": "Lead Data Scientist - Machine Learning",
    "company": "Almedia",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Cloud, A/B testing",
    "posted_at": "2024-08-28",
    "is_remote": "False",
    "snippet_fragments": "Extensive work experience, with industry experience in developing machine-learning models, and ideally leading projects and small teams., Expertise in building, deploying, measuring, and maintaining machine learning models to address real-world problems., Strong statistical knowledge (A/B tests, probability, regression)., A combination of Python, SQL, and cloud experience is essential., Excellent communication skills, with the ability to present complex findings in a clear and concise manner, Preference for candidates with backgrounds in ad tech,   An opportunity to work in an innovative,   A fast-paced and inclusive work environment in a team of highly motivated professionals",
    "description": "<p>Almedia helps leading brands in the digital space to acquire new customers. Users can find and test the latest games, apps, and products for rewards via our platforms.</p><br><p>With more than 25 million users since our launch in 2020, Almedia's Freecash.com is one of the fastest-growing providers and a leader in our industry. Our mission is to provide a win-win experience for both users and advertisers.</p><br><p>We are looking for a Lead Data Scientist to join our rapidly growing team in Berlin</p><br><p><strong>You Will</strong></p><ul><li>Identify high-value ML business opportunities and work with both business and technical stakeholders to realize business benefit.</li><li>Deliver and deploy end-to-end machine-learning models, build measurement plans, learn and iterate to drive results.</li><li>Apply a solid statistical mindset and best practices, in the process of model development, deployment, and evolution.</li><li>Deeply understand the data and customer and business problems, in order to more closely align machine-learning model objectives and develop the best features and models to predict them.</li><li>Collaborate effectively with cross-functional teams, including product managers, engineers, business developers, and user acquisition channel managers.</li></ul><p><strong>You Have:</strong></p><ul><li>Extensive work experience, with industry experience in developing machine-learning models, and ideally leading projects and small teams.</li><li>Expertise in building, deploying, measuring, and maintaining machine learning models to address real-world problems.</li><li>Strong statistical knowledge (A/B tests, probability, regression).</li><li>A combination of Python, SQL, and cloud experience is essential.</li><li>Excellent communication skills, with the ability to present complex findings in a clear and concise manner. Preference for candidates with backgrounds in ad tech, gaming, or marketing.</li></ul><p><strong>Benefits:</strong></p><ul><li>An opportunity to work in an innovative, high-growth startup that has been profitable from day one.</li><li>A fast-paced and inclusive work environment in a team of highly motivated professionals.</li><li>Continuous learning and development opportunities.</li><li>Flexible work arrangements and a modern office space in the heart of Berlin.</li><li>Work from abroad policy</li></ul><p>Almedia is an equal opportunity employer, we embrace and celebrate diversity and encourage individuals from all backgrounds to apply.</p><br>"
  },
  {
    "id": 55,
    "title": "Data Center Engineer (m/w/d)",
    "company": "Xecuro GmbH",
    "locations": "Berlin",
    "skills": "",
    "posted_at": "2024-08-26",
    "is_remote": "False",
    "snippet_fragments": "  Disposition und Durchf\u00fchrung von Zutritts- und Zugangskontrollen, Analyse, Dokumentation und Beseitigung von St\u00f6rungen bzw, Fachinformatiker oder Systemelektroniker oder eine vergleichbare technische Ausbildung,   Praktische Erfahrung im Betrieb von Datacenter-Komponenten und im WAN-/Carrier-Bereich sowie im Betrieb von DWDM-Komponenten vorteilhaft, Erfahrung im Betrieb von Rechenzentren, mit der zugeh\u00f6rigen Energieversorgung und mit Zutrittssystemen sowie im Kabelmanagement und in der Installation von Hardware-Komponenten,   Kenntnisse in der Anwendung von Monitoring-Tools und DCIM-Systemen,   Sicherheit im Umgang mit englischen Herstellerdokumentationen",
    "description": "<p>Zum n\u00e4chstm\u00f6glichen Zeitpunkt suchen wir Sie als Data Center Engineer f\u00fcr den Standort Berlin.<br><strong>Ihr Aufgabenbereich</strong></p><ul><li>Aufbau, Bedienung, Betrieb und \u00dcberwachung der Rechenzentrumsinfrastruktur und der dort installierten IT-Systeme (Verkabelung, Racks, Server, Netzwerke, Storage-Systeme)</li><li>Durchf\u00fchrung und Kontrolle der Change- und Configuration-Management-Prozesse in einem 24x7-Betriebsmodell</li><li>Ausf\u00fchrung, Steuerung und \u00dcberwachung vorgegebener Arbeitsabl\u00e4ufe nach Work-Order</li><li>Disposition und Durchf\u00fchrung von Zutritts- und Zugangskontrollen</li><li>Analyse, Dokumentation und Beseitigung von St\u00f6rungen bzw. Weiterleitung an die entsprechenden IT-Support-Teams<br><strong>Ihr Profil</strong><br></li><li>Abgeschlossene IT-Ausbildung, wie z. B. Fachinformatiker oder Systemelektroniker oder eine vergleichbare technische Ausbildung, alternativ Berufserfahrung im genannten Aufgabengebiet</li><li>Praktische Erfahrung im Betrieb von Datacenter-Komponenten und im WAN-/Carrier-Bereich sowie im Betrieb von DWDM-Komponenten vorteilhaft</li><li>Erfahrung im Betrieb von Rechenzentren, mit der zugeh\u00f6rigen Energieversorgung und mit Zutrittssystemen sowie im Kabelmanagement und in der Installation von Hardware-Komponenten</li><li>Kenntnisse in der Anwendung von Monitoring-Tools und DCIM-Systemen</li><li>Sicherheit im Umgang mit englischen Herstellerdokumentationen</li><li>Zuverl\u00e4ssige, eigenverantwortliche und strukturierte Arbeitsweise, gutes Kommunikationsverm\u00f6gen sowie Engagement und Teamgeist</li><li>Bereitschaft zur Schichtarbeit in einem 24x7-Betrieb</li></ul><br>"
  },
  {
    "id": 56,
    "title": "Senior Data Engineer (all genders)",
    "company": "diconium group",
    "locations": "Berlin",
    "skills": "Python, Machine Learning, Data Science, AWS, Data Pipelines, GCP, AI, Azure, Data Modeling, Big Data, Flink, Hadoop, Kafka, Spark, Java, Kanban, Scala, Scrum, Databricks",
    "posted_at": "2024-08-22",
    "is_remote": "False",
    "snippet_fragments": "Volkswagen, Bosch, Kodak Alaris oder SICK,      In einem modernen und flexiblen Arbeitsumfeld leben wir unsere 4 Kernwerte #courage, Innovation & Strategy, Customer Experience, Data & AI, Commerce Solutions, Technology Solutions, Digital Transformation",
    "description": "<p>Berlin</p><br><p>Diconium ist Spezialist in den Gebieten Daten und K\u00fcnstliche Intelligenz. Ob in den Bereichen Search, Social und Content, Personalisierung und Analytics, Data Engineering oder Data Science - unsere Expertise hilft unseren Kunden, die richtigen Daten zum richtigen Zeitpunkt zu erheben, Services und Angebote zu prognostizieren und somit datengetriebene Entscheidungen zu f\u00e4llen. Werde Teil der diconium data-Familie und unterst\u00fctze uns auf unserer Data &amp; AI-Reise!</p><br><p><strong>DAS ERWARTET DICH</strong></p><ul><li>Du entwirfst und entwickelst skalierbare Data Pipelines, um gro\u00dfe Mengen an Daten effizient zu verarbeiten und zu analysieren.</li><li>Du bewertest und implementierst neue Technologien und Tools im Bereich Data Engineering, um die Effizienz und Leistung unserer Datenverarbeitungsprozesse kontinuierlich zu verbessern.</li><li>Du unterst\u00fctzt unsere Kunden bei der einfachen und transparenten Beschaffung der notwendigen Daten, um intelligente Data-Produkte in verschiedenen Bereichen (Mobilit\u00e4t, Automobil, Industrie, Consumer, Finanzwesen und Non-Profit-Organisationen) zu entwickeln.</li><li>Du arbeitest eng mit Data Scientists und Analysten zusammen, identifizierst potenzielle Datenquellen und evaluierst deren Nutzen, um die Anforderungen an die Daten zu verstehen und geeignete L\u00f6sungen zu entwickeln.</li><li>Du teilst dein Fachwissen und deine Erfahrungen mit anderen Teammitgliedern, tr\u00e4gst zum Wissensaustausch und zur Weiterentwicklung des Teams bei und \u00fcbernimmst eine fachliche F\u00fchrungsrolle innerhalb des Teams.</li><li>Du entwickelst und pflegst Dokumentationen zu Data Engineering-Prozessen, Best Practices und Technologien.</li></ul><p><strong>DAS BRINGST DU MIT</strong></p><br><p><strong>Must haves:</strong></p><ul><li>Relevante Berufserfahrung von mindestens 5 Jahren im Bereich Data Engineering</li><li>Fundierte Kenntnisse in mindestens einer Programmiersprache (wie Python, Java oder Scala) und Erfahrung mit Big Data Technologien (wie Hadoop, Spark oder Kafka)</li><li>Fundierte Kenntnisse in Batch- und Real-Time Data Processing Frameworks wie z.B. Apache Spark, Apache Flink oder \u00c4hnlichen</li><li>Praktische Erfahrung mit Cloud-basierten Datenplattformen (Azure, AWS oder GCP), Verst\u00e4ndnis von Datenmodellierung &amp; Datenarchitektur und Erfahrung mit Databricks</li><li>Erfahrung in der fachlichen F\u00fchrung und der Beratung von Kunden zu technischen Konzepten</li></ul><p><strong>Nice to have:</strong></p><ul><li>Kenntnisse in der Entwicklung von Machine Learning Pipelines und Modellen</li><li>Erfahrung im Projektmanagement mit agilen Methoden wie SAFe, Scrum oder Kanban</li><li>Vertrautheit mit DataOps-Praktiken und DevOps-Konzepten</li><li>Erfahrung in der Implementierung von Data Quality- und Data Governance-Frameworks</li></ul><p><strong>DICONIUM AUF EINEN BLICK</strong></p><br><p><strong>KUNDEN</strong></p><br><p>u.a. Volkswagen, Bosch, Kodak Alaris oder SICK</p><br><p><strong>WERTE</strong></p><br><p>In einem modernen und flexiblen Arbeitsumfeld leben wir unsere 4 Kernwerte #courage, #mindfulness, #collaboration und #impact.</p><br><p><strong>PORTFOLIO</strong></p><br><p>Innovation &amp; Strategy, Customer Experience, Data &amp; AI, Commerce Solutions, Technology Solutions, Digital Transformation</p><br><p><strong>STANDORTE</strong></p><br><p>In diversen, interdisziplin\u00e4ren Teams arbeiten wir auf vielf\u00e4ltige Weise zusammen - ob remote oder vor Ort in einem unserer weltweiten B\u00fcros in Europa, Nordamerika und Asien.</p><br><p><strong>MITARBEITENDE</strong></p><br><p>\u00fcber 2.000 Menschen aus \u00fcber 70 Nationen</p><br>"
  },
  {
    "id": 57,
    "title": "Data Engineer (m/w/d)",
    "company": "Cornelsen",
    "locations": "Berlin",
    "skills": "Python, AWS, Azure, Ansible, Celery, Code Reviews, Docker, GitLab, Kubernetes, MongoDB, Pandas, PostgreSQL, Redis, SQLAlchemy, Terraform, Orchestration, RESTful APIs, Data Lake, Continuous Integration, AWS S3",
    "posted_at": "2024-08-22",
    "is_remote": "False",
    "snippet_fragments": "    Du arbeitest eng mit unseren Kund*innen und den cross-funktionalen Teams zusammen,       Du hast umfassende Erfahrungen im Design und der Implementierung von Data Plattformen, Dagster, DuckDB, FastAPI, pandas, Polars, SQLAlchemy), AWS, Azure, OTC (Cloud-Provider f\u00fcr MongoDB, PostgreSQL, Redis, S3, ), Kubernetes,       Du beherrscht das Design und die Entwicklung von REST APIs f\u00fcr Datenbereitstellungen,       Du hast sehr gute Englischkenntnisse und idealerweise auch gute Deutschkenntnisse,       Du hast einen Sinn f\u00fcr gut strukturierten,       Du beherrscht deine Python-Entwicklungsumgebung, insbesondere Dependency Management, Debugging, Testing, und auch Package Building,       Du kannst Data Service-Buildartefakte definieren (wir nutzen Docker und Gitlab CI),       Du hast SQL-Kenntnisse f\u00fcr die Implementierung von normalisierten und denormalisierten Datenmodellen,       Du bist in der Lage semi-strukturierte Daten zu modellieren,       Du hast erste Erfahrung mit verteilter Datenverarbeitung in bspw,       Du kannst Data Services in der Produktion bereitstellen (wir nutzen Ansible,     Gestalte die Zukunft der Bildung in einem sinnstiftenden Umfeld,     Erlebe optimale Work-Life-Balance mit 30 Tagen Urlaub und flexiblen Arbeitszeiten,     Arbeite flexibel mobil bis zu 4 Tage pro Woche und genie\u00dfe bis zu 20 Tage Workation in Europa (EWR) pro Jahr,     Arbeite agil in dynamischen und crossfunktionalen Teams,     St\u00e4rke deine Gesundheit und dein Wohlbefinden mit unserer Work-Life-Plattform evermood",
    "description": "<p><strong>DATA ENGINEER (M/W/D)</strong></p><br><p>Cornelsen Verlag GmbH</p><br><p>Pr\u00e4senz / Mobil</p><br><p>Berufserfahrung</p><br><p>IT</p><br><p>Voll/Teilzeit</p><br><p>Die Cornelsen Gruppe mit Hauptsitz in Berlin z\u00e4hlt mit Marken wie Cornelsen, Duden, Cornelsen eCademy &amp; inside, Cornelsen Experimenta sowie Veritas und dem Verlag an der Ruhr seit mehr als 75 Jahren zu den f\u00fchrenden Anbietern auf dem deutschsprachigen Bildungsmarkt. Mit \u00fcber 1.600 Mitarbeiter*innen entwickeln wir innovative crossmediale Bildungsl\u00f6sungen von der fr\u00fchen Kindheit bis ins Erwachsenen- und Berufsleben. Gemeinsam gestalten wir die Bildung von morgen und leisten einen sinnvollen Beitrag in einem Umfeld mit hoher gesellschaftlicher Relevanz.</p><br><p>Bei uns kannst du etwas bewegen und dein Potenzial entfalten. Werde Teil unseres Teams!</p><br><p>F\u00fcr unseren Bereich AI Products &amp; Services suchen wir am Standort Berlin unbefristet in Voll- oder Teilzeit zum n\u00e4chstm\u00f6glichen Zeitpunkt eine*n Data Engineer (m/w/d).</p><br><p><strong>DEINE AUFGABEN</strong></p><ul><li>Als Teammitglied unterst\u00fctzt du uns bei der Entwicklung innovativer KI-Anwendungen f\u00fcr den Einsatz in Schulen und in der Cornelsen Gruppe</li><li>Dabei unterst\u00fctzt du direkt bei der Entwicklung und beim Betrieb einer AI Data Plattform: Das Ziel der Plattform ist die Transformation und Bereitstellung von zumeist unstrukturierten und semi-strukturierten Daten in wiederverwendbare Data-Assets. In diesem Kontext kannst du auf umfassende Erfahrungen in den Bereichen Workflow Orchestration, Batch-Processing, Data Lake, Data Access Layer und Data Monitoring zur\u00fcckgreifen.</li><li>Du kennst die Bedeutung einer hohen Datenqualit\u00e4t und triffst fachliche und technische Entscheidungen, um diese im gesamten Data Lifecycle sicherzustellen</li><li>Du verfolgst die Entwicklung von Daten-Technologien und Good Practices im Themenfeld AI (z. B. Vektor-Datenbanken, Embedding Modelle, RAG) und implementierst diese gemeinsam mit dem Team</li><li>Du arbeitest eng mit unseren Kund*innen und den cross-funktionalen Teams zusammen, dabei bist du in der Lage, Kundenanforderungen zu analysieren und in verst\u00e4ndliche und konsistente fachliche Konzepte zu \u00fcberf\u00fchren</li></ul><p><strong>DEIN PROFIL</strong></p><ul><li>Du hast umfassende Erfahrungen im Design und der Implementierung von Data Plattformen</li><li>Du f\u00fchlst dich mit unserem Tech-Stack wohl und hast idealerweise bereits Erfahrung mit gro\u00dfen Teilen davon: Python (z. B. Dagster, DuckDB, FastAPI, pandas, Polars, SQLAlchemy), AWS, Azure, OTC (Cloud-Provider f\u00fcr MongoDB, PostgreSQL, Redis, S3, ...), Kubernetes</li><li>Du beherrscht das Design und die Entwicklung von REST APIs f\u00fcr Datenbereitstellungen, vorzugsweise mit FastAPI</li><li>Du hast sehr gute Englischkenntnisse und idealerweise auch gute Deutschkenntnisse</li></ul><p>Should:</p><ul><li>Du hast einen Sinn f\u00fcr gut strukturierten, produktiv-nutzbaren Code und achtest darauf in eigenem Code und in Code Reviews</li><li>Du beherrscht deine Python-Entwicklungsumgebung, insbesondere Dependency Management, Debugging, Testing, und auch Package Building</li><li>Du kannst Data Service-Buildartefakte definieren (wir nutzen Docker und Gitlab CI)</li></ul><p>Could:</p><ul><li>Du hast SQL-Kenntnisse f\u00fcr die Implementierung von normalisierten und denormalisierten Datenmodellen</li><li>Du bist in der Lage semi-strukturierte Daten zu modellieren</li><li>Du hast erste Erfahrung mit verteilter Datenverarbeitung in bspw. Celery oder Kubernetes</li><li>Du kannst Data Services in der Produktion bereitstellen (wir nutzen Ansible, Kubernetes und Terraform)</li></ul><p><strong>UNSER ANGEBOT</strong></p><ul><li><br><strong>Gestalte die Zukunft der Bildung in einem sinnstiftenden Umfeld</strong><br></li><li><br><strong>Erlebe optimale Work-Life-Balance</strong> mit 30 Tagen Urlaub und flexiblen Arbeitszeiten</li><li><br><strong>Arbeite flexibel mobil</strong> bis zu 4 Tage pro Woche und genie\u00dfe bis zu 20 Tage Workation in Europa (EWR) pro Jahr</li><li><br><strong>Arbeite agil</strong> in dynamischen und crossfunktionalen Teams</li><li><br><strong>St\u00e4rke deine Gesundheit und dein Wohlbefinden</strong> mit unserer Work-Life-Plattform evermood</li><li><br><strong>Profitiere von attraktiven Vorteilen</strong> wie Kita- und Hort-Zuschuss, Rabatte auf B\u00fccher, betrieblicher Altersvorsorge und verm\u00f6genswirksamen Leistungen</li><li><br><strong>Setze auf nachhaltige Mobilit\u00e4t</strong> mit Dienstrad-Leasing und reduziertem Deutschlandticket - gut f\u00fcr dich und unsere Umwelt</li><li><br><strong>Genie\u00dfe biologisch-regionales Essen</strong> in unserer hauseigenen Kantine bei gemeinsamen Mittagessen mit deinen Kolleg*innen</li><li><br><strong>Entfalte dein Potenzial</strong> durch pers\u00f6nliche und fachliche Entwicklungsm\u00f6glichkeiten (Weiterbildungen, Fachkonferenzen, E-Learnings &amp; Networking)</li><li><br><strong>Erlebe starken Teamgeist</strong> bei Sportveranstaltungen, Events und Mitarbeiter*innenfesten</li></ul><p>Cornelsen setzt sich f\u00fcr Chancengleichheit, Vielfalt und Integration am Arbeitsplatz ein. Wir unterbinden Diskriminierung und Bel\u00e4stigung jeder Art aufgrund von Geschlecht, Hautfarbe, Religion, sexueller Orientierung, Herkunft, Behinderung, geschlechtlicher Identit\u00e4t oder anderen gesch\u00fctzten Merkmalen.</p><br><p>Ihr findet auf unserer Karriereseite ausschlie\u00dflich waschechte Cornelsianer*innen! Noch sind wir nicht so divers, wie wir es gerne w\u00e4ren, D&amp;I ist uns aber ein sehr gro\u00dfes Anliegen.</p><br><p>Alina Broddack</p><br><p>Recruiting Partner/-in</p><br><p>alina.broddack@cornelsen.de</p><br>"
  },
  {
    "id": 58,
    "title": "(Senior) Data Engineer (m/f/d)",
    "company": "Riverty Group GmbH",
    "locations": "Berlin",
    "skills": "Python, SQL, Cloud, Data Pipelines, Azure, DevOps, Terraform, Cloud Platforms, Databricks, IaC, Git, Integrity, Architektur",
    "posted_at": "2024-08-22",
    "is_remote": "True",
    "snippet_fragments": "  Stay abreast of emerging technologies and trends in cloud computing, At Riverty, you can be who you are, We are committed to creating an inclusive environment and a culture of appreciation,   Prioritize your health with supported sports and leisure activities,   Take advantage of our numerous training and development opportunities! Enhance your skills with training offered by the Bertelsmann University,   Benefit from our discounts on Bertelsmann products and financial incentives, With our diverse work models, you can tailor your work to your preferences, Take advantage of mobile office, flexible working hours, and part-time models.,   Bachelor's or Master's degree in Computer Science,   5 years of experience in designing,   Proven experience in leading technical teams,   Deep expertise in Azure cloud services,   Strong proficiency in programming languages such as Python and SQL",
    "description": "<p>At Riverty, we believe that everyone should be in control of their own financial situation. Our shared commitment is to make financial solutions more innovative, empathetic and user-friendly to empower financial growth for everyone. To do this, we rely on 50 years of experience and the commitment of over 5,000 creative minds, innovators and explorers in 11 countries.</p><br><p>Are you ready?</p><br><p>As part of our community, you will have the opportunity to develop your skills and transform the world of finance together with us. We create an environment where you can evolve personally and benefit from our flexible working conditions and work-life balance.</p><br><p><strong>Everything we do, starts with you.</strong> Together with you, we build the most human-centric fintech. To enable everyone's future financial growth.</p><br><p><strong>We are looking for a</strong></p><br><p><strong>Senior Azure Cloud Engineer (m/f/d)</strong></p><br><p><strong>(unlimited, fulltime) Join our team at our location in Oslo, Berlin, Verl or Baden-Baden - flexible working conditions available</strong></p><br><p>We are a leading fintech company dedicated to revolutionizing the way data is managed, analyzed, and utilized. Our innovative cloud-based solutions empower organizations to harness the full potential of their data to drive business growth and innovation. We are seeking a highly skilled and experienced Senior Azure Cloud Engineer to join our dynamic team and lead our cloud data platform initiatives.</p><br><p>As the Senior Azure Cloud Engineer (m/f/d) you will play a pivotal role in architecting, implementing, and maintaining our cloud data platform on Microsoft Azure. You will technically lead a team of talented engineers, providing technical guidance and mentorship, while also collaborating with stakeholders to define and execute a roadmap for our cloud data platform. This position requires deep expertise in Azure cloud technologies, strong leadership skills, and a passion for driving innovation in data management and analytics.</p><br><p><strong>Your Responsibilities:</strong></p><ul><li>Professionally leading a technical team of Azure cloud engineers in designing, implementing, and managing our cloud data platform on Microsoft Azure</li><li>Provide technical guidance to team members, fostering a culture of collaboration and continuous learning</li><li>Collaborate with cross-functional teams to define requirements, architect solutions, and prioritize initiatives for the cloud data platform</li><li>Develop and maintain technical documentation, including architecture diagrams, design documents, and best practices guides</li><li>Lead the implementation of DevOps practices, utilizing tools such as Azure DevOps, Git, and Terraform to automate deployment, scaling, and monitoring of cloud infrastructure</li><li>Design and implement data pipelines using Azure Data Factory and Databricks</li><li>Optimize performance, scalability, and cost-effectiveness of the cloud data platform, leveraging Azure services and best practices</li><li>Implement security and compliance controls to ensure the integrity and confidentiality of data stored in the cloud platform</li><li>Stay abreast of emerging technologies and trends in cloud computing, data management, and analytics, and evaluate their potential impact on our platform<br><strong>Benefits:</strong><br></li><li>At Riverty, you can be who you are. We are committed to creating an inclusive environment and a culture of appreciation, enriched by our employee networks.</li><li>Prioritize your health with supported sports and leisure activities.</li><li>Take advantage of our numerous training and development opportunities! Enhance your skills with training offered by the Bertelsmann University, language courses, or leadership training.</li><li>Benefit from our discounts on Bertelsmann products and financial incentives.</li><li>With our diverse work models, you can tailor your work to your preferences. Take advantage of mobile office, flexible working hours, and part-time models.</li></ul><p><strong>Your Qualifications:</strong></p><ul><li>Bachelor's or Master's degree in Computer Science, Engineering, or related field</li><li>5+ years of experience in designing, implementing, and managing cloud-based solutions on Microsoft Azure</li><li>Proven experience in leading technical teams, with a focus on coaching, mentoring, and fostering collaboration</li><li>Deep expertise in Azure cloud services, including but not limited to Azure Data Factory, Azure Databricks, Azure DevOps, Azure SQL Database, and Azure Resource Manager</li><li>Strong proficiency in programming languages such as Python and SQL, with experience in building and optimizing data pipelines and analytics solutions</li><li>Experience with infrastructure-as-code tools such as Terraform for provisioning and managing cloud infrastructure</li><li>Excellent communication and interpersonal skills, with the ability to effectively collaborate with cross-functional teams and stakeholders</li><li>Exceptional communication skills in English, both written and verbal, German is a plus</li><li>Azure certifications (e.g. Azure Solutions Architect, Azure DevOps Engineer) are a plus</li></ul><p><strong>EQUAL OPPORTUNITY EMPLOYER STATEMENT</strong></p><br><p>We want to be a fair and inclusive employer. We value the diverse perspectives that a diverse workforce brings to the table. Therefore, we are actively looking for people who enrich our company through their identity, background and personal experiences, with or without a disability.</p><br>"
  },
  {
    "id": 59,
    "title": "Data Engineer (m/w/d)",
    "company": "ista Express Service GmbH",
    "locations": "Berlin",
    "skills": "Python, SQL, Mathematik, AWS, Data Analysis, GCP, Azure, Business Intelligence, Data Modeling, BigQuery, Java, Scala, Looker, Mac",
    "posted_at": "2024-08-21",
    "is_remote": "False",
    "snippet_fragments": "  Du verf\u00fcgst \u00fcber fundierte Kenntnisse in SQL vorzugsweise in BigQuery,   Du bist vertraut mit Programmiersprachen wie Python, Erfahrungen mit Cloud-Plattformen wie AWS, Azure oder bevorzugt Google Cloud sind von Vorteil.,   Du bringst Kenntnisse in der Datenmodellierung und -visualisierung vorzugsweise in Looker mit, Dateninterpretation ist f\u00fcr Dich ein Kinderspiel und mit Deinen Ideen kannst du im Team \u00fcberzeugen,   Du bist ein Teamplayer und hast Freude an der Zusammenarbeit in interdisziplin\u00e4ren Teams,   Du hast eine analytische Denkweise und ein hohes Ma\u00df an Probleml\u00f6sungskompetenz,   Einen unbefristeten Arbeitsvertrag mit einem attraktiven Gehalt in einem jungen, durch flache Hierarchien, kurze Entscheidungswege und Can-Do-Attitude, Wir arbeiten agil orientiert am Spotify-Modell,    Spannende und abwechslungsreiche Aufgaben mit viel Raum f\u00fcr eigenverantwortliches Arbeiten,    Work-Life Balance - flexible Arbeitszeiten und 30 Tage Urlaub,   Du bekommst von uns eine zugeschnittene Einarbeitung mit vielen Trainings- und Qualifizierungsma\u00dfnahmen,    Zahlreiche Weiterentwicklungsm\u00f6glichkeiten dank eines starken Expansionskurses und einem komplexen Umfeld,  Du arbeitest in modernen B\u00fcror\u00e4umlichkeiten im Herzen Berlins mit ergonomischen Arbeitspl\u00e4tzen und bester Hardware - Du w\u00e4hlst selbst zwischen Mac und PC.,    Mitarbeiterrabatte bei \u00fcber 800 Anbietern wie Zalando",
    "description": "<p><strong>WAS DU BEI UNS MACHST</strong></p><br><p><strong>PLEASE NOTE: THIS POSITION REQUIRES FLUENT GERMAN LANGUAGES SKILLS</strong></p><br><p>Du bist ein erfahrener Data Engineer und suchst nach einer neuen Herausforderung? Du hast eine Leidenschaft f\u00fcr Datenanalysen und m\u00f6chtest Dein Fachwissen nutzen, um bei der Optimierung die Gesch\u00e4ftsprozesse und -entscheidungen unseres Unternehmens zu unterst\u00fctzen? Dann komm in unser Team!</p><br><p><strong>Deine Aufgaben</strong></p><ul><li>Als Data Engineer entwickelst Du kontinuierliche unsere Business Intelligence L\u00f6sung und die Datenmodellen in der Google Cloud Platform weiter.</li><li>Du entwickelst und wartest Datenpipelines zur Verarbeitung gro\u00dfer Datenmengen.</li><li>Du verstehst Business Use Cases und \u00fcbersetzt diese in eine Datensprache, sodass der Use Cases durch die Daten interpretiert werden kann.</li><li>Du konzipierst und implementierst ETL-Prozesse f\u00fcr unterschiedliche Datenquellen.</li><li>Du arbeitest mit diversen Bereichen, wie z.B. Business Development und Softwareentwicklern zusammen, eng zusammen, um datengetriebene L\u00f6sungen zu entwickeln.</li><li>Du sorgst f\u00fcr die Datenqualit\u00e4t und -integrit\u00e4t in unseren Systemen.</li><li>Du unterst\u00fctzt bei der Optimierung und Skalierung unserer Datenarchitekturen.</li></ul><p><strong>WAS DU MITBRINGST</strong></p><ul><li>Du hast ein abgeschlossenes Studium in Informatik, Wirtschaftsinformatik, Mathematik, Ingenieurwissenschaften oder einem verwandten Bereich.</li><li>Du hast mindestens 3 Jahre fundierte Berufserfahrung in diesem Bereich.</li><li>Du verf\u00fcgst \u00fcber fundierte Kenntnisse in SQL vorzugsweise in BigQuery.</li><li>Du bist vertraut mit Programmiersprachen wie Python, Java oder Scala.</li><li>Erfahrungen mit Cloud-Plattformen wie AWS, Azure oder bevorzugt Google Cloud sind von Vorteil.</li><li>Du bringst Kenntnisse in der Datenmodellierung und -visualisierung vorzugsweise in Looker mit. Dateninterpretation ist f\u00fcr Dich ein Kinderspiel und mit Deinen Ideen kannst du im Team \u00fcberzeugen.</li><li>Du bist ein Teamplayer und hast Freude an der Zusammenarbeit in interdisziplin\u00e4ren Teams.</li><li>Du hast eine analytische Denkweise und ein hohes Ma\u00df an Probleml\u00f6sungskompetenz.</li></ul><p><strong>WAS WIR BIETEN</strong></p><ul><li>Einen <strong>unbefristeten Arbeitsvertrag mit einem attraktiven Gehalt</strong> in einem jungen, stabilen und zukunftsorientierten Unternehmen.</li><li><br><strong>Innovative Unternehmenskultur</strong>: Hier kannst Du unser Unternehmen kennenlernen: ista Express Service Mediathek (https://www.ista-express.de/videos/).</li><li><br><strong>Effiziente Teamarbeit</strong> durch flache Hierarchien, kurze Entscheidungswege und Can-Do-Attitude. Wir arbeiten agil orientiert am Spotify-Modell.</li><li><br><strong>Spannende und abwechslungsreiche Aufgaben</strong> mit viel Raum f\u00fcr eigenverantwortliches Arbeiten.</li><li><br><strong>Work-Life Balance</strong> - flexible Arbeitszeiten und 30 Tage Urlaub.</li><li>Zusatzleistungen: <strong>Eine betriebliche Krankenzusatzversicherung</strong> (z.B. f\u00fcr Brille, Zahnersatz, Heilpraktiker).</li><li>Du bekommst von uns eine <strong>zugeschnittene Einarbeitung mit vielen Trainings- und Qualifizierungsma\u00dfnahmen</strong>.</li><li><br><strong>Zahlreiche Weiterentwicklungsm\u00f6glichkeiten</strong> dank eines starken Expansionskurses und einem komplexen Umfeld, in dem sich immer wieder neue Themenfelder ergeben.</li><li><br><strong>Moderne Arbeitspl\u00e4tze:</strong> Du arbeitest in modernen B\u00fcror\u00e4umlichkeiten im Herzen Berlins mit ergonomischen Arbeitspl\u00e4tzen und bester Hardware - Du w\u00e4hlst selbst zwischen Mac und PC.</li><li><br><strong>Mitarbeiterrabatte</strong> bei \u00fcber 800 Anbietern wie Zalando, Adidas, Apple &amp; Co - da ist bestimmt auch f\u00fcr Dich etwas dabei!</li><li><br><strong>Mitarbeiter werben Mitarbeiter: Pr\u00e4mie</strong>.</li><li><br><strong>Extras</strong>: Auf Dich warten neben einem Siebtr\u00e4ger-Coffeemaker, Obstkorb und kostenlosen Getr\u00e4nken auch viele weitere Extras (z.B. Firmenevents, Gewinnspiele).</li></ul><p><strong>DU HAST NOCH FRAGEN?</strong></p><br><p>Wir beantworten Dir gerne Fragen zum Bewerbungsablauf f\u00fcr die Position als Data Engineer (m/w/d). Melde Dich einfach per Telefon unter +49 341 69700777.</p><br><p><strong>\u00dcBER UNS</strong></p><br><p>Seit 2020 sind wir als ista Express Service GmbH der professionelle Servicepartner f\u00fcr die zuverl\u00e4ssige Installation und Wartung von Messger\u00e4ten wie Hei\u00dfkostenverteiler, Wasserz\u00e4hler und Rauchwarnmelder in Privatr\u00e4umen und Gewerbeanlagen. Unser Ziel ist es, das perfekte Kundenerlebnis f\u00fcr Mieter:innen, Hausverwaltungen und Gro\u00dfkund:innen zu garantieren.</p><br><p>Mit aktuell 16 Standorten in ganz Deutschland (wie z.B. Berlin, Hamburg, Hannover, Leipzig, Mannheim, Osnabr\u00fcck, Frankfurt, Essen, Stuttgart, K\u00f6ln, D\u00fcsseldorf und Oldenburg) und weit \u00fcber 250 Mitarbeiter:innen werden wir unsere Unternehmensgr\u00f6\u00dfe auch in Zukunft nachhaltig erweitern.</p><br>"
  },
  {
    "id": 60,
    "title": "Data Engineer (m/w/d)",
    "company": "ista Express Service GmbH",
    "locations": "Berlin",
    "skills": "Python, SQL, Mathematik, AWS, Data Analysis, GCP, Azure, Business Intelligence, Data Modeling, BigQuery, Java, Scala, Looker, Mac",
    "posted_at": "2024-08-21",
    "is_remote": "False",
    "snippet_fragments": "  Du hast ein abgeschlossenes Studium in Informatik,   Du hast mindestens 3 Jahre fundierte Berufserfahrung in diesem Bereich,   Du verf\u00fcgst \u00fcber fundierte Kenntnisse in SQL vorzugsweise in BigQuery,   Du bist vertraut mit Programmiersprachen wie Python, Erfahrungen mit Cloud-Plattformen wie AWS, Azure oder bevorzugt Google Cloud sind von Vorteil.,   Du bringst Kenntnisse in der Datenmodellierung und -visualisierung vorzugsweise in Looker mit, Dateninterpretation ist f\u00fcr Dich ein Kinderspiel und mit Deinen Ideen kannst du im Team \u00fcberzeugen,   Du bist ein Teamplayer und hast Freude an der Zusammenarbeit in interdisziplin\u00e4ren Teams,   Du hast eine analytische Denkweise und ein hohes Ma\u00df an Probleml\u00f6sungskompetenz,   Einen unbefristeten Arbeitsvertrag mit einem attraktiven Gehalt in einem jungen, durch flache Hierarchien, kurze Entscheidungswege und Can-Do-Attitude, Wir arbeiten agil orientiert am Spotify-Modell,    Spannende und abwechslungsreiche Aufgaben mit viel Raum f\u00fcr eigenverantwortliches Arbeiten,    Work-Life Balance - flexible Arbeitszeiten und 30 Tage Urlaub,   Du bekommst von uns eine zugeschnittene Einarbeitung mit vielen Trainings- und Qualifizierungsma\u00dfnahmen,    Zahlreiche Weiterentwicklungsm\u00f6glichkeiten dank eines starken Expansionskurses und einem komplexen Umfeld,  Du arbeitest in modernen B\u00fcror\u00e4umlichkeiten im Herzen Berlins mit ergonomischen Arbeitspl\u00e4tzen und bester Hardware - Du w\u00e4hlst selbst zwischen Mac und PC.,    Mitarbeiterrabatte bei \u00fcber 800 Anbietern wie Zalando",
    "description": "<p><strong>WAS DU BEI UNS MACHST</strong></p><br><p><strong>PLEASE NOTE: THIS POSITION REQUIRES FLUENT GERMAN LANGUAGES SKILLS</strong></p><br><p>Du bist ein erfahrener Data Engineer und suchst nach einer neuen Herausforderung? Du hast eine Leidenschaft f\u00fcr Datenanalysen und m\u00f6chtest Dein Fachwissen nutzen, um bei der Optimierung die Gesch\u00e4ftsprozesse und -entscheidungen unseres Unternehmens zu unterst\u00fctzen? Dann komm in unser Team!</p><br><p><strong>Deine Aufgaben</strong></p><ul><li>Als Data Engineer entwickelst Du kontinuierliche unsere Business Intelligence L\u00f6sung und die Datenmodellen in der Google Cloud Platform weiter.</li><li>Du entwickelst und wartest Datenpipelines zur Verarbeitung gro\u00dfer Datenmengen.</li><li>Du verstehst Business Use Cases und \u00fcbersetzt diese in eine Datensprache, sodass der Use Cases durch die Daten interpretiert werden kann.</li><li>Du konzipierst und implementierst ETL-Prozesse f\u00fcr unterschiedliche Datenquellen.</li><li>Du arbeitest mit diversen Bereichen, wie z.B. Business Development und Softwareentwicklern zusammen, eng zusammen, um datengetriebene L\u00f6sungen zu entwickeln.</li><li>Du sorgst f\u00fcr die Datenqualit\u00e4t und -integrit\u00e4t in unseren Systemen.</li><li>Du unterst\u00fctzt bei der Optimierung und Skalierung unserer Datenarchitekturen.</li></ul><p><strong>WAS DU MITBRINGST</strong></p><ul><li>Du hast ein abgeschlossenes Studium in Informatik, Wirtschaftsinformatik, Mathematik, Ingenieurwissenschaften oder einem verwandten Bereich.</li><li>Du hast mindestens 3 Jahre fundierte Berufserfahrung in diesem Bereich.</li><li>Du verf\u00fcgst \u00fcber fundierte Kenntnisse in SQL vorzugsweise in BigQuery.</li><li>Du bist vertraut mit Programmiersprachen wie Python, Java oder Scala.</li><li>Erfahrungen mit Cloud-Plattformen wie AWS, Azure oder bevorzugt Google Cloud sind von Vorteil.</li><li>Du bringst Kenntnisse in der Datenmodellierung und -visualisierung vorzugsweise in Looker mit. Dateninterpretation ist f\u00fcr Dich ein Kinderspiel und mit Deinen Ideen kannst du im Team \u00fcberzeugen.</li><li>Du bist ein Teamplayer und hast Freude an der Zusammenarbeit in interdisziplin\u00e4ren Teams.</li><li>Du hast eine analytische Denkweise und ein hohes Ma\u00df an Probleml\u00f6sungskompetenz.</li></ul><p><strong>WAS WIR BIETEN</strong></p><ul><li>Einen <strong>unbefristeten Arbeitsvertrag mit einem attraktiven Gehalt</strong> in einem jungen, stabilen und zukunftsorientierten Unternehmen.</li><li><br><strong>Innovative Unternehmenskultur</strong>: Hier kannst Du unser Unternehmen kennenlernen: ista Express Service Mediathek (https://www.ista-express.de/videos/).</li><li><br><strong>Effiziente Teamarbeit</strong> durch flache Hierarchien, kurze Entscheidungswege und Can-Do-Attitude. Wir arbeiten agil orientiert am Spotify-Modell.</li><li><br><strong>Spannende und abwechslungsreiche Aufgaben</strong> mit viel Raum f\u00fcr eigenverantwortliches Arbeiten.</li><li><br><strong>Work-Life Balance</strong> - flexible Arbeitszeiten und 30 Tage Urlaub.</li><li>Zusatzleistungen: <strong>Eine betriebliche Krankenzusatzversicherung</strong> (z.B. f\u00fcr Brille, Zahnersatz, Heilpraktiker).</li><li>Du bekommst von uns eine <strong>zugeschnittene Einarbeitung mit vielen Trainings- und Qualifizierungsma\u00dfnahmen</strong>.</li><li><br><strong>Zahlreiche Weiterentwicklungsm\u00f6glichkeiten</strong> dank eines starken Expansionskurses und einem komplexen Umfeld, in dem sich immer wieder neue Themenfelder ergeben.</li><li><br><strong>Moderne Arbeitspl\u00e4tze:</strong> Du arbeitest in modernen B\u00fcror\u00e4umlichkeiten im Herzen Berlins mit ergonomischen Arbeitspl\u00e4tzen und bester Hardware - Du w\u00e4hlst selbst zwischen Mac und PC.</li><li><br><strong>Mitarbeiterrabatte</strong> bei \u00fcber 800 Anbietern wie Zalando, Adidas, Apple &amp; Co - da ist bestimmt auch f\u00fcr Dich etwas dabei!</li><li><br><strong>Mitarbeiter werben Mitarbeiter: Pr\u00e4mie</strong>.</li><li><br><strong>Extras</strong>: Auf Dich warten neben einem Siebtr\u00e4ger-Coffeemaker, Obstkorb und kostenlosen Getr\u00e4nken auch viele weitere Extras (z.B. Firmenevents, Gewinnspiele).</li></ul><p><strong>DU HAST NOCH FRAGEN?</strong></p><br><p>Wir beantworten Dir gerne Fragen zum Bewerbungsablauf f\u00fcr die Position als Data Engineer (m/w/d). Melde Dich einfach per Telefon unter +49 341 69700777.</p><br><p><strong>\u00dcBER UNS</strong></p><br><p>Seit 2020 sind wir als ista Express Service GmbH der professionelle Servicepartner f\u00fcr die zuverl\u00e4ssige Installation und Wartung von Messger\u00e4ten wie Hei\u00dfkostenverteiler, Wasserz\u00e4hler und Rauchwarnmelder in Privatr\u00e4umen und Gewerbeanlagen. Unser Ziel ist es, das perfekte Kundenerlebnis f\u00fcr Mieter:innen, Hausverwaltungen und Gro\u00dfkund:innen zu garantieren.</p><br><p>Mit aktuell 16 Standorten in ganz Deutschland (wie z.B. Berlin, Hamburg, Hannover, Leipzig, Mannheim, Osnabr\u00fcck, Frankfurt, Essen, Stuttgart, K\u00f6ln, D\u00fcsseldorf und Oldenburg) und weit \u00fcber 250 Mitarbeiter:innen werden wir unsere Unternehmensgr\u00f6\u00dfe auch in Zukunft nachhaltig erweitern.</p><br>"
  },
  {
    "id": 61,
    "title": "Data Engineer (m/w/d)",
    "company": "TastyUrban GmbH",
    "locations": "Berlin",
    "skills": "Python, SQL, AWS, Cloud, Data Pipelines, GCP, Azure, Business Intelligence, Data Modeling, Data Warehouse, ETL, Airflow, Redshift, BigQuery, MongoDB, MySQL, PostgreSQL, Luigi, Snowflake, Data Lake, Architektur",
    "posted_at": "2024-08-19",
    "is_remote": "False",
    "snippet_fragments": "Experience with data warehousing solutions (e, Knowledge of data modeling, data architecture, and data governance principles., Strong problem-solving skills and attention to detail, Opportunity to make a significant impact on the growth and success of a dynamic startup",
    "description": "<p><strong>About TastyUrban:</strong></p><br><p>TastyUrban is an innovative multi-brand food franchise start-up. We work with internationally acclaimed Chefs to develop best in market delivery-first food concepts, which are licensed out to local restaurant partners. TastyUrban is looking for a Data Engineer to join us at this exciting stage. You will help us grow and elevate our business across Germany and internationally.</p><br><p><strong>Job Summary:</strong></p><br><p>The Data Engineer will be responsible for designing, building, and maintaining data pipelines that ensure the timely delivery of data. This role requires proficiency in Python and SQL, as well as experience with data pipeline planning and automation. The ideal candidate will have a strong understanding of data architecture and the ability to work collaboratively with various teams to support our data needs.</p><br><p><strong>Key Responsibilities:</strong></p><br><p>Design, build, and maintain scalable data pipelines to collect, process, and deliver data from various sources. Ensure data quality and integrity through rigorous testing and validation.</p><br><p>Automate data collection, transformation, and loading (ETL) processes to ensure efficient data flow.</p><br><p>Implement data integration solutions to consolidate data from multiple sources.</p><br><p>Develop and maintain databases, data warehouses, and data lakes to support analytics and business intelligence. Optimize database performance and query efficiency.</p><br><p>Work closely with data analysts, data scientists, and other stakeholders to understand data requirements and deliver solutions. Provide support and troubleshooting for data-related issues.</p><br><p>Create and maintain comprehensive documentation for data pipelines, processes, and systems.</p><br><p>Stay up-to-date with industry best practices and emerging technologies in data engineering.</p><br><p><strong>Qualifications:</strong></p><br><ol><br><li>Bachelor's degree in Computer Science, Engineering, Information Systems, or a related field.</li><li>Minimum of 3-5 years of experience in data engineering or a related role.</li><li>Proficiency in Python and SQL for data manipulation and automation.</li><li>Experience with ETL tools and frameworks (e.g., Apache Airflow, Luigi).</li><li>Familiarity with cloud data platforms (e.g., AWS, Google Cloud, Azure).</li><li>Strong understanding of database management systems (e.g., MySQL, PostgreSQL, MongoDB).</li><li>Experience with data warehousing solutions (e.g., Redshift, BigQuery, Snowflake).</li><li>Knowledge of data modeling, data architecture, and data governance principles.</li><li>Strong problem-solving skills and attention to detail.</li><li>Excellent communication and collaboration skills.</li><li>German and English fluency.</li><br></ol><br><p><strong>Key Competencies:</strong></p><br><ol><br><li>Technical Expertise: Deep understanding of data engineering principles, tools, and technologies.</li><li>Analytical Skills: Ability to analyze complex data requirements and design efficient solutions.</li><li>Automation Mindset: Proficiency in automating data processes to improve efficiency and accuracy.</li><li>Collaboration: Strong interpersonal skills to work effectively with cross-functional teams.</li><li>Adaptability: Ability to thrive in a fast-paced, dynamic startup environment and adapt to evolving priorities.</li><br></ol><br><p><strong>Why Join Us:</strong></p><br><p>Opportunity to make a significant impact on the growth and success of a dynamic startup. Collaborative and innovative work environment. Competitive salary and equity compensation package.</p><br><p>Art der Stelle: Vollzeit</p><br><p>Arbeitszeiten:</p><ul><li>Montag bis Freitag</li></ul><p>Sprache:</p><ul><li>Deutsch (Erforderlich)</li><li>Englisch (Erforderlich)</li></ul><p>Arbeitsort: Vor Ort</p><br>"
  },
  {
    "id": 62,
    "title": "AI Data Engineer (m/w/d)",
    "company": "Deutsche Rentenversicherung Bund",
    "locations": "Berlin",
    "skills": "Python, SQL, Mathematik, Data Analysis, Hadoop, Kubernetes, APIs, Containerisation",
    "posted_at": "2024-08-19",
    "is_remote": "True",
    "snippet_fragments": "       Wir bieten Ihnen eine interessante und abwechslungsreiche T\u00e4tigkeit mit allen Vorteilen einer gro\u00dfen \u00f6ffentlichen Arbeitgeberin,        Die M\u00f6glichkeit durch eigene Ideen die digitale Transformation der DRV Bund mitzugestalten, Vielf\u00e4ltige Projekte wie KIRA, in dem eine KI-basierte Anwendung f\u00fcr den Betriebspr\u00fcfdienst der DRV entwickelt wird, Individuelle Fortbildungsm\u00f6glichkeiten, vielseitige Schulungsangebote und die Teilnahme an Fachkonferenzen f\u00f6rdern fachliches Wachstum sowie Communities of Practice (CoP) unterst\u00fctzen den kontinuierlichen Wissensaustausch,        Eine hervorragende Aussicht aus dem 16, Stock des Silberturms \u00fcber den D\u00e4chern Berlins am Hohenzollerndamm; mindestens ein bis zwei Tage Pr\u00e4senz pro Woche,        Vereinbarkeit von Familie und Beruf durch flexible Arbeitszeitmodelle sowie der M\u00f6glichkeit der Arbeit im Homeoffice,       Zur Besetzung der Position werden wir mit den qualifiziertesten Bewerber*innen ein Auswahlgespr\u00e4ch f\u00fchren, Bestandteil des Auswahlverfahrens wird eine Arbeitsprobe in Form einer Programmieraufgabe in Python sein,        Die T\u00e4tigkeit erfordert sehr gute Deutschkenntnisse in Wort und Schrift",
    "description": "<p><strong>T\u00c4TIGKEITSBEREICH</strong></p><br><p>Das KI-Labor b\u00fcndelt KI-Expertise und KI-Talente in einer zentralen Einheit in der Stabsstelle Digitalstrategie und digitale Transformation. Als Expertenteam f\u00fcr KI und Anwendungsfall-Fabrik bringen wir KI in die DRV Bund und stehen allen Fachabteilungen als Ansprechpartner*in mit unserem Unterst\u00fctzungs- und Beratungsangebot zur Seite. In einem stetig wachsenden interdisziplin\u00e4ren Team liefern wir mit Hilfe von KI-Technologien neue L\u00f6sungsans\u00e4tze und leisten so Pionierarbeit f\u00fcr die zahlreichen Herausforderungen einer Bundesbeh\u00f6rde mit mehr als 26.000 Mitarbeitenden.</p><br><p><strong>IHRE AUFGABEN</strong></p><ul><li>Verantwortliche Konzeption, Entwicklung und Implementierung von Data-Science-Anwendungen mit einem crossfunktionalen Team und/ oder externen Dienstleistern</li><li>Entwicklung skalierbarer und robuster Datenpipelines zur Sicherstellung von Datenintegrit\u00e4t und -effizienz im Kontext von Machine Learning-Anwendungen</li><li>Implementierung von mittleren und gro\u00dfen Sprachmodellen in unsere Datensysteme</li><li>Entwicklung von Python-Anwendungen f\u00fcr Datenimport, ereignisausl\u00f6sende Prozesse und die Optimierung von ML Ops- und DevOps-Prozessen.</li><li>Enge Zusammenarbeit mit den Product Ownern und IT-Spezialisten zur Gew\u00e4hrung reibungslosere Prozesse und zuverl\u00e4ssiger Resultate</li><li>Strategisches und fachliches Mitgestalten der hausweiten Technologielandschaft im Sinne der Weiterentwicklung der DRV Bund zu einer KI-versierten Organisation</li><li>Unterst\u00fctzen bei der fachlichen Entwicklung der juniorigen Kolleg*innen</li></ul><p><strong>IHR PROFIL</strong></p><ul><li>Abgeschlossene wissenschaftliche Hochschulbildung (Master / Diplom oder vergleichbar) mit quantitativem Schwerpunkt; idealerweise der Studienrichtung MINT (Mathematik, Informatik, Naturwissenschaften oder Technik) oder der Sozial- beziehungsweise Wirtschaftswissenschaften</li><li>Mehrj\u00e4hrige Berufserfahrung im Zusammentragen, Aufbereiten und Bereitstellen von Daten in optimierter Datenarchitektur, davon mindestens 1 Jahr im Kontext automatisierter KI-Systeme</li><li>Mehrj\u00e4hrige Berufserfahrung im Umgang mit relationalen Datenbanksystemen (vor allem Oracle), verteilten Datenmanagementsystemen (zum Beispiel Hadoop), Cloud-Plattformen und Containertechnologien (zum Beispiel Kubernetes)</li><li>Sehr gute Kenntnisse von g\u00e4ngigen Datenbanksprachen (insbesondere SQL), APIs (insbesondere REST) sowie ihrer Anbindung an Machine-Learning-Pipelines (insb. Python)</li><li>Sehr gutes Verst\u00e4ndnis f\u00fcr die effiziente Entwicklung, Automatisierung und Wartung von Datenfl\u00fcssen, sowie der Erstellung und Optimierung von Datenarchitekturen</li><li>Idealerweise erste Erfahrungen in der Integration von Large Language Modellen und Vektordatenbanken</li><li>Begeisterung f\u00fcr die Bereiche Data Analytics, K\u00fcnstliche Intelligenz und Gesch\u00e4ftsprozessautomatisierung, insbesondere im Kontext des \u00f6ffentlichen Sektors (GovTech)</li><li>Proaktives Kommunikationsverhalten, ausgepr\u00e4gte Kooperationsbereitschaft und vernetztes Denken in der agilen Zusammenarbeit</li></ul><p><strong>WIR BIETEN IHNEN</strong></p><ul><li>Wir bieten Ihnen eine interessante und abwechslungsreiche T\u00e4tigkeit mit allen Vorteilen einer gro\u00dfen \u00f6ffentlichen Arbeitgeberin</li><li>Die M\u00f6glichkeit durch eigene Ideen die digitale Transformation der DRV Bund mitzugestalten</li><li>Vielf\u00e4ltige Projekte wie KIRA, in dem eine KI-basierte Anwendung f\u00fcr den Betriebspr\u00fcfdienst der DRV entwickelt wird</li><li>Individuelle Fortbildungsm\u00f6glichkeiten, vielseitige Schulungsangebote und die Teilnahme an Fachkonferenzen f\u00f6rdern fachliches Wachstum sowie Communities of Practice (CoP) unterst\u00fctzen den kontinuierlichen Wissensaustausch</li><li>Eine hervorragende Aussicht aus dem 16. Stock des Silberturms \u00fcber den D\u00e4chern Berlins am Hohenzollerndamm; mindestens ein bis zwei Tage Pr\u00e4senz pro Woche</li><li>Vereinbarkeit von Familie und Beruf durch flexible Arbeitszeitmodelle sowie der M\u00f6glichkeit der Arbeit im Homeoffice</li></ul><p><strong>WEITERE INFORMATIONEN</strong></p><br><p>Zur Besetzung der Position werden wir mit den qualifiziertesten Bewerber*innen ein Auswahlgespr\u00e4ch f\u00fchren. Bestandteil des Auswahlverfahrens wird eine Arbeitsprobe in Form einer Programmieraufgabe in Python sein.</p><br><p>Die T\u00e4tigkeit erfordert sehr gute Deutschkenntnisse in Wort und Schrift.</p><br><p><strong>VORTEILE</strong></p><br><p>30 Urlaubstage bei 5-Tage-Woche</p><br><p>Jahressonderzahlungen und verm\u00f6genswirksame Leistungen</p><br><p>Unbefristete Stelle</p><br><p>Herausforderungen</p><br>"
  },
  {
    "id": 63,
    "title": "Intermediate Data Engineer",
    "company": "Omnipresent",
    "locations": "Berlin",
    "skills": "Python, SQL, AWS, Data Pipelines, GCP, Azure, Data Modeling, Data Warehouse, Database Design, Cloud Platforms, Snowflake",
    "posted_at": "2024-08-16",
    "is_remote": "True",
    "snippet_fragments": "  Collaborate with data analysts and other stakeholders to understand data requirements and deliver high-quality solutions,   Ensure data quality and integrity through regular monitoring and testing,   Troubleshoot and resolve data-related issues in a timely manner,   Utilize the data platform intensively for various operational use cases,   Stay up-to-date with the latest developments in data engineering technologies and best practices, Bachelor's degree in Computer Science, Information Technology, or a related field, or equivalent work experience.,   Proven experience with SQL and its application in data processing,   Strong problem-solving skills and attention to detail,   Ability to work independently and as part of a team, Awareness of writing clean, maintainable code and following coding patterns and best practices.,   Knowledge of Python or another programming language,   Understanding of data modeling and database design, Experience with cloud platforms (e.g., AWS, Azure, GCP).,  Work from anywhere in the world! We are genuinely as flexible as the work allows.,  Training, coaching, and an environment that promotes career ambition and progression.",
    "description": "<p><strong>WHO WE ARE</strong></p><br><p>Omnipresent is a global employment platform that enables organisations to compliantly hire, onboard, pay, and manage their employees and contractors worldwide. With our team of global HR, legal, payroll, and benefits experts, we offer premium Employer of Record services in over 150 countries, which includes legal support and streamlined employee onboarding and offboarding. Our services ensure compliance with tax obligations and local labor laws, timely and accurate payroll, and competitive global benefits, including pensions, health insurance, and family leave to ensure a great experience for both the employer and employee.</p><br><p>We enable our clients to be able to employ anyone, anywhere, any way.</p><br><p><strong>About the Role:</strong></p><br><p>We are seeking a talented and motivated Intermediate Data Engineer to join our dynamic team. The ideal candidate will have a solid understanding of data engineering principles, with a specific focus on DBT and Snowflake, and extensive knowledge of SQL. This role will involve designing, building, and maintaining data pipelines, ensuring efficient processing and storage of data, and supporting various operational use cases on our data platform.</p><br><p><strong>Key Responsibilities:</strong></p><ul><li>Design, build, and maintain efficient, scalable, and reliable data pipelines.</li><li>Implement and manage data transformation processes using DBT.</li><li>Work extensively with Snowflake for data warehousing solutions.</li><li>Write and optimize SQL queries for data transformation and reporting.</li><li>Collaborate with data analysts and other stakeholders to understand data requirements and deliver high-quality solutions.</li><li>Ensure data quality and integrity through regular monitoring and testing.</li><li>Troubleshoot and resolve data-related issues in a timely manner.</li><li>Utilize the data platform intensively for various operational use cases.</li><li>Stay up-to-date with the latest developments in data engineering technologies and best practices.</li></ul><p><strong>Qualifications:</strong></p><ul><li>Bachelor's degree in Computer Science, Information Technology, or a related field, or equivalent work experience.</li><li>Proven experience with SQL and its application in data processing.</li><li>Familiarity with DBT and Snowflake.</li><li>Strong problem-solving skills and attention to detail.</li><li>Excellent communication and collaboration abilities.</li><li>Ability to work independently and as part of a team.</li></ul><p><strong>Preferred Qualifications:</strong></p><ul><li>Awareness of writing clean, maintainable code and following coding patterns and best practices.</li><li>Knowledge of Python or another programming language.</li><li>Understanding of data modeling and database design.</li><li>Experience with cloud platforms (e.g., AWS, Azure, GCP).</li></ul><p><strong>What's in it for you?</strong></p><ul><li><br><strong>Shared ownership</strong>: Being a part of our journey means you'll own a piece of Omnipresent.</li><li><br><strong>Flexible working:</strong> Work from anywhere in the world! We are genuinely as flexible as the work allows.</li><li><br><strong>Development:</strong> Training, coaching, and an environment that promotes career ambition and progression.</li><li><br><strong>Work environment:</strong> We are fully remote, allowing you to work from wherever you live in a flexible manner.</li><li><br><strong>Wellbeing:</strong> Mental health and wellbeing support and services through Plumm</li><li><br><strong>Home office setup:</strong> We will provide you with the equipment you need to work from home: laptop, monitor and we will also cover your internet costs.</li><li><br><strong>Additional benefits:</strong> We offer additional benefits that vary from region to region, such as medical, life insurance, pension/retirement funds and more!</li></ul><p><strong>We believe remote working is a great equalizer and we practice what we preach. Inclusivity is fundamental to our mission and we are committed to conscious inclusion. We believe in the potential of everyone; regardless of race, religion or belief, ethnic origin, different physical ability, family structure, socio-economics, age, nationality or citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity.</strong></p><br><p>#LI-Remote</p><br>"
  },
  {
    "id": 64,
    "title": "Data Scientist (w/m/d) Siemens Historical Institute",
    "company": "Siemens AG",
    "locations": "Berlin",
    "skills": "Data Science, Data Analysis",
    "posted_at": "2024-08-15",
    "is_remote": "False",
    "snippet_fragments": " Verwaltung und Betreuung der IT-Infrastruktur sowie Archivsoftware-L\u00f6sungen, um einen stabilen und zuverl\u00e4ssigen Betrieb sicherzustellen,  Verantwortung und Umsetzung der relevanten Cyber-Security Bestimmungen und Prozesse sowie die Erstellung und \u00dcberwachung von Datenschutz- und Sicherheitsrichtlinien, Erstellung und Pflege technischer Dokumentationen und administrativer Eintr\u00e4ge in Siemens IT-Tools, Planung, Budgetierung und \u00dcberwachung des IT-Projektbudgets,  Zusammenarbeit mit internen und externen Stakeholdern, um den reibungslosen Datenaustausch zu gew\u00e4hrleisten,  Implementierung von Cloud-basierten Archiven f\u00fcr unterschiedliche Datenkategorien und Schaffung effektiver Klassifikations- und Ordnungssysteme,  Unterst\u00fctzen und Koordinieren von IT-Transformationsprojekten zur Modernisierung unserer IT-Landschaft und des digitalen Archivs, Auswahl zukunftsf\u00e4higer Archivierungsl\u00f6sungen und Planung der Migration, einschlie\u00dflich der Schulung und Unterst\u00fctzung von SHI-Mitarbeitern, Abgeschlossenes Bachelor-Studium im Bereich Informatik, Wirtschaftsinformatik oder einem verwandten Feld, Langj\u00e4hrige T\u00e4tigkeit in den Bereichen Data Science, Data Analytics und Archivierung,  Ausgepr\u00e4gte Kenntnisse in Cloud-Technologien, IT-Infrastrukturen und Archivsoftware sowie Kenntnisse \u00fcber Cyber-Security Bestimmungen sowie Bereitschaft sich in das IT Umfeld eines globalen Konzerns einzuarbeiten, Praxiserfahrung mit Digitalisierungstechnologien, Integration verschiedener IT-Anwendungen und dem Einsatz von KI-Technologien, Ausgepr\u00e4gte analytische und organisatorische F\u00e4higkeiten, strategisches Denkverm\u00f6gen, exzellente Kommunikationsf\u00e4higkeiten und Teamf\u00e4higkeit,  Flie\u00dfende Deutsch- und Englischkenntnisse in Wort und Schrift sind notwendig,        Eine herausfordernde T\u00e4tigkeit in einem dynamischen Umfeld, Die M\u00f6glichkeit, an bedeutenden IT-Transformationsprojekten zu arbeiten,        Ein engagiertes Team und eine offene Unternehmenskultur,        2 bis 3 Tage pro Woche mobiles Arbeiten als globaler Standard,        Die einzelnen Benefits sind jeweils zugeschnitten auf lokale gesetzliche Anforderungen",
    "description": "<p><strong>\u00dcber uns.</strong></p><br><p>Als Teil unserer globalen Brand-Abteilung sind wir vom Siemens Historical Institute (SHI) daf\u00fcr verantwortlich, das historische Erbe von Siemens zu bewahren und zu pflegen. Wir arbeiten daran, unsere IT-Systeme zu modernisieren und zukunftssicher zu machen, um die Effizienz und Produktivit\u00e4t unseres Archivs zu steigern.</p><br><p>Bist du bereit, Teil eines zukunftsorientierten Teams zu werden und eine Schl\u00fcsselrolle bei der Modernisierung unserer IT-Landschaft zu \u00fcbernehmen? Dann freuen wir uns auf deine Bewerbung!</p><br><p><strong>Deine T\u00e4tigkeiten.</strong></p><ul><li><br><strong>Prozesserstellung:</strong> Entwickeln und Standardisieren von Schnittstellen und Prozessen f\u00fcr die Akquisition, Archivierung und Verwaltung digitaler Assets sowie kontinuierliche Prozessoptimierung</li><li><br><strong>Automatisierung:</strong> Einf\u00fchrung und Einsatz von K\u00fcnstlicher Intelligenz zur automatischen Beschreibung und Zusammenfassung von Dokumenten, AV- und Social Media-Assets</li><li><br><strong>Administrationst\u00e4tigkeiten:</strong> Verwaltung und Betreuung der IT-Infrastruktur sowie Archivsoftware-L\u00f6sungen, um einen stabilen und zuverl\u00e4ssigen Betrieb sicherzustellen</li><li><br><strong>Cyber-Security:</strong> Verantwortung und Umsetzung der relevanten Cyber-Security Bestimmungen und Prozesse sowie die Erstellung und \u00dcberwachung von Datenschutz- und Sicherheitsrichtlinien</li><li><br><strong>Dokumentation:</strong> Erstellung und Pflege technischer Dokumentationen und administrativer Eintr\u00e4ge in Siemens IT-Tools</li><li><br><strong>Kostenmanagement:</strong> Planung, Budgetierung und \u00dcberwachung des IT-Projektbudgets</li><li><br><strong>Stakeholder-Management:</strong> Zusammenarbeit mit internen und externen Stakeholdern, um den reibungslosen Datenaustausch zu gew\u00e4hrleisten</li><li><br><strong>Entwicklung von L\u00f6sungen:</strong> Implementierung von Cloud-basierten Archiven f\u00fcr unterschiedliche Datenkategorien und Schaffung effektiver Klassifikations- und Ordnungssysteme</li><li><br><strong>Projektmanagement:</strong> Unterst\u00fctzen und Koordinieren von IT-Transformationsprojekten zur Modernisierung unserer IT-Landschaft und des digitalen Archivs</li><li><br><strong>Migrationsplanung:</strong> Auswahl zukunftsf\u00e4higer Archivierungsl\u00f6sungen und Planung der Migration, einschlie\u00dflich der Schulung und Unterst\u00fctzung von SHI-Mitarbeitern</li></ul><p><strong>Deine Qualifikationen.</strong></p><ul><li><br><strong>Ausbildung:</strong> Abgeschlossenes Bachelor-Studium im Bereich Informatik, Wirtschaftsinformatik oder einem verwandten Feld</li><li><br><strong>Berufserfahrung:</strong> Langj\u00e4hrige T\u00e4tigkeit in den Bereichen Data Science, Data Analytics und Archivierung</li><li><br><strong>Kenntnisse:</strong> Ausgepr\u00e4gte Kenntnisse in Cloud-Technologien, IT-Infrastrukturen und Archivsoftware sowie Kenntnisse \u00fcber Cyber-Security Bestimmungen sowie Bereitschaft sich in das IT Umfeld eines globalen Konzerns einzuarbeiten</li><li><br><strong>Technische Kenntnisse:</strong> Praxiserfahrung mit Digitalisierungstechnologien, Integration verschiedener IT-Anwendungen und dem Einsatz von KI-Technologien</li><li><br><strong>St\u00e4rken:</strong> Ausgepr\u00e4gte analytische und organisatorische F\u00e4higkeiten, strategisches Denkverm\u00f6gen, exzellente Kommunikationsf\u00e4higkeiten und Teamf\u00e4higkeit</li><li><br><strong>Sprachkenntnisse:</strong> Flie\u00dfende Deutsch- und Englischkenntnisse in Wort und Schrift sind notwendig</li><li><br><strong>Interesse</strong>: Begeisterung f\u00fcr die Geschichte des Unternehmens und Engagement, sich tief in die Materie einzuarbeiten</li></ul><p><strong>Was wir bieten.</strong></p><ul><li>Eine herausfordernde T\u00e4tigkeit in einem dynamischen Umfeld</li><li>Die M\u00f6glichkeit, an bedeutenden IT-Transformationsprojekten zu arbeiten</li><li>Ein engagiertes Team und eine offene Unternehmenskultur</li><li>2 bis 3 Tage pro Woche mobiles Arbeiten als globaler Standard</li><li>Ansprechendes Verg\u00fctungspaket</li><li>Zugang zu Aktienpl\u00e4nen f\u00fcr Mitarbeitende</li><li>Und viele weitere Benefits hier</li></ul><p>Die einzelnen Benefits sind jeweils zugeschnitten auf lokale gesetzliche Anforderungen, Vorgaben verschiedener Job-Profile und Standorte sowie individuelle Pr\u00e4ferenzen.</p><br><p><strong>Bewirb dich!</strong></p><br><p>Wir legen Wert auf Chancengleichheit und freuen uns \u00fcber Bewerbungen von Menschen mit Behinderung.</p><br><p><strong>https://new.siemens.com/</strong> - f\u00fcr mehr Informationen zu Jobs &amp; Karriere bei Siemens.</p><br><p><strong>FAQ</strong> - f\u00fcr Fragen zum Thema Bewerbung bei Siemens.</p><br>"
  },
  {
    "id": 65,
    "title": "(Senior) Data Platform Engineer (m/f/d)",
    "company": "MOIA",
    "locations": "Berlin",
    "skills": "Python, SQL, AWS, Data Pipelines, Airflow, Spark, Lambda, Continuous Integration, DevOps, JavaScript, Pair Programming, Protocol Buffers, TypeScript, Terraform, APIs, Orchestration, Serverless, Kinesis, Encryption, AWS Athena, Firehose, CD, AWS S3",
    "posted_at": "2024-08-14",
    "is_remote": "True",
    "snippet_fragments": "   Flexible working hours and possibility of flexible work arrangements depending on your needs (parenting,    Budget and monthly expense allowance for home office setup ,    Possibility of remote work from outside of Germany for up to 6 weeks per year from over 40 different countries - Connect work & travel! ,    Public transport ticket (fully subsidized) for commuting and traveling throughout Germany and discount on MOIA rides ,    Subsidized fitness club membership or bike leasing ,    Learning environment with continuous learning days, 30 vacation days, sabbatical and unpaid leave option,    Relocation support with service provider (visa,    Dog-friendly offices (at our Hamburg location) , For student & internship positions, we have an adjusted set of benefits,    We are a member of Charta der Vielfalt and are dedicated to actively fostering a workplace that celebrates and promotes diversity in various aspects such as age, At MOIA, we embrace a culture where people are accepted, respected, valued, appreciated, and included.,    In our commitment to promoting diversity and inclusivity, Furthermore, we continuously strive to enhance our hiring process by ensuring a diverse hiring panel.,    To reinforce an unbiased screening process",
    "description": "<p><strong>JOIN US AS A</strong> <strong>(SENIOR)</strong> <strong>DATA ENGINEER (M/F/D) IN OUR DATA PLATFORM TEAM ON A SHARED JOURNEY THAT MATTERS!</strong></p><br><p>The Data Platform team ensures that all data generated at MOIA can be accessed and processed in our data platform. We rely on a wide variety of AWS services to build our data products and keep our stack as serverless as possible. You will work at the core of MOIA's data engine room and interact with colleagues from 25+ different Teams. We provide automation, tools, operate services and evangelize best practices so that data at MOIA is processed in an efficient, secure and privacy-compliant way. We strive towards enabling our users to work as independently and self-sufficiently as possible.</p><br><p><strong>WHAT YOU WILL DO</strong></p><ul><li>Show a platform mindset by enabling and supporting others to make use of data with internal tools. Collaborating and communicating with teams across multiple tech stacks and business domains is crucial for the platform team's success! We also aim to support each other's growth and invite everyone to contribute to our learning days.</li><li>Design, develop, and maintain an internal data platform using AWS Athena, Apache Spark and Apache Airflow, building large scale data pipelines.</li><li>Build and optimize event-based data ingestion pipelines using AWS Kinesis, AWS Lambda and AWS Firehose and Protocol Buffers</li><li>Develop and deploy serverless applications using AWS Lambda and AWS API Gateway.</li><li>Design and build privacy-by-design solutions to make GDPR compliant data processing easier for the teams.</li><li>Design, implement and maintain internal APIs, libraries and tooling using Python and TypeScript.</li><li>Ensure availability, scalability and security of our data infrastructure on AWS.</li></ul><p><strong>WHAT WILL HELP YOU TO FULFILL YOUR ROLE</strong></p><ul><li>Effective communication skills and interest in being part of a highly autonomous team</li><li>We want to act and grow as a team. Collaborating via pair programming, sharing knowledge, communicating effectively and mentoring others should be something you value in your day-to-day work.</li><li>Strong programming skills in Python. Knowledge of the JavaScript/Typescript ecosystem and/or JVM-based languages is a relevant plus.</li><li>Experience developing and running applications in cloud-native environments, for example using AWS Lambda and S3, and deploying them through Infrastructure as Code (e.g. via CDK or Terraform).</li><li>Experience with GDPR compliant Data Engineering and Data Privacy, for example scalable Data Deletion, PII Encryption or Data Isolation</li><li>Familiarity with job orchestration frameworks for data pipeline management, for example Apache Airflow.</li><li>Experience with SQL in analytical and transactional database technologies.</li><li>Experience with DevOps practices, such as continuous integration and deployment using tools and methods like CI/CD, Containers, Monitoring, Alerting</li><li>Familiarity with dbt (Data Build Tool) for data transformation is a plus</li><li>Previous experience in designing and building (data) APIs is a plus</li></ul><p>We encourage you to apply even if your profile does not meet all the requirements for the role since we are looking for a diverse range of experiences, skills, and interests. We are certain that there will be something for everyone because we are working on such a variety of tasks and embrace individual growth at MOIA.</p><br><p>In case you have questions regarding your application, you can approach the recruiter Dennis directly.</p><br><p><strong>OUR BENEFITS IN A NUTSHELL</strong></p><ul><li>Competitive salary (including bonus)</li><li>Hybrid work setup: work from home or one of our offices - you and your team decide how often to meet, blending flexibility with collaboration!</li><li>Flexible working hours and possibility of flexible work arrangements depending on your needs (parenting, care work, volunteering, etc.)</li><li>Budget and monthly expense allowance for home office setup</li><li>Possibility of remote work from outside of Germany for up to 6 weeks per year from over 40 different countries - Connect work &amp; travel!</li><li>Public transport ticket (fully subsidized) for commuting and traveling throughout Germany and discount on MOIA rides</li><li>Subsidized fitness club membership or bike leasing</li><li>Learning environment with continuous learning days, job rotation, trainings and workshops, coaching, conferences, books, and language classes</li><li>Mental health support, 1:1 sessions with external professionals and mental unload workshops</li><li>30 vacation days, sabbatical and unpaid leave option</li><li>Relocation support with service provider (visa, administration, etc.)</li><li>Dog-friendly offices (at our Hamburg location)</li></ul><p>For student &amp; internship positions, we have an adjusted set of benefits. You can find them here.</p><br><p><strong>BE WHO YOU ARE!</strong></p><br><p>We are a member of Charta der Vielfalt and are dedicated to actively fostering a workplace that celebrates and promotes diversity in various aspects such as age, gender identity, race, sexual orientation, physical or cognitive ability, and ethnicity. At MOIA, we embrace a culture where people are accepted, respected, valued, appreciated, and included.</p><br><p>In our commitment to promoting diversity and inclusivity, we regularly provide unconscious bias training to all our employees. Furthermore, we continuously strive to enhance our hiring process by ensuring a diverse hiring panel.</p><br><p>To reinforce an unbiased screening process, we kindly ask you not to include your picture, age, address, or any other details that are unrelated to your qualifications and suitability for the role.</p><br><p><strong>OUR FUTURE WORK MODEL</strong></p><br><p>Since we love to collaborate, it is clear to us that we don't want to become a fully remote company, but we also don't need to spend every day of the week in the office to do a great job.</p><br><p>Our current hybrid work approach focuses on adapting to different needs, including increased flexibility that works best for the teams and the individuals with as much self-determination as possible.</p><br><p>Get more insights on how we work on our blog to find out more about our hiring process or follow us on Instagram for a look inside MOIA.</p><br><p><strong>WHO WE ARE</strong></p><br><p>At MOIA GmbH, our team of more than 350 employees develops the technical products for our on-demand ridepooling service in the form of an end-to-end integrated product, from hub, fleet, and driver management to passenger and B2B solutions. At the same time, we want to make the vision of an autonomously driving mobility service a reality and plan to bring the first autonomous MOIA ridepooling vehicle to the streets by 2025.</p><br><p>At our offices in Berlin and Hamburg, international teams of developers, engineers, designers, and strategists work on a shared mission. As a tech company, more than half of our employees are developers. We pursue value-driven development based on our product values of comfort, reliability, safety, and privacy.</p><br><p>We aspire to be a leading company in the fields of rethinking mobility and improving urban transportation by making it more relaxed, more affordable and an entirely positive experience for everyone.</p><br><p>MOIA gets things moving. On a shared journey - towards an easier, smarter, and more meaningful future.</p><br>"
  },
  {
    "id": 66,
    "title": "(Junior) Data Engineer (m/w/d)",
    "company": "RSG Group GmbH - Head Office Berlin",
    "locations": "Berlin",
    "skills": "Python, Machine Learning, Azure, ETL, Power BI, Snowflake, Vault",
    "posted_at": "2024-08-14",
    "is_remote": "True",
    "snippet_fragments": "    Flache Hierarchie und Verst\u00e4ndigung auf Augenh\u00f6he , Kostenlose Mitgliedschaft (McFIT, John Reed und Golds Gym), Du bist f\u00fcr die Anbindung, Maintenance und Optimierung von neuen Datenquellen und -pipelines mitverantwortlich,     Du entwickelst die Datenarchitektur weiter und optimierst bestehende Prozesse ,     Du entwickelst Business Logiken und implementierst diese in unser Datenmodell ,     Du bist mitverantwortlich f\u00fcr alle ETL/ELT-Prozesse und sorgst f\u00fcr deren reibungslosen Ablauf ,     Du hast ein abgeschlossenes Studium in Informatik,     Du bringst erste Berufserfahrung als Data Engineer mit oder hast relevante Praktika absolviert ,     Du besitzt fundierte Kenntnisse in Datenbanktechnologien und Datenintegration (ETL/ELT-Prozesse,     Du hast Erfahrung mit den genannten Tools und Technologien (Snowflake,     Du hast idealerweise erste Kenntnisse im Bereich ML,     Du besitzt starke analytische F\u00e4higkeiten und eine hohe Probleml\u00f6sungskompetenz ,     Du bist kommunikationsstark und arbeitest gerne im Team",
    "description": "<p><strong>WER WIR SIND</strong></p><br><p>Mit mehr als 4,5 Millionen Mitgliedern in ihren Studios ist die <strong>RSG Group</strong> eines der weltweit f\u00fchrenden Unternehmen im Bereich Fitness. Die 1997 von Rainer Schaller gegr\u00fcndete - und sich nach wie vor im Familienbesitz befindende - RSG Group hat sich zu einem international t\u00e4tigen Unternehmen entwickelt. Inklusive ihrer Franchisenehmer besch\u00e4ftigt sie 10.000 Mitarbeitende an \u00fcber 900 Standorten und ist in mehr als 30 L\u00e4ndern vertreten. Das umfangreiche und zukunftsorientierte Portfolio umfasst 11 innovative Marken, dazu z\u00e4hlen unter anderem Gold's Gym, McFIT und die JOHN REED Family. Die RSG Group setzt immer wieder neue Ma\u00dfst\u00e4be und sorgt somit daf\u00fcr, wesentlicher Bestandteil des aktiven Alltags ihrer Kundinnen und Kunden zu sein.</p><br><p><strong>WAS DU GEWINNST</strong></p><ul><li>Unbefristetes Besch\u00e4ftigungsverh\u00e4ltnis</li><li>13 Geh\u00e4lter (Urlaubs- und Weihnachtsgeld)</li><li>Home-Office Option</li><li>Flexible Arbeitszeiten</li><li>Flache Hierarchie und Verst\u00e4ndigung auf Augenh\u00f6he</li><li>Interne und externe Weiterbildungsm\u00f6glichkeiten</li><li>Come as you are</li><li>Regelm\u00e4\u00dfige Team- und Firmenevents</li><li>Kostenlose Mitgliedschaft (McFIT, John Reed und Gold\u00b4s Gym)</li></ul><p><strong>WAS DU BEI UNS BEWEGST</strong></p><ul><li>Du bist f\u00fcr die Anbindung, Maintenance und Optimierung von neuen Datenquellen und -pipelines mitverantwortlich</li><li>Du entwickelst die Datenarchitektur weiter und optimierst bestehende Prozesse</li><li>Du entwickelst Business Logiken und implementierst diese in unser Datenmodell</li><li>Du bist mitverantwortlich f\u00fcr alle ETL/ELT-Prozesse und sorgst f\u00fcr deren reibungslosen Ablauf</li></ul><p><strong>WAS UNS \u00dcBERZEUGT</strong></p><ul><li>Du hast ein abgeschlossenes Studium in Informatik, Wirtschaftsinformatik oder einem vergleichbaren Bereich</li><li>Du bringst erste Berufserfahrung als Data Engineer mit oder hast relevante Praktika absolviert</li><li>Du besitzt fundierte Kenntnisse in Datenbanktechnologien und Datenintegration (ETL/ELT-Prozesse, Data Vault 2.0)</li><li>Du hast Erfahrung mit den genannten Tools und Technologien (Snowflake, Azure Data Factory, Microsoft SQL Server Integration Services, Microsoft SQL Server Analysis Services, PowerBI, Python, Fivetran)</li><li>Du hast idealerweise erste Kenntnisse im Bereich ML, Predictive Models, im Umgang mit einer Customer Data Platform und Identity Resolution</li><li>Du besitzt starke analytische F\u00e4higkeiten und eine hohe Probleml\u00f6sungskompetenz</li><li>Du bist kommunikationsstark und arbeitest gerne im Team, sprichst Deutsch auf mindestens B2-Niveau und hast gute Englischkenntnisse</li></ul><p><strong>PASSEN WIR ZUSAMMEN?</strong></p><br><p>Die RSG Group bietet dir seit mehr als 25 Jahren eine einzigartige Unternehmenskultur mit Platz f\u00fcr Pers\u00f6nlichkeit: Wir betrachten Menschen als Menschen und somit als wertvoll f\u00fcr uns alle. Wir f\u00f6rdern und fordern. Wenn du somit talentiert bist und zu uns passt, erh\u00e4ltst du bei uns die Chancen und Herausforderungen, nach denen du schon immer gesucht hast.</p><br><p>Wir freuen uns auf dich!</p><br><p>RSG Group GmbH | Dein Karriere-Team | Saarbr\u00fccker Stra\u00dfe 38 | 10405 Berlin</p><br>"
  },
  {
    "id": 67,
    "title": "Business Intelligence Engineer, Community Data & Science",
    "company": "Amazon Development Center Germany GmbH",
    "locations": "Berlin",
    "skills": "Python, SQL, AWS, Business Intelligence, Data Modeling, Data Warehouse, ETL, Agile, DynamoDB, Redshift, Dashboards, MATLAB, MySQL, NoSQL, Quicksight, Tableau, Data Visualization, Data mining, Scripting Language, AWS EC2, R, SAS, AWS S3, Statistical Analysis",
    "posted_at": "2024-08-13",
    "is_remote": "False",
    "snippet_fragments": " Deliver on strategic analytical projects by coordinating with business,  Deep dive on down stream impact of various customer facing programs,  Build models/ heuristics/ frameworks that can directly feed into the tech team roadmap for business enhancements,  Build agile feedback loop mechanisms to do quick deep dives into new initiatives, Owning the design, development, and maintenance of scalable solutions for ongoing metrics, reports, analyses, dashboards, etc, to support analytical and business needs,  Develop queries and visualizations for ad-hoc requests and projects,  Write high quality SQL code to retrieve and analyze data from database tables (ex, Redshift, MySQL, Oracle), and learn and understand a broad range of Amazons data resources and know how, when, and which to use and which not to use.,  Experience with AWS solutions such as EC2, DynamoDB, Experience in data mining, ETL, etc, and using databases in a business environment with large-scale",
    "description": "<ul><li>Experience in analyzing and interpreting data with Redshift, Oracle, NoSQL etc.</li><li>Experience with data visualization using Tableau, Quicksight, or similar tools</li><li>Experience with data modeling, warehousing and building ETL pipelines</li><li>Experience in Statistical Analysis packages such as R, SAS and Matlab</li><li>Experience using SQL to pull data from a database or data warehouse and scripting experience (Python) to process data for modeling</li><li>Experience with SQL</li><li>Experience in the data/BI space<br> The Community Feedback org shapes products and technology used daily by millions of customers around the world. The team is responsible for many central Amazon experiences including Customer Reviews, Ask Questions &amp; Answers and Content Moderation. These experiences are world-wide, complex and vital to the on-going success of Amazon. Come work with us to drive the future of these products for our customers!</li></ul><p>We're looking for a Business Intelligence Engineer (BIE) who will be a key member of the Community Data &amp; Science team. This person will deliver on strategic analytical projects, define/produce end-to-end metrics that inform product decisions through data-driven insights and improve data/metric accessibility for our business.</p><br><p>The ideal candidate relishes working with large volumes of data, enjoys the challenge of highly complex business contexts, and, above all else, is passionate about data and analytics. They are an expert with business intelligence tools and passionately partner with the business to identify strategic opportunities where data-backed insights drive value creation. An effective communicator, the candidate crisply translates analysis result into executive-facing business terms. They are a self-starter, comfortable with ambiguity, able to think big (while paying careful attention to detail), and enjoy working in a fast-paced environment, driven by a desire to innovate and move fast.</p><br><p>Key job responsibilities</p><ul><li>Deliver on strategic analytical projects by coordinating with business, tech teams and other stakeholders as needed.</li><li>Deep dive on down stream impact of various customer facing programs, including extracting and analyzing large financial data sets.</li><li>Build models/ heuristics/ frameworks that can directly feed into the tech team roadmap for business enhancements.</li><li>Build agile feedback loop mechanisms to do quick deep dives into new initiatives, measure their efficacy and give recommendations to move closer to desired end state.</li><li>Owning the design, development, and maintenance of scalable solutions for ongoing metrics, reports, analyses, dashboards, etc. to support analytical and business needs.</li><li>Develop queries and visualizations for ad-hoc requests and projects, as well as ongoing reporting.</li><li>Write high quality SQL code to retrieve and analyze data from database tables (ex. Redshift, MySQL, Oracle), and learn and understand a broad range of Amazon's data resources and know how, when, and which to use and which not to use.</li><li>Experience with AWS solutions such as EC2, DynamoDB, S3, and Redshift</li><li>Experience in data mining, ETL, etc. and using databases in a business environment with large-scale, complex datasets<br> Amazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success. We make recruiting decisions based on your experience and skills. We value your passion to discover, invent, simplify and build. Protecting your privacy and the security of your data is a longstanding top priority for Amazon. Please consult our Privacy Notice (https://www.amazon.jobs/en/privacy_page) to know more about how we collect, use and transfer the personal data of our candidates.</li></ul><p>m/w/d</p><br>"
  },
  {
    "id": 68,
    "title": "Data Engineer (w/m/d)",
    "company": "Michael Page",
    "locations": "Berlin",
    "skills": "Python, SQL, JavaScript, SQL Server, PostGIS, ESRI, FME",
    "posted_at": "2024-08-12",
    "is_remote": "False",
    "snippet_fragments": "   Du hast idealerweise Erfahrungen in der Analyse, Du beherrschst Programmiersprachen wie Python, SQL oder JavaScript zur Schnittstellenprogrammierung,   Du verf\u00fcgst \u00fcber Kenntnisse zur Administration von Datenbanken wie Oracle, Ein sicheres Auftreten, Kommunikationsst\u00e4rke und Teamf\u00e4higkeit runden dein Profil ab",
    "description": "<p>Agiles Arbeitsumfeld &amp; flexible Arbeitszeiten|Individuelle Karriereplanung</p><br><p><strong>VERG\u00dcTUNGSPAKET</strong></p><ul><li>Teamorientiertes Arbeitsklima: Eine Arbeitsumgebung schaffen, die Teamarbeit und Zusammenarbeit f\u00f6rdert, damit gemeinsame Ziele effektiv erreicht werden k\u00f6nnen</li><li>Flexibilit\u00e4t in Projekten: Ermutigung zur Anpassung der Arbeitsweise, um schnell auf Ver\u00e4nderungen und neue Anforderungen reagieren zu k\u00f6nnen und die Eigenverantwortung der Mitarbeiter zu st\u00e4rken</li><li>Flexible Gestaltung der Arbeitszeiten, um den Mitarbeitern eine gesunde Balance zwischen Berufs- und Privatleben zu erm\u00f6glichen, einschlie\u00dflich Gleitzeit, Teilzeit und Homeoffice-Optionen</li><li>Gesundheitsf\u00f6rdernde Ma\u00dfnahmen: Bereitstellung von Programmen zur Unterst\u00fctzung der physischen und psychischen Gesundheit der Mitarbeiter, darunter Fitnessangebote und ergonomische Arbeitspl\u00e4tze</li><li>Innovationsf\u00f6rdernde Kultur: Unterst\u00fctzung von Kreativit\u00e4t und neuen Ideen durch eine experimentierfreudige Unternehmenskultur, die kontinuierliche Verbesserung und Effizienzsteigerung anstrebt</li></ul><p><strong>AUFGABENGEBIET</strong></p><ul><li><br><strong>Analyse der Datenanforderungen</strong>: Ermitteln der spezifischen Bed\u00fcrfnisse und Herausforderungen unserer Kunden in Bezug auf die Integration von Geodaten</li><li><br><strong>Entwicklung von Integrationsstrategien</strong>: Planen und Entwerfen von effizienten Datenintegrationsprozessen, die auf die Anforderungen und bestehenden Systeme der Kunden zugeschnitten sind</li><li><br><strong>Nutzung der FME\u00ae Plattform</strong>: Einsatz der FME-Plattform zur Automatisierung von Datenworkflows, um Geodaten aus unterschiedlichen Quellen zu kombinieren und zu transformieren</li><li><br><strong>Einsatz zus\u00e4tzlicher Technologien</strong>: Integration weiterer Technologien und Werkzeuge, um die Leistungsf\u00e4higkeit und Flexibilit\u00e4t der Datenintegration zu erh\u00f6hen</li><li><br><strong>Qualit\u00e4tssicherung und Optimierung</strong>: Sicherstellen der Datenqualit\u00e4t durch kontinuierliche Tests und Optimierungen der Integrationsprozesse</li></ul><p><strong>ANFORDERUNGSPROFIL</strong></p><ul><li>Du hast idealerweise Erfahrungen in der Analyse, Aufbereitung und Qualit\u00e4tssicherung von (Geo-)Daten mit Esri, FME oder vergleichbaren Technologien</li><li>Du beherrschst Programmiersprachen wie Python, SQL oder JavaScript zur Schnittstellenprogrammierung</li><li>Du verf\u00fcgst \u00fcber Kenntnisse zur Administration von Datenbanken wie Oracle, PostGIS, MSSQL Server oder vergleichbare</li><li>Ein sicheres Auftreten, Kommunikationsst\u00e4rke und Teamf\u00e4higkeit runden dein Profil ab</li></ul><p><strong>FIRMENPROFIL</strong></p><br><p>In dieser Position bist du verantwortlich f\u00fcr die Konzeption und Umsetzung von Prozessen zur Integration von Geodaten mit Hilfe der FME\u00ae Plattform sowie weiterer Technologien. Zudem entwickelst du FME-basierte L\u00f6sungsbausteine und ber\u00e4tst Kunden aus der Privatwirtschaft und Beh\u00f6rden bei der Umsetzung von Geodatenmanagementaufgaben.</p><br>"
  },
  {
    "id": 69,
    "title": "Genomic Data Scientist (all genders)",
    "company": "Bayer",
    "locations": "Berlin",
    "skills": "HPC, Immunologie, Proteomics, Bioinformatik, Transcriptomics, Genomik, Computational biology, Omics, Biomarker, Systembiologie",
    "posted_at": "2024-08-10",
    "is_remote": "False",
    "snippet_fragments": "  You hold a PhD in Life Sciences (Bioinformatics,   You have broad post-doctoral experience and/or several years of expertise in drug discovery or pharma ,   You possess expertise (hands-on) in human omics (transcriptomic,   You have advanced IT and programming skills and are familiar with high-performance computing , You are highly self-motivated, strive for scientific excellence, and show evidence of lifelong learning to advance,   You demonstrate very strong analytical thinking and scientific rigor,   You are capable of presenting complex issues clearly and convincingly to project teams or decision bodies,   You show clear leadership potential and possess very good soft skills You are fluent in English, What matters to you, matters to us!,   We ensure your financial stability through a competitive compensation package, In addition, managers can recognize special contributions by granting an individual performance award., to work how, when and where it is best for you.,   Your family is a top priority, We offer loving company daycare centers at multiple locations,   We support your professional growth by providing access to learning and development opportunities,   We promote health awareness and opportunities for selfcare through various measures,   We embrace diversity by providing an inclusive work environment in which you are welcomed,  Applications from employees in Germany who may be affected by personnel reduction will be treated favourably",
    "description": "<p><strong>At Bayer we're visionaries, driven to solve the world's toughest challenges and striving for a world where ,Health for all, Hunger for none' is no longer a dream, but a real possibility. We're doing it with energy, curiosity and sheer dedication, always learning from unique perspectives of those around us, expanding our thinking, growing our capabilities and redefining 'impossible'. There are so many reasons to join us. If you're hungry to build a varied and meaningful career in a community of brilliant and diverse minds to make a real difference, there's only one choice.</strong></p><br><p><strong>Genomic Data Scientist (all genders)</strong></p><br><p><strong>YOUR TASKS AND RESPONSIBILITIES</strong></p><ul><li>You will initiate and lead highly innovative research projects in cardiovascular, renal, and immunology indications, significantly contributing to gate stage decisions</li><li>You will identify novel targets and biomarkers in the above indications using state-of-the-art bioinformatics methods to analyze large and complex data sets, with a particular focus on human proteomics, transcriptomics, and electronic health record data</li><li>You will develop, evaluate, implement, and apply novel bioinformatics methods on complex data sets</li><li>You will be involved in collaborations with academic or commercial partners and represent Bayer, while also supporting scientific personnel (post-docs, PhD, master students, and interns)<br> You will maintain interfaces with other Pharma and R&amp;D functions involved in drug development and data sciences</li></ul><p><strong>WHO YOU ARE</strong></p><br><p>We are excited about your talent and passion for this position. Attracting the right talent is important to us. We would be happy to work with you to identify and create the career and development opportunities you are looking for. And if you don't meet all the requirements, we still look forward to receiving your application. We are all constantly learning!</p><ul><li>You hold a PhD in Life Sciences (Bioinformatics, Computational Biology, Systems Biology) with a very strong computational focus</li><li>You have broad post-doctoral experience and/or several years of expertise in drug discovery or pharma</li><li>You possess expertise (hands-on) in human omics (transcriptomic, proteomic, metabolomic, genetic data) analyses</li><li>You have advanced IT and programming skills and are familiar with high-performance computing</li><li>You are highly self-motivated, strive for scientific excellence, and show evidence of lifelong learning to advance</li><li>You demonstrate very strong analytical thinking and scientific rigor, favoring systematic approaches</li><li>You are capable of presenting complex issues clearly and convincingly to project teams or decision bodies, with good communication skills, and can manage a high degree of complexity</li><li>You show clear leadership potential and possess very good soft skills<br> You are fluent in English, both spoken and written</li></ul><p><strong>WHAT WE OFFER</strong></p><br><p>Our benefits package is flexible, appreciative, and tailored to your lifestyle, because: <strong>What matters to you, matters to us!</strong></p><ul><li>We ensure your <strong>financial stability</strong> through a competitive compensation package, consisting of an attractive base pay and our annual bonus. In addition, managers can recognize special contributions by granting an individual performance award.</li><li>Whether it's hybrid work models or part-time arrangements: Whenever it is possible, you will have the <strong>flexibility</strong> to work how, when and where it is best for you.</li><li>Your <strong>family</strong> is a top priority. We offer loving company daycare centers at multiple locations, support in finding childcare, time off for the care of elderly or dependent family members, summer camps for children, and much more.</li><li>We support your <strong>professional growth</strong> by providing access to learning and development opportunities, training programs through the Bayer Learning Academy, development dialogues, as well as coaching and mentoring programs.</li><li>We promote <strong>health awareness</strong> and opportunities for selfcare through various measures, such as free health checks with the company doctor and our health platform #machfit.</li><li>We embrace diversity by providing an <strong>inclusive work environment</strong> in which you are welcomed, supported, and encouraged to bring your whole self to work.</li></ul><p>Be You. Be Bayer.</p><br><p><strong>Applications from employees in Germany who may be affected by personnel reduction will be treated favourably.</strong></p><br><p><strong>YOUR APPLICATION</strong></p><br><p>This is your opportunity to tackle the world's biggest challenges with us: Maintaining our health, feeding growing populations and slowing the rate of climate change. You have a voice, ideas and perspectives and we want to hear them. Because our success begins with you. Be part of something big. Be Bayer.</p><br><p>Bayer welcomes applications from all individuals, regardless of race, national origin, gender, age, physical characteristics, social origin, disability, union membership, religion, family status, pregnancy, sexual orientation, gender identity, gender expression or any unlawful criterion under applicable law. We are committed to treating all applicants fairly and avoiding discrimination.</p><br><p><strong>Location:</strong> Germany : Berlin : Berlin || Germany : North Rhine Westfalia : Wuppertal-Aprath</p><br><p><strong>Division:</strong> Pharmaceuticals</p><br><p><strong>Reference Code:</strong> 824615</p><br>"
  },
  {
    "id": 70,
    "title": "Genomic Data Scientist (alle Geschlechter)",
    "company": "Bayer",
    "locations": "Berlin",
    "skills": "Immunologie, Proteomics, Metabolomics, Bioinformatik, Biologie, Transcriptomics, Genomik, Biomarker, Systembiologie",
    "posted_at": "2024-08-10",
    "is_remote": "False",
    "snippet_fragments": "  Du hast einen Doktortitel in Life Science (Bioinformatik,   Du verf\u00fcgst \u00fcber umfangreiche Postdoc-Erfahrung und/oder mehr mehrj\u00e4hriger Expertise in Drug Discovery oder in der Pharmaindustrie ,   Du besitzt Expertise (hands-on) in der Analyse menschlicher Omics-Daten (Transkriptomik,   Du hast fortgeschrittene IT- und Programmierkenntnisse und bist mit Hochleistungsrechnen vertraut , Du bist hochmotiviert, strebst nach wissenschaftlicher Exzellenz und zeigst Engagement f\u00fcr lebenslanges Lernen,   Du zeichnest dich durch sehr starkes analytisches Denken und wissenschaftliche Strenge aus und bevorzugst systematische Ans\u00e4tze , Du bist in der Lage, komplexe Themen klar und \u00fcberzeugend vor Projektteams oder Entscheidungsgremien zu pr\u00e4sentieren und verf\u00fcgst \u00fcber gute Kommunikationsf\u00e4higkeiten sowie die F\u00e4higkeit, eine hohe Komplexit\u00e4t zu managen,   Du zeigst ausgepr\u00e4gtes F\u00fchrungspotenzial und besitzt sehr gute Soft Skills Du beherrschst Englisch flie\u00dfend in Wort und Schrift , Was dir wichtig ist, ist uns wichtig!,   Deine finanzielle Stabilit\u00e4t sichern wir durch ein wettbewerbsf\u00e4higes Verg\u00fctungspaket, Dar\u00fcber hinaus k\u00f6nnen Vorgesetzte durch Individuelle Einmalzahlungen herausragende Leistungen w\u00fcrdigen,  zu arbeiten wie, wo und wann es f\u00fcr dich am besten ist.,   Deine Weiterentwicklung f\u00f6rdern wir durch Zugang zu Lern- und Entwicklungsma\u00dfnahmen,   Deine Gesundheit und einen selbstf\u00fcrsorglichen Lebensstil unterst\u00fctzen wir durch viele Ma\u00dfnahmen,   Diversit\u00e4t feiern wir in einer inklusiven Arbeitsumgebung, Bewerbungen von Mitarbeiter*innen in Deutschland, die vom Personalabbau betroffen sein k\u00f6nnten, werden bevorzugt behandelt.",
    "description": "<p><strong>Bei Bayer sind wir Vision\u00e4r*innen und entschlossen, die gr\u00f6\u00dften Herausforderungen unseres Planeten zu \u00fcberwinden und zu einer Welt beizutragen, in der genug Nahrung und ausreichende medizinische Versorgung f\u00fcr alle Menschen keine unerreichbaren Ziele mehr darstellen. Wir tun dies mit Energie, Neugier und purer Hingabe, lernen stets von den Menschen um uns herum, erweitern unsere Denkweise, verbessern unsere F\u00e4higkeiten und definieren das \u201eUnm\u00f6gliche&quot; neu. Es gibt viele Gr\u00fcnde, sich uns anzuschlie\u00dfen: Wenn Du nach einer abwechslungsreichen und bedeutungsvollen beruflichen Zukunft strebst, in der Du gemeinsam mit anderen brillanten K\u00f6pfen wirklich etwas bewegen kannst, m\u00f6chten wir Dich in unserem Team haben.</strong></p><br><p><strong>Genomic Data Scientist (alle Geschlechter)</strong></p><br><p><strong>DEINE AUFGABEN UND VERANTWORTLICHKEITEN</strong></p><ul><li>Du initiierst und leitest hochinnovative Forschungsprojekte in den Bereichen Herz-Kreislauf, Nieren und Immunologie, wobei du ma\u00dfgeblich zu Entscheidungsprozessen in verschiedenen Phasen beitr\u00e4gst</li><li>Du identifizierst neue Ziele und Biomarker in den genannten Bereichen mithilfe modernster bioinformatischer Methoden zur Analyse gro\u00dfer und komplexer Datens\u00e4tze, mit besonderem Fokus auf menschliche Proteomik, Transkriptomik und elektronische Gesundheitsakten</li><li>Du entwickelst, bewertest, implementierst und wendest neue bioinformatische Methoden auf komplexe Datens\u00e4tze an</li><li>Du arbeitest mit akademischen oder kommerziellen Partnern zusammen und repr\u00e4sentierst Bayer, w\u00e4hrend du gleichzeitig wissenschaftliches Personal (Postdocs, Doktoranden, Masterstudierende und Praktikant*innen) unterst\u00fctzt<br> Du pflegst Schnittstellen zu anderen Pharma- und F&amp;E-Funktionen, die an der Arzneimittelentwicklung und Datenwissenschaften beteiligt sind</li></ul><p><strong>WAS DU MITBRINGST</strong></p><br><p>Wir freuen uns \u00fcber Dein Talent und Deine Leidenschaft f\u00fcr diese Position. Die richtigen Talente gewinnen zu k\u00f6nnen, ist uns ein wichtiges Anliegen. Gerne identifizieren und gestalten wir gemeinsam mit Dir die Karriere- und Entwicklungs-m\u00f6glichkeiten, die Du suchst. Und wenn Du nicht alle Anforderungen erf\u00fcllst, freuen wir uns trotzdem auf Deine Bewerbung. Wir alle lernen dazu!</p><ul><li>Du hast einen Doktortitel in Life Science (Bioinformatik, computationale Biologie, Systembiologie) mit ausgepr\u00e4gten Computational-Fokus</li><li>Du verf\u00fcgst \u00fcber umfangreiche Postdoc-Erfahrung und/oder mehr mehrj\u00e4hriger Expertise in Drug Discovery oder in der Pharmaindustrie</li><li>Du besitzt Expertise (hands-on) in der Analyse menschlicher Omics-Daten (Transkriptomik, Proteomik, Metabolomik, genetische Daten)</li><li>Du hast fortgeschrittene IT- und Programmierkenntnisse und bist mit Hochleistungsrechnen vertraut</li><li>Du bist hochmotiviert, strebst nach wissenschaftlicher Exzellenz und zeigst Engagement f\u00fcr lebenslanges Lernen</li><li>Du zeichnest dich durch sehr starkes analytisches Denken und wissenschaftliche Strenge aus und bevorzugst systematische Ans\u00e4tze</li><li>Du bist in der Lage, komplexe Themen klar und \u00fcberzeugend vor Projektteams oder Entscheidungsgremien zu pr\u00e4sentieren und verf\u00fcgst \u00fcber gute Kommunikationsf\u00e4higkeiten sowie die F\u00e4higkeit, eine hohe Komplexit\u00e4t zu managen</li><li>Du zeigst ausgepr\u00e4gtes F\u00fchrungspotenzial und besitzt sehr gute Soft Skills<br> Du beherrschst Englisch flie\u00dfend in Wort und Schrift</li></ul><p><strong>WAS WIR BIETEN</strong></p><br><p>Unser Leistungspaket ist flexibel, wertsch\u00e4tzend und auf deine Lebensweise zugeschnitten, denn: <strong>Was dir wichtig ist, ist uns wichtig!</strong></p><ul><li>Deine <strong>finanzielle Stabilit\u00e4t</strong> sichern wir durch ein wettbewerbsf\u00e4higes Verg\u00fctungspaket, bestehend aus einem attraktiven Funktionseinkommen und einem leistungsorientierten Bonus. Dar\u00fcber hinaus k\u00f6nnen Vorgesetzte durch Individuelle Einmalzahlungen herausragende Leistungen w\u00fcrdigen.</li><li>Ob hybride Arbeitsmodelle oder Teilzeit: Wann immer es m\u00f6glich ist, geben wir dir die <strong>Flexibilit\u00e4t</strong> zu arbeiten wie, wo und wann es f\u00fcr dich am besten ist.</li><li>Deine <strong>Familie</strong> hat erste Priorit\u00e4t: Wir bieten liebevolle Konzernkitas an vielen Standorten, Unterst\u00fctzung bei der Suche nach Kinderbetreuung, Freistellung f\u00fcr die Pflege von Familienmitgliedern, Ferienprogramme und vieles mehr.</li><li>Deine <strong>Weiterentwicklung</strong> f\u00f6rdern wir durch Zugang zu Lern- und Entwicklungsma\u00dfnahmen, Schulungen und Trainings der Bayer Learning Academy, Entwicklungsdialoge, sowie durch Coaching und Mentoringprogramme.</li><li>Deine <strong>Gesundheit</strong> und einen selbstf\u00fcrsorglichen Lebensstil unterst\u00fctzen wir durch viele Ma\u00dfnahmen, wie kostenlose HealthChecks beim Werksarzt, Gesundheitsseminare und unsere Gesundheitsplattform #machtfit.</li><li>Diversit\u00e4t feiern wir in einer <strong>inklusiven Arbeitsumgebung</strong>, in der du willkommen gehei\u00dfen, unterst\u00fctzt und ermutigt wirst, deine ganze Pers\u00f6nlichkeit einzubringen.</li></ul><p>Be You. Be Bayer.</p><br><p><strong>Bewerbungen von Mitarbeiter*innen in Deutschland, die vom Personalabbau betroffen sein k\u00f6nnten, werden bevorzugt behandelt.</strong></p><br><p><strong>DEINE BEWERBUNG</strong></p><br><p>Dies ist deine Chance, dich mit uns gemeinsam den gr\u00f6\u00dften globalen Herausforderungen unserer Zeit zu stellen: die Gesundheit der Menschen zu erhalten, die wachsende Weltbev\u00f6lkerung zu ern\u00e4hren und den Klimawandel zu verlangsamen. Du hast eine Stimme, Ideen und Perspektiven, die wir h\u00f6ren m\u00f6chten. Denn unser Erfolg beginnt mit dir. Sei dabei. Sei Bayer.</p><br><p>Bayer begr\u00fc\u00dft Bewerbungen aller Menschen ungeachtet von ethnischer Herkunft, nationaler Herkunft, Geschlecht, Alter, k\u00f6rperlichen Merkmalen, sozialer Herkunft, Behinderung, Mitgliedschaft in einer Gewerkschaft, Religion, Familienstand, Schwangerschaft, sexueller Orientierung, Geschlechtsidentit\u00e4t oder einem anderen sachfremden Kriterium nach geltendem Recht. Wir bekennen uns zu dem Grundsatz, alle Bewerber*innen fair zu behandeln und Benachteiligungen zu vermeiden.</p><br><p><strong>Standort:</strong> Deutschland : Berlin : Berlin || Deutschland : Nordrhein-Westfalen : Wuppertal-Aprath</p><br><p><strong>Division:</strong> Pharmaceuticals</p><br><p><strong>Referenzcode:</strong> 824615</p><br>"
  },
  {
    "id": 71,
    "title": "Senior Data Scientist (Enterprise Solutions Unit)",
    "company": "Semrush",
    "locations": "Berlin",
    "skills": "Python, Data Science, Data Analysis, Data Warehouse, NumPy, Pandas, scikit-learn, SEMRush, APIs",
    "posted_at": "2024-08-02",
    "is_remote": "False",
    "snippet_fragments": " Bachelor's or higher degree in a relevant field such as Data Science,  Proven experience in designing and developing data analysis workflows , Strong programming skills, including proficiency in languages like Python and DS libraries such as pandas, numpy, scikit-learn, transformers, streamlit,  Knowledge of API integration and data collection from various sources ,  Experience in conducting comprehensive testing to ensure the reliability and performance of workflows ,  Strong problem-solving skills and the ability to collaborate effectively with cross-functional teams and external clients , Python, Standard DS libraries(pandas, numpy, scikit-learn, transformers etc,  They say there are no perfect candidates,  Knowledge of SEO best practices and industry trends is a plus ,  You can get to know the team better at one of the interviews,  Torch team is responsible for building ML-based automated workflows within the Semrush Enterprise Platform,  We will try to create all the right conditions for you to work and rest comfortably , You can #wfo, #wfh, or mix both.",
    "description": "<p>Job Description</p><br><p>Hi there!</p><br><p>We are Semrush, a global IT company developing our own product - a platform for digital marketers. New stars are born here, so don't miss your chance.</p><br><p>This is our role as a Data Scientist for those who like to design, develop, test and maintain multiple machine learning-based automated repeatable SEO analysis ('SEO Workflows'), and perform targeted data analysis assignments for external clients along with the SEO Consulting team.</p><br><p>Tasks in the role</p><br><p>Designing SEO Workflow prototype</p><ul><li>Collect workflow requirements from internal and external SEO experts.</li><li>Develop a simplified solution prototype.</li><li>Test the concept with SEO experts.<br> Defining the requirements for the workflows</li><li>Define success criteria for workflow performance.</li><li>Define API contracts to collect the data from Semrush Data Warehouse.</li><li>Develop the workflow output.<br> Developing the workflows</li><li>Develop the scripts to perform stable, repeatable, and scalable data analysis.</li><li>Develop request scripts to support and enable the main workflow script.<br> Developing workflow tests</li><li>Develop various tests and perform them in testing and production environments, including integration unit, regression, performance and other types of testing.<br> Custom analysis assignments for external clients</li><li>In close collaboration with the SEO Consulting team, develop custom SEO workflows for external clients to perform specific analysis to meet client needs.<br> Requirements</li></ul><p>Who we are looking for</p><ul><li>Bachelor's or higher degree in a relevant field such as Data Science, Computer Science, or a related discipline.</li><li>Proven experience in designing and developing data analysis workflows</li><li>Strong programming skills, including proficiency in languages like Python and DS libraries such as pandas, numpy, scikit-learn, transformers, streamlit</li><li>Knowledge of API integration and data collection from various sources</li><li>Experience in conducting comprehensive testing to ensure the reliability and performance of workflows</li><li>Strong problem-solving skills and the ability to collaborate effectively with cross-functional teams and external clients</li><li>Python, Standard DS libraries(pandas, numpy, scikit-learn, transformers etc. ), streamlit<br> They say there are no perfect candidates, but that might well be you, if</li><li>Knowledge of SEO best practices and industry trends is a plus</li><li>You share our common values: Trust, because we prefer to speak up and be our true selves; Sense of Ownership, because it's not worth wasting time on something you don't believe in; and enthusiasm for Constant Changes, because we are always looking to make things better<br> A bit about the team</li></ul><p>You can get to know the team better at one of the interviews, but some brief information about future colleagues will be useful now.</p><br><p>Torch team is responsible for building ML-based automated workflows within the Semrush Enterprise Platform.</p><br><p>We will try to create all the right conditions for you to work and rest comfortably</p><ul><li>Work format Choice: It's up to you to decide what work format works best for you. You can #wfo, #wfh, or mix both.</li><li>Flexible working day start</li><li>Unlimited PTO</li><li>Hobby benefit</li><li>Breakfast, snacks, and coffee at the office</li><li>Corporate events</li><li>Training, courses, conferences</li><li>Gifts for employees<br> Finally, a little more about our company</li></ul><p>We've been developing our product for 15 years and have been awarded G2's Top 100 Software Products, Global and US Search Awards 2021, Great Place to Work Certification, Deloitte Technology Fast 500 and many more. In March 2021 Semrush went public and started trading on the NYSE with the SEMR ticker.</p><br><p>10,000,000+ users in America, Europe, Asia, and Australia have already tried Semrush, and over 1,000 people around the world are working on its development. The Semrush team is constantly growing.</p><br><p>Semrush is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. We do not discriminate based upon race, religion, creed, color, national origin, sex, pregnancy, sexual orientation, gender identity, gender expression, age, ancestry, physical or mental disability, or medical condition including medical characteristics, genetic identity, marital status, military service, or any other classification protected by applicable local, state or federal laws. All employment decisions are based on business needs, job requirements, merit, and individual qualifications.</p><br>"
  },
  {
    "id": 72,
    "title": "Senior Machine Learning Engineer - Data Science (f/m/d)*",
    "company": "Parloa",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Data Science, Data Analysis, AI, Azure, Big Data, DevOps, Docker, Kubernetes, MongoDB, Redis, Terraform, Information Retrieval, Spark, Exploratory Testing, NLP",
    "posted_at": "2024-08-02",
    "is_remote": "False",
    "snippet_fragments": "  7 years of experience as a data scientist or machine learning engineer , Experience working with NLP, LLMs and information retrieval; experience with LLMs in a production environment is a strong plus, Strong proficiency in Python, proficiency with SQL,   Experience working with big data technologies (e, Spark) and using ML Ops platforms (e,   Experience in leading medium-sized technical projects (3-9 months roadmap) ,   Strong spoken and written communication skills in English , Be part of a dynamic, driven team of 20 nationalities with flat hierarchies and collaborative company culture.,   Hybrid work environment - we believe in hiring the best talent, However, we love to build real connections and want to welcome everyone in the office on certain days.,   Training and development budget which can be used for conferences and attending development courses to ensure continuous professional growth, Flexible working hours, 28 vacation days and workation opportunities.,   Enjoy unlimited access to a variety of fitness,   Leverage exclusive offers with our corporate benefits portal, Regular team events, game nights, and other social activities.,   Is something missing here? Reach out and let's talk about what else you need for your ideal next growth opportunity,   Recruiter video call Hiring Manager Interview Technical Stage (Coding Challenge  Machine Learning Case Study) Meeting the team,    Parloa is one of the fastest growing startups in the world of Generative AI and customer service, Parloa's voice-first GenAI platform for contact centers is built on the best AI technology to automate customer service with natural-sounding conversations for outstanding experiences on all communication channels, Leveraging natural language processing (NLP) and machine learning, The Parloa platform resolves the majority of customer queries quickly and automatically, Parloa was founded in 2018 by Malte Kosub and Stefan Ostwald and today employs over 250 people in Berlin",
    "description": "<p><strong>YOUR MISSION</strong></p><br><p>As a Senior Machine Learning Engineer - Data Science (f/m/d)*, you will work on Parloa's machine learning models and related software components that power our generative AI and NLU products. You will become a member of Parloa's AI &amp; Data Science Team that owns machine learning models and frameworks that power our product as well as the ML operations platform. You will work closely with product teams to help them solve customer problems with machine learning and AI. You will leverage cutting edge technologies to keep sharpening Parloa's competitive edge to transform the entire customer service industry with AI.</p><br><p><strong>IN THIS ROLE YOU WILL:</strong></p><ul><li>Take ownership of data science and machine learning projects that help us improve our generative AI product suite</li><li>Work closely with product management, design and product engineers to shape requirements and our product vision leveraging AI and LLMs in line with customer needs</li><li>Execute machine learning projects end-to-end: understanding user-facing requirements, data gathering and transformation, exploratory data analysis, model productionization, maintenance and support, continuous improvement</li><li>Shape our ML platform (ML / LLM Ops) by defining the requirements and/or designing and implementing parts of it in collaboration with our data platform and DevOps teams</li></ul><p><strong>Our</strong> <strong>Tech stack (Data):</strong> Microsoft Azure, Python, Kubernetes, Docker, Terraform, MongoDB, Redis (more technologies will added as we build our data and Machine Learning platforms)</p><br><p><strong>WHAT YOU BRING TO THE TABLE:</strong></p><ul><li>7+ years of experience as a data scientist or machine learning engineer</li><li>Experience working with NLP, LLMs and information retrieval; experience with LLMs in a production environment is a strong plus</li><li>Strong proficiency in Python, proficiency with SQL</li><li>Experience working with big data technologies (e.g. Spark) and using ML Ops platforms (e.g. MLFlow)</li><li>Experience with owning the ML process end-to-end: translating product requirements into technical requirements, data gathering/transformation and exploration, model productionization, maintenance, monitoring and optimization</li><li>Experience in leading medium-sized technical projects (3-9 months roadmap)</li><li>Strong spoken and written communication skills in English</li></ul><p><strong>WHAT'S IN IT FOR YOU?</strong></p><ul><li>Be part of a dynamic, driven team of +20 nationalities with flat hierarchies and collaborative company culture.</li><li>Hybrid work environment - we believe in hiring the best talent, no matter where they are based. However, we love to build real connections and want to welcome everyone in the office on certain days.</li><li>Attractive compensation package.</li><li>Training and development budget which can be used for conferences and attending development courses to ensure continuous professional growth.</li><li>Flexible working hours, 28 vacation days and workation opportunities.</li><li>Enjoy unlimited access to a variety of fitness, yoga, and leisure activities via Wellpass.</li><li>Leverage exclusive offers with our corporate benefits portal, giving you access to compelling deals from leading brands.</li><li>Regular team events, game nights, and other social activities.</li><li>And last but not least: a beautiful office with flair in the heart of Berlin with all the conveniences, such as adjustable desks, social area, fresh fruits, cereals and drinks.</li><li>Is something missing here? Reach out and let's talk about what else you need for your ideal next growth opportunity.</li></ul><p><strong>Your recruiting process at Parloa:</strong></p><br><p>Recruiter video call Hiring Manager Interview Technical Stage (Coding Challenge + Machine Learning Case Study) Meeting the team</p><br><p><strong>WHY PARLOA?</strong></p><br><p>Parloa is one of the fastest growing startups in the world of Generative AI and customer service. Parloa's voice-first GenAI platform for contact centers is built on the best AI technology to automate customer service with natural-sounding conversations for outstanding experiences on all communication channels. Leveraging natural language processing (NLP) and machine learning, Parloa creates intelligent phone and chat solutions for businesses that turn contact centers into value centers by boosting customer service efficiency. The Parloa platform resolves the majority of customer queries quickly and automatically, allowing human agents to focus on complex issues and relationships. Parloa was founded in 2018 by Malte Kosub and Stefan Ostwald and today employs over 250 people in Berlin, Munich, and New York.</p><br><p>When you join Parloa, you become part of a dynamic and innovative team made up of over 34 nationalities that's revolutionizing an entire industry. We're passionate about growing together and creating opportunities for personal and professional development. With our recent $66 million Series B investment, we're expanding globally and looking for talented individuals to join us on this exciting journey.</p><br><p>Do you have questions about Parloa, the role, or our team before you apply? Please feel free to get in touch with our Hiring Team.</p><br><p>Parloa is committed to upholding the highest data protection standards for our clients' and employees' data. All our employees are instrumental in ensuring the utmost care, GDPR, and ISO compliance, including ISO 27001, in handling sensitive information.</p><ul><li><br><strong>We provide equal opportunities to all qualified applicants regardless race, gender, sexual orientation, age, religion, national origin, disability status, socioeconomic background and other characteristics.</strong><br></li></ul><br>"
  },
  {
    "id": 73,
    "title": "Data Scientist, Germany - BCG X",
    "company": "Boston Consulting Group",
    "locations": "Berlin",
    "skills": "Python, Machine Learning, Data Science, AI, DevOps, Algorithms, Software Development Lifecycle, Statistik",
    "posted_at": "2024-08-01",
    "is_remote": "False",
    "snippet_fragments": "We work in a uniquely collaborative model across the firm and throughout all levels of the client organization,  Were a diverse team of more than 3,000 tech experts united by a drive to make a difference, Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today, We go beyond what was once thought possible, Leveraging BCGs global network and partnerships with leading organizations, Together, we strive to create solutions that will positively impact the lives of millions,  framing new business challenges, designing innovative algorithms, implementing, and deploying scalable solutions, and enabling colleagues and clients to fully embrace AI, Our product offerings span from fully custom-builds to industry specific leading edge AI software solutions,  Our Data Scientists and Senior Data Scientist are part of our rapidly growing team to apply data science methods and analytics to real-world business situations across industries to drive significant business impact, You'll have the chance to partner with clients in a variety of BCG regions and industries,  Additional responsibilities will include developing and delivering thought leadership in scientific communities and papers as well as leading conferences on behalf of BCG X, Successful candidates are intellectually curious builders who are biased toward action,  We are looking for dedicated individuals with a passion for data science,  Comfortable in a client-facing role with the ambition to lead teams ,  Likes to distill complex results or processes into simple,  Explain sophisticated data science concepts in an understandable manner ,  Love building things and are comfortable working with modern development tools and writing code collaboratively (bonus points if you have a software development or DevOps experience) ,  Significant experience applying advanced analytics to a variety of business situations and a proven ability to synthesize complex data ,  Deep understanding of modern machine learning techniques and their mathematical underpinnings",
    "description": "<p><strong>Locations:</strong> M\u00fcnchen | Berlin | Frankfurt</p><br><p>Who We Are</p><br><p>Boston Consulting Group partners with leaders in business and society to tackle their most important challenges and capture their greatest opportunities. BCG was the pioneer in business strategy when it was founded in 1963. Today, we help clients with total transformation-inspiring complex change, enabling organizations to grow, building competitive advantage, and driving bottom-line impact.</p><br><p>To succeed, organizations must blend digital and human capabilities. Our diverse, global teams bring deep industry and functional expertise and a range of perspectives to spark change. BCG delivers solutions through leading-edge management consulting along with technology and design, corporate and digital ventures-and business purpose. We work in a uniquely collaborative model across the firm and throughout all levels of the client organization, generating results that allow our clients to thrive.</p><br><p>We Are BCG X</p><br><p>We're a diverse team of more than 3,000 tech experts united by a drive to make a difference. Working across industries and disciplines, we combine our experience and expertise to tackle the biggest challenges faced by society today. We go beyond what was once thought possible, creating new and innovative solutions to the world's most complex problems. Leveraging BCG's global network and partnerships with leading organizations, BCG X provides a stable ecosystem for talent to build game-changing businesses, products, and services from the ground up, all while growing their career. Together, we strive to create solutions that will positively impact the lives of millions.</p><br><p>What You'll Do</p><br><p><strong>Our BCG X teams own the full analytics value-chain end to end:</strong> framing new business challenges, designing innovative algorithms, implementing, and deploying scalable solutions, and enabling colleagues and clients to fully embrace AI. Our product offerings span from fully custom-builds to industry specific leading edge AI software solutions.</p><br><p>Our Data Scientists and Senior Data Scientist are part of our rapidly growing team to apply data science methods and analytics to real-world business situations across industries to drive significant business impact. You'll have the chance to partner with clients in a variety of BCG regions and industries, and on key topics like climate change, enabling them to design, build, and deploy new and innovative solutions.</p><br><p>Additional responsibilities will include developing and delivering thought leadership in scientific communities and papers as well as leading conferences on behalf of BCG X. Successful candidates are intellectually curious builders who are biased toward action, creative, and communicative.</p><br><p>We are looking for dedicated individuals with a passion for data science, statistics, operations research and redefining organizations into AI led innovative companies. Successful candidates possess the following:</p><ul><li>Comfortable in a client-facing role with the ambition to lead teams</li><li>Likes to distill complex results or processes into simple, clear visualizations</li><li>Explain sophisticated data science concepts in an understandable manner</li><li>Love building things and are comfortable working with modern development tools and writing code collaboratively (bonus points if you have a software development or DevOps experience)</li><li>Significant experience applying advanced analytics to a variety of business situations and a proven ability to synthesize complex data</li><li>Deep understanding of modern machine learning techniques and their mathematical underpinnings, and can translate this into business implications for our clients</li><li>Have strong project management skills<br> What You'll Bring</li></ul><p><strong>TECHNOLOGIES:</strong></p><br><p><strong>Programming Languages:</strong> Python</p><br><p>Boston Consulting Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, age, religion, sex, sexual orientation, gender identity / expression, national origin, disability, protected veteran status, or any other characteristic protected under national, provincial, or local law, where applicable, and those with criminal histories will be considered in a manner consistent with applicable state and local laws.</p><br><p>BCG is an E - Verify Employer. Click here for more information on E-Verify.</p><br>"
  },
  {
    "id": 74,
    "title": "(Associate) Data Scientist - Logistics, Rider (all genders)",
    "company": "Delivery Hero",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Data Science, AWS, Cloud, GCP, Airflow, A/B testing, Redshift, BigQuery, Docker, Kubernetes, Matplotlib, NumPy, Pandas, scikit-learn, Git, Prototyping",
    "posted_at": "2024-07-31",
    "is_remote": "False",
    "snippet_fragments": "   Build solutions end-to-end from inception to production-grade systems - including research & prototyping,    Work on projects centered around experimental design and A/B testing,    Provide ideas in brainstorming sessions with your Data Science colleagues to solve the toughest modeling problems together, Pitching new ideas and improvement proposals to non-technical stakeholders,    Help defining data needs to further improve existing projects,  You write clean, maintainable code following best-practices, and know how to make your code run in a container for reusability and cloud deployment.,  You are fluent in SQL, and know how to work with large-scale datasets on platforms like Google BigQuery or Amazon Redshift.,    You have experience with a range of software engineering tools including Git,    You have prior experience applying machine learning or statistical methods to real-world datasets,    You have an eye for detail, Before starting to work on a use-case,  You are a strong communicator, and can explain the intuition behind your modeling approach to people with both technical and non-technical backgrounds.,    Prior exposure to location data (GPS pings,    First-hand experience with large-scale problems in the logistics or e-commerce industries",
    "description": "<p><strong>Company Description</strong></p><br><p>As the world's pioneering local delivery platform, our mission is to deliver an amazing experience, fast, easy, and to your door. We operate in over 70+ countries worldwide, powered by tech, designed by people. As one of Europe's largest tech platforms, we enable creative minds to deliver solutions that create impact within our ecosystem. We move fast, take action and adapt. No matter where you're from or what you believe in, we build, we deliver, we lead. We are Delivery Hero<br><strong>Job Description</strong><br> We are looking for an <strong>(Associate) Data Scientist - Logistics, Rider (all genders)</strong> to join our team to help us create a fast, reliable and transparent delivery experience.</p><br><p>You will join the new Data Science squad in the Deliveries tribe, a team set up to support all aspects of the rider journey during their day-to-day tasks with a focus on the last 100 meters of delivery. Together with your team you will work on projects ranging from providing accurate route information, and location pings, improving the ease of identifying partner and customer locations, and developing fraud detection models. We pride ourselves on our ability to connect research and theory to practical problems, and to bring our solutions to production systems. The squad is supported by an amazing squad of ML engineers who build reusable tooling to allow our data scientists to focus on solving modeling challenges. We also integrate closely with product teams so that we keep connected to the needs of the organization.</p><br><p>If you are a creative problem solver who is hungry for a new adventure, a diverse, international and inclusive workplace is waiting for you in the heart of Berlin!</p><ul><li>Conceptualize the right modeling approach for challenges in the field of Logistics at scale together with your squad lead and our stakeholders, using cutting-edge research to inform your decisions.</li><li>Build solutions end-to-end from inception to production-grade systems - including research &amp; prototyping, gathering data requirements, cross-team alignment, product development, experimentation, deployment and monitoring.</li><li>Work on projects centered around experimental design and A/B testing, fraud modeling, and location denoising, and make an impact in a global, fast-moving tech organization delivering more than 5 million orders each day.</li><li>Provide ideas in brainstorming sessions with your Data Science colleagues to solve the toughest modeling problems together. Pitching new ideas and improvement proposals to non-technical stakeholders.</li><li>Help defining data needs to further improve existing projects, to support data engineering and tech teams in planning their roadmap.<br><strong>Qualifications</strong></li><li>You speak fluent Python, and are familiar with its scientific computing stack such as NumPy, Pandas, Scikit-learn, Matplotlib, etc. Other languages are a bonus!</li><li>You write clean, maintainable code following best-practices, and know how to make your code run in a container for reusability and cloud deployment.</li><li>You are fluent in SQL, and know how to work with large-scale datasets on platforms like Google BigQuery or Amazon Redshift.</li><li>You have experience with a range of software engineering tools including Git, Docker, cloud technologies like GCP or AWS, Kubernetes and Airflow.</li><li>You have prior experience applying machine learning or statistical methods to real-world datasets, and a proven track record of delivering data science solutions to production systems.</li><li>You have a strong sense of responsibility and desire to run software for millions of users: we build it, we run it.</li><li>You have an eye for detail. Before starting to work on a use-case, you carefully challenge existing assumptions and care about clean data.</li><li>You are a strong communicator, and can explain the intuition behind your modeling approach to people with both technical and non-technical backgrounds.<br><strong>Additional Information</strong><br><strong>Nice-To-Haves</strong></li><li>Prior exposure to location data (GPS pings, maps, geographical shapes, etc.), and geospatial modeling.</li><li>First-hand experience with large-scale problems in the logistics or e-commerce industries.</li><li>Hands-on experience planning, carrying out, and analyzing results of A/B tests.</li><li>Experience deploying complex models to serve live traffic.</li></ul><p>At Delivery Hero, we believe diversity and inclusion are key to creating not only an exciting product, but also an amazing customer and employee experience. Fostering this starts with hiring - therefore we do not discriminate on the basis of racial identities, religious beliefs, color, national origin, gender identities or expressions, sexual orientations, age, marital or disability statuses, or any other aspect that makes you, you. Just be yourself and we can't wait to see what value you bring to the role. We're as interested in your character as we are in your talent.</p><br>"
  },
  {
    "id": 75,
    "title": "Data Engineer - Advanced Analytics / ETL / SQL (m/w/d)",
    "company": "Workwise GmbH",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Mathematik, Data Science, AWS, Data Pipelines, Azure, Business Intelligence, ETL, Big Data, CISA, Dashboards, SQL Server, MySQL, Predictive Analytics, Data mining, Snowflake, R, Amazon RDS, Statistik",
    "posted_at": "2024-07-31",
    "is_remote": "False",
    "snippet_fragments": "Unternehmen mit flachen Hierarchien, kurzen Entscheidungswegen und einer offenen Kommunikationspolitik,   Gute Anbindung an die \u00d6PNV sowie Innenstadtlage ,   Gute Anbindung an die \u00d6PNV sowie Innenstadtlage und Fahrtkostenzuschuss ,   Firmenhandy (iPhone) mit der M\u00f6glichkeit privater Nutzung ,  Was erwartet Dich als Senior Data Engineer?,   Du implementierst relationale Datenbanken und extrahierst relevante Informationen aus diesen , Du analysierst Gesch\u00e4ftsprozesse, identifizierst Optimierungspotentiale und entwickelst entsprechende Ma\u00dfnahmen, Du entwirfst, implementierst und pflegst Data Pipelines und systeme, insbesondere f\u00fcr ETL-Prozesse,   Du evaluierst verschiedene Methoden und Tools f\u00fcr Data Science und Data-Mining ,   Du unterst\u00fctzt bei der Konzeption und Aufbau von BI und Big Data Plattformen sowie der Auswahl von Speichertechnologien ,   Du unterst\u00fctzt bei der Erstellung von Reports und Dashboards ,   Du \u00fcbernimmst Projektmanagementt\u00e4tigkeiten und erstellst Statusberichte ,  Wir bieten Dir einen vielf\u00e4ltigen Aufgabenbereich und ein unternehmerisch orientiertes Arbeitsumfeld mit Freiraum f\u00fcr die Umsetzung deiner L\u00f6sungsans\u00e4tze sowie \u00fcberdurchschnittliche Perspektiven f\u00fcr deinen weiteren beruflichen Aufstieg,   Du hast mindestens 4-5 Jahre Berufserfahrung im Bereich Data Engineering ,   Du verf\u00fcgst \u00fcber ein abgeschlossenes Studium der Wirtschafts- (Informatik),   Du besitzt sehr gute Kenntnisse in der Programmierung f\u00fcr Advanced Analytics (SQL,   Du besitzt Kenntnisse zur Entwicklung und Verwaltung von Datenbanken,   Du hast Erfahrung mit Erstellung und Optimierung von ETL-Prozessen unter Ber\u00fccksichtigung der Datenplausibilit\u00e4t und Leistung ,   Du kannst effiziente Data Pipelines und -systeme entwerfen",
    "description": "<p><strong>\u00dcber BRL Risk Consulting GmbH &amp; Co. KG:</strong></p><br><p>Globale Expertise, lokale Pr\u00e4senz: Ihre verl\u00e4sslichen Partner f\u00fcr Rechts-, Wirtschafts- und Steuerfragen seit 2006.</p><br><p>Wir sind eine international ausgerichtete Partnerschaft von Rechtsanw\u00e4lten, Wirtschaftspr\u00fcfern und Steuerberatern, die im Jahr 2006 gegr\u00fcndet wurde. Heute sind wir mit rund 380 Mitarbeitern an den Standorten Hamburg, Berlin, Bochum, Hannover, Dortmund, M\u00fcnchen und Bielefeld vertreten.</p><br><p>Durch eine eigene Gesellschaft sowie \u00fcber Moore Global, ein globales Netzwerk unabh\u00e4ngiger WP/StB-Gesellschaften, sind wir bestens aufgestellt, um auch f\u00fcr l\u00e4nder\u00fcbergreifende Fragestellungen zuverl\u00e4ssige und effiziente L\u00f6sungen bereitzustellen. Heute sind in diesem Netzwerk weltweit rund 230 f\u00fchrende Wirtschaftspr\u00fcfungs- und Steuerberatungsgesellschaften zusammengeschlossen, mit Standorten in 522 St\u00e4dten und 112 L\u00e4ndern und mit mehr als 34.000 Mitarbeitern.</p><br><p>Wir sind ein interdisziplin\u00e4res Team, das sich leidenschaftlich daf\u00fcr einsetzt, unsere weltweit t\u00e4tigen Kunden bei der Identifikation, Steuerung und Vermeidung potenzieller Risiken in allen Gesch\u00e4ftsbereichen zu unterst\u00fctzen. Dabei betrachten wir finanzielle, technologische und gesch\u00e4ftsrelevante Risiken, um den Unternehmenserfolg langfristig zu sichern. Mit unseren breiten Pr\u00fcfungs- und Beratungsdienstleistungen bieten wir umfassende L\u00f6sungen f\u00fcr unsere Kunden an.</p><br><p>Unser Risk Advisory Services (RAS)-Team bietet umfassende Leistungen im Bereich Governance, Risk und Compliance an. Dabei wird ein einheitlicher und integrierter Ansatz verfolgt, um bestm\u00f6gliche Synergieeffekte zwischen den Bereichen Risikomanagement, interne Kontrollsystemen (IKS) und Interne Revision sowie Compliance Management und Corporate Governance zu erzielen.</p><br><p><strong>WAS BIETEN WIR DIR?</strong></p><ul><li>Unternehmen mit flachen Hierarchien, kurzen Entscheidungswegen und einer offenen Kommunikationspolitik</li><li>Ausgepr\u00e4gte Feedbackkultur</li><li>Gute Anbindung an die \u00d6PNV sowie Innenstadtlage</li><li>Regelm\u00e4\u00dfige Teamevents</li><li>Attraktive Corporate Benefits</li><li>Attraktive Weiterbildungsangebote sowie Unterst\u00fctzung beim Erwerb von beruflichen Zertifizierungen (z.B. CISA, CIA, CISA etc.)</li><li>Ein leistungsorientiertes Bonussystem</li><li>Gute Anbindung an die \u00d6PNV sowie Innenstadtlage und Fahrtkostenzuschuss</li><li>Betriebliche Altersvorsorge sowie Gesundheitsf\u00f6rderung</li><li>Firmenhandy (iPhone) mit der M\u00f6glichkeit privater Nutzung</li></ul><p><strong>WAS ERWARTET DICH ALS SENIOR DATA ENGINEER?</strong></p><ul><li>Du implementierst relationale Datenbanken und extrahierst relevante Informationen aus diesen</li><li>Du analysierst Gesch\u00e4ftsprozesse, identifizierst Optimierungspotentiale und entwickelst entsprechende Ma\u00dfnahmen</li><li>Du entwirfst, implementierst und pflegst Data Pipelines und -systeme, insbesondere f\u00fcr ETL-Prozesse</li><li>Du evaluierst verschiedene Methoden und Tools f\u00fcr Data Science und Data-Mining</li><li>Du unterst\u00fctzt bei der Konzeption und Aufbau von BI und Big Data Plattformen sowie der Auswahl von Speichertechnologien</li><li>Du unterst\u00fctzt bei der Erstellung von Reports und Dashboards</li><li>Du \u00fcbernimmst Projektmanagementt\u00e4tigkeiten und erstellst Statusberichte<br> Wir bieten Dir einen vielf\u00e4ltigen Aufgabenbereich und ein unternehmerisch orientiertes Arbeitsumfeld mit Freiraum f\u00fcr die Umsetzung deiner L\u00f6sungsans\u00e4tze sowie \u00fcberdurchschnittliche Perspektiven f\u00fcr deinen weiteren beruflichen Aufstieg.<br><strong>WAS SOLLTEST DU MITBRINGEN?</strong></li><li>Du hast mindestens 4-5 Jahre Berufserfahrung im Bereich Data Engineering</li><li>Du verf\u00fcgst \u00fcber ein abgeschlossenes Studium der Wirtschafts- (Informatik), Mathematik, Statistik oder in Data Science</li><li>Du besitzt sehr gute Kenntnisse in der Programmierung f\u00fcr Advanced Analytics (SQL, Python oder R f\u00fcr Data Mining, Predictive Analytics, Computational Statistics)</li><li>Du besitzt Kenntnisse zur Entwicklung und Verwaltung von Datenbanken, insbesondere mit einem Schwerpunkt auf relationalen Datenbanken wie MySQL oder SQL-Server</li><li>Du hast Erfahrung mit Erstellung und Optimierung von ETL-Prozessen unter Ber\u00fccksichtigung der Datenplausibilit\u00e4t und Leistung</li><li>Du kannst effiziente Data Pipelines und -systeme entwerfen, implementieren und warten, um eine hohe Skalierbarkeit, Zuverl\u00e4ssigkeit und Leistung sicherzustellen</li><li>Du hast bereits Erfahrungen mit der Implementierung von Cloud-basierten Datenbankservices gesammelt (z. B. AWS RDS, Google Cloud SQL, Azure SQL-Datenbank)</li><li>Erfahrungen mit Data-Warehouse-Technologien wie Snowflake sind von Vorteil</li><li>Ausgezeichnete Kommunikations- und Pr\u00e4sentationsf\u00e4higkeiten in Deutsch und Englisch, sowie F\u00e4higkeit, komplexe technische Konzepte verst\u00e4ndlich an nicht-technische Stakeholder zu vermitteln</li><li>Du konntest bereits Erfahrungen im Bereich Machine Learning und Big Data Technologien sammeln</li></ul><p>Unser Jobangebot Data Engineer - Advanced Analytics / ETL / SQL (m/w/d) klingt vielversprechend?</p><br><p>Bei unserem Partner <strong>Workwise</strong> ist eine Bewerbung f\u00fcr diesen Job <strong>in nur wenigen Minuten</strong> und <strong>ohne Anschreiben</strong> m\u00f6glich. Anschlie\u00dfend kann der Status der Bewerbung live verfolgt werden. Wir freuen wir uns auf eine <strong>Bewerbung \u00fcber Workwise</strong>.</p><br><p>Mehr Informationen zu uns und unseren Jobangeboten findet man auf unserem Unternehmensprofil bei Workwise.</p><br>"
  },
  {
    "id": 76,
    "title": "Data Engineer - Advanced Analytics / ETL / SQL (m/w/d)",
    "company": "BRL Risk Consulting GmbH & Co. KG",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Mathematik, Data Science, AWS, Data Pipelines, Azure, Business Intelligence, ETL, Big Data, CISA, Dashboards, SQL Server, MySQL, Predictive Analytics, Data mining, Snowflake, R, Amazon RDS, Statistik",
    "posted_at": "2024-07-31",
    "is_remote": "False",
    "snippet_fragments": "Unternehmen mit flachen Hierarchien, kurzen Entscheidungswegen und einer offenen Kommunikationspolitik,   Gute Anbindung an die \u00d6PNV sowie Innenstadtlage ,   Gute Anbindung an die \u00d6PNV sowie Innenstadtlage und Fahrtkostenzuschuss ,   Firmenhandy (iPhone) mit der M\u00f6glichkeit privater Nutzung ,  Was erwartet Dich als Senior Data Engineer?,   Du implementierst relationale Datenbanken und extrahierst relevante Informationen aus diesen , Du analysierst Gesch\u00e4ftsprozesse, identifizierst Optimierungspotentiale und entwickelst entsprechende Ma\u00dfnahmen, Du entwirfst, implementierst und pflegst Data Pipelines und systeme, insbesondere f\u00fcr ETL-Prozesse,   Du evaluierst verschiedene Methoden und Tools f\u00fcr Data Science und Data-Mining ,   Du unterst\u00fctzt bei der Konzeption und Aufbau von BI und Big Data Plattformen sowie der Auswahl von Speichertechnologien ,   Du unterst\u00fctzt bei der Erstellung von Reports und Dashboards ,   Du \u00fcbernimmst Projektmanagementt\u00e4tigkeiten und erstellst Statusberichte ,  Wir bieten Dir einen vielf\u00e4ltigen Aufgabenbereich und ein unternehmerisch orientiertes Arbeitsumfeld mit Freiraum f\u00fcr die Umsetzung deiner L\u00f6sungsans\u00e4tze sowie \u00fcberdurchschnittliche Perspektiven f\u00fcr deinen weiteren beruflichen Aufstieg,   Du hast mindestens 4-5 Jahre Berufserfahrung im Bereich Data Engineering ,   Du verf\u00fcgst \u00fcber ein abgeschlossenes Studium der Wirtschafts- (Informatik),   Du besitzt sehr gute Kenntnisse in der Programmierung f\u00fcr Advanced Analytics (SQL,   Du besitzt Kenntnisse zur Entwicklung und Verwaltung von Datenbanken,   Du hast Erfahrung mit Erstellung und Optimierung von ETL-Prozessen unter Ber\u00fccksichtigung der Datenplausibilit\u00e4t und Leistung ,   Du kannst effiziente Data Pipelines und -systeme entwerfen",
    "description": "<p><strong>\u00dcber BRL Risk Consulting GmbH &amp; Co. KG:</strong></p><br><p>Globale Expertise, lokale Pr\u00e4senz: Ihre verl\u00e4sslichen Partner f\u00fcr Rechts-, Wirtschafts- und Steuerfragen seit 2006.</p><br><p>Wir sind eine international ausgerichtete Partnerschaft von Rechtsanw\u00e4lten, Wirtschaftspr\u00fcfern und Steuerberatern, die im Jahr 2006 gegr\u00fcndet wurde. Heute sind wir mit rund 380 Mitarbeitern an den Standorten Hamburg, Berlin, Bochum, Hannover, Dortmund, M\u00fcnchen und Bielefeld vertreten.</p><br><p>Durch eine eigene Gesellschaft sowie \u00fcber Moore Global, ein globales Netzwerk unabh\u00e4ngiger WP/StB-Gesellschaften, sind wir bestens aufgestellt, um auch f\u00fcr l\u00e4nder\u00fcbergreifende Fragestellungen zuverl\u00e4ssige und effiziente L\u00f6sungen bereitzustellen. Heute sind in diesem Netzwerk weltweit rund 230 f\u00fchrende Wirtschaftspr\u00fcfungs- und Steuerberatungsgesellschaften zusammengeschlossen, mit Standorten in 522 St\u00e4dten und 112 L\u00e4ndern und mit mehr als 34.000 Mitarbeitern.</p><br><p>Wir sind ein interdisziplin\u00e4res Team, das sich leidenschaftlich daf\u00fcr einsetzt, unsere weltweit t\u00e4tigen Kunden bei der Identifikation, Steuerung und Vermeidung potenzieller Risiken in allen Gesch\u00e4ftsbereichen zu unterst\u00fctzen. Dabei betrachten wir finanzielle, technologische und gesch\u00e4ftsrelevante Risiken, um den Unternehmenserfolg langfristig zu sichern. Mit unseren breiten Pr\u00fcfungs- und Beratungsdienstleistungen bieten wir umfassende L\u00f6sungen f\u00fcr unsere Kunden an.</p><br><p>Unser Risk Advisory Services (RAS)-Team bietet umfassende Leistungen im Bereich Governance, Risk und Compliance an. Dabei wird ein einheitlicher und integrierter Ansatz verfolgt, um bestm\u00f6gliche Synergieeffekte zwischen den Bereichen Risikomanagement, interne Kontrollsystemen (IKS) und Interne Revision sowie Compliance Management und Corporate Governance zu erzielen.</p><br><p><strong>WAS BIETEN WIR DIR?</strong></p><ul><li>Unternehmen mit flachen Hierarchien, kurzen Entscheidungswegen und einer offenen Kommunikationspolitik</li><li>Ausgepr\u00e4gte Feedbackkultur</li><li>Gute Anbindung an die \u00d6PNV sowie Innenstadtlage</li><li>Regelm\u00e4\u00dfige Teamevents</li><li>Attraktive Corporate Benefits</li><li>Attraktive Weiterbildungsangebote sowie Unterst\u00fctzung beim Erwerb von beruflichen Zertifizierungen (z.B. CISA, CIA, CISA etc.)</li><li>Ein leistungsorientiertes Bonussystem</li><li>Gute Anbindung an die \u00d6PNV sowie Innenstadtlage und Fahrtkostenzuschuss</li><li>Betriebliche Altersvorsorge sowie Gesundheitsf\u00f6rderung</li><li>Firmenhandy (iPhone) mit der M\u00f6glichkeit privater Nutzung</li></ul><p><strong>WAS ERWARTET DICH ALS SENIOR DATA ENGINEER?</strong></p><ul><li>Du implementierst relationale Datenbanken und extrahierst relevante Informationen aus diesen</li><li>Du analysierst Gesch\u00e4ftsprozesse, identifizierst Optimierungspotentiale und entwickelst entsprechende Ma\u00dfnahmen</li><li>Du entwirfst, implementierst und pflegst Data Pipelines und -systeme, insbesondere f\u00fcr ETL-Prozesse</li><li>Du evaluierst verschiedene Methoden und Tools f\u00fcr Data Science und Data-Mining</li><li>Du unterst\u00fctzt bei der Konzeption und Aufbau von BI und Big Data Plattformen sowie der Auswahl von Speichertechnologien</li><li>Du unterst\u00fctzt bei der Erstellung von Reports und Dashboards</li><li>Du \u00fcbernimmst Projektmanagementt\u00e4tigkeiten und erstellst Statusberichte<br> Wir bieten Dir einen vielf\u00e4ltigen Aufgabenbereich und ein unternehmerisch orientiertes Arbeitsumfeld mit Freiraum f\u00fcr die Umsetzung deiner L\u00f6sungsans\u00e4tze sowie \u00fcberdurchschnittliche Perspektiven f\u00fcr deinen weiteren beruflichen Aufstieg.<br><strong>WAS SOLLTEST DU MITBRINGEN?</strong></li><li>Du hast mindestens 4-5 Jahre Berufserfahrung im Bereich Data Engineering</li><li>Du verf\u00fcgst \u00fcber ein abgeschlossenes Studium der Wirtschafts- (Informatik), Mathematik, Statistik oder in Data Science</li><li>Du besitzt sehr gute Kenntnisse in der Programmierung f\u00fcr Advanced Analytics (SQL, Python oder R f\u00fcr Data Mining, Predictive Analytics, Computational Statistics)</li><li>Du besitzt Kenntnisse zur Entwicklung und Verwaltung von Datenbanken, insbesondere mit einem Schwerpunkt auf relationalen Datenbanken wie MySQL oder SQL-Server</li><li>Du hast Erfahrung mit Erstellung und Optimierung von ETL-Prozessen unter Ber\u00fccksichtigung der Datenplausibilit\u00e4t und Leistung</li><li>Du kannst effiziente Data Pipelines und -systeme entwerfen, implementieren und warten, um eine hohe Skalierbarkeit, Zuverl\u00e4ssigkeit und Leistung sicherzustellen</li><li>Du hast bereits Erfahrungen mit der Implementierung von Cloud-basierten Datenbankservices gesammelt (z. B. AWS RDS, Google Cloud SQL, Azure SQL-Datenbank)</li><li>Erfahrungen mit Data-Warehouse-Technologien wie Snowflake sind von Vorteil</li><li>Ausgezeichnete Kommunikations- und Pr\u00e4sentationsf\u00e4higkeiten in Deutsch und Englisch, sowie F\u00e4higkeit, komplexe technische Konzepte verst\u00e4ndlich an nicht-technische Stakeholder zu vermitteln</li><li>Du konntest bereits Erfahrungen im Bereich Machine Learning und Big Data Technologien sammeln</li></ul><p>Unser Jobangebot Data Engineer - Advanced Analytics / ETL / SQL (m/w/d) klingt vielversprechend?</p><br><p>Bei unserem Partner <strong>Workwise</strong> ist eine Bewerbung f\u00fcr diesen Job <strong>in nur wenigen Minuten</strong> und <strong>ohne Anschreiben</strong> m\u00f6glich. Anschlie\u00dfend kann der Status der Bewerbung live verfolgt werden. Wir freuen wir uns auf eine <strong>Bewerbung \u00fcber Workwise</strong>.</p><br><p>Mehr Informationen zu uns und unseren Jobangeboten findet man auf unserem Unternehmensprofil bei Workwise.</p><br>"
  },
  {
    "id": 77,
    "title": "Data Engineer (d/m/w) - befristet (Elternzeitvertretung)",
    "company": "Toll Collect GmbH",
    "locations": "Berlin",
    "skills": "SQL, Mathematik, Linux, Cognos, PL/SQL, Windows",
    "posted_at": "2024-07-30",
    "is_remote": "False",
    "snippet_fragments": "    Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics,      Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL),      Sie beherrschen den Umgang mit Windows und Linux einwandfrei,      Sie haben ein abgeschlossenes Studium in der Mathematik,      Sie haben Berufserfahrung im Bereich Data Engineering,     Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung,      Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung,  Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet,      Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen oder Business-Bike bis zur betrieblichen Altersversorgung,     Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung, Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu, Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen",
    "description": "<p>Referenznummer: 20728</p><br><p>Ihre Aufgaben</p><ul><li>Sie verantworten die Strukturierung und Weiterentwicklung von Datenmodellen und Datenfl\u00fcssen sowie der zugeh\u00f6rigen IT-gest\u00fctzten Prozesse</li><li>Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit</li><li>Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten</li><li>Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen</li><li>Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit, bringen eigene Ideen ein und setzen diese um</li><li>Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen</li></ul><p>Ihre Kompetenzen</p><ul><li>Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics</li><li>Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL).</li><li>Sie beherrschen den Umgang mit Windows und Linux einwandfrei</li><li>Sie haben ein abgeschlossenes Studium in der Mathematik, Informatik oder in einem vergleichbaren Studiengang</li><li>Sie haben Berufserfahrung im Bereich Data Engineering</li></ul><p>Was bieten wir</p><ul><li>Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung</li><li>Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung</li><li>Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet</li><li>Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen oder Business-Bike bis zur betrieblichen Altersversorgung</li></ul><p>Interessiert?</p><br><p>Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung. Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu. Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen.</p><br><p>Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt.</p><br><p>Ihre Ansprechperson</p><br><p>Frau Silvia Barknecht, 030/74077-8214, karriere@toll-collect.de</p><br><p>Toll Collect GmbH * Personalmanagement * Linkstra\u00dfe 4, 10785 Berlin</p><br>"
  },
  {
    "id": 78,
    "title": "Senior Data Engineer",
    "company": "Latana",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Cloud, Data Pipelines, ETL, Big Data, DynamoDB, Legacy Code, MySQL, PostgreSQL, Ruby, Database Design, Codebase, Orchestration, Serverless, Containerisation, AWS Athena, Code Refactoring",
    "posted_at": "2024-07-27",
    "is_remote": "False",
    "snippet_fragments": "  Professional experience with data pipelines and ETL procedures ,   Iterative development  you continuously integrate your changes into the codebase even though you have a long term vision in mind ,   Ability to switch between programming languages and environments if required  our main languages are Python and Ruby , Experience of containerisation, infrastructure orchestration and serverless application management tools like SAM and CDK would also be beneficial, You have a pragmatic, polyglot approach  you use the best tool for the job,   You understand that proactive communication is a large part of software engineering ,   Youre just as happy when modifying or refactoring legacy code as when working on something brand new ,   You maintain a solid understanding of how your work relates to the goals of the company ,   You are enthusiastic about solving problems and motivated to help the people around you succeed ,   You are productive when working with legacy code and you are always looking for refactoring opportunities ,   You always keep the big picture in mind when focusing on part of the system ,   You have an automate-everything approach  streamlining processes and eliminating manual work excites you! , A challenging, yet encouraging work environment,   The opportunity to contribute to the success of a fast-growing,   A yearly education budget to contribute to your lifelong learning ,   A yearly stipend for use on either public transport or personal fitness via Urban Sports Club ,   In-house coaching to help you grow personally and professionally ,   A MacBook Pro and all the peripherals you need to succeed ",
    "description": "<p><strong>About us</strong></p><br><p>We are Latana, a leading brand insights company focused on capturing the $18 Billion+ brand tracking market. Put simply, Latana gives brands the tools to make better marketing and campaign decisions by giving them world-class insights about their brand performance. In its short existence, Latana has already started working with some of the hottest B2C brands, including Headspace, Revolut, Unilever, and more - and we're just getting started!</p><br><p><strong>The journey that awaits you</strong></p><br><p>You will work closely with our Data Engineering &amp; Software Engineering teams to make the transfer of data within our system fast, efficient and error-free, and to optimize the performance of our machine learning infrastructure.</p><br><p>As well as working to improve existing system features, you will design database schemas and ETL procedures that will scale Latana to meet demand in the years to come. Your role will be instrumental to the continued rapid growth of the business.</p><br><p><strong>Your skills and expertise</strong></p><ul><li>Professional experience in a data engineering role</li><li>Demonstrable track record of handling large data sets</li><li>Strong SQL knowledge, particularly for working optimally with big data</li><li>Experience with classic relational databases (PostgreSQL, MySQL) and modern cloud data products like Amazon Athena and DynamoDB</li><li>Professional experience with data pipelines and ETL procedures</li><li>Iterative development - you continuously integrate your changes into the codebase even though you have a long term vision in mind</li><li>Ability to switch between programming languages and environments if required - our main languages are Python and Ruby</li><li>Experience of containerisation, infrastructure orchestration and serverless application management tools like SAM and CDK would also be beneficial</li></ul><p><strong>Your character</strong></p><ul><li>You have a pragmatic, polyglot approach - you use the best tool for the job</li><li>You understand that proactive communication is a large part of software engineering</li><li>You're just as happy when modifying or refactoring legacy code as when working on something brand new</li><li>You maintain a solid understanding of how your work relates to the goals of the company</li><li>You are enthusiastic about solving problems and motivated to help the people around you succeed</li><li>You are productive when working with legacy code and you are always looking for refactoring opportunities</li><li>You always keep the big picture in mind when focusing on part of the system</li><li>You have an automate-everything approach - streamlining processes and eliminating manual work excites you!</li></ul><p><strong>What we offer</strong></p><ul><li>A challenging, yet encouraging work environment</li><li>The opportunity to contribute to the success of a fast-growing, market-leading product</li><li>A yearly education budget to contribute to your lifelong learning</li><li>A yearly stipend for use on either public transport or personal fitness via Urban Sports Club</li><li>In-house coaching to help you grow personally and professionally</li><li>A MacBook Pro and all the peripherals you need to succeed</li><li>A beautiful office in Berlin-Kreuzberg</li><li>Regular team outings on our two company boats!</li></ul><p><strong>Finally, a little bit more about us</strong></p><br><p>Our mission is to enable organizations of any size to accurately measure and track how people perceive their brand.</p><br><p>Our vision is to lead the development of a new generation of research technologies that enable us to better understand the desires, preferences, and dreams of people around the world.</p><br><p>You can read more about the values that drive us at latana.com/about-us.</p><br><p>Latana is committed to providing a respectful, safe, and welcoming environment for everyone who works here or with us, regardless of their gender identity and expression, sexual orientation, disability, physical appearance, body size, race, age, or religion (or lack thereof).</p><br>"
  },
  {
    "id": 79,
    "title": "Data Engineer (d/m/w) - befristet (Elternzeitvertretung)",
    "company": "Toll Collect GmbH",
    "locations": "Berlin",
    "skills": "SQL, Mathematik, Linux, Cognos, PL/SQL, Windows",
    "posted_at": "2024-07-27",
    "is_remote": "False",
    "snippet_fragments": "    Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics,      Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL),      Sie beherrschen den Umgang mit Windows und Linux einwandfrei,      Sie haben ein abgeschlossenes Studium in der Mathematik,      Sie haben Berufserfahrung im Bereich Data Engineering,     Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung,      Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung,  Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet,      Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen oder Business-Bike bis zur betrieblichen Altersversorgung,     Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung, Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu, Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen",
    "description": "<p>Referenznummer: 20728</p><br><p>Ihre Aufgaben</p><ul><li>Sie verantworten die Strukturierung und Weiterentwicklung von Datenmodellen und Datenfl\u00fcssen sowie der zugeh\u00f6rigen IT-gest\u00fctzten Prozesse</li><li>Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit</li><li>Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten</li><li>Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen</li><li>Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit, bringen eigene Ideen ein und setzen diese um</li><li>Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen</li></ul><p>Ihre Kompetenzen</p><ul><li>Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics</li><li>Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL).</li><li>Sie beherrschen den Umgang mit Windows und Linux einwandfrei</li><li>Sie haben ein abgeschlossenes Studium in der Mathematik, Informatik oder in einem vergleichbaren Studiengang</li><li>Sie haben Berufserfahrung im Bereich Data Engineering</li></ul><p>Was bieten wir</p><ul><li>Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung</li><li>Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung</li><li>Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet</li><li>Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen oder Business-Bike bis zur betrieblichen Altersversorgung</li></ul><p>Interessiert?</p><br><p>Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung. Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu. Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen.</p><br><p>Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt.</p><br><p>Ihre Ansprechperson</p><br><p>Frau Silvia Barknecht, 030/74077-8214, karriere@toll-collect.de</p><br><p>Toll Collect GmbH * Personalmanagement * Linkstra\u00dfe 4, 10785 Berlin</p><br>"
  },
  {
    "id": 80,
    "title": "(Junior) Data Engineer (m/w/d)",
    "company": "Alexander Thamm GmbH",
    "locations": "Berlin",
    "skills": "Python, SQL, Data Science, AWS, Data Analysis, Cloud, Data Pipelines, Azure, Data Warehouse, Docker, GitLab, Jenkins, Kubernetes, MySQL, PostgreSQL, Power BI, GitHub, Tableau, CD, Continuous Integration, Git",
    "posted_at": "2024-07-26",
    "is_remote": "False",
    "snippet_fragments": "   Starke schriftliche und m\u00fcndliche Kommunikationsf\u00e4higkeiten auf Deutsch und Englisch,    Sehr gute Programmierkenntnisse in Python und/ oder SQL,  (Azure und/ oder AWS) sowie mit ,    W\u00fcnschenswert sind Erfahrung in der Entwicklung von Data Warehouse oder Data Lakehouse L\u00f6sungen,  W\u00fcnschenswert sind Kenntnisse in Git, CI/CD Tools (GitLab CI, GitHub Actions, Jenkins) und Docker bzw,    Reisebereitschaft im Rahmen einer Consulting T\u00e4tigkeit,   Data bewegt uns! Was Dich auf Deiner pers\u00f6nlichen Journey erwartet, Dachterrasse), workation - nutze die M\u00f6glichkeit aus dem EU-Ausland zu arbeiten,  Einzigartige Teamatmosph\u00e4re, flache Hierarchien zu unserem CEO Alex sowie eine offene Feedbackkultur, j\u00e4hrliche Teamworkshops auf unserem Data.Castle im Zillertal, gelebtes Data.Musketeer Prinzip  einer f\u00fcr alle, alle f\u00fcr einen!, unser [at] Buddy Programm zur besseren Vernetzung, regelm\u00e4\u00dfig stattfindende Fach- und Freizeitevents, hundefreundliche B\u00fcros,  Intensiver Onboarding- & Einarbeitungsprozess, pers\u00f6nlicher Entwicklungsplan und individuelle Weiterbildungsm\u00f6glichkeiten, vielf\u00e4ltiges Workshop- und Schulungsangebot innerhalb der Data.Academy durch unsere erfahrenen Data.Musketeers sowie externen Anbieter, F\u00fchrungs-, Projektleiter- und Expertenlaufbahn, f\u00fcr Events und Reisen), Startguthaben in unserem internen Merchandise-Shop, kompetitives Gehalt mit variablen Anteilen,  Mental Health & Wellbeing Support sowie Coaching und Meditation durch nilo.health, Fitness- und Yogar\u00e4ume im M\u00fcnchner Office, regelm\u00e4\u00dfige Mitarbeiterumfragen, EGYM Well Pass Mitgliedschaft mit Plus1 Option, Fahrradleasing \u00fcber Jobrad nach der Probezeit, interne Gruppen f\u00fcr sportliche Aktivit\u00e4ten, kostenlose Hei\u00df- und Erfrischungsgetr\u00e4nke sowie frisches Obst im Office, Dachterrasse (Grill)",
    "description": "<p><strong>STARTDATUM</strong></p><br><p>Wir suchen Dich ab sofort an einem unserer Standorte in <strong>M\u00fcnchen, N\u00fcrnberg, Leipzig, Berlin</strong>!</p><br><p><strong>DEINE AUFGABEN</strong></p><br><p><strong>Data</strong> und <strong>AI</strong> sind Dein zu Hause? Des Weiteren gestaltet sich Deine neue Herausforderung wie folgt:</p><ul><li>Entwurf und Entwicklung, Testen und Debuggen sowie Automatisierung, Dokumentation und Optimierung von Data Pipelines auf Cloud Plattformen</li><li>Mitarbeit an der Architektur, der Entwicklung und der Technologieauswahl f\u00fcr die Realisierung von Data Analytics Plattformen und Data Analytics Use Cases</li><li>Regelm\u00e4\u00dfige Beratung und Kommunikation mit unseren Kunden</li><li>Entwicklung von Data &amp; Analytics Use Cases entlang der Gesch\u00e4ftsprozesse unserer Kunden, inkl. Requirements Engineering und Use Case Konzeption</li><li>Datenexploration und Datenvisualisierung bspw. mit Power BI und/ oder Tableau</li></ul><p><strong>DEIN PROFIL</strong></p><br><p><strong>Data</strong> ist auch in Deiner DNA? Das solltest Du mitbringen:</p><ul><li>Erfolgreich <strong>abgeschlossenes Studium</strong> der (Wirtschafts-) Informatik, Computer Science, Data Science, Data Engineering oder eine vergleichbare Qualifikation</li><li>Erste Berufserfahrung als <strong>Software Engineer, Software Developer, Data Engineer</strong> oder in einem \u00e4hnlichen Berufsfeld</li><li>Starke schriftliche und m\u00fcndliche Kommunikationsf\u00e4higkeiten auf <strong>Deutsch</strong> und <strong>Englisch</strong><br></li><li>Sehr gute Programmierkenntnisse in <strong>Python</strong> und/ oder <strong>SQL</strong><br></li><li>Praktische Erfahrung mit <strong>Cloud Technologien</strong> (Azure und/ oder AWS) sowie mit <strong>relationalen Datenbanken</strong> (z.B. MySQL und/ oder PostgreSQL)</li><li>W\u00fcnschenswert sind Erfahrung in der Entwicklung von <strong>Data Warehouse</strong> oder <strong>Data Lakehouse</strong> L\u00f6sungen, um strukturierte und unstrukturierte Daten zu speichern, zu organisieren und f\u00fcr Analysen zug\u00e4nglich zu machen, beispielsweise mittels der Verwendung des Spark-Frameworks</li><li>W\u00fcnschenswert sind Kenntnisse in Git, CI/CD Tools (GitLab CI, GitHub Actions, Jenkins) und Docker bzw. Kubernetes</li><li>Nice to have: Erfahrungswerte im Umgang mit <strong>Large Language Models</strong><br></li><li><br><strong>Reisebereitschaft</strong> im Rahmen einer Consulting T\u00e4tigkeit</li></ul><p><strong>WIR BIETEN</strong></p><br><p><strong>Data</strong> bewegt uns! Was Dich auf Deiner pers\u00f6nlichen Journey erwartet, findest Du hier:</p><br><p><strong>Work-Life-Balance</strong></p><br><p>Vertrauensarbeitszeit mit flexibler Arbeitszeitgestaltung - ob voll remote oder in einem unserer modern eingerichteten Innenstadtb\u00fcros (inkl. Dachterrasse), workation - nutze die M\u00f6glichkeit aus dem EU-Ausland zu arbeiten</p><br><p><strong>Kultur &amp; Zusammenarbeit</strong></p><br><p>Einzigartige Teamatmosph\u00e4re, flache Hierarchien zu unserem CEO Alex sowie eine offene Feedbackkultur, j\u00e4hrliche Teamworkshops auf unserem Data.Castle im Zillertal, gelebtes Data.Musketeer Prinzip - \u201eeiner f\u00fcr alle, alle f\u00fcr einen!&quot;, unser [at] Buddy Programm zur besseren Vernetzung, regelm\u00e4\u00dfig stattfindende Fach- und Freizeitevents, hundefreundliche B\u00fcros</p><br><p><strong>Fachliche &amp; pers\u00f6nliche Entwicklung</strong></p><br><p>Intensiver Onboarding- &amp; Einarbeitungsprozess, pers\u00f6nlicher Entwicklungsplan und individuelle Weiterbildungsm\u00f6glichkeiten, vielf\u00e4ltiges Workshop- und Schulungsangebot innerhalb der Data.Academy durch unsere erfahrenen Data.Musketeers sowie externen Anbieter, F\u00fchrungs-, Projektleiter- und Expertenlaufbahn</p><br><p><strong>Verg\u00fctung &amp; Zusatzleistungen</strong></p><br><p>Kita-Zuschuss, Betriebliche Altersvorsorge mit 20% Bezuschussung, zahlreiche Corporate Benefits &amp; Mitarbeiterangebote (z.B. f\u00fcr Events und Reisen), Startguthaben in unserem internen Merchandise-Shop, kompetitives Gehalt mit variablen Anteilen</p><br><p><strong>Gesundheit &amp; Wohlbefinden</strong></p><br><p>Mental Health &amp; Wellbeing Support sowie Coaching und Meditation durch nilo.health, Fitness- und Yogar\u00e4ume im M\u00fcnchner Office, regelm\u00e4\u00dfige Mitarbeiterumfragen, EGYM Well Pass Mitgliedschaft mit Plus1 Option, Fahrradleasing \u00fcber Jobrad nach der Probezeit, interne Gruppen f\u00fcr sportliche Aktivit\u00e4ten, kostenlose Hei\u00df- und Erfrischungsgetr\u00e4nke sowie frisches Obst im Office, Dachterrasse (Grill)</p><br><p><strong>Mobilit\u00e4t</strong></p><br><p>Zentrale Lage der Offices, gute Anbindung an den \u00d6ffentlichen Nahverkehr, M\u00f6glichkeit von anderen Standorten zu arbeiten</p><br><p><strong>ANSPRECHPARTNERIN</strong></p><br><p><strong>Marina</strong> Sommer, Principal Recruiting Manager: marina.sommer@alexanderthamm.com</p><br><p><strong>\u00dcBER UNS</strong></p><br><p>Die <strong>Alexander Thamm GmbH</strong> ist einer der f\u00fchrenden Anbieter von <strong>Data Science</strong> und <strong>K\u00fcnstlicher Intelligenz</strong> im deutschsprachigen Raum. Das Unternehmen generiert f\u00fcr und mit seinem Kunden aus Daten echte Mehrwerte, damit diese auch in Zukunft wettbewerbsf\u00e4hig sind. Dazu entwickelt und implementiert die <strong>Alexander Thamm GmbH</strong> datengetriebene Innovationen sowie Gesch\u00e4ftsmodelle. Das Leistungsportfolio umfasst die gesamte <strong>Data Journey</strong> - von der Datenstrategie \u00fcber die Entwicklung von Algorithmen und den Aufbau von IT-Architekturen bis hin zu Wartung und Betrieb. Du willst mehr \u00fcber uns erfahren und hinter die Kulissen schauen, dann besuch uns auf Facebook, Instagram, LinkedIn oder Stackoverflow.</p><br>"
  },
  {
    "id": 81,
    "title": "Senior/Expert Machine Learning Engineer (f/m/d): Data Privacy-Preserving AI",
    "company": "SAP",
    "locations": "Berlin",
    "skills": "Python, Machine Learning, Cloud, AI, TensorFlow, PyTorch, Integrity, SAP, Tabular, CRM",
    "posted_at": "2024-07-26",
    "is_remote": "False",
    "snippet_fragments": "   Your primary objective is to design,    Engineer and implement innovative methodologies to ensure the highest level of data integrity and security, Define processes, methods, and implement solutions from the ground up with an understanding to put them together for an End-to-End Foundational Model.,    Collaborate with the legal department to ensure alignment between data privacy approaches and legal requirements,    Contribute to thought leadership in a revolutionary new data modality for Foundation Models and Generative AI,    PhD or Masters degree in Computer Science, Extensive experience in data privacy, particularly in differential privacy, and its application in Foundation Models and Machine Learning.,    Strong technical vision on how to ensure data privacy for Foundation Models,    Deep understanding of issues and opportunities of applying Generative AI in a business context, Proficiency in Python, and experience with ML frameworks such as PyTorch, TensorFlow, or similar., Exceptional teamwork abilities, leadership and strategic thinking skills.,    Professional experience with Machine Learning on structured data,    Hands-on experience in developing and deploying secure and privacy-preserving ML solutions,   Meet your team SAP's AI organization is dedicated to seamlessly infusing AI into all enterprise applications, Join our international AI team where innovation thrives,   SAP innovations help more than four hundred thousand customers worldwide work together more efficiently and use business insight more effectively, Originally known for leadership in enterprise resource planning (ERP) software, As a cloud company with two hundred million users and more than one hundred thousand employees worldwide, Whether connecting global industries, people, or platforms, we help ensure every challenge gets the solution it deserves, At SAP, you can bring out your best.",
    "description": "<p><strong>We help the world run better</strong></p><br><p>At SAP, we enable you to bring out your best. Our company culture is focused on collaboration and a shared passion to help the world run better. How? We focus every day on building the foundation for tomorrow and creating a workplace that embraces differences, values flexibility, and is aligned to our purpose-driven and future-focused work. We offer a highly collaborative, caring team environment with a strong focus on learning and development, recognition for your individual contributions, and a variety of benefit options for you to choose from.</p><br><p><strong>What you`ll do</strong></p><br><p>Summary:</p><br><p>At SAP, we amplify the strength of AI technology, fusing it with our robust industry-focused data and profound process knowledge. Our vision is to infuse every SAP application with sophisticated AI capabilities, revolutionizing the way businesses operate. Large Language Models (LLMs) hold immense potential to change the way we work and develop products. They are reshaping the landscape of Machine Learning across various domains. However, their limited ability to leverage tabular data leaves a considerable share of enterprise data untapped. It is SAP's mission to overcome this challenge within the realm of Business AI. Our goal is to adapt Foundation Models to SAP data, enabling our clients to solve their business processes more effectively.</p><br><p>The Role:</p><ul><li>Unique opportunity to lead the engineering efforts in the area of data privacy for a newly established Foundation Model on structured business data.</li><li>Your primary objective is to design, develop, and execute technical solutions to safeguard our sensitive training data, focusing specifically on securing the models against potential threats and vulnerabilities.</li><li>Engineer and implement innovative methodologies to ensure the highest level of data integrity and security, as well as adhering to the highest ethical and regulatory standards with the Foundation Model.</li><li>Define processes, methods, and implement solutions from the ground up with an understanding to put them together for an End-to-End Foundational Model.</li><li>Collaborate with the legal department to ensure alignment between data privacy approaches and legal requirements.</li><li>Contribute to thought leadership in a revolutionary new data modality for Foundation Models and Generative AI.</li></ul><p><strong>What you bring</strong></p><ul><li>PhD or Master's degree in Computer Science, Artificial Intelligence, or other relevant disciplines.</li><li>Extensive experience in data privacy, particularly in differential privacy, and its application in Foundation Models and Machine Learning.</li><li>Strong technical vision on how to ensure data privacy for Foundation Models.</li><li>Deep understanding of issues and opportunities of applying Generative AI in a business context.</li><li>Proficiency in Python, and experience with ML frameworks such as PyTorch, TensorFlow, or similar.</li><li>Exceptional teamwork abilities, leadership and strategic thinking skills.</li><li>Professional experience with Machine Learning on structured data, preferably in the ERP or CRM domain.</li><li>Hands-on experience in developing and deploying secure and privacy-preserving ML solutions.</li></ul><p><strong>Meet your team</strong></p><br><p>SAP's AI organization is dedicated to seamlessly infusing AI into all enterprise applications, enabling customers, partners, and developers to enhance business processes and generate remarkable business value. Join our international AI team where innovation thrives, opportunities for personal development abound, and exceptional colleagues collaborate globally.</p><br><p>#SAPBusinessAICareers #SAPAICareers</p><br><p><strong>Bring out your best</strong></p><br><p>SAP innovations help more than four hundred thousand customers worldwide work together more efficiently and use business insight more effectively. Originally known for leadership in enterprise resource planning (ERP) software, SAP has evolved to become a market leader in end-to-end business application software and related services for database, analytics, intelligent technologies, and experience management. As a cloud company with two hundred million users and more than one hundred thousand employees worldwide, we are purpose-driven and future-focused, with a highly collaborative team ethic and commitment to personal development. Whether connecting global industries, people, or platforms, we help ensure every challenge gets the solution it deserves. At SAP, you can bring out your best.</p><br><p><strong>We win with inclusion</strong></p><br><p>SAP's culture of inclusion, focus on health and well-being, and flexible working models help ensure that everyone - regardless of background - feels included and can run at their best. At SAP, we believe we are made stronger by the unique capabilities and qualities that each person brings to our company, and we invest in our employees to inspire confidence and help everyone realize their full potential. We ultimately believe in unleashing all talent and creating a better and more equitable world.</p><br><p>SAP is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to the values of Equal Employment Opportunity and provide accessibility accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with SAP and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team: Careers@sap.com.</p><br><p>For SAP employees: Only permanent roles are eligible for the SAP Employee Referral Program, according to the eligibility rules set in the SAP Referral Policy. Specific conditions may apply for roles in Vocational Training.</p><br><p>Requisition ID: 395663 | Work Area: Software-Design and Development | Expected Travel: 0 - 10% | Career Status: Professional | Employment Type: Regular Full Time | #LI-Hybrid</p><br>"
  },
  {
    "id": 82,
    "title": "System Engineer Hyperscale Data Centers EMEA (m/f/d)",
    "company": "Corning",
    "locations": "Berlin",
    "skills": "Python, Java, JavaScript, Excel, Visio, Network Switches, Office 365, Routers, Ethernet, PRINCE2, Powerpoint, SOLID, IPv6, Bluebeam Revu, Architektur, Werkstofftechnik",
    "posted_at": "2024-07-25",
    "is_remote": "False",
    "snippet_fragments": "   Collaborate with account managers and customers to address technical inquiries, Create datasheets, system design, rack elevation drawings, technical papers and customer responses as needed, Deliver internal and external training, workshops and presentations on Corning products directly to customers, installers, and distribution partners,    Provide pre-sales and after-sales customer support including product recommendation,    Provide feedback to development/PLM (product line management) regarding new product evaluation,    Strong English writing and speaking skills,    Data center or Telecom Network Design knowledge and related proven experience,    Demonstrated Technical Support Experience (customer oriented,    Ability to effectively communicate technical and complex ideas to both highly technical audiences and individuals with limited technical background,    Comfortable working in cross-functional team environments and a willingness to collaborate and learn from others,    Strong computer skills (Office365, Power point",
    "description": "<p><strong>Date:</strong> Jul 9, 2024</p><br><p><strong>Location:</strong> Berlin, DE, 10117</p><br><p><strong>Company:</strong> Corning</p><br><p>Requisition Number: 63692</p><br><p>Corning is vital to progress - in the industries we help shape and in the world we share.</p><br><p>We invent life-changing technologies using materials science. Our scientific and manufacturing expertise, boundless curiosity, and commitment to purposeful invention place us at the center of the way the world interacts, works, learns, and lives.</p><br><p>Our sustained investment in research, development, and invention means we're always ready to solve the toughest challenges alongside our customers.</p><br><p>Our Optical Communications segment has recently evolved from being a manufacturer of optical fiber and cable, hardware and equipment to being a comprehensive provider of industry-leading optical solutions across the broader communications industry.This segment is classified into two main product groupings - carrier network and enterprise network. The carrier network product group consists primarily of products and solutions for optical-based communications infrastructure for services such as video, data and voice communications. The enterprise network product group consists primarily of optical-based communication networks sold to businesses, governments and individuals for their own use.</p><br><p>We are seeking a skilled and detail-oriented System Engineer (SE) to join our team in Berlin, Germany. The SE will be responsible for the Bill-of-Materials (BOMs) generation process and for providing products and solutions expertise to internal teams and external partners and customers at assigned data center (DC) accounts across the EMEA region. The SE will develop a deep knowledge of Corning Optical Communications portfolio to deliver a quick and reliable support to our customers. This position requires the SE to understand customer needs and highlight the value of our solutions that address those needs, ensuring maximum profitability. This role combines a blend of internal and external responsibilities, requiring a candidate with a robust background in DC network architecture, solid analytical skills, and excellent communication abilities. It also offers exposure to the latest technologies in the data center industry.</p><br><p><strong>Key Responsibilities:</strong></p><ul><li>Conduct thorough BOM verification to ensure accuracy, completeness, and compliance with specifications and Corning's product portfolio</li><li>Advise customers (internal or external) about products and their use in various applications. This includes explaining product benefits and determining detailed part number lists necessary for system solutions to fulfill customer RFQs (Request for Quote)</li><li>Collaborate with account managers and customers to address technical inquiries, provide solutions and resolve any discrepancies identified during the BOM verification process</li><li>Create datasheets, system design, rack elevation drawings, technical papers and customer responses as needed</li><li>Deliver internal and external training, workshops and presentations on Corning products directly to customers, installers, and distribution partners</li><li>Provide pre-sales and after-sales customer support including product recommendation, system design, system installation training, testing, and troubleshooting at customer site</li><li>Provide feedback to development/PLM (product line management) regarding new product evaluation, product improvements and compliance to regional standards and norms</li></ul><p><strong>Qualifications and Experience</strong></p><br><p><strong>Required Education (minimum required for consideration):</strong></p><ul><li>University Engineering Degree</li><li>Required Years and Area of Experience (minimum required for consideration): Preferred Telecom, IT or Datacom: 2-5 years</li></ul><p><strong>Required Skills</strong></p><ul><li>Strong English writing and speaking skills</li><li>Data center or Telecom Network Design knowledge and related proven experience</li><li>Demonstrated Technical Support Experience (customer oriented, field solutions, timely responses)</li><li>Ability to effectively communicate technical and complex ideas to both highly technical audiences and individuals with limited technical background</li><li>Comfortable working in cross-functional team environments and a willingness to collaborate and learn from others</li><li>Strong computer skills (Office365, Power point, Word, Excel, Visio) and BlueBeam</li></ul><p><strong>Desired Skills</strong></p><ul><li>Good hand skills: basic mechanical /troubleshooting/repair skills</li><li>Telecom active equipment configuration: Ethernet switches, IP routers, OLT/ONT, etc</li><li>Proficiency in programming languages such as Python, JavaScript, Java, or similar</li><li>Project Management skills or certifications such PMP, ACP, PRINCE2 or similar</li><li>Strong spoken/written skills in German. Any additional EMEA language (French, Spanish, Italian, Arabic, etc) will be considered as a plus</li></ul><p><strong>Travel Requirements:</strong> up to 25% of the working time as required. Primarily continental Europe. However, candidate must be prepared to travel anywhere within EMEA region including Israel or US and Asia for support. Flexibility to travel on short notice requiring overnight stay. Must have proper Visas to allow unrestricted travel. Candidate must possess current and valid local driving license and clean driving record to allow renting vehicles as required</p><br>"
  },
  {
    "id": 83,
    "title": "(Senior) Operations Engineer - Data Analytics & Management Plattform (m/w/d)",
    "company": "Bundesdruckerei GmbH",
    "locations": "Berlin",
    "skills": "Python, Ansible, Bash, Confluence, Docker, GitLab, Jira, Kubernetes, OpenShift, OpenStack, Perl, PostgreSQL, Terraform, JFrog, Grafana, Prometheus, Scripting Language, Proxmox, Go",
    "posted_at": "2024-07-25",
    "is_remote": "False",
    "snippet_fragments": "  Verantwortung f\u00fcr gemeldete Kundenprobleme und Verfolgung dieser bis zur L\u00f6sung , Untersuchung, Diagnose und Ermittlung von L\u00f6sungen zur Behebung von Problemen in den Services,   Einhaltung der vorgegebenen Prozesse f\u00fcr die Eskalation von ungel\u00f6sten Problemen an die zust\u00e4ndigen internen Teams , Management des Incident-Response-Flows, hinsichtlich der genutzten Anwendungen,   Bearbeitung und L\u00f6sung offener Support-Tickets unter Einhaltung der SLAs ,   Koordination mit unterschiedlichen Stakeholdern zur Durchf\u00fchrung von blameless Post-Mortems ,   Erfolgreich abgeschlossenes Studium mit Schwerpunkt Informatik",
    "description": "<p>Als <strong>(Senior) Operations Engineer</strong> arbeiten Sie an PLAIN, einer Datenanalyse- und KI-Plattform mit, welche die Basis f\u00fcr Data-Engineering-Projekte in einem Multi-Mandanten-Setup bildet. Hierzu geh\u00f6ren der Aufbau der technischen Infrastruktur als On-Premise L\u00f6sung im Rechenzentrum und die Entwicklung bzw. Integration von bestehenden Softwaresystemen f\u00fcr die Dienste Virtualisierung, Containerisierung, Automation und \u00dcberwachung.</p><br><p>PLAIN steht f\u00fcr \u201ePlatform Analysis and Information System&quot;. Mit PLAIN bef\u00e4higen wir unsere Kunden, Daten f\u00fcr die politische Entscheidungsfindung zu nutzen und das effiziente Arbeiten mit Daten zu professionalisieren. In unserem Arbeitsalltag arbeiten wir eng mit allen Bundesministerien und deren Datenlaboren zusammen und legen Wert auf Pers\u00f6nlichkeiten mit Eigenverantwortung und Teamgeist. Mehr Informationen unter https://www.bundesdruckerei.de/de/innovation-hub/plain.<br><strong>Ihr Aufgabenbereich</strong></p><ul><li>Verantwortung f\u00fcr gemeldete Kundenprobleme und Verfolgung dieser bis zur L\u00f6sung</li><li>Untersuchung, Diagnose und Ermittlung von L\u00f6sungen zur Behebung von Problemen in den Services</li><li>Einhaltung der vorgegebenen Prozesse f\u00fcr die Eskalation von ungel\u00f6sten Problemen an die zust\u00e4ndigen internen Teams</li><li>\u00dcberwachung der SLO-Alarme und Fehlerbudgets</li><li>Management des Incident-Response-Flows, hinsichtlich der genutzten Anwendungen</li><li>Identifizierung und Implementierung von Automatisierungsm\u00f6glichkeiten</li><li>Bearbeitung und L\u00f6sung offener Support-Tickets unter Einhaltung der SLAs</li><li>Koordination mit unterschiedlichen Stakeholdern zur Durchf\u00fchrung von blameless Post-Mortems<br><strong>Ihr Profil</strong><br></li><li>Erfolgreich abgeschlossenes Studium mit Schwerpunkt Informatik, eine abgeschlossene Ausbildung im IT-Bereich oder eine gleichwertige Qualifikation</li><li>Berufserfahrung im IT-Betrieb oder Produktionssupport</li><li>Praktische Erfahrung mit Linux-Plattformen</li><li>Know-how im Umgang mit: Proxmox, OpenStack, OpenShift, Artifactory Enterprise, Ansible, Kubernetes, Docker, PostgresSQL, Grafana, Prometheus, Gitlab, Terraform, Jira, Confluence u.w.</li><li>Kenntnisse in einer der Programmiersprachen: Python, Bash Scripting, Go oder Perl</li><li>Teamf\u00e4higkeit, Flexibilit\u00e4t und die Bereitschaft in einem 24x7 (Incentive) Supportmodell zu arbeiten</li><li>Sichere Deutsch- und Englischkenntnisse</li></ul><br>"
  },
  {
    "id": 84,
    "title": "Senior Data Analyst / Data Scientist",
    "company": "omos media GmbH",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Data Analysis, Data Pipelines, Big Data, Agile, BigQuery, Dashboards, NoSQL, Power BI, scikit-learn, TensorFlow, APIs, Algorithms, Tableau, Looker, Data Visualization, PyTorch, Predictive modelling, Klaviyo, R, SOLID",
    "posted_at": "2024-07-24",
    "is_remote": "False",
    "snippet_fragments": " Weve outgrown our startup phase but are still far from being a corporation, From day one, youll be a valuable part of a warm, supportive, and appreciative team, and you will immediately contribute to the companies culture.,  Theres no question that as a small team, we rely on everyone to pull together and develop collectively to enhance our performance, Feedback conversations are a given for us, In your role, you have complete flexibility and receive the technical equipment needed to be productive both in the office and outside of it, Our team now works from all over Germany, Youll receive 30 vacation days plus additional time off on December 24th and 31st each year., In addition to vacation days, you get 2 voluntary \"charity leave days\" to engage in volunteer activities of your choice., To support all our employees in being flexible while on the go, we offer various public transport tickets, covering most of the costs., While our minds are engaged in exciting projects every day, we also want to ensure that the rest of our bodies dont miss out, Therefore, we contribute significantly towards various fitness memberships., The future of our team is important to us; thats why we have a strong partner by our side and contribute well beyond the legally required minimum subsidy., We appreciate the hard work our team puts in but know that words alone arent enough, To give back to everyone, team events are very dear to us, Whether its a birthday, anniversary, or other highlights in your life, we celebrate special occasions with small gifts, Additionally, youll enjoy many benefits from our employee programs like Corporate Benefits and FutureBens., We take on a full sponsorship for a rescued animal at the Lasst die Tiere leben e.V. sanctuary in Brandenburg on your behalf",
    "description": "<p><strong>SCH\u00d6N, DASS DU HIER BIST</strong></p><br><p>Wednesday afternoon in Berlin: With a smile on your face you're on your way home from work.</p><br><p>Together with your team you've accomplished a lot this week!</p><br><p>After developing a complex data model today, you also managed to conduct relevant predictive analyses and are excited to see how your insights will improve the business strategy!</p><br><p>If you see yourself in this role, we have some great news: We are now looking for a <strong>full-time Senior Data Analyst / Data Scientist (m/f/d) - remote/hybrid in Berlin!</strong></p><br><p>Please note that it is a prerequisite for this role that you <strong>live</strong> <strong>i</strong>n Germany and are officially registered here.</p><br><p><strong>DIE STELLE</strong></p><ul><li><br><strong>Data Analysis and Visualization:</strong> Analyze and interpret large datasets to gain valuable insights for our business strategy. Create engaging visualizations and dashboards using tools like Tableau, Power BI, or Looker Studio that will impress our stakeholders.</li><li><br><strong>Predictive Modeling:</strong> Develop and implement advanced statistical models and machine learning algorithms such as scikit-learn, PyTorch, or TensorFlow to make accurate predictions and support data-driven decisions.</li><li><br><strong>Business Strategy:</strong> Use your analytical skills and creativity to develop innovative solutions that optimize business processes and enhance the customer journey.</li><li><br><strong>Data Integrity and Quality:</strong> Ensure that our data is clean, accurate, and consistent by reviewing and cleansing data sources.</li><li><br><strong>Cross-functional Collaboration:</strong> Work closely with various departments to understand data requirements and develop tailored solutions. Support the team in data-related projects and initiatives.</li><li><br><strong>Technical Support and Maintenance:</strong> Ensure that our data infrastructures run smoothly and are always up-to-date by providing continuous support and maintenance.</li><li><br><strong>APIs and Data Pipelines:</strong> Implement and manage interfaces to third-party APIs like Klarna, Klaviyo, and develop robust data pipelines for efficient processing and analysis of data.</li></ul><p><strong>DAS BRINGST DU IDEALERWEISE MIT</strong>*</p><ul><li><br><strong>Programming Skills:</strong> You have strong knowledge of SQL, Python, R, and other relevant programming languages.</li><li><br><strong>Statistical Methods:</strong> You possess solid knowledge of statistical methods and machine learning techniques.</li><li><br><strong>Data Visualization:</strong> You have experience working with visualization tools such as Tableau, Looker Studio, Power BI, or similar.</li><li><br><strong>Big Data Technologies:</strong> Ideally, you have experience with BigQuery and other big data technologies.</li><li><br><strong>Databases:</strong> You have practical experience with relational data bases as well as NoSQL data bases.</li><li><br><strong>Project Experience:</strong> You have several years of experience in data analysis and science, including model development and implementation of data-driven solutions.</li><li><br><strong>Team Player: Y</strong>ou are a true team player who has gained initial experience in an agile work environment and looks forward to celebrating successes together.</li><li><br><strong>Continuous Learning:</strong> You pursue self-directed learning and keep up with current trends in technology (we're happy to support you in that!).</li><li><br><strong>Language Skills:</strong> Our team speaks German; therefore, you should either have good German skills (B2/C1) and proficiency in English at B1/B2 level, or the other way around.</li></ul><p><strong>DAS M\u00d6CHTEN WIR DIR BIETEN</strong></p><ul><li><br><strong>Stability and Reliability:</strong> We've outgrown our startup phase but are still far from being a corporation. As a grown-up company, we offer you the best of both worlds: a secure foundation with plenty of room for creativity!</li><li><br><strong>Team Spirit:</strong> From day one, you'll be a valuable part of a warm, supportive, and appreciative team, and you will immediately contribute to the companies culture.</li><li><br><strong>Trust:</strong> Whether it's about your workplace (hybrid), your working hours (trust-based working hours), or your style of working, we trust you to give your best and that we share the same goal: to be successful together.</li><li><br><strong>Development:</strong> There's no question that as a small team, we rely on everyone to pull together and develop collectively to enhance our performance. Feedback conversations are a given for us, as is fostering your potential through various training opportunities.</li><li><br><strong>&quot;Fully Remote&quot; Option:</strong> In your role, you have complete flexibility and receive the technical equipment needed to be productive both in the office and outside of it. Our team now works from all over Germany.</li><li><br><strong>Balance and Recovery:</strong> You'll receive 30 vacation days plus additional time off on December 24th and 31st each year.</li><li><br><strong>Time for What Matters:</strong> In addition to vacation days, you get 2 voluntary &quot;charity leave days&quot; to engage in volunteer activities of your choice.</li><li><br><strong>Mobility:</strong> To support all our employees in being flexible while on the go, we offer various public transport tickets, covering most of the costs.</li><li><br><strong>Fitness:</strong> While our minds are engaged in exciting projects every day, we also want to ensure that the rest of our bodies don't miss out. Therefore, we contribute significantly towards various fitness memberships.</li><li><br><strong>Company Pension Scheme:</strong> The future of our team is important to us; that's why we have a strong partner by our side and contribute well beyond the legally required minimum subsidy.</li><li><br><strong>Gratitude:</strong> We appreciate the hard work our team puts in but know that words alone aren't enough. To give back to everyone, team events are very dear to us. Whether it's a birthday, anniversary, or other highlights in your life, we celebrate special occasions with small gifts. Additionally, you'll enjoy many benefits from our employee programs like Corporate Benefits and FutureBens.</li><li><br><strong>Animal Sponsorship:</strong> We take on a full sponsorship for a rescued animal at the &quot;Lasst die Tiere leben e.V.&quot; sanctuary in Brandenburg on your behalf. The animals carry the names of their sponsors.</li><li><br><strong>Enjoyment:</strong> Our entire product range is available to you and your family monthly in its full healthy variety. What we don't have: a fruit basket. But we do provide regular lunches, plenty of drinks, coffee, sweets, tea... If there's anything you're missing, just let us know!</li></ul><p><strong>BIST DU \u00dcBERZEUGT?</strong></p><br><p>Are you keen to revolutionize the health market with us? Then apply right away! We're also happy to answer any questions you may have in advance and show you why omos media is the right place for you, and how we can work together to make the world a better place sustainably.</p><br><p><strong>\u00dcBER UNS</strong></p><br><p>Als innovatives Unternehmen rund um die Themen Gesundheit, Fitness und Ern\u00e4hrung, wurde die omos media GmbH 2018 gegr\u00fcndet. Wir fokussieren uns auf die Personal Brand <strong>Jasper Caven</strong>, unsere Brand f\u00fcr vegane Supplement-Produkte <strong>Floranutris</strong> und <strong>MetaFlow</strong> - unsere Marke f\u00fcr gesunden und nachhaltigen Gewichtsverlust. 2023 haben wir mit <strong>WonderFast</strong> unsere vierte Marke gelaunched, deren Konzept es ist, nachhaltiges Intervallfasten zu unterst\u00fctzen.</p><br><p>Wir haben eine Mission: Als starkes, kreatives Team bei omos media werden wir weltweit vielen Menschen zu mehr Gesundheit, Lebensfreude und Wohlbefinden verhelfen.</p><br><p>Du bist neugierig geworden und m\u00f6chtest mehr erfahren? Das freut uns! Bitte hier entlang:</p><br><p>https://omosmedia.de/</p><br>"
  },
  {
    "id": 85,
    "title": "Data Engineer / Data Analyst (m/f/d)",
    "company": "TXT e-solutions SPA",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Data Science, AWS, Data Analysis, Data Pipelines, Azure, ETL, Big Data, Dashboards, Power BI, Tableau, Data Visualization, Snowflake, R, Network Analysis, Statistik, Statistical Analysis",
    "posted_at": "2024-07-24",
    "is_remote": "True",
    "snippet_fragments": "You ensure data quality and implement best practices for data governance and stay up-to-date with industry trends and advancements in data analysis and aviation technology, You hold a bachelors or masters degree in data science, You have at least 3 years of experience as a data engineer or data analyst , You have proven experience as a data analyst, You are proficient in data analysis tools and programming languages such as SQL, You have experience with big data technologies and platforms (e, You have strong analytical skills and attention to detail, You are excellent in communication and collaboration skills, You are able to work independently and manage multiple projects simultaneously, You understand flight operations, aircraft systems and maintenance procedures , You have a good mathematical understanding , An aerospace background is a plus , Experience with flight data monitoring (FDM) and analysis, An AWS certificate is a plus , Familiarity with machine learning techniques and tools, You are a fast learner and able to work independently / with own responsibility ,  An interesting job in the aerospace industry with direct interaction with many leading aerospace companies ,  Working with very talented and passionate people in a professional environment",
    "description": "<p>PACE Aerospace &amp; Information Technology GmbH, as a part of the TXT e-Solutions Group, is an internationally renowned software company that specializes in the development of innovative solutions for the aviation industry. Our customers include many of the world's largest aircraft manufacturers and airlines.</p><br><p>Since its inception in 1995, PACE has been creating and developing software for airplane design &amp; configuration, route network analysis, virtual training, and fuel efficiency improvements. PACE has an extensive network within the international academia community and partners in multiple national and European research projects. The company is based in Berlin, Germany, with subsidiaries in the USA, Canada and Singapore. As part of the stock-listed Milan-based TXT e-Solutions group, PACE is benefiting from an ecosystem of digital innovators in multiple industrial sectors.</p><br><p><strong>Data Engineer / Data Analyst (m/f/d):</strong></p><br><p>The PACE Flight Operations Team is currently looking for a Data Engineer / Data Analyst (m/f/d). The position is a full-time position, to be held in Berlin, Germany. In that role you are part of a team, that is developing a new product in the field of civil aviation. The ideal candidate will have a strong background in data analysis, data engineering, and a keen interest in the aviation or flight operations domain. You will be responsible for collecting, analyzing, and interpreting complex datasets related to flight operations and -performance. Your insights will help drive strategic decisions and innovations in our application. Be part of making the aviation more efficient!</p><br><p>Responsibilities &amp; Job Description</p><br><p>You are responsible for the data analytics of our Flight Profile Optimizer</p><br><p>You will maintain and re-new the necessary infrastructure</p><br><p>You collect, process, and analyze large datasets from various sources, including flight data, maintenance records, and operational logs.</p><br><p>You develop and maintain data pipelines and ETL processes to ensure data integrity and accessibility.</p><br><p>You perform statistical analysis and create and maintain dashboards, reports, and visualizations to communicate findings to stakeholders and customers</p><br><p>You collaborate with cross-functional teams, including developers, product owners, and aviation experts, to understand data requirements and deliver actionable insights.</p><br><p>You ensure data quality and implement best practices for data governance and stay up-to-date with industry trends and advancements in data analysis and aviation technology.</p><br><p>Required Qualifications</p><br><p>Mandatory</p><br><p>You hold a bachelor's or master's degree in data science, computer science, statistics, engineering, or a related field.</p><br><p>You have at least 3 years of experience as a data engineer or data analyst</p><br><p>You have proven experience as a data analyst, data engineer, or similar role, preferably in the aviation domain.</p><br><p>You are proficient in data analysis tools and programming languages such as SQL, Python, R, and data visualization tools like Tableau or Power BI.</p><br><p>You have experience with big data technologies and platforms (e.g., Snowflake, AWS, Azure)</p><br><p>You have strong analytical skills and attention to detail.</p><br><p>You are excellent in communication and collaboration skills.</p><br><p>You are able to work independently and manage multiple projects simultaneously.</p><br><p>Desired</p><br><p>You understand flight operations, aircraft systems and maintenance procedures</p><br><p>You have a good mathematical understanding</p><br><p>An aerospace background is a plus</p><br><p>Experience with flight data monitoring (FDM) and analysis.</p><br><p>An AWS certificate is a plus</p><br><p>Familiarity with machine learning techniques and tools.</p><br><p>Behavioral skills</p><br><p>You have a solution-oriented mindset</p><br><p>You are a fast learner and able to work independently / with own responsibility</p><br><p>We offer</p><br><p>An interesting job in the aerospace industry with direct interaction with many leading aerospace companies</p><br><p>Working with very talented and passionate people in a professional environment.</p><br><p>International projects with the opportunity to gain deep domain knowledge and expertise.</p><br><p>A modern office with top-of-the-line equipment, situated in the historic Westend train station with great transport accessibility.</p><br><p>Employee discounts from top suppliers from different business areas</p><br><p>Flexibility to work from home</p><br><p>A comprehensive compensation package</p><br><p>20 days per year of mobile working from other EU countries</p><br><p>If you find this position interesting, please send us your cover letter, CV, certificates and references.</p><br>"
  },
  {
    "id": 86,
    "title": "Data Engineer (m/f/d)",
    "company": "CGI Group, Inc.",
    "locations": "Berlin",
    "skills": "Python, SQL, Data Science, Data Pipelines, AI, Business Intelligence, Data Modeling, C#, Docker, Java, Jenkins, SQL Server, CD, Continuous Integration, Git, R",
    "posted_at": "2024-07-24",
    "is_remote": "False",
    "snippet_fragments": "  Von Vorteil sind gute Kenntnisse in einer objektorientierten Programmiersprache wie Java oder C#,   Ein Team mit dem die Zusammenarbeit Spa macht, Wir begegnen uns offen, duzen uns ber alle Positionen hinweg und denken nicht in Hierarchien oder Silos,   Du arbeitest meist direkt an deinem Heimatort weil wir Kundennhe wrtlich nehmen und uns Work-Life-Balance am Herzen liegt,   Du profitierst von flexiblen Arbeitszeiten und hast je nach Kundensituation die Mglichkeit,   Du bekommst ein Firmenhandy mit Vodafonevertrag (IPhone) auch fr private Nutzung,   In der IT ist es wichtig immer auf dem neusten Stand zu bleiben, Neben unserer internen E-Learning-Plattform Academia ermglichen wir dir das Absolvieren von Schulungen und Zertifikaten,   Einen Teil des Bruttogehalts kannst du in CGI Aktien investieren bis maximal 3 % des Monatsgehalts geben wir fr jeden Euro einen weiteren hinzu,  Wir bieten verschiedene Mobilitts-Modelle, wie Dienstfahrrad oder Firmenwagen,   Sabbatical oder Elternzeit werden untersttzt und sind bei uns kein Karriere-Stopper! ,  Wir sind an deiner Seite, auch wenn es einmal nicht so gut luft, Du kannst Sonderurlaub nehmen, und unsere Beratungshotline stehen dir immer zur Verfgung,   Eine Vielzahl an gemeinsamen Events und Freizeitaktivitten im Team, Together, as owners, lets turn meaningful insights into action.,   1976 gegrndet und nach wie vor familiengefhrt",
    "description": "<p><strong>Job order - J0324-0538 - Permanent Full Time</strong></p><br><p><strong>Title</strong> Data Engineer (m/f/d) <strong>Category</strong> Analytics and Emerging Digital Technologies <strong>City</strong> Dsseldorf, Kln oder Berlin, , Germany <strong>Job Description</strong> Data Engineer (m/f/d)</p><br><p>Stellenbeschreibung</p><br><p>Du willst die digitale Zukunft von Bund, Lndern und Kommunen mitgestalten? Dann bist du bei uns genau richtig! Wir bei CGI arbeiten in gemischten Teams aus erfahrenen Mitarbeiter:innen und Berufseinsteiger:innen in agilen Projekten an der Entwicklung von Lsungen fr die digitale Transformation Deutschlands. Bei all unseren Projekten haben wir immer das gleiche Ziel: Wir wollen unseren Kunden helfen das Leben fr Brger:innen und ffentlich Bedienstete einfacher zu machen. Das mchtest du auch? Dann freuen wir uns auf deine Bewerbung als Data Engineer (m/f/d) an unseren Standorten Berlin, Kln oder Dsseldorf.</p><br><p>Aufgaben</p><br><p>Das erwartet dich bei uns</p><br><p>Als Data Engineer (m/f/d) bist du unsere erste Wahl, wenn es um die Anbindung, Aufbereitung und Bereitstellung von</p><br><p>Daten im Kontext Analytics und BI geht. In Projekten untersttzt du als Teil der Data Intelligence-Einheit unsere Kunden</p><br><p>aus dem Public Sector bei den folgenden Aufgaben:</p><br><p>Design und Implementierung von Data Pipelines</p><br><p>Automation, Tuning und Betrieb von bestehenden Data Pipelines</p><br><p>Analyse und Bereinigung von Data Quality Issues</p><br><p>Betrieb und Optimierung eines hochverfgbaren SQL-Clusters</p><br><p>Entwicklung performanter Datenmodelle</p><br><p>Beratung bei der Auswahl der richtigen Technologien</p><br><p>Begleitung von Proof of Concepts Neugier, Vielseitigkeit und Enthusiasmus sind hier eine groe Hilfe</p><br><p>Qualifikation</p><br><p>Erfolgreich abgeschlossenes Studium der Informatik, Computer Science, Data Science oder eine</p><br><p>vergleichbare Ausbildung</p><br><p>Praktische Berufserfahrung im Kontext Data Pipelines als Softwareengineer, Softwareentwickler, Data</p><br><p>Engineer oder hnlichem Berufsfeld</p><br><p>Fundierte Erfahrungen in Datenmodellierung und Datenbankadministration insbesondere in SQL (z.B. in</p><br><p>MS SQL)</p><br><p>Gute Kenntnisse im Linux-Umfeld und/oder Windows-Umfeld</p><br><p>Vertrautheit mit Container Plattformen (z. B. Docker) und Werkzeugen im Kontext CI/CD (z.B. Git,</p><br><p>Jenkins)</p><br><p>Von Vorteil sind gute Kenntnisse in einer objektorientierten Programmiersprache wie Java oder C#</p><br><p>und/oder Python oder R</p><br><p>Deutschkenntnisse auf C1 Level</p><br><p><strong>Was wir bieten</strong></p><br><p>Ein Team mit dem die Zusammenarbeit Spa macht. Wir begegnen uns offen, duzen uns ber alle Positionen hinweg und denken nicht in Hierarchien oder Silos.</p><br><p>Du arbeitest meist direkt an deinem Heimatort weil wir Kundennhe wrtlich nehmen und uns Work-Life-Balance am Herzen liegt.</p><br><p>Du profitierst von flexiblen Arbeitszeiten und hast je nach Kundensituation die Mglichkeit, von zuhause zu arbeiten.</p><br><p>Du bekommst ein Firmenhandy mit Vodafonevertrag (IPhone) auch fr private Nutzung.</p><br><p>In der IT ist es wichtig immer auf dem neusten Stand zu bleiben, deshalb bringen die richtigen Trainings und Zertifikate deine Karriere voran. Neben unserer internen E-Learning-Plattform Academia ermglichen wir dir das Absolvieren von Schulungen und Zertifikaten.</p><br><p>Einen Teil des Bruttogehalts kannst du in CGI Aktien investieren bis maximal 3 % des Monatsgehalts geben wir fr jeden Euro einen weiteren hinzu.</p><br><p>Auerdem beteiligen wir dich am Unternehmenserfolg: Du erhltst eine Gewinnbeteiligung, die sich nach deiner individuellen Leistung, sowie der unternehmerischen finanziellen Zielerreichung des Unternehmens richtet.</p><br><p>Wir bieten verschiedene Mobilitts-Modelle, wie Dienstfahrrad oder Firmenwagen.</p><br><p>Sabbatical oder Elternzeit werden untersttzt und sind bei uns kein Karriere-Stopper!</p><br><p>Wir sind an deiner Seite, auch wenn es einmal nicht so gut luft. Du kannst Sonderurlaub nehmen, und unsere Beratungshotline stehen dir immer zur Verfgung.</p><br><p>Eine Vielzahl an gemeinsamen Events und Freizeitaktivitten im Team.</p><ul><li>LI-IF1</li></ul><p><strong>Together, as owners, lets turn meaningful insights into action.</strong></p><br><p>1976 gegrndet und nach wie vor familiengefhrt, ist CGI heute einer der weltweit grten unabhngigen Anbieter von IT und Business Consulting. Ein hohes Ma an Eigenverantwortung, Teamwork, Respekt und Zusammenhalt machen das Arbeiten bei uns besonders. Bei uns kannst du dein volles Potenzial entfalten!</p><br><p>Du darfst dich vom ersten Tag an als Miteigentmer:in von CGI verstehen. Wir lassen unsere Vision gemeinsam Wirklichkeit werden. Wir profitieren von unserem gemeinsamen Erfolg und haben die Mglichkeit und die Verantwortung, die Strategie und Ausrichtung unseres Unternehmens aktiv mitzugestalten.</p><br><p>Deine Arbeit schafft Mehrwert. Du findest innovative Lsungen und strkst dein Netzwerk aus Kolleg:innen und Kunden. Gleichzeitig hast du Zugang zu globalen Ressourcen, um groe Ideen zu verwirklichen, neue Chancen zu nutzen und von der immensen Branchen- und Technologie-Kompetenz zu profitieren.</p><br><p>Du bringst deine Karriere voran, da du in einem Unternehmen arbeitest, das auf Wachstum und Langlebigkeit ausgelegt ist. Du wirst von Fhrungskrften untersttzt, die deine Gesundheit und Zufriedenheit frdern und dir Mglichkeiten bieten, deine Fhigkeiten zu vertiefen und deinen Horizont zu erweitern.</p><br><p><strong>Skills</strong></p><ul><li>Artificial Intelligence<br><strong>Reference</strong> 1113142</li></ul><br>"
  },
  {
    "id": 87,
    "title": "(Senior) Operations Engineer - Data Analytics & Management Plattform (m/w/d)",
    "company": "Bundesdruckerei GmbH",
    "locations": "Berlin",
    "skills": "Python, Ansible, Bash, Confluence, Docker, GitLab, Jira, Kubernetes, OpenShift, OpenStack, Perl, PostgreSQL, Terraform, JFrog, Grafana, Prometheus, Scripting Language, Proxmox, Go",
    "posted_at": "2024-07-24",
    "is_remote": "False",
    "snippet_fragments": "Mit PLAIN bef\u00e4higen wir unsere Kunden, In unserem Arbeitsalltag arbeiten wir eng mit allen Bundesministerien und deren Datenlaboren zusammen und legen Wert auf Pers\u00f6nlichkeiten mit Eigenverantwortung und Teamgeist,   Verantwortung f\u00fcr gemeldete Kundenprobleme und Verfolgung dieser bis zur L\u00f6sung , Untersuchung, Diagnose und Ermittlung von L\u00f6sungen zur Behebung von Problemen in den Services,   Einhaltung der vorgegebenen Prozesse f\u00fcr die Eskalation von ungel\u00f6sten Problemen an die zust\u00e4ndigen internen Teams , Management des Incident-Response-Flows, hinsichtlich der genutzten Anwendungen,   Bearbeitung und L\u00f6sung offener Support-Tickets unter Einhaltung der SLAs ,   Koordination mit unterschiedlichen Stakeholdern zur Durchf\u00fchrung von blameless Post-Mortems ,   Erfolgreich abgeschlossenes Studium mit Schwerpunkt Informatik",
    "description": "<p>Als <strong>(Senior) Operations Engineer</strong> arbeiten Sie an PLAIN, einer Datenanalyse- und KI-Plattform mit, welche die Basis f\u00fcr Data-Engineering-Projekte in einem Multi-Mandanten-Setup bildet. Hierzu geh\u00f6ren der Aufbau der technischen Infrastruktur als On-Premise L\u00f6sung im Rechenzentrum und die Entwicklung bzw. Integration von bestehenden Softwaresystemen f\u00fcr die Dienste Virtualisierung, Containerisierung, Automation und \u00dcberwachung.</p><br><p>PLAIN steht f\u00fcr \u201ePlatform Analysis and Information System&quot;. Mit PLAIN bef\u00e4higen wir unsere Kunden, Daten f\u00fcr die politische Entscheidungsfindung zu nutzen und das effiziente Arbeiten mit Daten zu professionalisieren. In unserem Arbeitsalltag arbeiten wir eng mit allen Bundesministerien und deren Datenlaboren zusammen und legen Wert auf Pers\u00f6nlichkeiten mit Eigenverantwortung und Teamgeist. Mehr Informationen unter https://www.bundesdruckerei.de/de/innovation-hub/plain.<br><strong>Ihr Aufgabenbereich</strong></p><ul><li>Verantwortung f\u00fcr gemeldete Kundenprobleme und Verfolgung dieser bis zur L\u00f6sung</li><li>Untersuchung, Diagnose und Ermittlung von L\u00f6sungen zur Behebung von Problemen in den Services</li><li>Einhaltung der vorgegebenen Prozesse f\u00fcr die Eskalation von ungel\u00f6sten Problemen an die zust\u00e4ndigen internen Teams</li><li>\u00dcberwachung der SLO-Alarme und Fehlerbudgets</li><li>Management des Incident-Response-Flows, hinsichtlich der genutzten Anwendungen</li><li>Identifizierung und Implementierung von Automatisierungsm\u00f6glichkeiten</li><li>Bearbeitung und L\u00f6sung offener Support-Tickets unter Einhaltung der SLAs</li><li>Koordination mit unterschiedlichen Stakeholdern zur Durchf\u00fchrung von blameless Post-Mortems<br><strong>Ihr Profil</strong><br></li><li>Erfolgreich abgeschlossenes Studium mit Schwerpunkt Informatik, eine abgeschlossene Ausbildung im IT-Bereich oder eine gleichwertige Qualifikation</li><li>Berufserfahrung im IT-Betrieb oder Produktionssupport</li><li>Praktische Erfahrung mit Linux-Plattformen</li><li>Know-how im Umgang mit: Proxmox, OpenStack, OpenShift, Artifactory Enterprise, Ansible, Kubernetes, Docker, PostgresSQL, Grafana, Prometheus, Gitlab, Terraform, Jira, Confluence u.w.</li><li>Kenntnisse in einer der Programmiersprachen: Python, Bash Scripting, Go oder Perl</li><li>Teamf\u00e4higkeit, Flexibilit\u00e4t und die Bereitschaft in einem 24x7 (Incentive) Supportmodell zu arbeiten</li><li>Sichere Deutsch- und Englischkenntnisse</li></ul><br>"
  },
  {
    "id": 88,
    "title": "(Senior) Test Engineer - Data Analytics & Management Plattform (m/w/d)",
    "company": "Bundesdruckerei GmbH",
    "locations": "Berlin",
    "skills": "Python, Confluence, Jenkins, Jira, Scrum, SoapUI, Postman, Cypress, Continuous Integration, APIs",
    "posted_at": "2024-07-24",
    "is_remote": "False",
    "snippet_fragments": "  Verantwortung sowohl f\u00fcr das Reporting der Testergebnisse als auch f\u00fcr die Pflege und Verbesserung bestehender Testf\u00e4lle und des Arbeitsablaufs , Erstellung, Pflege und Verbesserung von Testf\u00e4llen ,   Technische Unterst\u00fctzung bei der Integration von Testtools ,   Durchf\u00fchrung der Akzeptanztests im Sprint und der Regressionstests zum Sprintende ,   Abgeschlossenes Studium der Informatik oder einer vergleichbaren Fachrichtung sowie fundierte Erfahrung in der Entwicklung und Dokumentation von Testf\u00e4llen hinsichtlich Funktionalit\u00e4t,   Erfahrung mit Unit- und Infrastruktur-Tests im Container- und Entwicklungs-Umfeld ,   Sichere Kenntnisse der Microservices-Tests in komplexen Architekturen mit CI/CD-Struktur und Pipelines, Umfassendes Know-how im Bereich Testautomatisierung, Behavior Driven Testing sowie in Frameworks wie z",
    "description": "<p><strong>Ihr Aufgabenbereich</strong></p><ul><li>Proaktive Zusammenarbeit mit dem Entwicklungsteam im agilen Kontext</li><li>Erstellung von Test-Code/Glue-Code f\u00fcr BDD-Testing und Code f\u00fcr die Test-Automatisierung</li><li>Verantwortung sowohl f\u00fcr das Reporting der Testergebnisse als auch f\u00fcr die Pflege und Verbesserung bestehender Testf\u00e4lle und des Arbeitsablaufs</li><li>Erstellung, Pflege und Verbesserung von Testf\u00e4llen</li><li>Technische Unterst\u00fctzung bei der Integration von Testtools</li><li>Aufbereitung der Testdaten und ggf. Aufbau von Mocking-Systemen</li><li>Durchf\u00fchrung der Akzeptanztests im Sprint und der Regressionstests zum Sprintende<br><strong>Ihr Profil</strong><br></li><li>Abgeschlossenes Studium der Informatik oder einer vergleichbaren Fachrichtung sowie fundierte Erfahrung in der Entwicklung und Dokumentation von Testf\u00e4llen hinsichtlich Funktionalit\u00e4t, API, Leistung, Integration und Nutzbarkeit</li><li>Erfahrung mit Unit- und Infrastruktur-Tests im Container- und Entwicklungs-Umfeld</li><li>Sichere Kenntnisse der Microservices-Tests in komplexen Architekturen mit CI/CD-Struktur und Pipelines, z. B. Gitlab-Pipeline/Jenkins sowie Grundkenntnisse von DevOps-T\u00e4tigkeiten</li><li>Umfassendes Know-how im Bereich Testautomatisierung, Behavior Driven Testing sowie in Frameworks wie z. B. Cypress und Playwright</li><li>Kenntnisse in der Programmiersprache Python f\u00fcr den Entwurf und die Implementierung von funktionalen und nicht-funktionalen Compliance- &amp; API-Tests</li><li>Erfahrung in agilen Projekten (Scrum) sowie mit Ticketmanagement- und Dokumentationstools (Jira, Confluence)</li><li>Praxis mit Komponenten-, Akzeptanz-, Integrations-, Last- und Stresstests, Debugging und Performance-Messungen sowie mit Tools wie Postman oder SoapUI</li></ul><br>"
  },
  {
    "id": 89,
    "title": "Data Engineer (d/m/w) - befristet (Elternzeitvertretung)",
    "company": "Toll Collect GmbH",
    "locations": "Berlin",
    "skills": "SQL, Mathematik, Linux, Cognos, PL/SQL, Windows",
    "posted_at": "2024-07-21",
    "is_remote": "False",
    "snippet_fragments": "     Sie haben Berufserfahrung im Bereich Data Engineering,     Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung,      Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung,  Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet,      Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen oder Business-Bike bis zur betrieblichen Altersversorgung,     Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung, Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu, Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen",
    "description": "<p>Referenznummer: 20728</p><br><p>Ihre Aufgaben</p><ul><li>Sie verantworten die Strukturierung und Weiterentwicklung von Datenmodellen und Datenfl\u00fcssen sowie der zugeh\u00f6rigen IT-gest\u00fctzten Prozesse</li><li>Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit</li><li>Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten</li><li>Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen</li><li>Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit, bringen eigene Ideen ein und setzen diese um</li><li>Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen</li></ul><p>Ihre Kompetenzen</p><ul><li>Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics</li><li>Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL).</li><li>Sie beherrschen den Umgang mit Windows und Linux einwandfrei</li><li>Sie haben ein abgeschlossenes Studium in der Mathematik, Informatik oder in einem vergleichbaren Studiengang</li><li>Sie haben Berufserfahrung im Bereich Data Engineering</li></ul><p>Was bieten wir</p><ul><li>Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung</li><li>Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung</li><li>Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet</li><li>Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen oder Business-Bike bis zur betrieblichen Altersversorgung</li></ul><p>Interessiert?</p><br><p>Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung. Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu. Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen.</p><br><p>Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt.</p><br><p>Ihre Ansprechperson</p><br><p>Frau Silvia Barknecht, 030/74077-8214, karriere@toll-collect.de</p><br><p>Toll Collect GmbH * Personalmanagement * Linkstra\u00dfe 4, 10785 Berlin</p><br>"
  },
  {
    "id": 90,
    "title": "Data Scientist",
    "company": "Vanilla Steel",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Mathematik, Data Science, AWS, Data Analysis, Cloud, GCP, AI, A/B testing, Dashboards, Keras, MATLAB, Excel, TensorFlow, Algorithms, PyTorch, Statistical modeling, Scripting Language, SAP, Statistik",
    "posted_at": "2024-07-19",
    "is_remote": "True",
    "snippet_fragments": "Create, develop, and maintain metrics on dashboards to measure algorithm performance and the value generated for our customers and for the company.,  At least 2 years of experience working in data science or machine learning or statistical modeling,  Experience working with data querying languages (e,  Experience working with Product and Business stakeholders in order to understand the customer problems and goals for which you would be building out data centric solutions,  Ability to communicate and work well with Technology teams to take the solution to the actual end user,  An exceptional understanding of data analysis tools,  Experience applying theoretical models in an applied environment, A degree in Computer Science, Mathematics, Statistics or another quantitative discipline.,  Excellent communication skills (both verbal and written) and confidence in presenting ideas and findings to stakeholders with the right level of detail,  Experience with using solutioning approaches like Opportunity Solution Tree or something similar in order to independently identify top opportunities is nice to have",
    "description": "<p>We are a Berlin-based startup that has successfully established a leading B2B marketplace for industrial metal trading across Europe.</p><br><p>The multi-billion-euro metal trading industry is operated on Excel, PDF and Email. We are on a mission to transform buying and selling in one of the oldest industries of the modern world with seamless and intuitive digital solutions. Our technologies increase liquidity, accelerate transactions, reduce scrapping rates and enhance buying convenience for hundreds of steel and metal distributors across Europe.</p><br><p>The Opportunity</p><br><p>Join our VC-backed company during this exciting phase of growth. We are creating a Data Team to oversee data analysis, data engineering and data science. As a Data Scientist, your primary contribution will be to develop our material matchmaking algorithm from zero to one, enabling spotting of new transactions and realizing direct impact on new transaction growth.</p><br><p>This position is based full-time in our vibrant Berlin office. We believe that working together in a dynamic office setting fosters collaboration and accelerates the growth of our ambitious startup.</p><br><p>Tasks</p><ul><li>Work closely with Product to understand customer/business needs, success metrics and priorities to plan out your own solution space and roadmap.</li><li>Develop material recommendation algorithms based on live material inventory, purchase behavior and buying preferences.</li><li>Develop models and algorithms to aggregate, clean, structure and standardize supplier inventory data from various data sources and formats including Excel, PDF, ERP and unstructured natural language.</li><li>Design and analyze large-scale A/B tests to continuously improve and iterate algorithm performance.</li><li>Evaluate algorithm performance to identify improvement opportunities.</li><li>Proactively communicate, share your conclusions, and explain complex topics tailored to diverse audiences.</li><li>Push new ideas into the design and concept funnel while keeping business priorities, trade-offs, and technical feasibility in mind.</li><li>Create, develop, and maintain metrics on dashboards to measure algorithm performance and the value generated for our customers and for the company.<br> Requirements</li><li>At least 2 years of experience working in data science or machine learning or statistical modeling.</li><li>Experience working with data querying languages (e.g. SQL), scripting languages (e.g. Python) or statistical/mathematical software (e.g. Matlab).</li><li>Experience working with Product and Business stakeholders in order to understand the customer problems and goals for which you would be building out data centric solutions.</li><li>Ability to communicate and work well with Technology teams to take the solution to the actual end user.</li><li>An exceptional understanding of data analysis tools, techniques and limitations, statistics concepts, and A/B testing.</li><li>Experience applying theoretical models in an applied environment.</li><li>A degree in Computer Science, Mathematics, Statistics or another quantitative discipline.</li><li>Excellent communication skills (both verbal and written) and confidence in presenting ideas and findings to stakeholders with the right level of detail.</li><li>Experience with using solutioning approaches like Opportunity Solution Tree or something similar in order to independently identify top opportunities is nice to have.<br><strong>Nice-to-Haves:</strong></li><li>AI Systems: Exposure to AI in a professional environment or at least in your free time.</li><li>Technical Skills: Professional exposure to TensorFlow, PyTorch, Keras or other AI/ML libraries.</li><li>Cloud Experience: Experience with using AI models on AWS or GCP.<br> Benefits</li><li>Ownership of projects with a focus on outcomes rather than time-tracking.</li><li>Fast-paced yet collaborative culture fostering individual performance and teamwork.</li><li>Competitive compensation based on experience.</li><li>Home Office Tuesdays.</li><li>Beautiful office located in the heart of Prenzlauer Berg, Berlin.</li><li>Friday drinks on us!</li></ul><br>"
  },
  {
    "id": 91,
    "title": "Data Scientist Generative AI (m/w/d)",
    "company": "Materna Information & Communications SE",
    "locations": "Berlin",
    "skills": "Python, SQL, Mathematik, Data Science, Data Analysis, AI, Big Data, Hadoop, Kafka, Keras, TensorFlow, Deep Learning, Kernel Methods, J2EE, Bayesian, PyTorch, NLTK, Bidirectional Encoder Representations from Transformers, Spark, R, Torch, Splunk, GAN, Physik",
    "posted_at": "2024-07-19",
    "is_remote": "True",
    "snippet_fragments": "    ber\u00e4tst du unsere Partner zu Themen rund um die k\u00fcnstliche Intelligenz und pr\u00e4sentierst die Ergebnisse unseren Auftraggebern,     designst du skalierbare Data Analytics-Plattformen und Komponenten,     entwickelst du die KI-Strategie weiter und kooperierst mit anderen Materna-Gesch\u00e4ftsbereichen,     f\u00fchrst du Schulungen im Bereich Data Science durch,     Ein erfolgreich abgeschlossenes Studium mit Schwerpunkt (Wirtschafts-)Informatik,     Mehrj\u00e4hrige Erfahrungen mit Data Analytics oder Machine Learning-Projekten, Fundiertes Wissen \u00fcber generative KI-Modelle, einschlie\u00dflich aber nicht beschr\u00e4nkt auf Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs) und Transformer-basierte Modelle f\u00fcr die Generierung von Text und Bildern.,     Praktische Erfahrung mit spezialisierten Tools und Frameworks f\u00fcr generative KI, OpenAI's GPT-Reihe, Google's BERT und T5, oder spezialisierte Bibliotheken wie PyTorch Lightning oder FastAI f\u00fcr generatives Deep Learning.,     Kenntnisse im Umgang mit gro\u00dfen Datens\u00e4tzen und dem Training von ressourcenintensiven Modellen,     Erfahrung in der Anwendung generativer KI-Modelle in realen Szenarien, zur Inhaltsproduktion, Datenanreicherung, Anomalieerkennung oder zur Simulation und Vorhersage von Szenarien.,     Kreativit\u00e4t und Innovationsf\u00e4higkeit bei der Identifizierung und Umsetzung neuer Anwendungsf\u00e4lle f\u00fcr generative KI in verschiedenen Branchen und Bereichen, Praktische Erfahrungen im maschinellen Lernen, z, in den Bereichen Natural Language Processing, Umfassende Erfahrung mit SQL, Python, R und andere relevante ML-Bibliotheken, idealerweise zudem Erfahrung mit TensorFlow, Keras, NLTK, Torch, Spark, Hadoop, Java EE, Kafka oder splunk,     Sehr gute Deutsch- sowie gute Englischkenntnisse in Wort und Schrift ",
    "description": "<ul><li>Materna Information &amp; Communications SE</li><li>Berlin</li><li>Dortmund</li><li>D\u00fcsseldorf</li><li>Frankfurt am Main</li><li>Hamburg</li><li>K\u00f6ln</li><li>M\u00fcnchen</li></ul><p>In einer digitalen Gesellschaft sind Daten die wichtigste Ressource, um den gro\u00dfen Herausforderungen wie Klimawandel, gesellschaftliche Teilhabe und Nachhaltigkeit zu begegnen. Die Bereiche Gesundheitsvorsorge, Mobilit\u00e4t, Energie- und Ressourceneffizienz und Umweltschutz k\u00f6nnen dabei von der Datennutzung \u00fcberproportional profitieren.</p><br><p>Bei der Bereitstellung und Verarbeitung gro\u00dfer, verteilter Datenmengen kommen innovative Technologien, wie Cloud-Computing, Internet of Things, Big Data und K\u00fcnstliche Intelligenz zur Anwendung.</p><br><p>Die mit diesen Daten und Technologien verbundenen Chancen und Potentiale f\u00fcr datengetriebene Gesch\u00e4ftsmodelle und Anwendungen zu heben, bestimmt das Handeln in Unternehmen und Beh\u00f6rden in der Digitalen Daten\u00f6konomie der Zukunft.</p><br><p>Daher arbeiten unsere interdisziplin\u00e4ren Teams tagt\u00e4glich intensiv daran unsere Kunden aus Wirtschaft und Verwaltung eine optimale Wertsch\u00f6pfung der Daten zu bieten. Hierzu setzen wir durch k\u00fcnstliche Intelligenz gesteuerte Applikationen ein, um Bev\u00f6lkerungs- und Katastrophenschutz, Mobilit\u00e4tsdatenplattformen sowie Smart Citys in die digitale Zukunft zu f\u00fchren. Werde auch du Teil unserer digitalen Erfolgsgeschichte und komm als <strong>Data Scientist Generative AI (m/w/d)</strong> zu uns an Bord!</p><br><p><strong>ALS DATA SCIENTIST GENERATIVE AI BEI MATERNA</strong></p><ul><li>konzeptionierst und entwickelst du hoch performante Data Analytics- und Machine Learning-L\u00f6sungen und setzt diese in unseren spannenden Projekten um.</li><li>entwirfst und implementierst du innovative Anwendungen im Bereich der generativen KI, wie z.B. automatisierte Textgenerierung, Bilderkennung und -bearbeitung, um neue Gesch\u00e4ftsm\u00f6glichkeiten und Effizienzsteigerungen zu erschlie\u00dfen.</li><li>ber\u00e4tst du unsere Partner zu Themen rund um die k\u00fcnstliche Intelligenz und pr\u00e4sentierst die Ergebnisse unseren Auftraggebern.</li><li>designst du skalierbare Data Analytics-Plattformen und Komponenten, richtest sie ein und betreust diese.</li><li>entwickelst du die KI-Strategie weiter und kooperierst mit anderen Materna-Gesch\u00e4ftsbereichen, um neue Data Analytics und Machine Learning-Anwendungsf\u00e4lle zu identifizieren.</li><li>f\u00fchrst du Schulungen im Bereich Data Science durch.</li></ul><p><strong>DAS BRINGST DU MIT</strong></p><ul><li>Ein erfolgreich abgeschlossenes Studium mit Schwerpunkt (Wirtschafts-)Informatik, Mathematik, Physik o. \u00c4.</li><li>Mehrj\u00e4hrige Erfahrungen mit Data Analytics oder Machine Learning-Projekten, idealerweise im \u00f6ffentlichen Sektor</li><li>Fundiertes Wissen \u00fcber generative KI-Modelle, einschlie\u00dflich aber nicht beschr\u00e4nkt auf Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs) und Transformer-basierte Modelle f\u00fcr die Generierung von Text und Bildern.</li><li>Praktische Erfahrung mit spezialisierten Tools und Frameworks f\u00fcr generative KI, wie z.B. OpenAI's GPT-Reihe, Google's BERT und T5, oder spezialisierte Bibliotheken wie PyTorch Lightning oder FastAI f\u00fcr generatives Deep Learning.</li><li>Kenntnisse im Umgang mit gro\u00dfen Datens\u00e4tzen und dem Training von ressourcenintensiven Modellen, einschlie\u00dflich Optimierungstechniken zur Effizienzsteigerung.</li><li>Erfahrung in der Anwendung generativer KI-Modelle in realen Szenarien, z.B. zur Inhaltsproduktion, Datenanreicherung, Anomalieerkennung oder zur Simulation und Vorhersage von Szenarien.</li><li>Kreativit\u00e4t und Innovationsf\u00e4higkeit bei der Identifizierung und Umsetzung neuer Anwendungsf\u00e4lle f\u00fcr generative KI in verschiedenen Branchen und Bereichen.</li><li>Praktische Erfahrungen im maschinellen Lernen, z. B. in den Bereichen Natural Language Processing, Deep Learning, Bayesian Methods, logikbasiertes maschinelles Lernen oder Kernel Methods mit Anwendungen in der Analyse von strukturierten und unstrukturierten Daten</li><li>Umfassende Erfahrung mit SQL, Python, R und andere relevante ML-Bibliotheken, idealerweise zudem Erfahrung mit TensorFlow, Keras, NLTK, Torch, Spark, Hadoop, Java EE, Kafka oder splunk</li><li>Sehr gute Deutsch- sowie gute Englischkenntnisse in Wort und Schrift</li></ul><p><strong>DEINE VORTEILE</strong></p><ul><li>Flexible Arbeitszeit ohne Kernarbeitszeit</li><li>Mobiles Arbeiten</li><li>Come-as-you-are-Mentalit\u00e4t</li><li>Duz-Kultur und flache Hierarchien</li><li>Events: Mal fachlich wie unsere Brown Bag Sessions und mal zwanglos bei unserer Weihnachtsfeier.</li><li>Paten-Konzept f\u00fcr deine individuelle Einarbeitung</li><li>Fahrradleasing mit JobRad</li><li>Betriebliche Altersvorsorge</li><li>Anna Pax</li><li>Talent Acquisition Manager</li><li>+49 231 5599 - 5563</li><li>anna.pax@materna.group</li></ul><br>"
  },
  {
    "id": 92,
    "title": "Data Engineer (m/w/d)",
    "company": "Bertrandt AG",
    "locations": "Berlin",
    "skills": "SQL, Dashboards, Tableau, Alteryx, Data mining, APIs",
    "posted_at": "2024-07-19",
    "is_remote": "True",
    "snippet_fragments": "",
    "description": "<p><strong>DATA ENGINEER (M/W/D)</strong></p><br><p><strong>Arbeitsort:</strong> 13629, Berlin</p><br><p><strong>Was Sie erwartet:</strong></p><ul><li>Erhebung und Auswertung von Fertigungsdaten</li><li>Kreieren digitaler Dashboards zur Visualisierung</li><li>Erstellung und Reporting von Fertigungs- und Forschung &amp; Entwicklung KPIs</li></ul><p><strong>Was Sie mitbringen:</strong></p><ul><li>Abschluss: Studium der Ingenieurwissenschaft, Informatik oder vergleichbar</li><li>Verst\u00e4ndnis: von Datenvisualisierung und Datenmodellen, sowie Expertenwissen in Datenanalyse (tidy, transform, visualize, model, communicate)</li><li>Tools: Tableau und Tableau Server, Alteryx und Alteryx Server, Grundkenntnisse in statistischer Programmierung (z.B. R-Studio), idealerweise Erfahrung im \u201eData-Mining&quot;</li><li>Erfahrung: in der Verkn\u00fcpfung unterschiedlicher Datenquelle wie SQL und API und in der Erhebung von Fertigungsdaten</li></ul><p>Neben einem <strong>unbefristeten Arbeitsvertrag</strong> und <strong>30 Tagen Urlaub</strong> warten zahlreiche Sozialleistungen und Benefits auf Sie.</p><br><p>Sind Sie bereit f\u00fcr Ihre n\u00e4chste berufliche Herausforderung? Dann laden Sie in nur wenigen Minuten Ihren Lebenslauf hoch.</p><br><p><strong>Wir freuen uns auf Ihre Bewerbung und stehen f\u00fcr Fragen, sowie weitere Informationen gerne zur Verf\u00fcgung!</strong></p><br><p><strong>Was wir k\u00f6nnen:</strong></p><ul><li>Verantwortungsvolle Aufgaben</li><li>Mobiles Arbeiten</li><li>Eigenverantwortliches Arbeiten</li><li>Intensive Einarbeitung</li><li>Attraktive Verg\u00fctung</li><li>Betriebliche Altersvorsorge und BU-Versicherung</li><li>Teamorientierte Arbeitsweise</li></ul><p><strong>Kontakt:</strong></p><br><p>Felicitas Schneider</p><br><p>Tel.: +49 7034 65612497</p><br><p><strong>Was wir k\u00f6nnen:</strong></p><br><p>Verantwortungsvolle Aufgaben</p><br><p>Mobiles Arbeiten</p><br><p>Eigenverantwortliches Arbeiten</p><br><p>Intensive Einarbeitung</p><br><p>Attraktive Verg\u00fctung</p><br><p>Betriebliche Altersvorsorge und BU-Versicherung</p><br><p>Teamorientierte Arbeitsweise</p><br><p>Verantwortungsvolle Aufgaben</p><br><p>Mobiles Arbeiten</p><br><p>Eigenverantwortliches Arbeiten</p><br><p>Intensive Einarbeitung</p><br><p>Attraktive Verg\u00fctung</p><br><p>Betriebliche Altersvorsorge und BU-Versicherung</p><br><p>Teamorientierte Arbeitsweise</p><br><p><strong>KONTAKT:</strong></p><br><p>Felicitas Schneider</p><br><p>Tel.: +49 7034 65612497</p><br>"
  },
  {
    "id": 93,
    "title": "Data Engineer (f/m/d)",
    "company": "Aleph Alpha",
    "locations": "Berlin",
    "skills": "Python, Machine Learning, Data Science, AWS, Data Pipelines, GCP, AI, Azure, Data Wrangling, Go, Excel, Web Services",
    "posted_at": "2024-07-19",
    "is_remote": "False",
    "snippet_fragments": "   Prepare datasets for various Machine Learning use cases,    Build and automate preprocessing pipelines tailored to different applications,    Provide reliable data services that enable other teams to build new products on top of our data infrastructure,    You have 3 years of experience working as a Data Engineer,    You are fluent in Python and at least one other programming language,    You possess a strong understanding of distributed systems and how to leverage them for efficient data pipelines,    You have a solid software engineering background with a focus on writing clean and pragmatic code,  You excel in data wrangling, including extracting, transforming, cleaning, and standardizing data from multiple sources.,    You are knowledgeable about Generative AI use cases and the critical role of data in developing new solutions,    Experience working in multicloud environments (e,    Experience with Machine Learning and/or Data Science,    Experience in Golang is a plus,    Become part of an AI revolution",
    "description": "<p><strong>OVERVIEW:</strong></p><br><p>Join our forward-thinking data team to create advanced data tools for GenAI applications. We use data to help our customers and support our own new products and research. As a Data Engineer, you will play a crucial role in building and optimizing data infrastructure, ensuring our solutions are robust, scalable, and ready for the challenges of tomorrow.</p><br><p><strong>YOUR RESPONSIBILITIES:</strong></p><ul><li>Design and implement scalable processes to handle large-scale data (terabytes of text) for storage, versioning, and documentation.</li><li>Architect, develop, and maintain web services that allow for efficient consumption of harvested data.</li><li>Collaborate with researchers and software engineers to enhance data collection methodologies.</li><li>Prepare datasets for various Machine Learning use cases, including Generative AI.</li><li>Build and automate preprocessing pipelines tailored to different applications</li><li>Provide reliable data services that enable other teams to build new products on top of our data infrastructure.</li></ul><p><strong>YOUR PROFILE:</strong></p><ul><li>You have 3+ years of experience working as a Data Engineer.</li><li>You are fluent in Python and at least one other programming language.</li><li>You possess a strong understanding of distributed systems and how to leverage them for efficient data pipelines.</li><li>You have a solid software engineering background with a focus on writing clean and pragmatic code.</li><li>You excel in data wrangling, including extracting, transforming, cleaning, and standardizing data from multiple sources.</li><li>You are knowledgeable about Generative AI use cases and the critical role of data in developing new solutions.</li></ul><p><strong>NICE IF YOU HAVE:</strong></p><ul><li>Experience working in multicloud environments (e.g., GCP, Azure, AWS) and on-premise setups.</li><li>Experience with Machine Learning and/or Data Science.</li><li>Experience in Golang is a plus</li></ul><p><strong>WHAT YOU CAN EXPECT FROM US:</strong></p><ul><li>Become part of an AI revolution</li><li>30 Days of paid vacation</li><li>Flexible working hours</li><li>Join a dynamic start-up and a rapidly growing team</li><li>Work with international industry and science experts</li><li>Take on responsibility and shape our company and technology</li><li>Regular team events</li></ul><br>"
  },
  {
    "id": 94,
    "title": "(Senior) DevOps Engineer - Data Analytics & Management Plattform (m/w/d)",
    "company": "Bundesdruckerei GmbH",
    "locations": "Berlin",
    "skills": "Python, Data Analysis, Ansible, Ceph, DevOps, GitLab, Kanban, OpenShift, OpenStack, Scrum, Unit Testing, Terraform, Red Hat Linux, IaC",
    "posted_at": "2024-07-19",
    "is_remote": "False",
    "snippet_fragments": "Konzeption, Aufbau und Wartung von Red Hat OpenStack (RHOSP) und von Multicluster-L\u00f6sungen mit Red Hat OpenShift (ab Version 4), Anlage, Verwaltung und Optimierung von OpenShift- Ressourcen und von der virtuellen Netzwerkinfrastruktur,   Implementierung und Konzeption von Automation als IaC (bspw,   Planung und Implementierung von Storagel\u00f6sungen mit Red Hat Ceph und Data Foundation, \u00dcbernahme von Testaktivit\u00e4ten, in Form von beispielsweise in Form von Unit Tests in einem BDD- Set-up,   Erfolgreich abgeschlossenes Studium der Informatik bzw, einer vergleichbaren Fachrichtung oder eine IT-technische Ausbildung mit einschl\u00e4giger Berufspraxis in vergleichbarer Position ,   Expertise im Aufbau und Betrieb von OpenStack und OpenShift , Python, Shell, Ansible, Terraform) und im Umgang mit agilen Methoden (Scrum, Kanban) und agiles Mindset,   Kenntnisse in der Automatisierung und Verwaltung von Linux-Systemadministrationsaufgaben sowie verteilten Versionierungssystemen (insb",
    "description": "<p>Als (Senior) DevOps Engineer - Data Analytics &amp; Management Plattform (m/w/d) arbeiten Sie an PLAIN, einer Datenanalyse- und KI-Plattform mit, welche die Basis f\u00fcr Data-Engineering-Projekte in einem Multi-Mandanten-Setup bildet. Hierzu geh\u00f6ren der Aufbau der technischen Infrastruktur als On-Premise L\u00f6sung im Rechenzentrum und die Entwicklung bzw. Integration von bestehenden Softwaresystemen f\u00fcr die Dienste Virtualisierung, Containerisierung, Automation und \u00dcberwachung.</p><br><p>PLAIN steht f\u00fcr \u201ePlatform Analysis and Information System&quot;. Mit PLAIN bef\u00e4higen wir unsere Kunden, Daten f\u00fcr die politische Entscheidungsfindung zu nutzen und das effiziente Arbeiten mit Daten zu professionalisieren. In unserem Arbeitsalltag arbeiten wir eng mit allen Bundesministerien und deren Datenlaboren zusammen und legen Wert auf Pers\u00f6nlichkeiten mit Eigenverantwortung und Teamgeist. Mehr Informationen unter https://www.bundesdruckerei.de/de/innovation-hub/plain.<br><strong>Ihr Aufgabenbereich</strong></p><ul><li>Konzeption, Aufbau und Wartung von Red Hat OpenStack (RHOSP) und von Multicluster-L\u00f6sungen mit Red Hat OpenShift (ab Version 4)</li><li>Anlage, Verwaltung und Optimierung von OpenShift- Ressourcen und von der virtuellen Netzwerkinfrastruktur</li><li>Implementierung und Konzeption von Automation als IaC (bspw. mit Terraform und Ansible)</li><li>Planung und Implementierung von Storagel\u00f6sungen mit Red Hat Ceph und Data Foundation, sowie dem Betrieb eines Zero-Trust- Networks</li><li>\u00dcbernahme von Testaktivit\u00e4ten, in Form von beispielsweise in Form von Unit Tests in einem BDD- Set-up<br><strong>Ihr Profil</strong><br></li><li>Erfolgreich abgeschlossenes Studium der Informatik bzw. einer vergleichbaren Fachrichtung oder eine IT-technische Ausbildung mit einschl\u00e4giger Berufspraxis in vergleichbarer Position</li><li>Expertise im Aufbau und Betrieb von OpenStack und OpenShift</li><li>Know-how im Bereich allgemeine Programmierung/Skripting/IaC (z.B. Python, Shell, Ansible, Terraform) und im Umgang mit agilen Methoden (Scrum, Kanban) und agiles Mindset</li><li>Kenntnisse in der Automatisierung und Verwaltung von Linux-Systemadministrationsaufgaben sowie verteilten Versionierungssystemen (insb. GitLab)</li><li>Praktisches Wissen in Infrastructure Automation, Confiuguration Management, Log Management und Monitoring</li><li>Erfahrung in der Sicherung von IT-Infrastrukturen nach ISO 27001 oder BSI- Grundschutz sowie im Betrieb von Softwarel\u00f6sungen bei externen Cloud-Anbietern</li></ul><br>"
  },
  {
    "id": 95,
    "title": "Data Engineer",
    "company": "IntApp",
    "locations": "Berlin",
    "skills": "Python, SQL, Data Analysis, Data Pipelines, Azure, Docker, JSON, Kubernetes, Load Balancing, NoSQL, NumPy, Pandas, Scrapy, XPath, Orchestration, Web Scraping, Containerisation, Exploratory Testing, SOLID",
    "posted_at": "2024-07-18",
    "is_remote": "False",
    "snippet_fragments": "     Competitive base salary plus variable compensation and equity,      Generous paid parental leave, including adoptive leave,        Family Formation benefit offered by Carrot,        Wellness programs and benefits provided by Modern Health,        Paid volunteer time off and donation matching for the causes you care about,      Opportunities for personal growth and professional development supported by a community of talented professionals,      An open, collaborative environment where your background and contributions are valued,      Experience at a growing public company where you can make an impact and achieve your goals,      Open offices and break areas stocked with beverages and snacks",
    "description": "<p>As a Data Engineer at Intapp, you will play a critical role in designing, building, and maintaining data pipelines and data loaders, as well as scraping data from various sources. You will ensure the quality, integrity, and availability of our data, which is essential for our data-driven decision-making processes.</p><br><p>What you will do:</p><ul><li>Develop, deploy, and maintain web scraping tools to gather data from targeted websites efficiently and reliably.</li><li>Design and implement data scraping architectures that are scalable and robust.</li><li>Design, develop, and maintain scalable and efficient data pipelines to ingest and process large volumes of data from diverse sources.</li><li>Build and optimize data loaders to ensure seamless data integration and transformation.</li><li>Collaborate with data scientists, analysts, and other stakeholders to understand data requirements and deliver high-quality data solutions.</li><li>Implement and maintain data quality checks to ensure the accuracy and consistency of data.</li><li>Perform exploratory data analysis to identify trends, patterns, and insights.</li><li>Stay up-to-date with industry best practices in web scraping, data analytics, and data privacy regulations.</li></ul><p>What you will need:</p><ul><li>Strong programming skills in Python.</li><li>Experience in building and deploying web scrapers using tools like Scrapy, Beautiful Soup, XPath, etc.</li><li>Knowledge of parallel and distributed programming including load balancing, scalability, and concurrency</li><li>Familiarity with data storage technologies like databases (SQL, NoSQL) and data formats (JSON, CSV, etc.)</li><li>Problem-solving skills and attention to detail, ensuring accuracy and quality in scraped data.</li><li>Strong communication skills to effectively convey findings and collaborate with team members.</li></ul><p>Bonus if you have:</p><ul><li>Experience with data manipulation libraries (e.g., pandas, NumPy).</li><li>Solid analytical skills with the ability to analyze complex datasets and extract actionable insights.</li><li>Familiarity with Azure and their data services.</li><li>Knowledge of data governance and data security best practices.</li><li>Experience with containerization and orchestration tools (e.g., Docker, Kubernetes).</li></ul><p>What you will get:</p><br><p>In return for your passion, commitment, and collaborative approach, we offer:</p><ul><li>Competitive base salary plus variable compensation and equity</li><li>A flexible work environment</li><li>Generous paid parental leave, including adoptive leave</li><li>Traditional comprehensive benefits, plus:</li><li>Flexible Paid Time Off</li><li>Family Formation benefit offered by Carrot</li><li>Wellness programs and benefits provided by Modern Health</li><li>Paid volunteer time off and donation matching for the causes you care about</li><li>Opportunities for personal growth and professional development supported by a community of talented professionals</li><li>An open, collaborative environment where your background and contributions are valued</li><li>Experience at a growing public company where you can make an impact and achieve your goals</li><li>Open offices and break areas stocked with beverages and snacks</li></ul><p>#Li-MT1</p><br><p>Intapp provides equal employment opportunities to all qualified applicants and will make hiring decisions without regard to race, color, sex, sexual orientation, gender identity or expression, religion, national origin or ancestry, age, disability, marital status, pregnancy, protected veteran status, protected genetic information, political affiliation, or any other characteristic protected by federal, state or local laws. All offers are contingent upon passing a criminal history and other background checks if applicable to the position.</p><br><p>Please note: Intapp will not hire through text message, social media, or email alone. We will never extend a job offer unless you have been contacted directly by an Intapp recruiter and have participated in the interview process which will generally consist of 3 or more virtual or in person meetings. Please note that Intapp only uses company email addresses, which contain &quot;@intapp.com&quot; or &quot;@dealcloud.com&quot; to communicate with candidates via email. Intapp will never ask for financial information of any kind or for any payment during the job application process. We post all legitimate job openings on the Intapp Career Site at</p><br><p>https://www.intapp.com/working-at-intapp/<br> . If you believe you were a victim of such a scam, you may contact your local authorities. Intapp is not responsible for any claims, losses, damages, or expenses resulting from scammers.</p><br>"
  },
  {
    "id": 96,
    "title": "Data Scientist",
    "company": "SumUp",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, AI, Big Data, NumPy, Pandas, scikit-learn, Algorithms, Statistik",
    "posted_at": "2024-07-18",
    "is_remote": "False",
    "snippet_fragments": "  3 years of experience working with customer behavioural models,   Excellent understanding of AI/ML and Statistics, Coding proficiency in Python, including experience with open-source libraries and frameworks such as scikit-learn, numpy, and pandas.,   Strong adherence to coding best practices and a commitment to delivering high-quality production code,   Experience working both independently and as a key team member, Ability to explain data storytelling, analysis, and insights to business leaders and both technical and non-technical stakeholders., Flexibility and a proactive approach, with the capability to handle diverse tasks in a fast-paced environment.,   Opportunity to work with SumUppers globally on large-scale fintech products used by millions of businesses worldwide,   A dedicated annual L&D budget of 2,000 for attending conferences and/or advancing your career through further education,   A corporate pension scheme where we match up to 20% of your contributions ,   \ufe0f Numerous other benefits such as Urban Sports Club subsidy,   SumUp is a leading financial technology company, We're the financial partner of choice for more than 4 million merchants in over 35 markets, We collectively build, plan and fine-tune the technology that drives SumUp and empowers small businesses around the world.,   We believe in the everyday hero",
    "description": "<p><strong>About the team:</strong></p><br><p>Within the Global Operations organisation, our mission is to build the best customer experience in the fintech industry by delivering an effortless experience to all our merchants. We are seeking a skilled and passionate Data Scientist to join our talented AI and Data Team and contribute to the development of customer behavioural models and algorithms that will drive our customer support service to new heights, by identifying customers at risk and supporting Customer Success teams to prioritize high-value customers in their campaigns.</p><br><p>As a Data Scientist at SumUp, you will be responsible for designing, testing and implementing behavioural models and evaluating the effectiveness of real campaigns for different channels in support and across the company. You will directly impact the revenue of the company by developing, improving and scaling state-of-the-art ML models such as churn prediction, identification of seasonality businesses, segmentation prediction for early merchants right after signup, and CLV among others. Your expertise will be crucial in driving the success of our initiatives. You will work closely with cross-functional teams, analysts, ML engineers, data scientists and product managers, to translate business requirements into ML solutions. Your contributions will shape the future of our company and help us grow healthy with a customer-centric focus.</p><br><p><strong>What you'll do</strong></p><ul><li>Design, develop, analyse, and evaluate customer behaviour models such as churn prediction, seasonality trends, customer segmentation, and CLV.</li><li>Utilise machine learning techniques (supervised and unsupervised) and statistical methods for hypothesis testing (experimentation) to optimise business needs.</li><li>Clean and manipulate large datasets using SQL and big data tools.</li><li>Visualise insights and results, and present findings to stakeholders across the organisation.</li><li>Own end-to-end implementation of models, from design to production and measurement strategies.</li><li>Make recommendations and derive insights based on analysis and models, evaluating their impact on the business.</li><li>Collaborate with cross-functional teams to implement data-driven strategies.</li><li>Regularly exchange knowledge with Data Scientists at various levels of seniority within the company.</li></ul><p><strong>You'll be great for this position if you have:</strong></p><ul><li>3+ years of experience working with customer behavioural models.</li><li>Excellent understanding of AI/ML and Statistics, along with practical experience in hypothesis testing.</li><li>Coding proficiency in Python, including experience with open-source libraries and frameworks such as scikit-learn, numpy, and pandas.</li><li>Strong adherence to coding best practices and a commitment to delivering high-quality production code.</li><li>Experience working both independently and as a key team member.</li><li>Ability to explain data storytelling, analysis, and insights to business leaders and both technical and non-technical stakeholders.</li><li>Flexibility and a proactive approach, with the capability to handle diverse tasks in a fast-paced environment.</li></ul><p><strong>Why you should join SumUp:</strong></p><br><p>Opportunity to work with SumUppers globally on large-scale fintech products used by millions of businesses worldwide, from our Berlin office. This involves an office-first setup.</p><br><p>Commitment to Diversity and Inclusion: Be part of a workplace that values and promotes diversity, fostering an inclusive environment where everyone's perspectives are respected and embraced</p><br><p>A dedicated annual L&amp;D budget of \u20ac2,000 for attending conferences and/or advancing your career through further education.</p><br><p>Enrolment onto our VSOP program: You will own a stake in SumUp's future success</p><br><p>A corporate pension scheme where we match up to 20% of your contributions</p><br><p>30 Days Sabbatical: Enjoy the unique opportunity to take a well-deserved break with our 30 days sabbatical benefit after completing 3 years of employment with SumUp.</p><br><p>Referral Bonus: Earn additional rewards by referring talented individuals to join the SumUp team.</p><ul><li>\ufe0f Numerous other benefits such as Urban Sports Club subsidy, Kita placement assistance, relocation assistance, subsidised office lunches.</li></ul><p><strong>About us:</strong></p><br><p>SumUp is a leading financial technology company, founded in 2012 with the goal of empowering small businesses around the globe. We're the financial partner of choice for more than 4 million merchants in over 35 markets. We collectively build, plan and fine-tune the technology that drives SumUp and empowers small businesses around the world.</p><br><p>We believe in the everyday hero. Those who have the courage to follow their passion and who have the strength and determination to realise their dreams. Small business owners are at the heart of all we do, so we're creating powerful, easy-to-use financial solutions to help them run their business. With a founders mentality and a 'team-first attitude' our diverse teams across Europe, South America, and the United States work together to ensure that small business owners can be successful doing what they love.</p><br><p>SumUp is an Equal Employment Opportunity employer that proudly pursues and hires a diverse workforce. SumUp does not make hiring or employment decisions on the basis of race, colour, religion or religious belief, ethnic or national origin, nationality, sex, gender, gender identity, sexual orientation, disability, age or any other basis protected by applicable laws or prohibited by Company policy. SumUp also strives for a healthy and safe workplace and strictly prohibits harassment of any kind.</p><br><p><strong>Job Application Tip</strong></p><br><p>We recognise that candidates feel they need to meet 100% of the job criteria in order to apply for a job. Please note that this is only a guide. If you don't tick every box, it's ok too because it means you have room to learn and develop your career at SumUp.</p><br>"
  },
  {
    "id": 97,
    "title": "Senior Data Engineer - Platform (all genders)",
    "company": "Babbel",
    "locations": "Berlin",
    "skills": "Python, Machine Learning, AWS, Data Analysis, Cloud, ETL, Airflow, Spark, DevOps, Terraform, GitHub, Codebase, PySpark, Databricks, Snowflake",
    "posted_at": "2024-07-18",
    "is_remote": "False",
    "snippet_fragments": " Mastered Python and PySpark and want to raise the bar for our codebase ,  Confidence in working extensively with AWS services and cloud architectures ,  Broad experience implementing complex ETL/streaming pipelines and managing data lakehouses (like with Databricks) and warehouses (like Snowflake) ,  Familiarity with Terraform and Github Actions , Been there, done that, at testing, logging, monitoring and alerting (better yet if you still love it!),  Fluency in written and spoken English ,  Scheduled complex data flows with Airflow or DBT ,  Been keen on evangelizing the DevOps mindset across your workplace ,  Showed interest in Machine Learning / have experience building ML-driven or algorithmic data products ,  Enjoy 30 vacation days and the chance to take a 3-month Sabbatical, Plus family and life situation counseling, Decide how, when and from where you want to work with our flexible working hours and remote friendly options as Jobbatical (up to 3 months inside the EU) or work from our fully equipped office with nap, faith and family rooms.,  Learn and grow with the internal learning opportunities",
    "description": "<p>We are looking for a Senior Data Engineer (full-time) to join our Data Engineering team in Berlin.</p><br><p>As our newest Data Engineer in Data Platform team, your mission at Babbel will be to change the face of language learning one automation at a time. Working alongside your teammates in a fast-paced environment, you'll be collaborating and diving into different areas such as Data Engineering, Data Analytics, Site Reliability, InfoSec and many more to deliver innovations right on our Babbel learners hands.</p><br><p><strong>You will:</strong></p><ul><li>Shape our data platform</li><li>Secure our precious data and the infrastructure it relies upon</li><li>Keep the data moving towards where is actually needed (streaming and batch) with well-tested and performant solutions</li><li>Automate them all!</li><li>Monitoring and alerting (might be boring, but... refer to the previous point)</li><li>Participate in our knowledge sharing sessions (we're a learning company after all!)<br><strong>You have:</strong></li><li>Mastered Python and PySpark and want to raise the bar for our codebase</li><li>Confidence in working extensively with AWS services and cloud architectures</li><li>Broad experience implementing complex ETL/streaming pipelines and managing data lakehouses (like with Databricks) and warehouses (like Snowflake)</li><li>Familiarity with Terraform and Github Actions</li><li>Been there, done that, at testing, logging, monitoring and alerting (better yet if you still love it!)</li><li>Fluency in written and spoken English<br><strong>Nice to have:</strong></li><li>Scheduled complex data flows with Airflow or DBT</li><li>Been keen on evangelizing the DevOps mindset across your workplace</li><li>Showed interest in Machine Learning / have experience building ML-driven or algorithmic data products<br><strong>Some perks of becoming a Babbelonian:</strong></li><li>Enjoy 30 vacation days and the chance to take a 3-month Sabbatical. Plus family and life situation counseling.</li><li>Decide how, when and from where you want to work with our flexible working hours and remote friendly options as Jobbatical (up to 3 months inside the EU) or work from our fully equipped office with nap, faith and family rooms.</li><li>Learn and grow with the internal learning opportunities, and use a yearly learning &amp; development budget for external training. Learn languages with Babbel for free with your full access to Babbel &amp; Babbel Live classes.</li><li>Take advantage of your mobility benefits options and a discounted Urban Sports Club membership.</li><li>Be part of our employee communities (such as Femgineers, DE&amp;I Ambassadors and LGBTQIA groups), attend cultural and regular social events.<br> Diversity at Babbel</li></ul><p>As part of our ongoing journey towards building a diverse, equitable and inclusive company, we welcome everyone to apply, especially those individuals who are underrepresented in tech. We are a learning company, inside and out, and we encourage you to apply even if you do not fit all the technical requirements - all candidates are assessed based on skills, qualifications and on our business needs. Please state your pronouns in your application, and let us know if you'd like to be addressed by a name other than the one appearing on your official documents. If you have a disability or special need, feel welcome to inform us, so that we can provide you with the proper assistance in the application process.</p><br>"
  },
  {
    "id": 98,
    "title": "(Senior) Data Engineer (m/f/d) - Fleet Analytics",
    "company": "MOIA",
    "locations": "Berlin",
    "skills": "Python, SQL, AWS, Cloud, Data Pipelines, Airflow, Pandas, Terraform, CloudWatch, APIs, GitHub, Grafana, Jupyter, CD, Continuous Integration",
    "posted_at": "2024-07-18",
    "is_remote": "True",
    "snippet_fragments": "  Collaborate with data producing teams to ensure data quality and data consuming teams to build great data products ,  What will help you to fulfill your role ,   Extensive experience in the field of data,   Experience with building and orchestrating data pipelines (e,   Experience in Python (or similar language) and SQL ,   You know your way around developing and deploying cloud infrastructure and services (e, Proficiency with CI/CD (e.g., Github actions), Monitoring (e.g., Cloudwatch, Grafana) and Alerting,   Experience with dbt (data build tool) ,   Experience with Pandas & Jupyter Notebooks ,   Experience in designing and building (data) APIs ,  We encourage you to apply even if your profile does not meet all the requirements for the role since we are looking for a diverse range of experiences, We are certain that there will be something for everyone because we are working on such a variety of tasks and embrace individual growth at MOIA,   In case you have questions regarding your application,    Flexible working hours and possibility of flexible work arrangements depending on your needs (parenting,    Budget and monthly expense allowance for home office setup ,    Possibility of remote work from outside of Germany for up to 6 weeks per year from over 40 different countries - Connect work & travel! ,    Public transport ticket (fully subsidized) for commuting and traveling throughout Germany and discount on MOIA rides ,    Subsidized fitness club membership or bike leasing ,    Learning environment with continuous learning days, 30 vacation days, sabbatical and unpaid leave option,    Relocation support with service provider (visa,    Dog-friendly offices (at our Hamburg location) , For student & internship positions, we have an adjusted set of benefits,    We are a member of Charta der Vielfalt and are dedicated to actively fostering a workplace that celebrates and promotes diversity in various aspects such as age, At MOIA, we embrace a culture where people are accepted, respected, valued, appreciated, and included.",
    "description": "<p><strong>JOIN US AS A</strong> <strong>(SENIOR)</strong> <strong>DATA ENGINEER (M/F/D) IN OUR FLEET ANALYTICS TEAM ON A SHARED JOURNEY THAT MATTERS!</strong></p><br><p>MOIA is bringing fleets of autonomous vehicles onto the streets of Europe over the next few years. To achieve this, a holistic understanding of our complex fleet operations is essential. This is what our interdisciplinary team of analysts, data scientists and data engineers work on every day. We share a common passion about using data to create tooling that allows internal analysts and fleet operators to analyze and monitor fleet operation processes. We also build the foundational infrastructure and datasets around that tooling. By processing a diverse range of data, including vehicle telemetry, geospatial information, and operational metrics, we lay the foundational work for self-service tools, traceability and in-depth analysis.</p><br><p><strong>WHAT YOU WILL DO</strong></p><ul><li>You will play a pivotal role in shaping our analytics data infrastructure, enabling the development of customer-facing data products and driving analytical insights</li><li>Leverage cloud infrastructure to create data models accessible via our web platform, where entire vehicle fleets are monitored and managed</li><li>Collaborate closely with team members during pair-programming and feedback sessions, promoting knowledge sharing and professional growth</li><li>Collaborate with data producing teams to ensure data quality and data consuming teams to build great data products</li></ul><p><strong>WHAT WILL HELP YOU TO FULFILL YOUR ROLE</strong></p><ul><li>Extensive experience in the field of data, particularly as a data engineer or software engineer with a focus on data engineering</li><li>Experience with building and orchestrating data pipelines (e.g., Airflow, dbt)</li><li>Experience in Python (or similar language) and SQL</li><li>You know your way around developing and deploying cloud infrastructure and services (e.g., with AWS CDK or Terraform)</li><li>Proficiency with CI/CD (e.g., Github actions), Monitoring (e.g., Cloudwatch, Grafana) and Alerting</li><li>Effective communication skills in English</li></ul><p><strong>Nice to have:</strong></p><ul><li>Experience with dbt (data build tool)</li><li>Experience with AWS</li><li>Experience with Pandas &amp; Jupyter Notebooks</li><li>Experience in designing and building (data) APIs</li></ul><p>We encourage you to apply even if your profile does not meet all the requirements for the role since we are looking for a diverse range of experiences, skills, and interests. We are certain that there will be something for everyone because we are working on such a variety of tasks and embrace individual growth at MOIA.</p><br><p>In case you have questions regarding your application, you can approach the recruiter Dennis directly.</p><br><p><strong>OUR BENEFITS IN A NUTSHELL</strong></p><ul><li>Competitive salary (including bonus)</li><li>Hybrid work setup: work from home or one of our offices - you and your team decide how often to meet, blending flexibility with collaboration!</li><li>Flexible working hours and possibility of flexible work arrangements depending on your needs (parenting, care work, volunteering, etc.)</li><li>Budget and monthly expense allowance for home office setup</li><li>Possibility of remote work from outside of Germany for up to 6 weeks per year from over 40 different countries - Connect work &amp; travel!</li><li>Public transport ticket (fully subsidized) for commuting and traveling throughout Germany and discount on MOIA rides</li><li>Subsidized fitness club membership or bike leasing</li><li>Learning environment with continuous learning days, job rotation, trainings and workshops, coaching, conferences, books, and language classes</li><li>Mental health support, 1:1 sessions with external professionals and mental unload workshops</li><li>30 vacation days, sabbatical and unpaid leave option</li><li>Relocation support with service provider (visa, administration, etc.)</li><li>Dog-friendly offices (at our Hamburg location)</li></ul><p>For student &amp; internship positions, we have an adjusted set of benefits. You can find them here.</p><br><p><strong>BE WHO YOU ARE!</strong></p><br><p>We are a member of Charta der Vielfalt and are dedicated to actively fostering a workplace that celebrates and promotes diversity in various aspects such as age, gender identity, race, sexual orientation, physical or cognitive ability, and ethnicity. At MOIA, we embrace a culture where people are accepted, respected, valued, appreciated, and included.</p><br><p>In our commitment to promoting diversity and inclusivity, we regularly provide unconscious bias training to all our employees. Furthermore, we continuously strive to enhance our hiring process by ensuring a diverse hiring panel.</p><br><p>To reinforce an unbiased screening process, we kindly ask you not to include your picture, age, address, or any other details that are unrelated to your qualifications and suitability for the role.</p><br><p><strong>OUR FUTURE WORK MODEL</strong></p><br><p>Since we love to collaborate, it is clear to us that we don't want to become a fully remote company, but we also don't need to spend every day of the week in the office to do a great job.</p><br><p>Our current hybrid work approach focuses on adapting to different needs, including increased flexibility that works best for the teams and the individuals with as much self-determination as possible.</p><br><p>Get more insights on how we work on our blog to find out more about our hiring process or follow us on Instagram for a look inside MOIA.</p><br><p><strong>WHO WE ARE</strong></p><br><p>At MOIA GmbH, our team of more than 350 employees develops the technical products for our on-demand ridepooling service in the form of an end-to-end integrated product, from hub, fleet, and driver management to passenger and B2B solutions. At the same time, we want to make the vision of an autonomously driving mobility service a reality and plan to bring the first autonomous MOIA ridepooling vehicle to the streets by 2025.</p><br><p>At our offices in Berlin and Hamburg, international teams of developers, engineers, designers, and strategists work on a shared mission. As a tech company, more than half of our employees are developers. We pursue value-driven development based on our product values of comfort, reliability, safety, and privacy.</p><br><p>We aspire to be a leading company in the fields of rethinking mobility and improving urban transportation by making it more relaxed, more affordable and an entirely positive experience for everyone.</p><br><p>MOIA gets things moving. On a shared journey - towards an easier, smarter, and more meaningful future.</p><br>"
  },
  {
    "id": 99,
    "title": "Data Engineer (d/m/w) - befristet (Elternzeitvertretung)",
    "company": "Toll Collect GmbH",
    "locations": "Berlin",
    "skills": "SQL, Mathematik, Linux, Cognos, PL/SQL, Windows",
    "posted_at": "2024-07-18",
    "is_remote": "False",
    "snippet_fragments": "    Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics,      Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL),      Sie beherrschen den Umgang mit Windows und Linux einwandfrei,      Sie haben ein abgeschlossenes Studium in der Mathematik,      Sie haben Berufserfahrung im Bereich Data Engineering,     Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung,      Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung,  Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet,      Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen oder Business-Bike bis zur betrieblichen Altersversorgung,     Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung, Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu, Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen",
    "description": "<p>Referenznummer: 20728</p><br><p>Ihre Aufgaben</p><ul><li>Sie verantworten die Strukturierung und Weiterentwicklung von Datenmodellen und Datenfl\u00fcssen sowie der zugeh\u00f6rigen IT-gest\u00fctzten Prozesse</li><li>Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit</li><li>Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten</li><li>Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen</li><li>Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit, bringen eigene Ideen ein und setzen diese um</li><li>Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen</li></ul><p>Ihre Kompetenzen</p><ul><li>Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics</li><li>Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL).</li><li>Sie beherrschen den Umgang mit Windows und Linux einwandfrei</li><li>Sie haben ein abgeschlossenes Studium in der Mathematik, Informatik oder in einem vergleichbaren Studiengang</li><li>Sie haben Berufserfahrung im Bereich Data Engineering</li></ul><p>Was bieten wir</p><ul><li>Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung</li><li>Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung</li><li>Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet</li><li>Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen oder Business-Bike bis zur betrieblichen Altersversorgung</li></ul><p>Interessiert?</p><br><p>Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung. Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu. Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen.</p><br><p>Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt.</p><br><p>Ihre Ansprechperson</p><br><p>Frau Silvia Barknecht, 030/74077-8214, karriere@toll-collect.de</p><br><p>Toll Collect GmbH * Personalmanagement * Linkstra\u00dfe 4, 10785 Berlin</p><br>"
  },
  {
    "id": 100,
    "title": "Sr Staff Data Platform Software Engineer",
    "company": "ServiceNow",
    "locations": "Berlin",
    "skills": "SQL, AI, C++, Kernel, MariaDB, OO, PostgreSQL, TDD, Database Design, Data mining, C, SOLID, Architektur",
    "posted_at": "2024-07-17",
    "is_remote": "False",
    "snippet_fragments": "   In depth knowledge of computer and general systems architecture (threads,    Excellent skills in object-oriented programming combined with some C/C and SQL knowledge,    Solid understanding and experience with agile software development methodologies and working in a large,    Ability to handle multiple competing priorities in a fast-paced environment,    Skill to manage your own complex tasks,    Strong problem-solving and analytical skills and the ability to communicate them effectively in design documents and architect-level discussions,    An aptitude for learning new technologies and an itch to code,    Experience working with at least one of OS kernel,    Experience with relational databases is a plus,    6 years of experience developing professional software,    Experience with deep knowledge in one of operating systems,    Proven track record of delivering sub-modules or software features end-to-end,   ServiceNow is an Equal Employment Opportunity Employer, All qualified applicants will receive consideration for employment without regard to race, At ServiceNow, we lead with flexibility and trust in our distributed world of work",
    "description": "<p><strong>Company Description</strong></p><br><p>At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can't wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.</p><br><p>With more than 7,700+ customers, we serve approximately 85% of the Fortune 500\u00ae, and we're proud to be one of FORTUNE 100 Best Companies to Work For\u00ae and World's Most Admired Companies\u2122.</p><br><p>Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.</p><br><p>Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.<br><strong>Job Description</strong><br><strong>Team:</strong></p><br><p>ServiceNow Project RaptorDB, based on Postgres, the world's most advanced open\u2011source database, acts as a foundational data layer that will allow ServiceNow customers to process massive volumes of transactional data on the Now Platform in real time to meet the demands of AI\u2011powered applications. It adds analytical capabilities to meet advanced reporting and data mining needs. This team is building the core of RaptorDB and even the smallest optimization can have a dramatic impact on our customers and our bottom line.</p><br><p>We are looking for an experienced developer with C/C++ knowledge who wants to contribute heavily to building the very core of our ServiceNow database. You will work directly with other engineers on the Data Platform team solving challenging problems in scaling and querying large data sets efficiently both vertically and horizontally. Our work is based on Postgres with significant in-house enhancements and unique features. This is your opportunity to contribute to cutting edge database software used at massive scale.</p><br><p><strong>What you get to do in this role:</strong></p><ul><li>You'll collaborate with a team of 15+ dedicated database-internals engineers.</li><li>Be part of building the next-gen database platform using and contributing to the latest open-source technologies</li><li>Analyze storage/memory/compute performance and scalability bottlenecks in the system and build targeted software solutions</li><li>Develop complex and creative solutions with quality modern C/C++ code and a highly automated build and test infrastructure</li><li>Improve reliability and observability by designing and building self-diagnostic and self-healing system capabilities</li><li>Learn state-of-the-art development practices for performance, reliability and error prevention</li><li>Partner with core and cross-functional teams to create the next-generation database engine powering ServiceNow</li></ul><p><strong>Qualifications</strong></p><br><p><strong>To be successful in this role you have:</strong></p><ul><li>In depth knowledge of computer and general systems architecture (threads, networking, kernel, etc)</li><li>Excellent skills in object-oriented programming combined with some C/C++ and SQL knowledge</li><li>Experience in test-driven development</li><li>Solid understanding and experience with agile software development methodologies and working in a large, ambitious team</li><li>Ability to handle multiple competing priorities in a fast-paced environment</li><li>Skill to manage your own complex tasks, know when to synchronize and re-align with the team, and lead more junior team members working with you</li><li>Strong problem-solving and analytical skills and the ability to communicate them effectively in design documents and architect-level discussions</li><li>An aptitude for learning new technologies and an itch to code</li><li>Experience working with at least one of OS kernel, memory manager, multi-threaded software modules, or distributed systems</li></ul><p><strong>Nice to have:</strong></p><ul><li>Experience with relational databases is a plus, MariaDB and/or Postgres</li></ul><p><strong>Qualifications</strong></p><ul><li>6+ years of experience developing professional software</li><li>Experience with deep knowledge in one of operating systems, complex layered software products or database systems</li><li>Proven track record of delivering sub-modules or software features end-to-end</li><li>Ability to handle multiple competing priorities in a fast-paced environment</li><li>Knowledge of C/C++ and SQL</li></ul><p><strong>Additional Information</strong></p><br><p>ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.</p><br><p>At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.</p><br><p>If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.</p><br><p>For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.</p><br><p>Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.</p><br><p>From Fortune. \u00a9 2022 Fortune Media IP Limited All rights reserved. Used under license.</p><br><p>Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.</p><br>"
  },
  {
    "id": 101,
    "title": "Senior Data Engineer - Platform (all genders)",
    "company": "Babbel",
    "locations": "Berlin",
    "skills": "Python, Machine Learning, AWS, Data Analysis, Cloud, ETL, Airflow, Spark, DevOps, Terraform, GitHub, Codebase, PySpark, Databricks, Snowflake",
    "posted_at": "2024-07-17",
    "is_remote": "False",
    "snippet_fragments": "  Monitoring and alerting (might be boring,   Participate in our knowledge sharing sessions (we're a learning company after all!) ,   Mastered Python and PySpark and want to raise the bar for our codebase ,   Confidence in working extensively with AWS services and cloud architectures ,   Broad experience implementing complex ETL/streaming pipelines and managing data lakehouses (like with Databricks) and warehouses (like Snowflake) ,   Familiarity with Terraform and Github Actions , Been there, done that, at testing, logging, monitoring and alerting (better yet if you still love it!),   Fluency in written and spoken English ,   Scheduled complex data flows with Airflow or DBT ,   Been keen on evangelizing the DevOps mindset across your workplace ,   Showed interest in Machine Learning / have experience building ML-driven or algorithmic data products ,   Enjoy 30 vacation days and the chance to take a 3-month Sabbatical, Plus family and life situation counseling, Decide how, when and from where you want to work with our flexible working hours and remote friendly options as Jobbatical (up to 3 months inside the EU) or work from our fully equipped office with nap, faith and family rooms.,   Learn and grow with the internal learning opportunities, Learn languages with Babbel for free with your full access to Babbel & Babbel Live classes,   Take advantage of your mobility benefits options and a discounted Urban Sports Club membership",
    "description": "<p><strong>We are looking for a Senior Data Engineer (full-time) to join our Data Engineering team in Berlin.</strong></p><br><p>As our newest Data Engineer in Data Platform team, your mission at Babbel will be to change the face of language learning one automation at a time. Working alongside your teammates in a fast-paced environment, you'll be collaborating and diving into different areas such as Data Engineering, Data Analytics, Site Reliability, InfoSec and many more to deliver innovations right on our Babbel learners hands.</p><br><p><strong>You will:</strong></p><ul><li>Shape our data platform</li><li>Secure our precious data and the infrastructure it relies upon</li><li>Keep the data moving towards where is actually needed (streaming and batch) with well-tested and performant solutions</li><li>Automate them all!</li><li>Monitoring and alerting (might be boring, but... refer to the previous point)</li><li>Participate in our knowledge sharing sessions (we're a learning company after all!)</li></ul><p><strong>You have:</strong></p><ul><li>Mastered Python and PySpark and want to raise the bar for our codebase</li><li>Confidence in working extensively with AWS services and cloud architectures</li><li>Broad experience implementing complex ETL/streaming pipelines and managing data lakehouses (like with Databricks) and warehouses (like Snowflake)</li><li>Familiarity with Terraform and Github Actions</li><li>Been there, done that, at testing, logging, monitoring and alerting (better yet if you still love it!)</li><li>Fluency in written and spoken English</li></ul><p><strong>Nice to have:</strong></p><ul><li>Scheduled complex data flows with Airflow or DBT</li><li>Been keen on evangelizing the DevOps mindset across your workplace</li><li>Showed interest in Machine Learning / have experience building ML-driven or algorithmic data products</li></ul><p><strong>Some perks of becoming a Babbelonian:</strong></p><ul><li>Enjoy 30 vacation days and the chance to take a 3-month Sabbatical. Plus family and life situation counseling.</li><li>Decide how, when and from where you want to work with our flexible working hours and remote friendly options as Jobbatical (up to 3 months inside the EU) or work from our fully equipped office with nap, faith and family rooms.</li><li>Learn and grow with the internal learning opportunities, and use a yearly learning &amp; development budget for external training. Learn languages with Babbel for free with your full access to Babbel &amp; Babbel Live classes.</li><li>Take advantage of your mobility benefits options and a discounted Urban Sports Club membership.</li><li>Be part of our employee communities (such as Femgineers, DE&amp;I Ambassadors and LGBTQIA groups), attend cultural and regular social events.</li></ul><p><strong>Diversity at Babbel</strong></p><br><p>As part of our ongoing journey towards building a diverse, equitable and inclusive company, we welcome everyone to apply, especially those individuals who are underrepresented in tech. We are a learning company, inside and out, and we encourage you to apply even if you do not fit all the technical requirements - all candidates are assessed based on skills, qualifications and on our business needs. Please state your pronouns in your application, and let us know if you'd like to be addressed by a name other than the one appearing on your official documents. If you have a disability or special need, feel welcome to inform us, so that we can provide you with the proper assistance in the application process.</p><br>"
  },
  {
    "id": 102,
    "title": "Data Engineer (m/w/d)",
    "company": "IT4IPM",
    "locations": "Berlin",
    "skills": "Python, SQL, Mathematik, Data Science, Kafka, NoSQL, Spark, Git",
    "posted_at": "2024-07-17",
    "is_remote": "False",
    "snippet_fragments": "     Unterst\u00fctzung und technische Betreuung von Team-Kollegen, Informatik, Data Science, Mathematik) oder vergleichbare Qualifikation.,      Sehr gute Kenntnisse im Umgang mit Spark,      Fundierte Kenntnisse in SQL und NoSQL Datenbanken,      Kenntnisse von g\u00e4ngigen Konzepten des Data Engineerings (CDC,      Kenntnisse in Streaming-Technologien (Kafka ist ein Plus)",
    "description": "<p>Berlin, M\u00fcnchen, Dresden</p><br><ol start=\"11\"><br><li>Juli 2024</li><br></ol><br><p><strong>DATA ENGINEER (M/W/D)</strong></p><br><p>Deine Aufgaben:</p><ul><li>Implementierung funktionaler Anforderungen und \u00dcbersetzung in robuste Datenprodukte, die gut in die gesamte Datenarchitektur (Data Lakehouse) integriert sind.</li><li>Sicherstellung der Datenqualit\u00e4t und -verf\u00fcgbarkeit.</li><li>Evaluation und Verbesserung bestehender Datenprodukte.</li><li>Unterst\u00fctzung und technische Betreuung von Team-Kollegen.</li><li>Technische Beratung der Dom\u00e4nenexperten.</li></ul><p>Dein Profil:</p><ul><li>Abgeschlossenes Studium in einem relevanten Bereich (z. B. Informatik, Data Science, Mathematik) oder vergleichbare Qualifikation.</li><li>Sehr gute Kenntnisse in Python.</li><li>Sehr gute Kenntnisse im Umgang mit Spark</li><li>Fundierte Kenntnisse in SQL und NoSQL Datenbanken.</li><li>Kenntnisse von g\u00e4ngigen Konzepten des Data Engineerings (CDC, Lakehouse-Architektur, EL(T)- und ETL-Prozesse).</li><li>Erfahrung mit Code-Versionsverwaltung (GIT).</li><li>Kenntnisse in Streaming-Technologien (Kafka ist ein Plus).</li><li>Neugier, Technologieaffinit\u00e4t und Gestaltungsfreude. Ausgezeichnete Teamf\u00e4higkeit und Kommunikationsst\u00e4rke.</li><li>Gute Deutsch- und Englischkenntnisse (in Wort und Schrift).</li></ul><p>Wir freuen uns auf Deine Bewerbung.</p><br>"
  },
  {
    "id": 103,
    "title": "Data Engineer (d/m/w) - befristet (Elternzeitvertretung)",
    "company": "Toll Collect GmbH",
    "locations": "Berlin",
    "skills": "SQL, Mathematik, Linux, Cognos, PL/SQL, Windows",
    "posted_at": "2024-07-17",
    "is_remote": "False",
    "snippet_fragments": "    Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics,      Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL),      Sie beherrschen den Umgang mit Windows und Linux einwandfrei,      Sie haben ein abgeschlossenes Studium in der Mathematik,      Sie haben Berufserfahrung im Bereich Data Engineering,     Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung,      Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung,  Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet,      Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen oder Business-Bike bis zur betrieblichen Altersversorgung,     Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung,     Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu, Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen",
    "description": "<p>Referenznummer: 20728</p><br><p>Ihre Aufgaben</p><ul><li>Sie verantworten die Strukturierung und Weiterentwicklung von Datenmodellen und Datenfl\u00fcssen sowie der zugeh\u00f6rigen IT-gest\u00fctzten Prozesse</li><li>Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit</li><li>Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten</li><li>Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen</li><li>Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit, bringen eigene Ideen ein und setzen diese um</li><li>Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen</li></ul><p>Ihre Kompetenzen</p><ul><li>Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics</li><li>Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL).</li><li>Sie beherrschen den Umgang mit Windows und Linux einwandfrei</li><li>Sie haben ein abgeschlossenes Studium in der Mathematik, Informatik oder in einem vergleichbaren Studiengang</li><li>Sie haben Berufserfahrung im Bereich Data Engineering</li></ul><p>Was bieten wir</p><ul><li>Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung</li><li>Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung</li><li>Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet</li><li>Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen oder Business-Bike bis zur betrieblichen Altersversorgung</li></ul><p>Interessiert?</p><br><p>Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung.</p><br><p>Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu. Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen. Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt.</p><br><p>Ihre Ansprechperson</p><br><p>Frau Silvia Barknecht, 030/74077-8214, karriere@toll-collect.de</p><br><p>Toll Collect GmbH * Personalmanagement * Linkstra\u00dfe 4, 10785 Berlin</p><br>"
  },
  {
    "id": 104,
    "title": "Senior Data Engineer (all genders)",
    "company": "Babbel",
    "locations": "Berlin",
    "skills": "Python, SQL, AWS, Cloud, Data Warehouse, DynamoDB, Lambda, Kinesis, Databricks, Snowflake, SOLID, Amazon RDS, AWS S3, Architektur",
    "posted_at": "2024-07-16",
    "is_remote": "False",
    "snippet_fragments": "  Collaborate with data analysts and data scientists to deliver high-quality data solutions ,   Participate in our knowledge sharing sessions (we're a learning company,   Solid experience in Dimensional Modelling and Data Warehousing ,   Strong understanding of data governance principles and best practices ,   Hands-on experience with cloud data warehouses,   Expertise in working with the AWS environment (S3, Kinesis,   In-depth SQL knowledge and extensive experience working with dbt ,   Designing and maintaining complex dimensional schemas ,   Designing data architecture for a domain or a whole organization ,   Enjoy 30 vacation days and the chance to take a 3-month Sabbatical, Plus family and life situation counseling, Decide how, when and from where you want to work with our flexible working hours and remote friendly options as Jobbatical (up to 3 months inside the EU) or work from our fully equipped office with nap, faith and family rooms.,   Learn and grow with the internal learning opportunities, Learn languages with Babbel for free with your full access to Babbel & Babbel Live classes",
    "description": "<p><strong>We are looking for a Senior Data Engineer (full-time) to join our Data Engineering team in Berlin.</strong></p><br><p>Do you want to help us leverage data to transform the way people learn languages? Join us as a Senior Data Engineer and play a pivotal role in empowering millions of individuals worldwide to explore new languages and cultures. As part of our diverse and supportive team, you'll enjoy flexible work hours and remote options while taking the lead in shaping our data architecture and designing innovative data models.</p><br><p><strong>You will:</strong></p><ul><li>Lead the development and evolution of our data architecture</li><li>Mentor and coach other data engineers, fostering a culture of learning and growth</li><li>Lead the design and implementation of data models to support business needs at scale using dbt, Snowflake and Databricks Lakehouse Platform</li><li>Collaborate with data analysts and data scientists to deliver high-quality data solutions</li><li>Participate in our knowledge sharing sessions (we're a learning company, after all!)</li></ul><p><strong>You have:</strong></p><ul><li>Solid experience in Dimensional Modelling and Data Warehousing</li><li>Strong understanding of data governance principles and best practices</li><li>Hands-on experience with cloud data warehouses, ideally Snowflake or Databricks Lakehouse Platform</li><li>Expertise in working with the AWS environment (S3, Kinesis, Lambdas, RDS, DynamoDB)</li><li>Fluency in Python</li><li>In-depth SQL knowledge and extensive experience working with dbt</li></ul><p><strong>Nice to have:</strong></p><ul><li>Organizing knowledge sharing sessions</li><li>Mentoring other engineers</li><li>Designing and maintaining complex dimensional schemas</li><li>Defining data contracts</li><li>Optimizing complex SQL queries</li><li>Designing data architecture for a domain or a whole organization</li></ul><p><strong>Some perks of becoming a Babbelonian:</strong></p><ul><li>Enjoy 30 vacation days and the chance to take a 3-month Sabbatical. Plus family and life situation counseling.</li><li>Decide how, when and from where you want to work with our flexible working hours and remote friendly options as Jobbatical (up to 3 months inside the EU) or work from our fully equipped office with nap, faith and family rooms.</li><li>Learn and grow with the internal learning opportunities, and use a yearly learning &amp; development budget for external training. Learn languages with Babbel for free with your full access to Babbel &amp; Babbel Live classes.</li><li>Take advantage of your mobility benefits options and a discounted Urban Sports Club membership.</li><li>Be part of our employee communities (such as Femgineers, DE&amp;I Ambassadors and LGBTQIA groups), attend cultural and regular social events.</li></ul><p><strong>Diversity at Babbel</strong></p><br><p>As part of our ongoing journey towards building a diverse, equitable and inclusive company, we welcome everyone to apply, especially those individuals who are underrepresented in tech. We are a learning company, inside and out, and we encourage you to apply even if you do not fit all the technical requirements - all candidates are assessed based on skills, qualifications and on our business needs. Please state your pronouns in your application, and let us know if you'd like to be addressed by a name other than the one appearing on your official documents. If you have a disability or special need, feel welcome to inform us, so that we can provide you with the proper assistance in the application process.</p><br>"
  },
  {
    "id": 105,
    "title": "Data Engineer (m/w/d)",
    "company": "Skillspark AB",
    "locations": "Berlin",
    "skills": "SQL, Dashboards, Tableau, Alteryx, Data mining, APIs",
    "posted_at": "2024-07-16",
    "is_remote": "False",
    "snippet_fragments": "  F\u00fcr unseren Kunden aus der Energie Branche suchen wir einen DATA Engineer (m/w/d) in Berlin,  Die Vertragsart ist Arbeitnehmer\u00fcberlassung, bei einer Laufzeit von 18 Monaten und einer w\u00f6chentliche Arbeitszeit von 35 Stunden, Eine Verl\u00e4ngerung der Beauftragung ist m\u00f6glich,     Erstellung und Reporting von Fertigungs- und F&E KPIs,     Fortgeschrittene Tableau und Tableau Server Kenntnisse,  Expertenwissen in Datenanalyse (tidy, transform, visualize, model, communicate),     Erfahrung mit Alteryx und Alteryx Server, Erfahrung in der Verkn\u00fcpfung unterschiedlicher Datenquelle wie SQL und API,     Erfahrung in der Erhebung von Fertigungsdaten von Vorteil",
    "description": "<p><strong>Start</strong><br><strong>31-08-2024</strong><br><strong>Duration</strong><br><strong>&gt; 12 months</strong></p><br><p>F\u00fcr unseren Kunden aus der Energie Branche suchen wir einen <strong>DATA Engineer (m/w/d) in Berlin</strong></p><br><p>Die Vertragsart ist Arbeitnehmer\u00fcberlassung, bei einer Laufzeit von 18 Monaten und einer w\u00f6chentliche Arbeitszeit von 35 Stunden. Eine Verl\u00e4ngerung der Beauftragung ist m\u00f6glich.</p><br><p><strong>Aufgaben:</strong></p><ul><li>Erhebung und Auswertung von Fertigungsdaten</li><li>Kreieren digitalier Dashboards zur Visualisierung</li><li>Erstellung und Reporting von Fertigungs- und F&amp;E KPIs</li></ul><p><strong>Anforderungen</strong></p><ul><li>Fortgeschrittene Tableau und Tableau Server Kenntnisse</li><li>Verst\u00e4ndnis von Datenvisualisierung und Datenmodellen</li><li>Expertenwissen in Datenanalyse (tidy, transform, visualize, model, communicate)</li><li>Grundkenntnisse in statistischer Programmierung (z.B. R-Studio)</li><li>Erfahrung mit Alteryx und Alteryx Server</li><li>\u201eData-Mining&quot; Erfahrung von Vorteil</li><li>Kenntnisse bzw. Erfahrung in der Verkn\u00fcpfung unterschiedlicher Datenquelle wie SQL und API</li><li>Erfahrung in der Erhebung von Fertigungsdaten von Vorteil</li><li>Sprachkenntnisse in Deutsch und Englisch</li></ul><p>Die Stelle klingt spannend und Ihr Profil passt auf die Anforderungen? Dann freuen wir uns \u00fcber Ihre Bewerbung mit Angabe Ihres Wunschgehalts.</p><br><p><strong>Ihre Ansprechpartnerin bei emagine:</strong></p><br><p><strong>SILVIA KASTNER</strong></p><br><p>Partner Manager</p><br><p>+49 89 340819-38</p><br><p>sakr@emagine.de</p><br>"
  },
  {
    "id": 106,
    "title": "Intern Data Engineer (m/w/d)",
    "company": "McMakler",
    "locations": "Berlin",
    "skills": "Python, Machine Learning, Data Science, Data Pipelines, Data Warehouse, Software Development Lifecycle",
    "posted_at": "2024-07-16",
    "is_remote": "False",
    "snippet_fragments": "Experience the richness of diverse cultures and perspectives as you work towards shared objectives, The Data Team plays an essential role in enabling data-driven decisions across the company and utilizing modern AI to optimize processes and marketing, Your contributions will directly impact various business units and enhance overall efficiency, Currently pursuing a degree in Computer Science, Information Technology, Data Science, or a related field with a strong foundation in data management and data engineering., Basic knowledge in Python and best practices in software development, Data extraction techniques (scraping/parsing) and data warehouse integration are highly desirable skills to have, Effective communication skills - capable of collaborating with team members and participating in technical discussions., Passion for data and technology with a strong willingness to learn new tools and practices.,  Excellent organizational and time-management skills, with the ability to work on multiple projects in a fast-paced environment.,   What we all build on together, Our corporate values serve as a compass for the big and small decisions we make every day,   We are challenging the conservative stereotype of an agent,   With innovative marketing strategies and excellent customer care",
    "description": "<p><strong>Company Description</strong></p><br><p>At McMakler, we believe that the real estate market is ready for change. With over 350 agents at more than 30 locations across Germany and a 250-member expert team at our Berlin headquarters, we are setting new standards in real estate brokerage. We combine local agent expertise and years of experience with an automated, digitized sales process, making real estate transactions even easier, more convenient, and transparent. In doing so, we offer our customers all the essential services related to real estate: from finding the dream property to securing suitable financing and even energy consulting.</p><br><p>As a Data Intern, your role is to collaborate with diverse stakeholders to support the development and maintenance of data pipelines, ensuring accurate and reliable data that drives informed business decisions.</p><br><p><strong>What we offer:</strong></p><br><p><strong>Responsibility:</strong> Assist in the creation and upkeep of data pipelines that efficiently extract data from various sources (such as scraping/parsing) and integrate it into the data warehouse.</p><br><p><strong>Collaboration and Learning:</strong> Collaborate with team members to comprehend data requirements and assist in implementing data solutions. Acquire knowledge and apply data cleansing, validation, and quality assurance processes to guarantee accurate and reliable data.</p><br><p><strong>Technical Growth:</strong> Assist with the creation and improvement of efficient Python code. Contribute to improving efficiency and reducing manual intervention by automating routine data tasks.</p><br><p><strong>Team Integration:</strong> Be part of our interdisciplinary Data Team consisting of Machine Learning Experts, Data Engineers, and Analytics Engineers. Engage in a supportive environment where team members share knowledge and expertise.</p><br><p><strong>International Environment:</strong> Join an international team of six people with diverse backgrounds and experiences. Experience the richness of diverse cultures and perspectives as you work towards shared objectives.</p><br><p><strong>Impact:</strong> The Data Team plays an essential role in enabling data-driven decisions across the company and utilizing modern AI to optimize processes and marketing. Your contributions will directly impact various business units and enhance overall efficiency.</p><br><p><strong>What we expect:</strong></p><br><p><strong>Educational Background:</strong> Currently pursuing a degree in Computer Science, Information Technology, Data Science, or a related field with a strong foundation in data management and data engineering.</p><br><p><strong>Technical Skills:</strong> Basic knowledge in Python and best practices in software development. Data extraction techniques (scraping/parsing) and data warehouse integration are highly desirable skills to have.</p><br><p><strong>Communication Skills:</strong> Effective communication skills - capable of collaborating with team members and participating in technical discussions.</p><br><p><strong>Adaptability and Eagerness to Learn:</strong> Passion for data and technology with a strong willingness to learn new tools and practices.</p><br><p><strong>Time Management:</strong> Excellent organizational and time-management skills, with the ability to work on multiple projects in a fast-paced environment.</p><br><p><strong>Additional Information</strong></p><br><p>What we all build on together. Our corporate values serve as a compass for the big and small decisions we make every day.</p><br><p><strong>#change</strong></p><br><p>We are challenging the conservative stereotype of an agent, eliminating outdated preconceptions and revolutionising the real estate market.</p><br><p><strong>#quality</strong></p><br><p>With innovative marketing strategies and excellent customer care, we set new standards and deliver the highest quality of service.</p><br><p><strong>#fightingspirit</strong></p><br><p>We are successful because we burn for the McMakler vision and always give 110 percent.</p><br><p><strong>#oneteam</strong></p><br><p>At McMakler we live a diverse corporate culture characterised by mutual appreciation, loyalty and respect.</p><br><p>Were we able to convince you? Then apply for a job with us!</p><br><p>If you have any questions, please contact jobs@mcmakler.de</p><br>"
  },
  {
    "id": 107,
    "title": "Data Engineer (d/m/w) - befristet (Elternzeitvertretung)",
    "company": "Toll Collect GmbH",
    "locations": "Berlin",
    "skills": "SQL, Mathematik, Linux, Cognos, PL/SQL, Windows",
    "posted_at": "2024-07-16",
    "is_remote": "False",
    "snippet_fragments": "     Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit,      Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen ,     Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics,      Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL),      Sie beherrschen den Umgang mit Windows und Linux einwandfrei,      Sie haben ein abgeschlossenes Studium in der Mathematik,      Sie haben Berufserfahrung im Bereich Data Engineering,     Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung,      Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung,  Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet,      Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung,     Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung,     Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu, Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen, Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt",
    "description": "<p>Referenznummer: 20728</p><br><p>Ihre Aufgaben</p><ul><li>Sie verantworten die Strukturierung und Weiterentwicklung von Datenmodellen und Datenfl\u00fcssen sowie der zugeh\u00f6rigen IT-gest\u00fctzten Prozesse</li><li>Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit</li><li>Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten</li><li>Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen</li><li>Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit, bringen eigene Ideen ein und setzen diese um</li><li>Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen<br> Ihr Profil</li><li>Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics</li><li>Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL).</li><li>Sie beherrschen den Umgang mit Windows und Linux einwandfrei</li><li>Sie haben ein abgeschlossenes Studium in der Mathematik, Informatik oder in einem vergleichbaren Studiengang</li><li>Sie haben Berufserfahrung im Bereich Data Engineering<br> Was bieten wir</li><li>Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung</li><li>Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung</li><li>Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet</li><li>Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung</li></ul><p>Interessiert?</p><br><p>Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung.</p><br><p>Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu. Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen. Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt.</p><br><p>Ihre Ansprechperson</p><br><p>Frau Silvia Barknecht, 030/74077-8214, karriere@toll-collect.de</p><br><p>Toll Collect GmbH * Personalmanagement * Linkstra\u00dfe 4, 10785 Berlin</p><br>"
  },
  {
    "id": 108,
    "title": "Data Engineer (d/m/w) - befristet (Elternzeitvertretung)",
    "company": "Toll Collect GmbH",
    "locations": "Berlin",
    "skills": "SQL, Mathematik, Linux, Cognos, PL/SQL, Windows",
    "posted_at": "2024-07-15",
    "is_remote": "False",
    "snippet_fragments": "     Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit,      Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen ,     Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics,      Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL),      Sie beherrschen den Umgang mit Windows und Linux einwandfrei,      Sie haben ein abgeschlossenes Studium in der Mathematik,      Sie haben Berufserfahrung im Bereich Data Engineering,     Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung,      Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung,  Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet,      Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung,     Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung,     Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu, Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen, Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt",
    "description": "<p>Referenznummer: 20728</p><br><p>Ihre Aufgaben</p><ul><li>Sie verantworten die Strukturierung und Weiterentwicklung von Datenmodellen und Datenfl\u00fcssen sowie der zugeh\u00f6rigen IT-gest\u00fctzten Prozesse</li><li>Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit</li><li>Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten</li><li>Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen</li><li>Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit, bringen eigene Ideen ein und setzen diese um</li><li>Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen<br> Ihr Profil</li><li>Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics</li><li>Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL).</li><li>Sie beherrschen den Umgang mit Windows und Linux einwandfrei</li><li>Sie haben ein abgeschlossenes Studium in der Mathematik, Informatik oder in einem vergleichbaren Studiengang</li><li>Sie haben Berufserfahrung im Bereich Data Engineering<br> Was bieten wir</li><li>Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung</li><li>Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung</li><li>Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet</li><li>Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung</li></ul><p>Interessiert?</p><br><p>Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung.</p><br><p>Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu. Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen. Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt.</p><br><p>Ihre Ansprechperson</p><br><p>Frau Silvia Barknecht, 030/74077-8214, karriere@toll-collect.de</p><br><p>Toll Collect GmbH * Personalmanagement * Linkstra\u00dfe 4, 10785 Berlin</p><br>"
  },
  {
    "id": 109,
    "title": "Python Composable Data Stack Engineer",
    "company": "dltHub",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Data Science, AWS, Cloud, GCP, Code Reviews, DevOps, Docker, Kubernetes, Unit Testing, GitHub, Rasa, Data Lake, CD, Continuous Integration, pip",
    "posted_at": "2024-07-12",
    "is_remote": "True",
    "snippet_fragments": "  If you are fascinated by the emerging ecosystem of data libraries in Python, You know what duckdb, arrow, datafusion, lancedb, delta-rs, ibis, pyiceberg, sqlglot, kedro, hamilton and similar Python libraries / pip installable components do and know when to apply them.,   You have experience in building data apps or product based on composable data stack ,    or you were contributing code to any (or similar) of projects above ,   You know what so called modern data stack is and appreciate certain aspects of it (ie, maturity, fitting into enterprise workflows etc.),    and in fact you are interested in combining both worlds,   You really like Python and are fluent in writing Python code (e,   You have a degree in computer science,   You are familiar with GitHub workflows (e,   You are based in Berlin and willing to work in our office regularly ,   You have a hacker nature and you love to make things optimized , Experience with DevOps (e.g., CI systems like GitHub Actions, Docker, Kubernetes, AWS/GCP/Digital Ocean, etc.), Experience with machine learning (e.g., the toolset, the workflows, practical applications, etc.),  In our work culture, we value each others autonomy and efficiency, We have set hours for communication and deep work, We like automation, so we automate our work before we automate the work of others.",
    "description": "<p><strong>WHO WE ARE</strong></p><br><p>We are looking for a Software or Data Engineer experienced with high performance Python data processing libraries (Composable Data Stack) to collaborate directly with our CTO and the product team.</p><br><p>dlt is an open-source library that automatically creates datasets from messy, unstructured data sources. You can use the library to move data from about anywhere into the most well-known SQL and vector stores, data lakes, storage buckets, or local engines like DuckDB, Arrow or delta-rs.. It automates many cumbersome data engineering tasks and can be handled by anyone who knows Python. More details in this Hacker News article.</p><br><p>dltHub is based in Berlin and New York City. It was founded by data and machine learning veterans. We are backed by Foundation Capital, Dig Venture, and many technical founders from companies such as Hugging Face, Instana, Matillion, Miro, and Rasa.</p><br><p><strong>YOUR TASKS AND RESPONSIBILITIES:</strong></p><br><p>dlt is a missing part of composable data stack: a gateway that creates datasets which the other components can then process. Our mission is to integrate dlt fully with this new, emerging ecosystem in a way that our users love. This means we respect their time, effort and previous investments in modern data stack when designing features.</p><ul><li>You design and implement OSS features that make dlt a gateway to composable data stack: integrating query engines, transformation frameworks, table formats with our library</li><li>You listen to our users, always paying attention to what they need to go to production with dlt.</li><li>You work with our customers in commercial projects where dlt is combined with existing &quot;modern data stack&quot; infrastructure</li><li>You maintain the open source project with the team (e.g., review PRs, resolve issues, talk with community contributors, etc.)</li></ul><p><strong>Requirements</strong></p><br><p><strong>WHO YOU ARE</strong></p><br><p>If you are fascinated by the emerging ecosystem of data libraries in Python, which allows you to do on a single machine what until recently was possibly only in the cloud - you'll enjoy working with us.</p><ul><li>You know what duckdb, arrow, datafusion, lancedb, delta-rs, ibis, pyiceberg, sqlglot, kedro, hamilton and similar Python libraries / pip installable components do and know when to apply them.</li><li>You have experience in building data apps or product based on composable data stack</li><li>... or you were contributing code to any (or similar) of projects above</li><li>You know what so called &quot;modern data stack&quot; is and appreciate certain aspects of it (ie. maturity, fitting into enterprise workflows etc.)</li><li>... and in fact you are interested in combining both worlds.</li><li>You really like Python and are fluent in writing Python code (e.g., Python typing, unit testing, writing docstrings, etc.)</li><li>You have a degree in computer science, data science, or other equivalent experience</li><li>You are familiar with GitHub workflows (e.g., pull requests, code reviews, CI/CD services, etc.)</li></ul><p><strong>NICE TO HAVE:</strong></p><ul><li>You are based in Berlin and willing to work in our office regularly</li><li>You have a hacker nature and you love to make things optimized</li><li>Experience with DevOps (e.g., CI systems like GitHub Actions, Docker, Kubernetes, AWS/GCP/Digital Ocean, etc.)</li><li>Experience with machine learning (e.g., the toolset, the workflows, practical applications, etc.)</li></ul><p><strong>Benefits</strong></p><br><p><strong>WHAT DO WE OFFER</strong></p><br><p>In our work culture, we value each other's autonomy and efficiency. We have set hours for communication and deep work. We like automation, so we automate our work before we automate the work of others.</p><ul><li>We are an office-first company but give you plenty of opportunities for deep work and work from home. Dedicated &quot;no meeting days&quot; to help the team focus on their most impactful work</li><li>As we work often from the Berlin office, we cover your public transportation ticket</li><li>We are deeply committed to your personal and professional growth, so we have an annual budget for learning and development.</li><li>We offer regular subsidized team lunches and Urban Sports Club membership.</li><li>We also have an ESOP plan for employees, depending on their role and dedication. We provide an option to increase your ESOP if you grow with us.</li></ul><br>"
  },
  {
    "id": 110,
    "title": "(Senior) Data Engineer (m/f/d)",
    "company": "CBRE",
    "locations": "Berlin",
    "skills": "Python, SQL, Data Analysis, Cloud, Data Pipelines, Linux, Business Intelligence, Data Modeling, Data Warehouse, Bash, Dashboards, Load Balancing, PostgreSQL, Routing, DevSecOps, Snowflake, CD, Continuous Integration, Code Refactoring, DNS",
    "posted_at": "2024-07-12",
    "is_remote": "False",
    "snippet_fragments": "   Debugging applications (level 2 or 3 support) and completing tests for performance optimization,    Independent coordination and implementation of technical requirements with data analysts as well as technical architects and developers,    Technical support for the ongoing development of the central,    Technical implementation of critical data cleansing projects using internal and external reference data sets as well as data quality KPIs defined by the business,    Close co-operation with international developer teams,    Minimum Bachelor's degree in computer science or another relevant field,    Proven professional experience (5 years) as a cloud backend developer as well as sound experience with DevSecOps development lifecycle management (CI / CD,    Deep knowledge & experience in the design,  Practical experience/proficiency with Python, Linux, Bash, Postgres, dbt,    Expertise with SQL preferably PostgreSQL and Snowflake functions and features,  Hands-on experience with data modeling, data cleansing and data quality management,    Willingness to learn and practice new technologies depending on the project requirements,    Self-starters with excellent analytical skills and the ability to articulate complex data concepts in a clear and understandable manner,    Ability to work in a team with a willingness to solve problems and the motivation to work in an international or virtual team,    Very good knowledge in English & German,    Become a part of our open,    Become an integral part of our team,    Work-Life balance is important to us",
    "description": "<p><strong>OUR EMPLOYEES - OUR SUCCESS</strong></p><br><p>Our growing Data Intelligence &amp; Digital Enablement team is responsible for data analytics, product management &amp; digital enablement support for all CBRE locations in Germany. Using innovative solutions, we implement business-relevant use cases and support our operational teams in expanding, maintaining, analyzing and visualizing a unique real estate data landscape. We look forward to strengthening our dynamic and international team.</p><br><p>To support our ambitious business goals we go on investing in our growing cloud-based data platform. For this we need committed talents who support the extension and enhancement of our databases and data pipelines in close cooperation with the German business units as well as the data teams in Continental Europe, USA &amp; India.</p><br><p>Therefore, we are looking for an experienced (Senior) Data Engineer at Hamburg, Frankfurt am Main or Berlin as soon as possible. You have the chance to actively shape our constantly changing, unique real estate data landscape and to become part of a dynamic and international team.</p><br><p><strong>ABOUT CBRE</strong></p><br><p>CBRE is the world's largest commercial real estate services and investment firm (based on 2023 revenue). The company has more than 130,000 employees serving clients in more than 100 countries. CBRE serves a diverse range of clients with an integrated suite of services - over the entire life cycle of a property.</p><br><p><strong>YOUR MISSION</strong></p><ul><li>Administration, maintenance, monitoring, optimization (especially performance and stability) of a cloud-based Postgres database / data warehouse based on various internal and external data sources</li><li>Preparation &amp; support of a large migration and refactoring project of a Postgres database / data warehouse to a modern Snowflake Cloud Data Platform</li><li>Creation, further development, maintenance, monitoring and documentation of data delivery pipelines for enterprise applications, self-service data analytics applications and business intelligence dashboards</li><li>Ensuring data security around highly sensitive, NDA-protected data through best practice permission management in the database</li><li>Debugging applications (level 2 or 3 support) and completing tests for performance optimization</li><li>Independent coordination and implementation of technical requirements with data analysts as well as technical architects and developers</li><li>Technical support for the ongoing development of the central, cross-divisional data model, which includes customer, property, transaction, and external market data</li><li>Technical implementation of critical data cleansing projects using internal and external reference data sets as well as data quality KPIs defined by the business</li><li>Close co-operation with international developer teams</li></ul><p><strong>YOUR PROFILE</strong></p><ul><li>Minimum Bachelor's degree in computer science or another relevant field</li><li>Proven professional experience (5+ years) as a cloud backend developer as well as sound experience with DevSecOps development lifecycle management (CI / CD, automation / configuration, monitoring / logging / alerting, routing / DNS / load balancing ...)</li><li>Deep knowledge &amp; experience in the design, development and implementation of data platforms using Snowflake</li><li>Practical experience/proficiency with Python, Linux, Bash, Postgres, dbt</li><li>Expertise with SQL preferably PostgreSQL and Snowflake functions and features</li><li>Hands-on experience with data modeling, data cleansing and data quality management</li><li>Willingness to learn and practice new technologies depending on the project requirements</li><li>Self-starters with excellent analytical skills and the ability to articulate complex data concepts in a clear and understandable manner</li><li>Ability to work in a team with a willingness to solve problems and the motivation to work in an international or virtual team</li><li>Very good knowledge in English &amp; German, both spoken and written</li></ul><p><strong>OUR OFFER</strong></p><ul><li>Become a part of our open, cooperative and dynamic company culture with flat hierarchies and short decision-making processes</li><li>Become an integral part of our team, in which your ideas are greatly valued</li><li>Work-Life balance is important to us, which is why you can work flexibly and in part remotely</li><li>&quot;NEW WORK&quot;: Our cutting-edge offices are equipped with the latest technologies and are designed by our workplace colleagues based on the latest concepts and ideas - all to boost efficiency and collaboration.</li><li>We are continuing to expand our ESG roadmap and offer our employees the opportunity to protect the environment, while staying healthy by using the employee benefit scheme &quot;JobRad&quot;</li><li>Get to know your colleagues better at regular employee events and create shared experiences in a relaxed atmosphere</li></ul><p><strong>ARE YOU READY TO JOIN?</strong></p><br><p>Our employees appreciate the responsibility, the involvement in exciting projects, the various possibilities for further developments and the positive working atmosphere. Are you interested in working with us? We look forward to receiving your application in English.</p><ul><li>Your Career Builder, Regardless of your gEnder</li></ul><br>"
  },
  {
    "id": 111,
    "title": "Data Engineer (d/m/w) - befristet (Elternzeitvertretung)",
    "company": "Toll Collect GmbH",
    "locations": "Berlin",
    "skills": "SQL, Mathematik, Linux, Cognos, PL/SQL, Windows",
    "posted_at": "2024-07-12",
    "is_remote": "False",
    "snippet_fragments": "     Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL),      Sie beherrschen den Umgang mit Windows und Linux einwandfrei,      Sie haben ein abgeschlossenes Studium in der Mathematik,      Sie haben Berufserfahrung im Bereich Data Engineering,     Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung,      Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung,  Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet,      Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung,     Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung,     Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu, Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen, Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt",
    "description": "<p>Referenznummer: 20728</p><br><p>Ihre Aufgaben</p><ul><li>Sie verantworten die Strukturierung und Weiterentwicklung von Datenmodellen und Datenfl\u00fcssen sowie der zugeh\u00f6rigen IT-gest\u00fctzten Prozesse</li><li>Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit</li><li>Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten</li><li>Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen</li><li>Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit, bringen eigene Ideen ein und setzen diese um</li><li>Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen<br> Ihr Profil</li><li>Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics</li><li>Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL).</li><li>Sie beherrschen den Umgang mit Windows und Linux einwandfrei</li><li>Sie haben ein abgeschlossenes Studium in der Mathematik, Informatik oder in einem vergleichbaren Studiengang</li><li>Sie haben Berufserfahrung im Bereich Data Engineering<br> Was bieten wir</li><li>Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung</li><li>Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung</li><li>Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet</li><li>Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung</li></ul><p>Interessiert?</p><br><p>Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung.</p><br><p>Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu. Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen. Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt.</p><br><p>Ihre Ansprechperson</p><br><p>Frau Silvia Barknecht, 030/74077-8214, karriere@toll-collect.de</p><br><p>Toll Collect GmbH * Personalmanagement * Linkstra\u00dfe 4, 10785 Berlin</p><br>"
  },
  {
    "id": 112,
    "title": "(Inhouse) Data Engineer (m/w/d)",
    "company": "CANCOM SE",
    "locations": "Berlin",
    "skills": "Python, SQL, Data Modeling, Java, Version Control, Git, SAP, Architektur",
    "posted_at": "2024-07-11",
    "is_remote": "True",
    "snippet_fragments": "        Entwicklung von ETL- und Datenintegrationsl\u00f6sungen unter Verwendung verschiedener Technologien und Datenquellen ,         Arbeiten mit Cloud-basierten Infrastrukturen f\u00fcr das Hosting von Datenl\u00f6sungen und Anwendungen , Aggregation, Bereinigung und Anreicherung der Daten f\u00fcr unterschiedliche Anwendungssituationen im Unternehmen, Performante Bereitstellung f\u00fcr Data Analysts, Data Scientists, fachliche Mitarbeiter und Unternehmenskunden,         Erstellung von Datenmodellen f\u00fcr analytische Anwendungen ,         Unterst\u00fctzung bei der Entwicklung von Analyse- und Berichtsl\u00f6sungen ,         Ausbildung im IT-Bereich oder ein Studium mit Schwerpunkt Informatik / Wirtschaftsinformatik ,         Erfahrung in der Arbeit mit Data-Warehouse-L\u00f6sungen und ETL-Prozessen , Erfahrung mit Datenbanken und Datenmodellierung, insb,         Gute Kenntnisse des SAP Data Architecture Stacks ,         Deutsch und Englisch in Wort und Schrift ,         Flexible Arbeitszeiten und Mobile Office in Abstimmung mit dem Vorgesetzten ,         Rabatte dank dem Portal Corporate Benefits ",
    "description": "<p><strong>PROFESSIONAL</strong></p><br><p><strong>(INHOUSE) DATA ENGINEER (M/W/D)</strong></p><br><p>Berlin, Erfurt, Frankfurt am Main, Hamburg, Hannover, K\u00f6ln, Leipzig, M\u00fcnchen, N\u00fcrnberg, Stuttgart</p><br><p>JETZT BEWERBEN</p><br><p>Bei CANCOM erwartet dich ein innovatives, agiles und nachhaltiges Umfeld: Mehr als 5.600 Mitarbeiter arbeiten tagt\u00e4glich daran, mit Hilfe moderner IT-L\u00f6sungen die Zusammenarbeit und den Austausch in verschiedenen Lebensbereichen zu verbessern. Du hast Lust ein Teil davon zu sein und den n\u00e4chsten Karriereschritt zu gehen? Dann werde Teil unserer Digital Journey. Wir freuen uns auf Menschen aus den unterschiedlichsten Fachrichtungen, die aufgeschlossen f\u00fcr Neues sind, innovative Einf\u00e4lle haben und im Team gemeinsam Ziele voranbringen wollen.</p><br><p><strong>DEINE NEUEN AUFGABEN</strong></p><ul><li>Unternehmensweite, system\u00fcbergreifende Erschlie\u00dfung und Aufbereitung von Daten und Bereitstellung auf einer zentralen Analyseplattform</li><li>Aufbau einer Dateninfrastruktur mit Datenpipelines, die einen reibungslosen Datenfluss von der Quelle bis zum Nutzer erm\u00f6glichen, inkl. Datenqualit\u00e4t, Datensicherheit</li><li>Entwicklung von ETL- und Datenintegrationsl\u00f6sungen unter Verwendung verschiedener Technologien und Datenquellen</li><li>Arbeiten mit Cloud-basierten Infrastrukturen f\u00fcr das Hosting von Datenl\u00f6sungen und Anwendungen</li><li>Aggregation, Bereinigung und Anreicherung der Daten f\u00fcr unterschiedliche Anwendungssituationen im Unternehmen</li><li>Monitoring der Datenqualit\u00e4t und Prozesse</li><li>Performante Bereitstellung f\u00fcr Data Analysts, Data Scientists, fachliche Mitarbeiter und Unternehmenskunden</li><li>Erstellung von Datenmodellen f\u00fcr analytische Anwendungen</li><li>Unterst\u00fctzung bei der Entwicklung von Analyse- und Berichtsl\u00f6sungen</li></ul><p><strong>DAS BRINGST DU MIT</strong></p><ul><li>Ausbildung im IT-Bereich oder ein Studium mit Schwerpunkt Informatik / Wirtschaftsinformatik</li><li>Erfahrung in der Arbeit mit Data-Warehouse-L\u00f6sungen und ETL-Prozessen</li><li>Erfahrung mit Datenbanken und Datenmodellierung, insb. SQL</li><li>Gute Kenntnisse des SAP Data Architecture Stacks</li><li>Sehr gute Programmierkenntnisse (z.B. Python, Java)</li><li>Erfahrung in der Arbeit mit Versionskontrollsystemen (z.B. Git)</li><li>Deutsch und Englisch in Wort und Schrift</li></ul><p><strong>UNSERE BENEFITS</strong></p><ul><li>Flexible Arbeitszeiten und Mobile Office in Abstimmung mit dem Vorgesetzten</li><li>Rabatte dank dem Portal \u201eCorporate Benefits&quot;</li><li>Bike-Leasing</li><li>Kostenlose Getr\u00e4nke &amp; Obst</li><li>Weiterbildungsm\u00f6glichkeiten</li><li>Mitarbeiterevents</li></ul><p>Weitere Benefits f\u00fcr Deutschland</p><br><p><strong>KONTAKT</strong></p><br><p>Sascha Sturm</p><br><p>Team Leader Recruiting</p><br><p>+49 89 54054-5454</p><br>"
  },
  {
    "id": 113,
    "title": "Data Engineer (d/m/w) - befristet (Elternzeitvertretung)",
    "company": "Toll Collect GmbH",
    "locations": "Berlin",
    "skills": "SQL, Mathematik, Linux, Cognos, PL/SQL, Windows",
    "posted_at": "2024-07-11",
    "is_remote": "False",
    "snippet_fragments": "     Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit,      Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten,      Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen,      Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit,      Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen ,     Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics,      Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL),      Sie beherrschen den Umgang mit Windows und Linux einwandfrei,      Sie haben ein abgeschlossenes Studium in der Mathematik,      Sie haben Berufserfahrung im Bereich Data Engineering,     Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung,      Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung,  Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet,      Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung,     Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung,     Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu, Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen, Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt",
    "description": "<p>Referenznummer: 20728</p><br><p>Ihre Aufgaben</p><ul><li>Sie verantworten die Strukturierung und Weiterentwicklung von Datenmodellen und Datenfl\u00fcssen sowie der zugeh\u00f6rigen IT-gest\u00fctzten Prozesse</li><li>Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit</li><li>Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten</li><li>Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen</li><li>Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit, bringen eigene Ideen ein und setzen diese um</li><li>Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen<br> Ihr Profil</li><li>Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics</li><li>Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL).</li><li>Sie beherrschen den Umgang mit Windows und Linux einwandfrei</li><li>Sie haben ein abgeschlossenes Studium in der Mathematik, Informatik oder in einem vergleichbaren Studiengang</li><li>Sie haben Berufserfahrung im Bereich Data Engineering<br> Was bieten wir</li><li>Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung</li><li>Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung</li><li>Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet</li><li>Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung</li></ul><p>Interessiert?</p><br><p>Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung.</p><br><p>Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu. Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen. Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt.</p><br><p>Ihre Ansprechperson</p><br><p>Frau Silvia Barknecht, 030/74077-8214, karriere@toll-collect.de</p><br><p>Toll Collect GmbH * Personalmanagement * Linkstra\u00dfe 4, 10785 Berlin</p><br>"
  },
  {
    "id": 114,
    "title": "Data Engineer",
    "company": "SumUp",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Data Pipelines, Data Warehouse, Airflow, Kafka, Data Lake",
    "posted_at": "2024-07-10",
    "is_remote": "False",
    "snippet_fragments": " You'll be great for this role if ,   You have excellent skills in building,   You are cheerfully working with Python and Airflow ,   You are renowned for skillfully sending (e, Kafka), querying (SQL), and transforming data (e.g,   You have experience with machine learning models and their application as well as traditional engineering and operational excellence ,   You are a great communicator and collaborator who is fun to work with ,   Knowledge in marketing or ML Ops would be a plus ,   We're a truly global team of 3000 people from 60 countries,   We get together regularly for breakfasts,   You'll receive a budget for attending conferences and external training ,   We offer a corporate pension scheme,   You'll be based in the heart of Berlin,   You'll attend global offsites and/or hackathons ,   We believe in the everyday hero, Those who have the courage to follow their passion and who have the strength and determination to realize their dreams, Small business owners are at the heart of all we do, With a founder's mentality and a 'team-first attitude' our diverse teams across Europe",
    "description": "<p><strong>Location</strong>: Berlin, office-first</p><br><p>SumUp enables merchants around the world to get paid easily, process orders quickly, sell online instantly and manage their money more efficiently. SumUp creates the tools merchants need to make their customer experience and their business thrive.</p><br><p>The cross-functional MarTech team is responsible for improving our customer acquisition. This includes optimizing our worldwide online marketing spendings, attributing new customers to marketing campaigns, automating content creation through AI, calculating the customer lifetime value of our merchants, and making data from various sources available for analysis and decision making.</p><br><p>Data is the underlying prerequisite for all of these tasks. We are looking for a passionate Data Engineer to complement our team. The role is crucial to extract, transform, clean-up, ingest, and manage data from various sources for our ML models, analytics, and product use cases with the needed quality.</p><br><p><strong>What you'll do</strong></p><ul><li>Work closely with stakeholders to build valuable solutions and enable them to use these efficiently</li><li>Build and scale complex data pipelines that power machine learning and data products based on a wide spectrum of data sources from within SumUp</li><li>Make key data available in our data lake and DWH</li><li>Ensure the timeliness and accuracy of data sets through monitoring and data quality checks</li><li>Optimise our data models towards maintainability and scalability</li></ul><p><strong>You'll be great for this role if</strong></p><ul><li>You have excellent skills in building, operating and leveraging data pipelines, machine learning models, and systems leveraging both</li><li>You are cheerfully working with Python and Airflow</li><li>You are renowned for skillfully sending (e.g. Kafka), querying (SQL), and transforming data (e.g. dbt)</li><li>You have experience with machine learning models and their application as well as traditional engineering and operational excellence</li><li>You are a great communicator and collaborator who is fun to work with</li><li>Knowledge in marketing or ML Ops would be a plus</li></ul><p><strong>Why you should join SumUp</strong></p><ul><li>We're a truly global team of 3000+ people from 60+ countries, spread across 3 continents</li><li>We get together regularly for breakfasts, team events, office parties, and sports</li><li>You'll receive a budget for attending conferences and external training</li><li>We offer a corporate pension scheme, 28 days' paid leave, free German and yoga classes, subsidized Urban Sports Club membership, a stock option plan, and other great benefits</li><li>You'll be based in the heart of Berlin, one of Europe's leading tech hubs and most vibrant cities</li><li>You'll attend global offsites and/or hackathons</li></ul><p><strong>About SumUp</strong></p><br><p>We believe in the everyday hero. Those who have the courage to follow their passion and who have the strength and determination to realize their dreams. Small business owners are at the heart of all we do, so we're creating powerful, easy-to-use financial solutions to help them run their businesses. With a founder's mentality and a 'team-first attitude' our diverse teams across Europe, South America, and the United States work together to ensure that small business owners can be successful doing what they love.</p><br><p>SumUp is an Equal Employment Opportunity employer that proudly pursues and hires a diverse workforce. SumUp does not make hiring or employment decisions on the basis of race, colour, religion or religious belief, ethnic or national origin, nationality, sex, gender, gender identity, sexual orientation, disability, age, or any other basis protected by applicable laws or prohibited by Company policy. SumUp also strives for a healthy and safe workplace and strictly prohibits harassment of any kind.</p><br><p><strong>Job Application Tip</strong></p><br><p>We recognise that candidates feel they need to meet 100% of the job criteria in order to apply for a job. Please note that this is only a guide. If you don't tick every box, it's ok too because it means you have room to learn and develop your career at SumUp.</p><br>"
  },
  {
    "id": 115,
    "title": "Senior Data Scientist",
    "company": "Almedia",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Cloud, A/B testing",
    "posted_at": "2024-07-10",
    "is_remote": "False",
    "snippet_fragments": " Strong statistical knowledge (A/B tests, probability, regression),  Combination of Python, SQL and cloud experience is essential,  Excellent communication skills, with the ability to present complex findings in a clear and concise manner,    An opportunity to work in an innovative,   A fast-paced and inclusive work environment in a team of highly motivated professionals",
    "description": "<p>Almedia helps leading brands in the digital space to acquire new customers. Users can find and test the latest games, apps, and products for rewards via our platforms.</p><br><p>With more than 20 million users since our launch in 2020, Almedia's Freecash.com is one of the fastest-growing providers and a leader in our industry. Our mission is to provide a win-win experience for both users and advertisers.</p><br><p>We are looking for an experienced Data Scientist to join our rapidly growing team in Berlin.</p><br><p><strong>You Will</strong>:</p><ul><li>Identify high-value ML business opportunities and work with both business and technical stakeholders to realise business benefit</li><li>Deliver and deploy end-to-end machine-learning models, build measurement plans, learn and iterate to drive results</li><li>Apply a solid statistical mindset and best practices, in the process of model development, deployment and evolution</li><li>Deeply understand the data and customer and business problems, in order to more closely align machine-learning model objectives and develop the best features and models to predict them</li><li>Collaborate effectively with cross-functional teams, including product mangers, engineers, business developers, and user acquisition channel managers</li></ul><p><strong>You Have:</strong></p><ul><li>5+ years of work experience, developing machine-learning models, and ideally leading projects and small teams</li><li>Expertise in building, deploying, measuring, and maintaining machine learning models to address real-world problems</li><li>Strong statistical knowledge (A/B tests, probability, regression)</li><li>Combination of Python, SQL and cloud experience is essential</li><li>Excellent communication skills, with the ability to present complex findings in a clear and concise manner</li></ul><p><strong>Benefits:</strong></p><ul><li>An opportunity to work in an innovative, high-growth startup that has been profitable from day one.</li><li>A fast-paced and inclusive work environment in a team of highly motivated professionals.</li><li>Continuous learning and development opportunities.</li><li>Flexible work arrangements and a modern office space in the heart of Berlin.</li><li>Work from abroad policy</li></ul><p>Almedia is an equal opportunity employer, we embrace and celebrate diversity and encourage individuals from all backgrounds to apply.</p><br>"
  },
  {
    "id": 116,
    "title": "Data Engineer (d/m/w) - befristet (Elternzeitvertretung)",
    "company": "Toll Collect GmbH",
    "locations": "Berlin",
    "skills": "SQL, Mathematik, Linux, Cognos, PL/SQL, Windows",
    "posted_at": "2024-07-10",
    "is_remote": "False",
    "snippet_fragments": "     Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen,      Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit,      Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen ,     Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics,      Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL),      Sie beherrschen den Umgang mit Windows und Linux einwandfrei,      Sie haben ein abgeschlossenes Studium in der Mathematik,      Sie haben Berufserfahrung im Bereich Data Engineering,     Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung,      Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung,  Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet,      Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung,     Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung,     Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu, Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen, Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt",
    "description": "<p>Referenznummer: 20728</p><br><p>Ihre Aufgaben</p><ul><li>Sie verantworten die Strukturierung und Weiterentwicklung von Datenmodellen und Datenfl\u00fcssen sowie der zugeh\u00f6rigen IT-gest\u00fctzten Prozesse</li><li>Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit</li><li>Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten</li><li>Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen</li><li>Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit, bringen eigene Ideen ein und setzen diese um</li><li>Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen<br> Ihr Profil</li><li>Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics</li><li>Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL).</li><li>Sie beherrschen den Umgang mit Windows und Linux einwandfrei</li><li>Sie haben ein abgeschlossenes Studium in der Mathematik, Informatik oder in einem vergleichbaren Studiengang</li><li>Sie haben Berufserfahrung im Bereich Data Engineering<br> Was bieten wir</li><li>Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung</li><li>Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung</li><li>Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet</li><li>Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung</li></ul><p>Interessiert?</p><br><p>Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung.</p><br><p>Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu. Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen. Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt.</p><br><p>Ihre Ansprechperson</p><br><p>Frau Silvia Barknecht, 030/74077-8214, karriere@toll-collect.de</p><br><p>Toll Collect GmbH * Personalmanagement * Linkstra\u00dfe 4, 10785 Berlin</p><br>"
  },
  {
    "id": 117,
    "title": "Data Engineer (w/m/d)",
    "company": "Kassen\u00e4rztliche Bundesvereinigung Kd\u00f6R",
    "locations": "Berlin",
    "skills": "Data Analysis, Business Intelligence, Data Modeling, Agile, MicroStrategy, Oracle Exadata",
    "posted_at": "2024-07-10",
    "is_remote": "True",
    "snippet_fragments": "    Sie setzen komplexe Datenanalysen um und treiben die Entwicklung von Dash-Boards und automatisierten R\u00fcckmeldeberichten eigenverantwortlich voran ,     Von Ihnen konzipierte L\u00f6sungen setzen Sie bis zum Roll-Out um ,     Gutes Verst\u00e4ndnis von DWH- und BI-Architekturen ,     Erfahrungen im Umgang mit BI- und Datenbank-Technologien sowie gute SQL- und Python-Kenntnisse ,     Kenntnisse im Bereich Reporting und Datenvisualisierung , Gute Kenntnisse im Bereich Datenanalyse, Datenmodellierung und Datenintegration, L\u00f6sungsorientierte Denkweise, Kreativit\u00e4t, ein hohes analytisches Verst\u00e4ndnis sowie ausgepr\u00e4gte Teamorientierung,  Sie genie\u00dfen die Vorteile eines sicheren Arbeitsplatzes und agieren zugleich in einem innovativen IT-Umfeld aus Systemhaus und Dienstleister,     Fr\u00fchaufsteher oder Langschl\u00e4fer? Ihre Arbeitszeit k\u00f6nnen Sie flexibel durch mobiles Arbeiten und unser Gleitzeitmodell gestalten ,  Wir wertsch\u00e4tzen Ihre Arbeit mit einer attraktiven Bezahlung,  Wir f\u00f6rdern Sie mit passenden Weiterbildungen in unserer hauseigenen Akademie oder bei externen Anbietern,  Betriebliche Altersvorsorge, Kantine, Sportangebote, eine Kindertagesst\u00e4tte im Haus sowie Zuschuss zum Firmenticket sind nur einige Beispiele",
    "description": "<p>Mehr als 100.000 Praxen arbeiten mit der IT, die die Kassen\u00e4rztliche Bundesvereinigung konzipiert, entwickelt oder zertifiziert.</p><br><p>F\u00fcr unser gr\u00f6\u00dftes Dezernat IT und Digitalisierung im Zentrum von Berlin suchen wir zum n\u00e4chstm\u00f6glichen Zeitpunkt unbefristet als Senior-Referent/-in eine/n</p><br><p><strong>DATA ENGINEER (W/M/D)</strong><br> Mit Ihrer Expertise tragen Sie zu ausfallsicherer Software bei, die im Ernstfall Leben rettet im reibungslosen Praxis-betrieb f\u00fcr mehr als 73 Millionen gesetzlich Krankenversicherte.<br> Ihre Aufgaben</p><ul><li>Sie modellieren und realisieren Business Intelligence (BI)-L\u00f6sungen auf Basis von Oracle Exadata und Microstrategy</li><li>Sie planen und begleiten Updates, Installationen und Konfigurationen der BI-Software</li><li>Sie treiben Controls zur Steigerung der Datenqualit\u00e4t/-validit\u00e4t voran</li><li>Sie unterst\u00fctzen bei der Planung und Umsetzung von Prozessoptimierungen im Bereich Datenmanagement</li><li>Sie stimmen Anforderungen im Rahmen der Datenanalyse mit den Fachabteilungen ab und beraten und begleiten sie fachlich in der Nutzung von Gesundheitsdaten</li><li>Sie setzen komplexe Datenanalysen um und treiben die Entwicklung von Dash-Boards und automatisierten R\u00fcckmeldeberichten eigenverantwortlich voran</li><li>Von Ihnen konzipierte L\u00f6sungen setzen Sie bis zum Roll-Out um</li></ul><p>Ihr Profil</p><ul><li>Sie verf\u00fcgen \u00fcber ein abgeschlossenes Studium (idealerweise: Wirtschafts-/Medizin- oder (techn.) Informatik)</li><li>Gutes Verst\u00e4ndnis von DWH- und BI-Architekturen</li><li>Erfahrungen im Umgang mit BI- und Datenbank-Technologien sowie gute SQL- und Python-Kenntnisse</li><li>Kenntnisse im Bereich Reporting und Datenvisualisierung</li><li>Gute Kenntnisse im Bereich Datenanalyse, Datenmodellierung und Datenintegration</li><li>L\u00f6sungsorientierte Denkweise, Kreativit\u00e4t, ein hohes analytisches Verst\u00e4ndnis sowie ausgepr\u00e4gte Teamorientierung</li><li>Erfahrungen im Gesundheitswesen sind vorteilhaft</li><li>Sprachkenntnisse (CEFR-Niveau): Deutsch mindestens C1</li></ul><p>Wir bieten Ihnen</p><ul><li><br><strong>Agile Kombination:</strong> Sie genie\u00dfen die Vorteile eines sicheren Arbeitsplatzes und agieren zugleich in einem innovativen IT-Umfeld aus Systemhaus und Dienstleister</li><li><br><strong>Fr\u00fchaufsteher oder Langschl\u00e4fer?</strong> Ihre Arbeitszeit k\u00f6nnen Sie flexibel durch mobiles Arbeiten und unser Gleitzeitmodell gestalten</li><li><br><strong>Verg\u00fctung:</strong> Wir wertsch\u00e4tzen Ihre Arbeit mit einer attraktiven Bezahlung</li><li><br><strong>Berufliche Entwicklung:</strong> Wir f\u00f6rdern Sie mit passenden Weiterbildungen in unserer hauseigenen Akademie oder bei externen Anbietern</li><li><br><strong>Weitere Benefits:</strong> Betriebliche Altersvorsorge, Kantine, Sportangebote, eine Kindertagesst\u00e4tte im Haus sowie Zuschuss zum Firmenticket sind nur einige Beispiele</li></ul><p>Die KBV gew\u00e4hrleistet die berufliche Gleichstellung von Frauen und M\u00e4nnern. Schwerbehinderte Menschen werden bei gleicher Eignung besonders ber\u00fccksichtigt. Die Stelle ist f\u00fcr die Besetzung mit Teilzeitkr\u00e4ften grunds\u00e4tzlich geeignet.</p><br><p><strong>Haben wir Ihr Interesse geweckt?</strong></p><br><p>Dann bewerben Sie sich bis zum <strong>25.07.2024</strong> F\u00fcr R\u00fcckfragen steht Ihnen Frau Diana Kurch-Bek gern unter 030 4005 2082 zur Verf\u00fcgung. Wir freuen uns auf Ihre Bewerbung! Weitere Infos auf https://it-karriere.kbv.de/.</p><br>"
  },
  {
    "id": 118,
    "title": "Data Engineer (d/m/w) - befristet (Elternzeitvertretung)",
    "company": "Toll Collect GmbH",
    "locations": "Berlin",
    "skills": "SQL, Mathematik, Linux, Cognos, PL/SQL, Windows",
    "posted_at": "2024-07-07",
    "is_remote": "False",
    "snippet_fragments": "     Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit,      Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten,      Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen,      Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit,      Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen ,     Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics,      Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL),      Sie beherrschen den Umgang mit Windows und Linux einwandfrei,      Sie haben ein abgeschlossenes Studium in der Mathematik,      Sie haben Berufserfahrung im Bereich Data Engineering,     Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung,      Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung,  Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet,      Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung,     Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung,     Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu, Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen, Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt",
    "description": "<p>Referenznummer: 20728</p><br><p>Ihre Aufgaben</p><ul><li>Sie verantworten die Strukturierung und Weiterentwicklung von Datenmodellen und Datenfl\u00fcssen sowie der zugeh\u00f6rigen IT-gest\u00fctzten Prozesse</li><li>Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit</li><li>Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten</li><li>Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen</li><li>Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit, bringen eigene Ideen ein und setzen diese um</li><li>Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen<br> Ihr Profil</li><li>Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics</li><li>Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL).</li><li>Sie beherrschen den Umgang mit Windows und Linux einwandfrei</li><li>Sie haben ein abgeschlossenes Studium in der Mathematik, Informatik oder in einem vergleichbaren Studiengang</li><li>Sie haben Berufserfahrung im Bereich Data Engineering<br> Was bieten wir</li><li>Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung</li><li>Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung</li><li>Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet</li><li>Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung</li></ul><p>Interessiert?</p><br><p>Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung.</p><br><p>Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu. Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen. Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt.</p><br><p>Ihre Ansprechperson</p><br><p>Frau Silvia Barknecht, 030/74077-8214, karriere@toll-collect.de</p><br><p>Toll Collect GmbH * Personalmanagement * Linkstra\u00dfe 4, 10785 Berlin</p><br>"
  },
  {
    "id": 119,
    "title": "Senior Data Engineer",
    "company": "DataCamp",
    "locations": "Berlin",
    "skills": "Python, SQL, Data Science, AWS, Data Pipelines, GCP, Azure, Business Intelligence, Data Warehouse, ETL, Airflow, Ansible, BigQuery, Code Reviews, Docker, Kanban, Kubernetes, Scrum, Terraform, Cloud Platforms, Looker, IaC, Snowflake, Metabase, CD, Continuous Integration",
    "posted_at": "2024-07-04",
    "is_remote": "False",
    "snippet_fragments": "You thrive in a fast-paced, high-performing environment and are driven by a passion for making a meaningful impact, You're adaptable, embracing change and ambiguity with enthusiasm, Your initiative and entrepreneurial spirit push you beyond just meeting targetsyou aim to understand the \"why\" behind our goals and take ownership to drive the business forward, You're a collaborative team player who values transparency and always seeks to improve and innovate, If this sounds like you, we encourage you to apply!,  Maintain self-serve systems for teams to access data for informed decision-making, avoiding central bottlenecks.,  Keep data pipelines and development processes operational and efficient.,  Take charge of daily tasks and promptly address operational issues.,  Focus 80% on planned quarterly OKR work and 20% on support work, achieved through automation.,  Act as a force multiplier by being approachable and assisting others with data engineering needs.,  Utilize Python proficiency and advise on SQL best practices.,  Understand data ingestion, processing, and reverse ETL processes.,  Uphold strong data governance practices and act as a gatekeeper for data platform security.,   Is an experienced Data Engineer of between 1-3 years,   Has experience of data warehousing (e, Big Query or Snowflake) and data engineering related tools (e,   Has some knowledge of cloud platforms (AWS,   Can develop in Python and write SQL ,   Has excellent oral and written communication skills ,   Is interested in understanding and scaling complex data pipelines ,   Is interested in monitoring and self healing systems ,   Is highly organized with a flexible,   Improves the team with code reviews,   Is able to work collaboratively in teams and develop meaningful relationships to achieve common goals , You have experience in Docker, CI/CD, Kubernetes,   You have experience of Data Marts ,   You have experience with Infrastructure-as-code (Terraform,   You are passionate about data science and education ,   Joining DataCamp means becoming part of a dynamic",
    "description": "<p><strong>Who We Are:</strong></p><br><p>At DataCamp, we're not just a platform; we're the catalyst for a data-fluent world. We enable individuals and businesses to leap forward in data science, providing them with top-tier education, certification, and collaboration tools.</p><br><p><strong>By the Numbers:</strong></p><ul><li>400+ dynamic courses</li><li>270+ renowned instructors from 35 Countries</li><li>90+ hands-on projects</li><li>12 million+ global learners</li></ul><p>We're proud to be backed by Spectrum Equity, Accomplice, and Arthur Ventures, aiming to hit $100M ARR in the upcoming years. While our roots are in New York City, our presence spans London to Leuven, with a vibrant team of 200+ members working both on-site and remotely.</p><br><p><strong>About the role</strong></p><br><p>As a Data Engineer at DataCamp, you will play a pivotal role in enhancing our data-driven decision-making and operational efficiency. You will manage and optimize our Datalakehouse on Google Cloud's BigQuery, ensuring our leadership team has the precise and timely BI reports needed to steer the company towards its OKRs and vision. Your work will empower our engineering teams to make informed, data-driven decisions, boosting their project effectiveness and overall productivity.</p><br><p><strong>About you</strong></p><br><p>At DataCamp, we seek individuals who embody our core values of data-driven decision-making, action, transparency, ownership, and customer focus. You thrive in a fast-paced, high-performing environment and are driven by a passion for making a meaningful impact. You're adaptable, embracing change and ambiguity with enthusiasm. Your initiative and entrepreneurial spirit push you beyond just meeting targets-you aim to understand the &quot;why&quot; behind our goals and take ownership to drive the business forward. You're a collaborative team player who values transparency and always seeks to improve and innovate. If this sounds like you, we encourage you to apply!</p><br><p><strong>Responsibilities</strong></p><ul><li><br><strong>Ensure Accessibility:</strong> Maintain self-serve systems for teams to access data for informed decision-making, avoiding central bottlenecks.</li><li><br><strong>Data Pipeline Management:</strong> Keep data pipelines and development processes operational and efficient.</li><li><br><strong>Plan Improvements</strong>: Collaborate with the senior data engineer to enhance the data platform, development process, and testing procedures.</li><li><br><strong>Ownership and Proactivity:</strong> Take charge of daily tasks and promptly address operational issues.</li><li><br><strong>Capability Development:</strong> Focus 80% on planned quarterly OKR work and 20% on support work, achieved through automation.</li><li><br><strong>Support and Collaboration:</strong> Act as a force multiplier by being approachable and assisting others with data engineering needs.</li><li><br><strong>Technical Expertise:</strong> Utilize Python proficiency and advise on SQL best practices.</li><li><br><strong>Data Handling Knowledge:</strong> Understand data ingestion, processing, and reverse ETL processes.</li><li><br><strong>Data Governance:</strong> Uphold strong data governance practices and act as a gatekeeper for data platform security.</li></ul><p><strong>Qualifications</strong></p><ul><li>Is an experienced Data Engineer of between 1-3 years.</li><li>Has experience of data warehousing (e.g. Big Query or Snowflake) and data engineering related tools (e.g. Airflow, Looker, Metabase, Fivetran)</li><li>Has some knowledge of cloud platforms (AWS, GCP or Azure)</li><li>Can develop in Python and write SQL</li><li>Understand Scrum and Kanban</li><li>Has excellent oral and written communication skills</li><li>Is interested in understanding and scaling complex data pipelines</li><li>Is interested in monitoring and self healing systems</li><li>Is highly organized with a flexible, can-do attitude and a willingness/aptitude for learning</li><li>Improves the team with code reviews, technical discussions and documentation</li><li>Is able to work collaboratively in teams and develop meaningful relationships to achieve common goals</li></ul><p><strong>It's a plus if</strong></p><ul><li>You have experience in DBT</li><li>You have experience in Docker, CI/CD, Kubernetes</li><li>You have experience of Data Marts</li><li>You have experience with Infrastructure-as-code (Terraform, Ansible, etc)</li><li>You are passionate about data science and education</li></ul><p><strong>Why Datacamp?</strong></p><br><p>Joining DataCamp means becoming part of a dynamic, creative, and international start-up. Here are just a few of the reasons why you'll love being on our team:</p><ul><li>Exciting challenges: Face new technical challenges daily, keeping your work engaging and rewarding.</li><li>Competitive compensation: We offer a competitive salary with attractive benefits.</li><li>Flexibility: Benefit from flexible working hours because the future is flexible!</li><li>Continuous learning: Access a yearly learning budget for conferences &amp; training to support your professional growth.</li><li>Global retreats: Participate in international company retreats, fostering a global team spirit.</li><li>Amazing team: Collaborate with a truly exceptional team-seriously, we're awesome!</li></ul><p><strong>What's in it for you:</strong></p><br><p>In addition to joining a creative and international start-up, as a permanent employee you'll enjoy:</p><ul><li>A very competitive salary</li><li>An exciting job that will offer you technical challenges every day</li><li>Flexible working hours</li><li>International company retreats</li><li>Conference and hardware budget</li><li>Working with a great team (everyone says this, but we're serious-we're pretty great)</li></ul><p>DataCamp is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.</p><br>"
  },
  {
    "id": 120,
    "title": "Data Analyst / Decision Scientist, Help Experience",
    "company": "Vinted",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Data Science, A/B testing, Algorithms, Tableau, Looker, Statistical Programming, R, Statistik, \u00d6konometrie, Applied Mathematics",
    "posted_at": "2024-07-04",
    "is_remote": "True",
    "snippet_fragments": "  BSc or MSc in Applied Mathematics,   Highly business-oriented and comfortable with iterative processes ,   A good communicator who can present complex topics clearly and persuasively to different audiences ,   Are able to balance between analyses depth (time needed) and business impact ,   Ability to deal with uncertainty and to combine data insights with strategic thinking ,   Advanced knowledge of at least one statistical programming language (Python,   Fluency with SQL and experience with dashboarding tools (e,   The opportunity to benefit from our share options programme ,   30 days of paid annual leave ,   Mental and emotional health support through the Mindletic app ,   A personal monthly budget for shopping on Vinted ,   A subsidised gym membership with ClassPass or Urban Sports Card ,   A subsidised pension plan provided by Vinted ",
    "description": "<p>BRIEF INFO ABOUT VINTED</p><br><p>Vinted Marketplace is the largest online international C2C marketplace in Europe dedicated to second-hand fashion, with millions of registered members spanning 22 markets in Europe and North America. With a mission to make second-hand the first choice worldwide, Vinted enables people to sell and buy second-hand clothes and lifestyle items from each other, helping give those items a second or even third life.</p><br><p>Vinted Go launched in 2022, with a focus on developing products and solutions for more seamless shipping and delivery across Europe. Vinted Go has connected more than 40 carriers and more than 200,000 PUDO points across Europe to support the delivery of millions of parcels per year.</p><br><p>The Vinted Group, composed of Vinted Marketplace and Vinted Go, is headquartered in Vilnius, with workplaces in Germany, Lithuania, France, the United Kingdom, the Netherlands and over 2,000 employees. It is backed by six leading venture capital firms: Accel, Burda Principal Investments, EQT Growth, Insight Partners, Lightspeed Venture Partners, and Sprints Capital.</p><br><p>INFORMATION ABOUT THE POSITION</p><br><p>As our new Decision Scientist, you'll become part of a cross-functional team in the Help Experience domain with a mission to enable an effortless, scalable and cost effective support experience for our Vinted members. Your team's focus will be on supporting our Member Support function and enabling quality and efficiency improvements through automation, self-service, and operational excellence.</p><br><p>We're looking for someone who is a strategic thinker, a problem solver, with a strong data background, who aims high. You like to work in a fast-changing environment, and you are passionate about the product we're building together.</p><br><p>Next to the product team you will be part of the cross-domain Data Science &amp; Analytics (DSA) guild where you will interact and learn from all data people in Vinted. Within Data Science &amp; Analytics (DSA) we have three distinct roles. To understand your role within DSA context better, here are brief descriptions of each role we have in the department:</p><ul><li><br><strong>Decision Scientists</strong> are responsible for actionable insights, identifying and sizing opportunities, and automated tools that increase the quality of product and business decisions by applying statistical methods and data-driven decision making.</li><li><br><strong>Analytics Engineers</strong> are responsible for data curation - translating data needs from stakeholders into architecting, building and maintaining efficient &amp; reliable data models and pipelines.</li><li><br><strong>Data Scientists</strong> are responsible for identification of algorithmic opportunities, ensuring those opportunities are addressed in an optimal fashion and design, development and maintenance of production-grade statistical and machine learning algorithms.</li></ul><p>You will report to the Director of data science &amp; analytics in Help Experience and work closely with other leaders in the domain, particularly in the data science &amp; analytics and product functions.</p><br><p>IN THIS POSITION, YOU'LL</p><ul><li>Collaborate with your team and direct stakeholders to identify strategic opportunities and answer key business questions</li><li>Ensure these questions are answered in an optimal fashion (e.g. in the form of an ad hoc deep-dive, experiment, dashboard, or automatically recurring analysis)</li><li>Analyze identified opportunities to understand their scope and impact (i.e. size opportunities)</li><li>Own the key performance indicators for a team, including selection, tracking, forecasting, and proactively flagging issues</li><li>Enable your team and direct stakeholders to independently leverage data for business insights via self-serving and dashboarding tools (Looker)</li><li>Define the requirements for (A/B) testing and analyze the results of (A/B) tests</li><li>Help to create a backlog with prioritized hypotheses and analyses</li></ul><p>ABOUT YOU</p><ul><li>Demonstratable experience as a Decision Scientist, Data Analyst, Product Analyst or a Strategic role with a strong data component.</li><li>BSc or MSc in Applied Mathematics, Data Science, Computer Science, Economics, Statistics, Econometrics, or another related field (equivalent working experience is also acceptable)</li><li>Highly business-oriented and comfortable with iterative processes</li><li>A good communicator who can present complex topics clearly and persuasively to different audiences</li><li>Excellent written and spoken English</li><li>Are able to balance between analyses depth (time needed) and business impact</li><li>Ability to deal with uncertainty and to combine data insights with strategic thinking</li><li>Statistical proficiency (e.g. A/B testing, regression analysis)</li><li>Advanced knowledge of at least one statistical programming language (Python, R, etc.)</li><li>Fluency with SQL and experience with dashboarding tools (e.g. Looker, Tableau, etc.)</li></ul><p>WORK PERKS</p><ul><li>The opportunity to benefit from our share options programme</li><li>30 days of paid annual leave</li><li>Newest MacBook models</li><li>Mental and emotional health support through the Mindletic app</li><li>Home office support: we provide IT workstation equipment and a personal budget of up to \u20ac540 for home workplace furniture</li><li>A daily lunch allowance</li><li>Frequent team-building events</li><li>A personal monthly budget for shopping on Vinted</li><li>A subsidised gym membership with ClassPass or Urban Sports Card</li><li>A subsidised pension plan provided by Vinted</li><li>Hallesche Supplemental health insurance</li><li>Life and disability insurance provided</li><li>A subsidised Deutschlandticket</li><li>The opportunity to spend up to 90 days per year - 21 of which can be spent working outside of the EU - on workation</li><li>A dog-friendly office</li></ul><p>WORKING AT VINTED</p><br><p><strong>Individual Learning Budget</strong></p><br><p>Vinted will set aside a yearly sum equal to 10-13.2% of your annual salary to be invested in your continuous professional development. You'll be able to take the initiative to use it for covering relevant learning activities that benefit your role.</p><br><p><strong>Hybrid Work</strong></p><br><p>We've adopted a hybrid workplace model where 2 days in the office are recommended but not enforced. It's up to you and your team to decide on the exact days you'll spend working together in person.</p><br><p><strong>Equal Opportunity</strong></p><br><p>The Vinted Group is committed to building an inclusive workplace where people from all walks of life feel a sense of belonging. We welcome applications from people of all backgrounds, identities and life experiences. At Vinted, all applicants are treated fairly without regard to their race, age, religion or belief, sex, national origin, citizenship, gender identity, sexual orientation, disability, or any other protected characteristic.</p><br><p>The salary range for this position is <strong>\u20ac</strong>69,000 <strong>- \u20ac93,400</strong> gross per year.</p><br>"
  },
  {
    "id": 121,
    "title": "Principal Data Platform Software Engineer",
    "company": "ServiceNow",
    "locations": "Berlin",
    "skills": "SQL, AI, C++, Kernel, MariaDB, OO, PostgreSQL, TDD, Database Design, Data mining, C, SOLID, Architektur",
    "posted_at": "2024-07-04",
    "is_remote": "False",
    "snippet_fragments": "   Youll collaborate with a team of 15 dedicated database-internals engineers,    Be part of building the next-gen database platform using and contributing to the latest open-source technologies,    Analyze storage/memory/compute performance and scalability bottlenecks in the system and build targeted software solutions,    Develop complex and creative solutions with quality modern C/C code and a highly automated build and test infrastructure,    Improve reliability and observability by designing and building self-diagnostic and self-healing system capabilities,    Learn state-of-the-art development practices for performance,    Partner with core and cross-functional teams to create the next-generation database engine powering ServiceNow,    In depth knowledge of computer and general systems architecture (threads,    Excellent skills in object-oriented programming combined with some C/C and SQL knowledge,    Solid understanding and experience with agile software development methodologies and working in a large,    Ability to handle multiple competing priorities in a fast-paced environment,    Skill to manage your own complex tasks,    Strong problem-solving and analytical skills and the ability to communicate them effectively in design documents and architect-level discussions,    An aptitude for learning new technologies and an itch to code,    Experience working with at least one of OS kernel,    Experience with relational databases is a plus,    6 years of experience developing professional software,    Experience with deep knowledge in one of operating systems,    Proven track record of delivering sub-modules or software features end-to-end,   ServiceNow is an Equal Employment Opportunity Employer, All qualified applicants will receive consideration for employment without regard to race, At ServiceNow, we lead with flexibility and trust in our distributed world of work",
    "description": "<p><strong>Company Description</strong></p><br><p>At ServiceNow, our technology makes the world work for everyone, and our people make it possible. We move fast because the world can't wait, and we innovate in ways no one else can for our customers and communities. By joining ServiceNow, you are part of an ambitious team of change makers who have a restless curiosity and a drive for ingenuity. We know that your best work happens when you live your best life and share your unique talents, so we do everything we can to make that possible. We dream big together, supporting each other to make our individual and collective dreams come true. The future is ours, and it starts with you.</p><br><p>With more than 7,700+ customers, we serve approximately 85% of the Fortune 500\u00ae, and we're proud to be one of FORTUNE 100 Best Companies to Work For\u00ae and World's Most Admired Companies\u2122.</p><br><p>Learn more on Life at Now blog and hear from our employees about their experiences working at ServiceNow.</p><br><p>Unsure if you meet all the qualifications of a job description but are deeply excited about the role? We still encourage you to apply! At ServiceNow, we are committed to creating an inclusive environment where all voices are heard, valued, and respected. We welcome all candidates, including individuals from non-traditional, varied backgrounds, that might not come from a typical path connected to this role. We believe skills and experience are transferrable, and the desire to dream big makes for great candidates.<br><strong>Job Description</strong><br><strong>Team:</strong></p><br><p>ServiceNow Project RaptorDB, based on Postgres, the world's most advanced open\u2011source database, acts as a foundational data layer that will allow ServiceNow customers to process massive volumes of transactional data on the Now Platform in real time to meet the demands of AI\u2011powered applications. It adds analytical capabilities to meet advanced reporting and data mining needs. This team is building the core of RaptorDB and even the smallest optimization can have a dramatic impact on our customers and our bottom line.</p><br><p>We are looking for an experienced developer with C/C++ knowledge who wants to contribute heavily to building the very core of our ServiceNow database. You will work directly with other engineers on the Data Platform team solving challenging problems in scaling and querying large data sets efficiently both vertically and horizontally. Our work is based on Postgres with significant in-house enhancements and unique features. This is your opportunity to contribute to cutting edge database software used at massive scale.</p><br><p><strong>What you get to do in this role:</strong></p><ul><li>You'll collaborate with a team of 15+ dedicated database-internals engineers.</li><li>Be part of building the next-gen database platform using and contributing to the latest open-source technologies</li><li>Analyze storage/memory/compute performance and scalability bottlenecks in the system and build targeted software solutions</li><li>Develop complex and creative solutions with quality modern C/C++ code and a highly automated build and test infrastructure</li><li>Improve reliability and observability by designing and building self-diagnostic and self-healing system capabilities</li><li>Learn state-of-the-art development practices for performance, reliability and error prevention</li><li>Partner with core and cross-functional teams to create the next-generation database engine powering ServiceNow</li></ul><p><strong>Qualifications</strong></p><br><p><strong>To be successful in this role you have:</strong></p><ul><li>In depth knowledge of computer and general systems architecture (threads, networking, kernel, etc)</li><li>Excellent skills in object-oriented programming combined with some C/C++ and SQL knowledge</li><li>Experience in test-driven development</li><li>Solid understanding and experience with agile software development methodologies and working in a large, ambitious team</li><li>Ability to handle multiple competing priorities in a fast-paced environment</li><li>Skill to manage your own complex tasks, know when to synchronize and re-align with the team, and lead more junior team members working with you</li><li>Strong problem-solving and analytical skills and the ability to communicate them effectively in design documents and architect-level discussions</li><li>An aptitude for learning new technologies and an itch to code</li><li>Experience working with at least one of OS kernel, memory manager, multi-threaded software modules, or distributed systems</li></ul><p><strong>Nice to have:</strong></p><ul><li>Experience with relational databases is a plus, MariaDB and/or Postgres</li></ul><p><strong>Qualifications</strong></p><ul><li>6+ years of experience developing professional software</li><li>Experience with deep knowledge in one of operating systems, complex layered software products or database systems</li><li>Proven track record of delivering sub-modules or software features end-to-end</li><li>Ability to handle multiple competing priorities in a fast-paced environment</li><li>Knowledge of C/C++ and SQL</li></ul><p><strong>Additional Information</strong></p><br><p>ServiceNow is an Equal Employment Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, creed, religion, sex, sexual orientation, national origin or nationality, ancestry, age, disability, gender identity or expression, marital status, veteran status or any other category protected by law.</p><br><p>At ServiceNow, we lead with flexibility and trust in our distributed world of work. Click here to learn about our work personas: flexible, remote and required-in-office.</p><br><p>If you require a reasonable accommodation to complete any part of the application process, or are limited in the ability or unable to access or use this online application process and need an alternative method for applying, you may contact us at talent.acquisition@servicenow.com for assistance.</p><br><p>For positions requiring access to technical data subject to export control regulations, including Export Administration Regulations (EAR), ServiceNow may have to obtain export licensing approval from the U.S. Government for certain individuals. All employment is contingent upon ServiceNow obtaining any export license or other approval that may be required by the U.S. Government.</p><br><p>Please Note: Fraudulent job postings/job scams are increasingly common. Click here to learn what to watch out for and how to protect yourself. All genuine ServiceNow job postings can be found through the ServiceNow Careers site.</p><br><p>From Fortune. \u00a9 2022 Fortune Media IP Limited All rights reserved. Used under license.</p><br><p>Fortune and Fortune Media IP Limited are not affiliated with, and do not endorse products or services of, ServiceNow.</p><br>"
  },
  {
    "id": 122,
    "title": "Senior Data Engineer - Databricks Expert Supply Solutions (m/w/d)",
    "company": "msg systems ag",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, AWS, Cloud, GCP, Azure, Business Intelligence, ETL, Big Data, DevOps, Power BI, Scala, Databricks, Snowflake, Data Lake, Spark, CD, Continuous Integration, Git, IoT, Mobile Device Management",
    "posted_at": "2024-07-04",
    "is_remote": "True",
    "snippet_fragments": "    Erfahrung mit den Methoden des agilen Projektmanagement , Sichere Deutsch- und Englischkenntnisse, Teamf\u00e4higkeit sowie Flexibilit\u00e4t und Reisebereitschaft ",
    "description": "<p>F\u00fcr den Standort:</p><br><p>Berlin, D\u00fcsseldorf, Essen, Frankfurt, Hamburg, Karlsruhe, K\u00f6ln, M\u00fcnchen, Stuttgart, Deutschlandweit</p><br><p>Sie denken smart, begeistern sich f\u00fcr modernste Technologien und sind erst zufrieden, wenn alle Prozesse und Systeme einwandfrei funktionieren? Dann sind Sie bei uns im Team genau richtig. Durch unsere digitalen L\u00f6sungen aus den Bereichen MDM, BI, Analytics, Big Data sowie IoT gelingt es Unternehmen aus Daten relevantes Wissen zu generieren, Prozesse auf smarte Weise zu digitalisieren und somit die Welt von Morgen mit neuen Produkten zu begeistern. Unser Gesch\u00e4ftsbereich New Data Solutions unterst\u00fctzt andere Unternehmen auf allen Ebenen mit modernsten Technologien.</p><br><p>msg ist eine unabh\u00e4ngige Unternehmensgruppe mit weltweit mehr als 10.000 Mitarbeitenden. Unseren ausgezeichneten Ruf verdanken wir unserem ganzheitlichen Leistungsspektrum aus einfallsreicher strategischer Beratung und intelligenten, nachhaltig wertsch\u00f6pfenden IT-L\u00f6sungen f\u00fcr eine Vielzahl von Branchen.</p><br><p><strong>DAS ERWARTET SIE BEI UNS</strong></p><ul><li>Sie beraten und unterst\u00fctzen unsere Kunden von der Konzeption bis hin zur Implementierung von Datenl\u00f6sungen in der AWS, Azure und GCP Cloud</li><li>Sie entwickeln Datenplattform-L\u00f6sungen mithilfe neuster Big Data-Technologien wie Databricks und Snowflake</li><li>Sie \u00fcbernehmen schnell Verantwortung und unterst\u00fctzen bei der Einarbeitung und Betreuung von Kollegen</li><li>In unserem fachlich und technologisch innovativen sowie agilen Arbeitsumfeld finden Sie exzellente M\u00f6glichkeiten zur pers\u00f6nlichen und technologischen Weiterentwicklung</li><li>Bei uns gehen spannende und abwechslungsreiche Consulting-Projekte mit einer gelebten Work-Life-Balance und einem Stundenkonto einher</li></ul><p><strong>DAS BRINGEN SIE MIT</strong></p><ul><li>Tiefgreifende Kenntnisse in der Konzeption, Entwicklung und Implementierung von Datenl\u00f6sungen mithilfe von Databricks in der AWS, Azure oder GCP Cloud</li><li>Erfahrung mit ETL/ELT-Pipelines, Data Warehouse- und Data Lake Technologien</li><li>Sehr gute Kenntnisse in Python, Spark, SQL (Scala ist ein Plus)</li><li>Kenntnisse in DevOps (CI/CD, Infrastructure as Code, Git)</li><li>Idealerweise Erfahrung mit BI-Tools (z.B. Power BI) und Machine Learning</li><li>Erfahrung mit den Methoden des agilen Projektmanagement</li><li>Sichere Deutsch- und Englischkenntnisse, Teamf\u00e4higkeit sowie Flexibilit\u00e4t und Reisebereitschaft</li></ul><p><strong>DAS IST UNSER ANGEBOT</strong></p><br><p>Gelebte Kultur \u201eMensch im Mittelpunkt&quot;</p><br><p>Nachhaltige Projekte &amp; Soziales Engagement</p><br><p>F\u00f6rderung von Diversit\u00e4t &amp; Chancengleichheit</p><br><p>Vertrauensvoller Teamspirit &amp; Gestaltungsfreiheit</p><br><p>Passgenaue Weiterentwicklung &amp; Mentoring</p><br><p>Flexibles Arbeiten &amp; Work-Life Integration</p><br><p>Corporate Benefits</p><br><p>Mobiles Arbeiten</p><br><p>Sie sind neugierig geworden? Dann freuen wir uns \u00fcber Ihre Onlinebewerbung unter Angabe Ihrer Gehaltsvorstellungen und der Kennziffer:</p><br><p>msg-50699518-000</p><br>"
  },
  {
    "id": 123,
    "title": "(Senior) Cloud Data Engineer Supply Solutions (m/w/d)",
    "company": "msg systems ag",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Data Analysis, Cloud, AI, Business Intelligence, Big Data, Databricks, Snowflake, IoT, Mobile Device Management",
    "posted_at": "2024-07-04",
    "is_remote": "True",
    "snippet_fragments": "    Sie beraten und unterst\u00fctzen unsere Kunden von der Konzeption bis hin zur Implementierung ,     Sie entwickeln innovative L\u00f6sungen und arbeiten mit neuesten Cloud- und Big Data-Technologien ,     Sie \u00fcbernehmen schnell Verantwortung und unterst\u00fctzen bei der Einarbeitung und Betreuung von Kollegen ,     Bei uns finden Sie ein fachlich und technologisch innovatives und agiles Arbeitsumfeld,     Sie sind aktiver Teil unseres interdisziplin\u00e4ren Wissensaustausches ,     Erfahrung in erfolgreich umgesetzten Projekten im Public Cloud Umfeld, Databricks, Snowflake und Deltalake) als Hilfe bei der Aufbereitung und Analyse gro\u00dfer Datenmengen ,     Kenntnisse im Bereich Machine Learning und/oder Datenvisualisierung als Plus,     Erfahrung mit den Methoden des agilen Projektmanagement ,     Teamf\u00e4hige Person sowie eine gute Auffassungsgabe ,     Sichere Kommunikation in Wort und Schrift (Deutsch",
    "description": "<p>F\u00fcr den Standort:</p><br><p>Berlin, D\u00fcsseldorf, Essen, Frankfurt, Hamburg, Karlsruhe, K\u00f6ln, M\u00fcnchen, Stuttgart, Deutschlandweit</p><br><p>Sie denken smart, begeistern sich f\u00fcr modernste Technologien und sind erst zufrieden, wenn alle Prozesse und Systeme einwandfrei funktionieren? Dann sind Sie bei uns genau richtig. Durch unsere digitalen L\u00f6sungen aus den Bereichen MDM, BI, Analytics, Big Data sowie IoT gelingt es Unternehmen aus Daten relevantes Wissen zu generieren, Prozesse auf smarte Weise zu digitalisieren und somit die Welt von Morgen mit neuen Produkten zu begeistern. Unser Gesch\u00e4ftsbereich New Data Solutions fokussiert auf innovative L\u00f6sungen f\u00fcr die Industrie mit modernsten Technologien!</p><br><p>msg ist eine unabh\u00e4ngige Unternehmensgruppe mit weltweit mehr als 10.000 Mitarbeitenden. Unseren ausgezeichneten Ruf verdanken wir unserem ganzheitlichen Leistungsspektrum aus einfallsreicher strategischer Beratung und intelligenten, nachhaltig wertsch\u00f6pfenden IT-L\u00f6sungen f\u00fcr eine Vielzahl von Branchen.</p><br><p><strong>DAS ERWARTET SIE BEI UNS</strong></p><ul><li>Sie beraten und unterst\u00fctzen unsere Kunden von der Konzeption bis hin zur Implementierung</li><li>Sie entwickeln innovative L\u00f6sungen und arbeiten mit neuesten Cloud- und Big Data-Technologien</li><li>Sie \u00fcbernehmen schnell Verantwortung und unterst\u00fctzen bei der Einarbeitung und Betreuung von Kollegen</li><li>Bei uns finden Sie ein fachlich und technologisch innovatives und agiles Arbeitsumfeld, sowie exzellente M\u00f6glichkeiten zur pers\u00f6nlichen und technologischen Weiterentwicklung</li><li>Sie sind aktiver Teil unseres interdisziplin\u00e4ren Wissensaustausches</li></ul><p><strong>DAS BRINGEN SIE MIT</strong></p><ul><li>Erfahrung in erfolgreich umgesetzten Projekten im Public Cloud Umfeld, idealerweise im Kontext Datenintegration, Datenmanagement sowie Data Analytics oder AI &amp; Machine Learning</li><li>Kenntnisse in SQL, Python sowie Cloud- und Big Data-Technologien (z.B. Databricks, Snowflake und Deltalake) als Hilfe bei der Aufbereitung und Analyse gro\u00dfer Datenmengen</li><li>Kenntnisse im Bereich Machine Learning und/oder Datenvisualisierung als Plus, aber kein Muss</li><li>Erfahrung mit den Methoden des agilen Projektmanagement</li><li>Teamf\u00e4hige Person sowie eine gute Auffassungsgabe</li><li>Sichere Kommunikation in Wort und Schrift (Deutsch, Englisch) sowie Flexibilit\u00e4t und Reisebereitschaft</li></ul><p><strong>DAS IST UNSER ANGEBOT</strong></p><br><p>Gelebte Kultur \u201eMensch im Mittelpunkt&quot;</p><br><p>Nachhaltige Projekte &amp; Soziales Engagement</p><br><p>F\u00f6rderung von Diversit\u00e4t &amp; Chancengleichheit</p><br><p>Vertrauensvoller Teamspirit &amp; Gestaltungsfreiheit</p><br><p>Passgenaue Weiterentwicklung &amp; Mentoring</p><br><p>Flexibles Arbeiten &amp; Work-Life Integration</p><br><p>Corporate Benefits</p><br><p>Mobiles Arbeiten</p><br><p>Sie sind neugierig geworden? Dann freuen wir uns \u00fcber Ihre Onlinebewerbung unter Angabe Ihrer Gehaltsvorstellungen und der Kennziffer:</p><br><p>msg-50562376-000</p><br>"
  },
  {
    "id": 124,
    "title": "Junior Cloud Data Engineer Supply Solutions (m/w/d)",
    "company": "msg systems ag",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, AWS, GCP, Azure, Business Intelligence, Big Data, Spark, IoT, Mobile Device Management",
    "posted_at": "2024-07-04",
    "is_remote": "True",
    "snippet_fragments": "    Erhalten Sie eine individuelle Aus- und Weiterbildung im Umgang mit neusten Cloud- und Big Data-Technologien inklusive der M\u00f6glichkeit zur Zertifizierung ,     Sie \u00fcbernehmen in Ihrer jeweiligen Projektrolle schnell Verantwortung ,     Bei uns finden Sie ein fachlich und technologisch innovatives und agiles Arbeitsumfeld,     Bei uns gehen spannende und abwechslungsreiche Consulting-Projekte mit einer gelebten Work-Life-Balance und einem Stundenkonto einher ,     Abgeschlossenes Hochschulstudium mit IT-relevantem Bezug oder vergleichbare Qualifikation , Erste Programmierkenntnisse in Python, Spark und/oder SQL helfen Ihnen bei der Anbindung, Aufbereitung und Analyse gro\u00dfer Datenmengen ,     Idealerweise grundlegende Kenntnisse im Bereich Machine Learning, Teamf\u00e4higkeit sowie gute Auffassungsgabe, l\u00f6sungsorientiertes Handeln und selbstst\u00e4ndige Arbeitsweise ,     Sichere Kommunikation in Wort und Schrift in Deutsch und Englisch sowie Flexibilit\u00e4t und Reisebereitschaft ",
    "description": "<p>F\u00fcr den Standort:</p><br><p>Berlin, D\u00fcsseldorf, Essen, Frankfurt, Hamburg, Karlsruhe, K\u00f6ln, M\u00fcnchen, Stuttgart, Deutschlandweit</p><br><p>Sie denken smart, begeistern sich f\u00fcr modernste Technologien und sind erst zufrieden, wenn alle Prozesse und Systeme einwandfrei funktionieren? Dann sind Sie bei uns genau richtig. Durch unsere digitalen L\u00f6sungen aus den Bereichen MDM, BI, Analytics, Big Data sowie IoT gelingt es Unternehmen aus Daten relevantes Wissen zu generieren, Prozesse auf smarte Weise zu digitalisieren und somit die Welt von Morgen mit neuen Produkten zu begeistern. Unser Gesch\u00e4ftsbereich New Data Solutions fokussiert auf innovative L\u00f6sungen f\u00fcr die Industrie mit modernsten Technologien!</p><br><p>msg ist eine unabh\u00e4ngige Unternehmensgruppe mit weltweit mehr als 10.000 Mitarbeitenden. Unseren ausgezeichneten Ruf verdanken wir unserem ganzheitlichen Leistungsspektrum aus einfallsreicher strategischer Beratung und intelligenten, nachhaltig wertsch\u00f6pfenden IT-L\u00f6sungen f\u00fcr eine Vielzahl von Branchen.</p><br><p><strong>DAS ERWARTET SIE BEI UNS</strong></p><ul><li>Sie erwerben wertvolles Wissen durch gezielte Projekteins\u00e4tze und Training-on-the-Job</li><li>Erhalten Sie eine individuelle Aus- und Weiterbildung im Umgang mit neusten Cloud- und Big Data-Technologien inklusive der M\u00f6glichkeit zur Zertifizierung</li><li>Sie \u00fcbernehmen in Ihrer jeweiligen Projektrolle schnell Verantwortung</li><li>Bei uns finden Sie ein fachlich und technologisch innovatives und agiles Arbeitsumfeld, sowie exzellente M\u00f6glichkeiten zur pers\u00f6nlichen und technologischen Weiterentwicklung</li><li>Bei uns gehen spannende und abwechslungsreiche Consulting-Projekte mit einer gelebten Work-Life-Balance und einem Stundenkonto einher</li></ul><p><strong>DAS BRINGEN SIE MIT</strong></p><ul><li>Abgeschlossenes Hochschulstudium mit IT-relevantem Bezug oder vergleichbare Qualifikation</li><li>Erste Programmierkenntnisse in Python, Spark und/oder SQL helfen Ihnen bei der Anbindung, Aufbereitung und Analyse gro\u00dfer Datenmengen</li><li>Idealerweise grundlegende Kenntnisse im Bereich Machine Learning, Datenvisualisierung und/oder den Services der gro\u00dfen Hyperscaler (Azure, AWS, GCP)</li><li>Teamf\u00e4higkeit sowie gute Auffassungsgabe, l\u00f6sungsorientiertes Handeln und selbstst\u00e4ndige Arbeitsweise</li><li>Sichere Kommunikation in Wort und Schrift in Deutsch und Englisch sowie Flexibilit\u00e4t und Reisebereitschaft</li></ul><p><strong>DAS IST UNSER ANGEBOT</strong></p><br><p>Gelebte Kultur \u201eMensch im Mittelpunkt&quot;</p><br><p>Nachhaltige Projekte &amp; Soziales Engagement</p><br><p>F\u00f6rderung von Diversit\u00e4t &amp; Chancengleichheit</p><br><p>Vertrauensvoller Teamspirit &amp; Gestaltungsfreiheit</p><br><p>Passgenaue Weiterentwicklung &amp; Mentoring</p><br><p>Flexibles Arbeiten &amp; Work-Life Integration</p><br><p>Corporate Benefits</p><br><p>Mobiles Arbeiten</p><br><p>Sie sind neugierig geworden? Dann freuen wir uns \u00fcber Ihre Onlinebewerbung unter Angabe Ihrer Gehaltsvorstellungen und der Kennziffer:</p><br><p>msg-50562378-000</p><br>"
  },
  {
    "id": 125,
    "title": "(Senior) Consultant Data Scientist - Strategy and Transactions (w/m/d)",
    "company": "EY",
    "locations": "Berlin",
    "skills": "Python, SQL, Mathematik, Business Intelligence, Power BI, Tableau, Datenanalytik, Statistik",
    "posted_at": "2024-07-04",
    "is_remote": "False",
    "snippet_fragments": "   Du hast erste Programmiererfahrungen oder Praktika im Zusammenhang mit Datenverarbeitung und Datenanalyse gesammelt,    Erste Erfahrungen in der Datenvisualisierung (PowerBI,    Du verf\u00fcgst \u00fcber zus\u00e4tzliches Wissen in einem der Bereiche BI, Alternativ hast du die starke Motivation,    Du hast hervorragende Kommunikations- und Pr\u00e4sentationsf\u00e4higkeiten in Englisch und Deutsch,   Das bieten wir dir  ein inspirierendes Arbeitsumfeld,   Bei EY setzen wir alles daran, Daf\u00fcr hinterfragen wir t\u00e4glich den Status quo und suchen schon heute die Antworten von morgen, Wandel? Sehen wir als Chance und Treiber f\u00fcr Innovation,  Wenn du auch so tickst, dann bist du bei uns genau richtig, Das erfordert Zusammenarbeit auf Augenh\u00f6he und das Verlassen ausgetretener Pfade, Diese beschreitest du als Teil von interdisziplin\u00e4ren Teams  innovativ und multikulturell aufgestellt in Deutschland,    Damit auch du pers\u00f6nlich und beruflich \u00fcber dich hinausw\u00e4chst, Das Tempo und Ziel auf deinem Weg bestimmst du selbst",
    "description": "<p><strong>Das erwartet dich bei uns - Erfahrungen, von denen du ein Leben lang profitierst</strong></p><br><p>Als Teil unseres Data &amp; Analytics-Teams in Hamburg, Berlin, M\u00fcnchen, Stuttgart, D\u00fcsseldorf und Frankfurt/Main \u00fcbernimmst du relevante und zuverl\u00e4ssige Analysen w\u00e4hrend des gesamten Deal- und Transformationszyklus und unterst\u00fctzt damit unsere Kund:innen bei den dringendsten Gesch\u00e4ftsfragen und Herausforderungen. Dabei \u00fcbernimmst du vielf\u00e4ltige Aufgaben:</p><ul><li>Du ber\u00e4tst nationale und internationale Unternehmen w\u00e4hrend und nach einem Deal sowie Transformationsprozess</li><li>Du bist f\u00fcr die Ausf\u00fchrung und Implementierung innovativer datengesteuerter L\u00f6sungen verantwortlich</li><li>Du planst, f\u00fchrst aus und implementierst innovative datengetriebene L\u00f6sungen: Du wendest erweiterte Analyseverfahren an, durchdringst gro\u00dfe und komplexe Datens\u00e4tze und \u00fcbersetzt Erkenntnisse in \u00fcberzeugende kommerzielle Handlungsanweisungen</li><li>Du nutzt K\u00fcnstliche Intelligenz (einschlie\u00dflich GenAI und maschinelles Lernen), um Herausforderungen der Kunden zu bew\u00e4ltigen</li><li>Du hilfst dabei, eine Kultur der datengetriebenen Innovation zu f\u00f6rdern, indem du die Erforschung und Annahme neuer analytischer Methoden und Werkzeuge anregst</li></ul><p><strong>Das bringst du mit - F\u00e4higkeiten, mit denen du die Zukunft gestaltest</strong></p><ul><li>Du hast dein Studium im Bereich der Datenanalytik, Statistik, Mathematik, Operations Research, Wirtschaftswissenschaften oder einem \u00e4hnlich quantitativ ausgerichteten Studienfeld abgeschlossen und starkes Interesse daran, deine fortgeschrittenen analytischen F\u00e4higkeiten weiterzuentwickeln</li><li>Du hast erste Programmiererfahrungen oder Praktika im Zusammenhang mit Datenverarbeitung und Datenanalyse gesammelt, insbesondere mit Python und SQL</li><li>Erste Erfahrungen in der Datenvisualisierung (PowerBI, Tableau) und mit Low-Code-Datenanalyseplattformen sind von Vorteil</li><li>Du verf\u00fcgst \u00fcber zus\u00e4tzliches Wissen in einem der Bereiche BI, Corporate Finance, Rechnungswesen/Controlling/Marketing oder Operations. Alternativ hast du die starke Motivation, Kenntnisse in einem oder mehreren dieser Bereiche zu entwickeln</li><li>Du hast hervorragende Kommunikations- und Pr\u00e4sentationsf\u00e4higkeiten in Englisch und Deutsch</li></ul><p><strong>Das bieten wir dir</strong> <strong>-</strong> <strong>ein inspirierendes Arbeitsumfeld</strong></p><br><p>Bei EY setzen wir alles daran, dass die Welt besser funktioniert. Daf\u00fcr hinterfragen wir t\u00e4glich den Status quo und suchen schon heute die Antworten von morgen. Stillstand? Keine Option. Wandel? Sehen wir als Chance und Treiber f\u00fcr Innovation.</p><br><p>Wenn du auch so tickst, dann bist du bei uns genau richtig. Wir suchen Macher:innen, die Unternehmen, Entrepreneuren, Privatpersonen und der \u00f6ffentlichen Hand helfen, \u00fcber sich hinaus zu wachsen. Das erfordert Zusammenarbeit auf Augenh\u00f6he und das Verlassen ausgetretener Pfade. Diese beschreitest du als Teil von interdisziplin\u00e4ren Teams - innovativ und multikulturell aufgestellt in Deutschland, Europa und der ganzen Welt.</p><br><p>Damit auch du pers\u00f6nlich und beruflich \u00fcber dich hinausw\u00e4chst, begleiten wir dich auf deinem Karriereweg mit auf dich zugeschnittenen Arbeitsmodellen sowie Trainings- und Entwicklungsm\u00f6glichkeiten on- und off-the-Job. Das Tempo und Ziel auf deinem Weg bestimmst du selbst.</p><br><p>Wir wissen: Erstklassiger Service f\u00fcr unsere Mandant:innen und Kund:innen beginnt bei zufriedenen und motivierten Mitarbeitenden. Deshalb reicht unser Angebot von flexiblen Arbeitsmodellen, Auslandeins\u00e4tzen und Weiterbildungen \u00fcber Sport- und Freizeitangeboten bis hin zu Rabatten bekannter Marken und Anbieter sowie Altersvorsorge. Erfahre mehr \u00fcber deine Benefits bei EY.</p><br><p><strong>Du hast Lust was zu bewegen? Dann werde Teil unseres Teams.</strong></p><br><p>Bewirb dich jetzt \u00fcber unser Jobportal: www.de.ey.com/karriere.</p><br><p>Mehr Informationen zum Bewerbungsprozess bei EY findest du auf unserer Karriereseite.</p><br><p>Deine Fragen beantwortet gerne unser Recruitment Center unter: +49 6196 996 10005.</p><br><p>Was andere \u00fcber uns sagen, findest du auf kununu und Glassdoor.</p><br>"
  },
  {
    "id": 126,
    "title": "Data Engineer (d/m/w) - befristet (Elternzeitvertretung)",
    "company": "Toll Collect GmbH",
    "locations": "Berlin",
    "skills": "SQL, Mathematik, Linux, Cognos, PL/SQL, Windows",
    "posted_at": "2024-07-04",
    "is_remote": "False",
    "snippet_fragments": "     Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit,      Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen ,     Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics,      Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL),      Sie beherrschen den Umgang mit Windows und Linux einwandfrei,      Sie haben ein abgeschlossenes Studium in der Mathematik,      Sie haben Berufserfahrung im Bereich Data Engineering,     Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung,      Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung,  Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet,      Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung,     Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung,     Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu, Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen, Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt",
    "description": "<p>Referenznummer: 20728</p><br><p>Ihre Aufgaben</p><ul><li>Sie verantworten die Strukturierung und Weiterentwicklung von Datenmodellen und Datenfl\u00fcssen sowie der zugeh\u00f6rigen IT-gest\u00fctzten Prozesse</li><li>Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit</li><li>Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten</li><li>Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen</li><li>Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit, bringen eigene Ideen ein und setzen diese um</li><li>Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen<br> Ihr Profil</li><li>Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics</li><li>Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL).</li><li>Sie beherrschen den Umgang mit Windows und Linux einwandfrei</li><li>Sie haben ein abgeschlossenes Studium in der Mathematik, Informatik oder in einem vergleichbaren Studiengang</li><li>Sie haben Berufserfahrung im Bereich Data Engineering<br> Was bieten wir</li><li>Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung</li><li>Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung</li><li>Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet</li><li>Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung</li></ul><p>Interessiert?</p><br><p>Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung.</p><br><p>Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu. Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen. Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt.</p><br><p>Ihre Ansprechperson</p><br><p>Frau Silvia Barknecht, 030/74077-8214, karriere@toll-collect.de</p><br><p>Toll Collect GmbH * Personalmanagement * Linkstra\u00dfe 4, 10785 Berlin</p><br>"
  },
  {
    "id": 127,
    "title": "DATA SCIENTIST ENGINEER (M/W/D) DIGITAL SOLUTIONS \u2013 BRAUNSCHWEIG, BERLIN",
    "company": "Stadler Signalling Deutschland GmbH",
    "locations": "Berlin",
    "skills": "Python, Machine Learning, Mathematik, Data Science, Data Modeling, C#, C++, Java, MATLAB, Rust, Stata, Text Mining, Data mining, Statistik",
    "posted_at": "2024-07-03",
    "is_remote": "False",
    "snippet_fragments": "     Entwickeln von Algorithmen und Software zur Nutzung von Betriebs- und Instandhaltungsdaten auf Basis von Mathematik / Statistik,       Erstellen und Weiterentwickeln hoch-performanter sowie zuverl\u00e4ssiger Software-Konzeption und Algorithmik f\u00fcr branchenspezifische datenbasierte Modellierungen und Prognosen,       Anwenden von Techniken des maschinellen Lernens z, Klassifikation, Regression, Natural Language Processing, Text Mining, Image Processing, Image and Object Recognition,       Identifizieren und Evaluieren von Zusammenh\u00e4ngen und Trends,       Aufbereiten und Anbinden von Datenquellen aus diversen Datenbanken,       Ver- und Bearbeiten von gro\u00dfen Datenmengen,       Erstellen von Reports und Datenvisualisierungen der Analyseergebnisse,  Initiieren und Umsetzen von Sonderthemen, Projekten und Systementwicklungen,       Allgemeine administrative T\u00e4tigkeiten sowie Gew\u00e4hrleistung eines effektiven Wissenstransfers innerhalb des Bereichs, Master Mathematik, Data Science, Informatik oder vergleichbar,  Fundiertes mathematisches Wissen, insbesondere Algorithmik und Statistik,       Umfassende Kenntnisse in skriptbasierten Sprachen (Python,       Vertiefte Kenntnisse in den Bereichen Data-Analytics / Data Mining und Machine Learning,       Idealerweise Kenntnisse in der Datenmodellierung und -aufbereitung,       Vertiefte Kenntnisse in den Bereichen Data-Analytics / Datamining und Machine Learning,       Enge kollegiale Zusammenarbeit im Team mit Entwicklern und Technikexperten,       Sehr gute Deutsch- und gute Englischkenntnisse in Wort und Schrift,      Z\u00f6gern Sie nicht, uns bei Fragen zu kontaktieren, Wir freuen uns auf Ihre Online-Bewerbung",
    "description": "<p>Data Scientist Engineer (m/w/d) Digital Solutions Vollzeit</p><br><p>Data Scientist Engineer (m/w/d) Digital Solutions</p><ul><li>Braunschweig, Deutschland</li><li>Vollzeit</li><li>unbefristet<br> Stadler baut seit \u00fcber 80 Jahren Z\u00fcge. Mit unserer Innovationskraft, Flexibilit\u00e4t und Zuverl\u00e4ssigkeit sind wir heute ein f\u00fchrender Hersteller von Schienenfahrzeugen. Nebst unseren Schweizer Standorten arbeiten rund 13 500 Mitarbeitende an mehreren Produktions- und Engineering-Standorten sowie \u00fcber 70 Servicestandorten in Europa, Nordamerika und Nordafrika.<br> Stadler Signalling ist das Kompetenzzentrum f\u00fcr Signaltechnik und Digitalisierung der Stadler-Gruppe mit mehreren Standorten in Deutschland, der Schweiz und in Nordamerika. In den Bereichen automatisiertes Fahren (ATO), Zugbeeinflussung (ETCS) moderne Gesamtsysteme (CBTC), Stellwerke und Fahrgastinformationssystemen arbeiten unsere Teams von top-qualifizierten Mitarbeitenden an der Weiterentwicklung unserer Signalling-L\u00f6sungen. Wir suchen Verst\u00e4rkung f\u00fcr unser Team, um gemeinsam die Zukunft der Mobilit\u00e4t zu gestalten!</li></ul><p>IHRE AUFGABEN</p><ul><li>Entwickeln von Algorithmen und Software zur Nutzung von Betriebs- und Instandhaltungsdaten auf Basis von Mathematik / Statistik, Daten und Expertenwissen</li><li>Erstellen und Weiterentwickeln hoch-performanter sowie zuverl\u00e4ssiger Software-Konzeption und Algorithmik f\u00fcr branchenspezifische datenbasierte Modellierungen und Prognosen</li><li>Anwenden von Techniken des maschinellen Lernens z.B. Klassifikation, Regression, Natural Language Processing, Text Mining, Image Processing, Image and Object Recognition</li><li>Identifizieren und Evaluieren von Zusammenh\u00e4ngen und Trends</li><li>Aufbereiten und Anbinden von Datenquellen aus diversen Datenbanken</li><li>Ver- und Bearbeiten von gro\u00dfen Datenmengen</li><li>Erstellen von Reports und Datenvisualisierungen der Analyseergebnisse</li><li>Initiieren und Umsetzen von Sonderthemen, Projekten und Systementwicklungen</li><li>Allgemeine administrative T\u00e4tigkeiten sowie Gew\u00e4hrleistung eines effektiven Wissenstransfers innerhalb des Bereichs</li><li>Regelm\u00e4\u00dfige Dienstreisen nach Berlin</li></ul><p>IHR PROFIL</p><ul><li>Master Mathematik, Data Science, Informatik oder vergleichbar</li><li>Berufserfahrung in vergleichbarer Stelle</li><li>Fundiertes mathematisches Wissen, insbesondere Algorithmik und Statistik</li><li>Umfassende Kenntnisse in skriptbasierten Sprachen (Python, MatLab oder STATA) und universellen Programmiersprachen (z.B. C#, Java, C++, Rust)</li><li>Vertiefte Kenntnisse in den Bereichen Data-Analytics / Data Mining und Machine Learning</li><li>Idealerweise Kenntnisse in der Datenmodellierung und -aufbereitung</li><li>Vertiefte Kenntnisse in den Bereichen Data-Analytics / Datamining und Machine Learning</li><li>Enge kollegiale Zusammenarbeit im Team mit Entwicklern und Technikexperten</li><li>Sehr gute Deutsch- und gute Englischkenntnisse in Wort und Schrift</li><li>Reisebereitschaft</li></ul><p>KONTAKT</p><br><p>Z\u00f6gern Sie nicht, uns bei Fragen zu kontaktieren. Wir freuen uns auf Ihre Online-Bewerbung.</p><br><p>Informationen zur Bewerbung</p><br><p>Stefanie Weber</p><br><p>Recruiterin</p><br><p>+49 531 273 004 71</p><br>"
  },
  {
    "id": 128,
    "title": "DATA SCIENTIST ENGINEER (M/W/D) DIGITAL SOLUTIONS \u2013 BRAUNSCHWEIG, BERLIN",
    "company": "Stadler Signalling Deutschland GmbH",
    "locations": "Berlin",
    "skills": "Python, Machine Learning, Mathematik, Data Science, Data Modeling, C#, C++, Java, MATLAB, Rust, Stata, Text Mining, Data mining, Statistik",
    "posted_at": "2024-07-03",
    "is_remote": "False",
    "snippet_fragments": "Master Mathematik, Data Science, Informatik oder vergleichbar,  Fundiertes mathematisches Wissen, insbesondere Algorithmik und Statistik,       Umfassende Kenntnisse in skriptbasierten Sprachen (Python,       Vertiefte Kenntnisse in den Bereichen Data-Analytics / Data Mining und Machine Learning,       Idealerweise Kenntnisse in der Datenmodellierung und -aufbereitung,       Vertiefte Kenntnisse in den Bereichen Data-Analytics / Datamining und Machine Learning,       Enge kollegiale Zusammenarbeit im Team mit Entwicklern und Technikexperten,       Sehr gute Deutsch- und gute Englischkenntnisse in Wort und Schrift,      Z\u00f6gern Sie nicht, uns bei Fragen zu kontaktieren, Wir freuen uns auf Ihre Online-Bewerbung",
    "description": "<p>Data Scientist Engineer (m/w/d) Digital Solutions</p><ul><li>Braunschweig, Deutschland</li><li>Vollzeit</li><li>unbefristet<br> Stadler baut seit \u00fcber 80 Jahren Z\u00fcge. Mit unserer Innovationskraft, Flexibilit\u00e4t und Zuverl\u00e4ssigkeit sind wir heute ein f\u00fchrender Hersteller von Schienenfahrzeugen. Nebst unseren Schweizer Standorten arbeiten rund 13 500 Mitarbeitende an mehreren Produktions- und Engineering-Standorten sowie \u00fcber 70 Servicestandorten in Europa, Nordamerika und Nordafrika.<br> Stadler Signalling ist das Kompetenzzentrum f\u00fcr Signaltechnik und Digitalisierung der Stadler-Gruppe mit mehreren Standorten in Deutschland, der Schweiz und in Nordamerika. In den Bereichen automatisiertes Fahren (ATO), Zugbeeinflussung (ETCS) moderne Gesamtsysteme (CBTC), Stellwerke und Fahrgastinformationssystemen arbeiten unsere Teams von top-qualifizierten Mitarbeitenden an der Weiterentwicklung unserer Signalling-L\u00f6sungen. Wir suchen Verst\u00e4rkung f\u00fcr unser Team, um gemeinsam die Zukunft der Mobilit\u00e4t zu gestalten!</li></ul><p>IHRE AUFGABEN</p><ul><li>Entwickeln von Algorithmen und Software zur Nutzung von Betriebs- und Instandhaltungsdaten auf Basis von Mathematik / Statistik, Daten und Expertenwissen</li><li>Erstellen und Weiterentwickeln hoch-performanter sowie zuverl\u00e4ssiger Software-Konzeption und Algorithmik f\u00fcr branchenspezifische datenbasierte Modellierungen und Prognosen</li><li>Anwenden von Techniken des maschinellen Lernens z.B. Klassifikation, Regression, Natural Language Processing, Text Mining, Image Processing, Image and Object Recognition</li><li>Identifizieren und Evaluieren von Zusammenh\u00e4ngen und Trends</li><li>Aufbereiten und Anbinden von Datenquellen aus diversen Datenbanken</li><li>Ver- und Bearbeiten von gro\u00dfen Datenmengen</li><li>Erstellen von Reports und Datenvisualisierungen der Analyseergebnisse</li><li>Initiieren und Umsetzen von Sonderthemen, Projekten und Systementwicklungen</li><li>Allgemeine administrative T\u00e4tigkeiten sowie Gew\u00e4hrleistung eines effektiven Wissenstransfers innerhalb des Bereichs</li><li>Regelm\u00e4\u00dfige Dienstreisen nach Berlin</li></ul><p>IHR PROFIL</p><ul><li>Master Mathematik, Data Science, Informatik oder vergleichbar</li><li>Berufserfahrung in vergleichbarer Stelle</li><li>Fundiertes mathematisches Wissen, insbesondere Algorithmik und Statistik</li><li>Umfassende Kenntnisse in skriptbasierten Sprachen (Python, MatLab oder STATA) und universellen Programmiersprachen (z.B. C#, Java, C++, Rust)</li><li>Vertiefte Kenntnisse in den Bereichen Data-Analytics / Data Mining und Machine Learning</li><li>Idealerweise Kenntnisse in der Datenmodellierung und -aufbereitung</li><li>Vertiefte Kenntnisse in den Bereichen Data-Analytics / Datamining und Machine Learning</li><li>Enge kollegiale Zusammenarbeit im Team mit Entwicklern und Technikexperten</li><li>Sehr gute Deutsch- und gute Englischkenntnisse in Wort und Schrift</li><li>Reisebereitschaft</li></ul><p>KONTAKT</p><br><p>Z\u00f6gern Sie nicht, uns bei Fragen zu kontaktieren. Wir freuen uns auf Ihre Online-Bewerbung.</p><br><p>Stefanie Weber</p><br><p>Recruiterin</p><br><p>+49 531 273 004 71</p><br>"
  },
  {
    "id": 129,
    "title": "(Senior) Data Platform Engineer II - Java (m/f/d)",
    "company": "Conductor LLC",
    "locations": "Berlin",
    "skills": "Mathematik, AWS, Cloud, Data Pipelines, ETL, Kafka, Java, SaaS, Spark, SEO, Architektur",
    "posted_at": "2024-07-03",
    "is_remote": "False",
    "snippet_fragments": "Advocates for best practices, investigates new technologies and mentors other engineers.,  The successful candidate must thrive in ambiguity with a strong decision-making capability along with a sense of accountability, The candidate must have a passion to solve hard problems with technical expertise and a growth-mindset,   A hands-on data platform engineer with 6 years experience in data engineering,   Hands-on experience with cloud-based data storage and processing platforms based on AWS or similar providers,   Extended knowledge of various database technologies and query languages,   A strong developer with comprehensive understanding of the data sources,   A polyglot programmer with expertise in Java ,   Have a minimum of bachelor's degree in Computer Science,   Have excellent verbal and written communication skills  can communicate clear technical solutions to complex data problems to both technical and non-technical audiences, Friendly, open-minded and helpful international colleagues,   Access to the learning platform LinkedIn Learning , Soft drinks, fruits, and pizza days",
    "description": "<p>Conductor is a leading Website Optimization &amp; Intelligence platform. Today's top brands use Conductor to create and optimize digital experiences that get found organically in search engines and drive value for customers. The platform provides actionable SEO, content, and technical website intelligence paired with real-time website monitoring to help customers accelerate-and protect-digital growth.</p><br><p>Conductor is a mission-driven company with a commitment to innovation, customer success, and culture. For Conductor, success is improving the lives of all the people in our orbit-our customers, our customers' customers, our employee-owners, and our communities.</p><br><p><strong>(SENIOR) DATA PLATFORM ENGINEER II - JAVA (M/F/D)</strong></p><br><p>(Hybrid in Berlin or remote in Germany/ Full-time/ Permanent Contract)</p><br><p>What are we looking for?</p><br><p>Conductor is seeking a seasoned, product-minded data engineer with data architecture and data platform design experience to power massive scale SaaS applications. The individual plays a pivotal role in the design, development and maintenance of our data platform.</p><br><p><strong>The candidate will</strong></p><ul><li>Collaborate with application developers, cloud infrastructure experts and other stakeholders to gather requirements, design and implement data solutions that meet business needs and execute on the enterprise data strategy.</li><li>Develop, maintain, and test all aspects of Conductors' data platform, including a data lakehouse, ETL pipelines, and efficient data consumption.</li><li>Create position papers and contribute driving Conductors data strategy across teams</li><li>Optimize data storage and retrieval processes to ensure scalability, reliability and cost-effectiveness.</li><li>Leverage Conductor's data platform core tools and technologies such as Onehouse.ai (Hudi), CelerData (StarRocks), Spark, Kafka, and more</li><li>Replace legacy systems with state-of-the-art data pipelines</li><li>Stay up-to-date with industry trends, standards, best practices and emerging technologies to continuously improve our data platform.</li><li>Is motivated to understand the challenges in the SEO space, has a passion for solving problems and not just delivering features</li><li>Influences strategic thinking across the team. Advocates for best practices, investigates new technologies and mentors other engineers.</li></ul><p>The successful candidate must thrive in ambiguity with a strong decision-making capability along with a sense of accountability, having a collaborative and supportive attitude. The candidate must have a passion to solve hard problems with technical expertise and a growth-mindset, using strong engineering rigor and data-driven operational skills to drive the desired outcomes across global teams.</p><br><p><strong>Who you are</strong></p><ul><li>A hands-on data platform engineer with 6+ years experience in data engineering, building scalable and secure data platforms and distributed systems.</li><li>Hands-on experience with cloud-based data storage and processing platforms based on AWS or similar providers.</li><li>Extended knowledge of various database technologies and query languages.</li><li>A strong developer with comprehensive understanding of the data sources, data formats, and data processing challenges at scale</li><li>A polyglot programmer with expertise in Java</li><li>Have a minimum of bachelor's degree in Computer Science, Mathematics, or a related field.</li><li>Have excellent verbal and written communication skills - can communicate clear technical solutions to complex data problems to both technical and non-technical audiences.</li></ul><p><strong>YOUR BENEFITS:</strong></p><ul><li>Friendly, open-minded and helpful international colleagues</li><li>Access to the learning platform LinkedIn Learning</li><li>Soft drinks, fruits, and pizza days</li><li>Team and company events</li><li>Urban Sports (M) or Fitness First membership</li><li>28 days vacation at the start, 30 days after two years</li><li>Company pension allowance</li><li>Dog-friendly office</li></ul><p>Interested? Then we look forward to receiving your application via the application link on our careers page. After receiving your application, you will immediately receive a confirmation e-mail from us. If you do not receive it, please check your spam folder and redirect the mails from our mail address to your inbox.</p><br>"
  },
  {
    "id": 130,
    "title": "Data Engineer (d/m/w) - befristet (Elternzeitvertretung)",
    "company": "Toll Collect GmbH",
    "locations": "Berlin",
    "skills": "SQL, Mathematik, Linux, Cognos, PL/SQL, Windows",
    "posted_at": "2024-07-03",
    "is_remote": "False",
    "snippet_fragments": "    Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung,      Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung,  Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet,      Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung,     Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung,     Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu, Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen, Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt",
    "description": "<p>Referenznummer: 20728</p><br><p>Ihre Aufgaben</p><ul><li>Sie verantworten die Strukturierung und Weiterentwicklung von Datenmodellen und Datenfl\u00fcssen sowie der zugeh\u00f6rigen IT-gest\u00fctzten Prozesse</li><li>Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit</li><li>Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten</li><li>Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen</li><li>Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit, bringen eigene Ideen ein und setzen diese um</li><li>Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen<br> Ihr Profil</li><li>Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics</li><li>Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL).</li><li>Sie beherrschen den Umgang mit Windows und Linux einwandfrei</li><li>Sie haben ein abgeschlossenes Studium in der Mathematik, Informatik oder in einem vergleichbaren Studiengang</li><li>Sie haben Berufserfahrung im Bereich Data Engineering<br> Was bieten wir</li><li>Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung</li><li>Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung</li><li>Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet</li><li>Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung</li></ul><p>Interessiert?</p><br><p>Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung.</p><br><p>Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu. Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen. Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt.</p><br><p>Ihre Ansprechperson</p><br><p>Frau Silvia Barknecht, 030/74077-8214, karriere@toll-collect.de</p><br><p>Toll Collect GmbH * Personalmanagement * Linkstra\u00dfe 4, 10785 Berlin</p><br>"
  },
  {
    "id": 131,
    "title": "Senior Data Scientist",
    "company": "Wooga",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Data Science, Data Analysis, Statistik",
    "posted_at": "2024-07-01",
    "is_remote": "True",
    "snippet_fragments": "  You have a degree in a highly quantitative field (e,   You are proficient in using Python for data analysis ,   You can use SQL effectively to query large volumes of data ,   You have extensive professional experience in data science or a related analytical field ,   You have a solid understanding of how data science can impact the core business and economics in a freemium business model ,   You have a deep understanding of commonly applied advanced statistical and ML techniques and have shown that you can apply and adapt these techniques to a range of situations , Here at Wooga, the desire to learn and the willingness to solve problems are more important to us than your experience on paper, We encourage you to apply even if you do not think that you tick all the boxes - thinking outside of such boxes and embracing the diversity of mindsets and backgrounds is what we believe makes our teams thrive,    Shape the future! Challenge the status quo and team up with a diverse group of experts (over 57 nationalities!) working on crafting the world's best games,    We offer a generous relocation package and home search support if you are not already located in Berlin, Did we mention that we also cooperate with Kindergartens? ,    Make use of a significant education budget and extra days off for self-development, Join our meet-ups, talks, brown bag lunches, internal trainings, workshops and many others., Enjoy the yoga, mindfulness app, sports and transport subsidies, And a Purpose Day to donate your time to a worthy cause! ,    Via our Company KPI bonus all Wooga employees benefit from our games being commercially successful! ",
    "description": "<p><strong>WE ARE PROUD TO BELONG TO THE TOP 1% OF ALL EMPLOYERS IN GERMANY 2021, 2022, 2023 &amp; 2024!</strong></p><br><p><strong>Our Story</strong></p><br><p>At Wooga, we are very proud of the diverse, creative and friendly environment we have established and we believe you will enjoy working with some of the best people in the industry. Each of our Woogas plays an important role in our success as a company and in shaping our culture. We really value our razor-sharp focus on story-driven casual games, excellent craftsmanship, truly collaborative way of working, and the values we strive to live up to every day. We create joyful experiences that awaken our players' desire to see what happens next. Based in the heart of Berlin, with over 300 employees from around the world, we work together to create high-quality casual games with engaging stories at the core of the experience.</p><br><p><strong>About the role</strong></p><br><p>At Wooga, our Data Scientists play an instrumental role in driving the successful development of our games. The Data Science team explores new methodologies and delves deep into every aspect of our data to identify opportunities and make a real impact on our business. We are looking for a data enthusiast, who is passionate about games and can think analytically about what makes a game great!</p><ul><li>You will lead analytics projects involving multiple team members to understand, segment, predict and influence the behaviour of our players across our games portfolio</li><li>You will build data tools for our product managers, empowering them to deliver actionable insights and recommendations for our game teams</li><li>You will use experiments, advanced analytics and ML to find levers for product optimization</li><li>You will proactively drive improvements of and provide education on our analytics tools</li><li>You will help coach and train more junior members of the team in both technical and soft skills</li></ul><p><strong>About you</strong></p><ul><li>You have a degree in a highly quantitative field (e.g. statistics, economics, research, computer science)</li><li>You are proficient in using Python for data analysis</li><li>You can use SQL effectively to query large volumes of data</li><li>You have extensive professional experience in data science or a related analytical field</li><li>You have a solid understanding of how data science can impact the core business and economics in a freemium business model</li><li>You have a deep understanding of commonly applied advanced statistical and ML techniques and have shown that you can apply and adapt these techniques to a range of situations</li></ul><p>Please note: Research has shown that some under-represented groups in the gaming industry (eg: women) tend to apply only if they meet every single requirement. Here at Wooga, the desire to learn and the willingness to solve problems are more important to us than your experience on paper. We encourage you to apply even if you do not think that you tick all the boxes - thinking outside of such boxes and embracing the diversity of mindsets and backgrounds is what we believe makes our teams thrive.</p><br><p><strong>Our Promise</strong></p><ul><li>Shape the future! Challenge the status quo and team up with a diverse group of experts (over 57 nationalities!) working on crafting the world's best games.</li><li>We offer a generous relocation package and home search support if you are not already located in Berlin. Did we mention that we also cooperate with Kindergartens?</li><li>Make use of a significant education budget and extra days off for self-development. Join our meet-ups, talks, brown bag lunches, internal trainings, workshops and many others.</li><li>Enjoy the yoga, mindfulness app, sports and transport subsidies. And a Purpose Day to donate your time to a worthy cause!</li><li>Via our Company KPI bonus all Wooga employees benefit from our games being commercially successful!</li><li>Did you know that German is the third most commonly taught language worldwide? Learn it too! We offer German language classes for you and your significant other.</li><li>With our hybrid work model you will work in the office with your teams twice a week, to encourage in-person collaboration and team bonding The other three days you can choose if you want to work from home or from the office. We also offer 10 days a year to work from abroad. We got your back!</li></ul><p>At Wooga we are committed to providing a friendly, safe and welcoming environment for everyone who works here or with us, regardless of gender, gender identity and expression, sexual orientation, disability, physical appearance, body size, race, age, religion (or lack thereof) and game preferences. Be yourself, we like you that way!</p><br><p>By clicking &quot;Submit Application&quot; you acknowledge that you have read our Candidate Privacy Policy</p><br>"
  },
  {
    "id": 132,
    "title": "Data Engineer (d/m/w) - befristet (Elternzeitvertretung)",
    "company": "Toll Collect GmbH",
    "locations": "Berlin",
    "skills": "SQL, Mathematik, Linux, Cognos, PL/SQL, Windows",
    "posted_at": "2024-07-01",
    "is_remote": "False",
    "snippet_fragments": "     Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit,      Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten,      Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen,      Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit,      Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen ,     Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics,      Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL),      Sie beherrschen den Umgang mit Windows und Linux einwandfrei,      Sie haben ein abgeschlossenes Studium in der Mathematik,      Sie haben Berufserfahrung im Bereich Data Engineering,     Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung,      Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung,  Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet,      Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung,     Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung,     Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu, Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen, Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt",
    "description": "<p>Referenznummer: 20728</p><br><p>Ihre Aufgaben</p><ul><li>Sie verantworten die Strukturierung und Weiterentwicklung von Datenmodellen und Datenfl\u00fcssen sowie der zugeh\u00f6rigen IT-gest\u00fctzten Prozesse</li><li>Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit</li><li>Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten</li><li>Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen</li><li>Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit, bringen eigene Ideen ein und setzen diese um</li><li>Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen<br> Ihr Profil</li><li>Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics</li><li>Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL).</li><li>Sie beherrschen den Umgang mit Windows und Linux einwandfrei</li><li>Sie haben ein abgeschlossenes Studium in der Mathematik, Informatik oder in einem vergleichbaren Studiengang</li><li>Sie haben Berufserfahrung im Bereich Data Engineering<br> Was bieten wir</li><li>Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung</li><li>Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung</li><li>Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet</li><li>Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung</li></ul><p>Interessiert?</p><br><p>Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung.</p><br><p>Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu. Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen. Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt.</p><br><p>Ihre Ansprechperson</p><br><p>Frau Silvia Barknecht, 030/74077-8214, karriere@toll-collect.de</p><br><p>Toll Collect GmbH * Personalmanagement * Linkstra\u00dfe 4, 10785 Berlin</p><br>"
  },
  {
    "id": 133,
    "title": "Data Engineer (d/m/w) - befristet (Elternzeitvertretung)",
    "company": "Toll Collect GmbH",
    "locations": "Berlin",
    "skills": "SQL, Mathematik, Linux, Cognos, PL/SQL, Windows",
    "posted_at": "2024-06-30",
    "is_remote": "False",
    "snippet_fragments": "     Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit,      Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten,      Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen,      Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit,      Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen ,     Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics,      Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL),      Sie beherrschen den Umgang mit Windows und Linux einwandfrei,      Sie haben ein abgeschlossenes Studium in der Mathematik,      Sie haben Berufserfahrung im Bereich Data Engineering,     Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung,      Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung,  Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet,      Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung,     Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung,     Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu, Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen, Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt",
    "description": "<p>Referenznummer: 20728</p><br><p>Ihre Aufgaben</p><ul><li>Sie verantworten die Strukturierung und Weiterentwicklung von Datenmodellen und Datenfl\u00fcssen sowie der zugeh\u00f6rigen IT-gest\u00fctzten Prozesse</li><li>Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit</li><li>Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten</li><li>Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen</li><li>Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit, bringen eigene Ideen ein und setzen diese um</li><li>Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen<br> Ihr Profil</li><li>Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics</li><li>Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL).</li><li>Sie beherrschen den Umgang mit Windows und Linux einwandfrei</li><li>Sie haben ein abgeschlossenes Studium in der Mathematik, Informatik oder in einem vergleichbaren Studiengang</li><li>Sie haben Berufserfahrung im Bereich Data Engineering<br> Was bieten wir</li><li>Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung</li><li>Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung</li><li>Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet</li><li>Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung</li></ul><p>Interessiert?</p><br><p>Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung.</p><br><p>Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu. Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen. Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt.</p><br><p>Ihre Ansprechperson</p><br><p>Frau Silvia Barknecht, 030/74077-8214, karriere@toll-collect.de</p><br><p>Toll Collect GmbH * Personalmanagement * Linkstra\u00dfe 4, 10785 Berlin</p><br>"
  },
  {
    "id": 134,
    "title": "Solution Engineer Data Center Technologies (m/w/d) f\u00fcr AIRBUS",
    "company": "Orizon GmbH, Unit Aviation",
    "locations": "Berlin",
    "skills": "VMware, KVM, Nachrichtentechnik",
    "posted_at": "2024-06-29",
    "is_remote": "False",
    "snippet_fragments": "   Sicherstellung der \u00fcbergreifenden L\u00f6sungsanpassung \u00fcber Anwendungen,    Mitwirkung in allen Phasen des Entwicklungsablaufs der Anwendungen,  Unterst\u00fctzung der Bereiche Vertrieb, Marketing und Bid Management in den Phasen Pre-Sales, Angebot, Projektabwicklung und technische Kundenpr\u00e4sentationen,  Abgeschlossenes Studium der Fachrichtung Informatik, Ingenieurwesen, Nachrichtentechnik, Kommunikationstechnik oder eine vergleichbare Qualifikation,    Verhandlungssichere Deutsch- und Englischkenntnisse in Wort und Schrift,   Orizon geh\u00f6rt zu den f\u00fcnfzehn gr\u00f6\u00dften Personaldienstleistern in Deutschland, Als einer der Marktf\u00fchrer f\u00fcr den deutschen Mittelstand \u00fcberlassen und vermitteln wir Fach- und F\u00fchrungskr\u00e4fte aus allen Berufsfeldern an namhafte Unternehmen, Finden auch Sie mit uns Ihren Platz!",
    "description": "<p><strong>UNSER ANGEBOT:</strong></p><ul><li>Attraktives Arbeitsumfeld mit guten Perspektiven</li><li>Tarifliche Entlohnung nach iGZ/DGB Tarif zzgl. Branchenzuschl\u00e4gen</li><li>Pers\u00f6nliche Einsatzbegleitung und qualifizierte Beratung</li><li>Unser Mitarbeiter-Benefit-Programm Orizon PlusPunkte</li><li>Bis zu 30 Tage Jahresurlaub</li></ul><p><strong>IHRE ZUK\u00dcNFTIGE ARBEITSSTELLE:</strong><br> F\u00fcr unseren Kunden Airbus Secure Land Communications am Standort Ulm sind Sie als Solution Engineer (m/w/d) f\u00fcr Data Center Technologies t\u00e4tig.</p><ul><li>Die Secure Land Communications ist die Programmlinie von Airbus Defence and Space f\u00fcr professionelle Mobilfunkl\u00f6sungen. Weltweit bieten sie Kunden eine umfassende Palette an Funk- und IT-L\u00f6sungen f\u00fcr mobile, taktische Kommunikation an. Dies umfasst die Realisierung von landesweiten Sicherheitsfunknetzen, wie beispielsweise dem digitalen Beh\u00f6rdenfunk der Bundesrepublik Deutschland.</li></ul><p><strong>IHRE AUFGABEN:</strong></p><ul><li>Lieferung des globalen Design f\u00fcr Data Center L\u00f6sungen einschlie\u00dflich technischer Anforderungen, Prinzipien und Modelle in \u00dcbereinstimmung mit den Konzern- Architektur-Richtlinien</li><li>Analyse und \u00dcbersetzung von Gesch\u00e4ftsanforderungen in IT Requirements und deren Anpassung an das Architektur-spezifische Blueprint</li><li>Sicherstellung der \u00fcbergreifenden L\u00f6sungsanpassung \u00fcber Anwendungen, Systeme und Plattformen und Gew\u00e4hrleistung der Konsistenz der IT-Produkte</li><li>Mitwirkung in allen Phasen des Entwicklungsablaufs der Anwendungen, einschlie\u00dflich Forschung, Design, Entwicklung, Test, Implementierung und Support</li><li>Unterst\u00fctzung der Bereiche Vertrieb, Marketing und Bid Management in den Phasen Pre-Sales, Angebot, Projektabwicklung und technische Kundenpr\u00e4sentationen</li></ul><p><strong>IHR PROFIL:</strong></p><ul><li>Abgeschlossenes Studium der Fachrichtung Informatik, Ingenieurwesen, Nachrichtentechnik, Kommunikationstechnik oder eine vergleichbare Qualifikation</li><li>Berufserfahrung im System Engineering</li><li>Technische Kenntnisse von Virtualisierungstools (z. B. KVM oder VMware) erforderlich</li><li>Verhandlungssichere Deutsch- und Englischkenntnisse in Wort und Schrift</li></ul><p><strong>IHR PARTNER:</strong><br> Sie sind auf der Suche nach Ihrem Wunschjob? Orizon unterst\u00fctzt Sie dabei! Mit individueller Beratung und pers\u00f6nlicher Betreuung finden wir f\u00fcr Sie den Job, der am besten zu Ihnen passt.<br> Orizon geh\u00f6rt zu den f\u00fcnfzehn gr\u00f6\u00dften Personaldienstleistern in Deutschland. Als einer der Marktf\u00fchrer f\u00fcr den deutschen Mittelstand \u00fcberlassen und vermitteln wir Fach- und F\u00fchrungskr\u00e4fte aus allen Berufsfeldern an namhafte Unternehmen. Finden auch Sie mit uns Ihren Platz!</p><br><p><strong>NOCH FRAGEN ZU DIESER ANZEIGE?</strong></p><br><p><strong>PERS\u00d6NLICHER KONTAKT:</strong></p><br><p>Herr Kai Bachmann</p><br><p>T: +49 421 16037-72</p><br><p>E: IndeedBewerbung.aviation@orizon.de</p><br><p>Postanschrift:</p><br><p>Orizon GmbH, Unit Aviation</p><br><p>S\u00f6gestr. 59 - 61</p><br><p>28195 Bremen</p><br><p><strong>BEWERBUNG UND R\u00dcCKFRAGEN:</strong></p><br><p>Wir freuen uns auf Bewerbungen (unter Angabe von ID-Nummer 279445, Verf\u00fcgbarkeit und Gehaltsvorstellung) gerne per E-Mail an IndeedBewerbung.aviation@orizon.de oder \u00fcber den Bewerbungs-Button in dieser Anzeige.</p><br><p>F\u00fcr Fragen steht Herr Kai Bachmann gern unter der Telefonnummer +49 421 16037-72</p><br><p>zur Verf\u00fcgung.</p><br><p>Weitere Stellenangebote sind unter orizon.de zu finden.</p><br><p>Wir nehmen den Schutz personenbezogener Daten ernst: www.orizon.de/de/datenschutzvereinbarungen</p><br>"
  },
  {
    "id": 135,
    "title": "Data Engineer (d/m/w) - befristet (Elternzeitvertretung)",
    "company": "Toll Collect GmbH",
    "locations": "Berlin",
    "skills": "SQL, Mathematik, Linux, Cognos, PL/SQL, Windows",
    "posted_at": "2024-06-29",
    "is_remote": "False",
    "snippet_fragments": "    Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics,      Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL),      Sie beherrschen den Umgang mit Windows und Linux einwandfrei,      Sie haben ein abgeschlossenes Studium in der Mathematik,      Sie haben Berufserfahrung im Bereich Data Engineering,     Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung,      Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung,  Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet,      Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung,     Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung,     Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu, Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen, Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt",
    "description": "<p>Referenznummer: 20728</p><br><p>Ihre Aufgaben</p><ul><li>Sie verantworten die Strukturierung und Weiterentwicklung von Datenmodellen und Datenfl\u00fcssen sowie der zugeh\u00f6rigen IT-gest\u00fctzten Prozesse</li><li>Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit</li><li>Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten</li><li>Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen</li><li>Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit, bringen eigene Ideen ein und setzen diese um</li><li>Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen<br> Ihr Profil</li><li>Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics</li><li>Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL).</li><li>Sie beherrschen den Umgang mit Windows und Linux einwandfrei</li><li>Sie haben ein abgeschlossenes Studium in der Mathematik, Informatik oder in einem vergleichbaren Studiengang</li><li>Sie haben Berufserfahrung im Bereich Data Engineering<br> Was bieten wir</li><li>Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung</li><li>Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung</li><li>Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet</li><li>Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung</li></ul><p>Interessiert?</p><br><p>Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung.</p><br><p>Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu. Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen. Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt.</p><br><p>Ihre Ansprechperson</p><br><p>Frau Silvia Barknecht, 030/74077-8214, karriere@toll-collect.de</p><br><p>Toll Collect GmbH * Personalmanagement * Linkstra\u00dfe 4, 10785 Berlin</p><br>"
  },
  {
    "id": 136,
    "title": "Data Solution Engineer (m/w/d)",
    "company": "FUNKE MEDIENGRUPPE",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Data Analysis, Cloud, GCP, Business Intelligence, Airflow, Apache Beam, BigQuery, Bigtable, Composer, Dashboards, PostgreSQL, DataFlow, CloudSQL",
    "posted_at": "2024-06-28",
    "is_remote": "False",
    "snippet_fragments": "         Idealerweise konntest Du bereits mindestens zwei Jahre Berufserfahrung im Data Engineering, Teamarbeit, innovative Ideen sowie die Leidenschaft zu Daten zeichnen Dich aus,          Auf Dich kann man sich verlassen & Du \u00fcbernimmst gerne Verantwortung ,          Du verf\u00fcgst \u00fcber sehr gute Deutsch- und Englischkenntnisse ,  Du gestaltest die digitale Transformation unserer Mediengruppe mit,  Ob in Berlin oder Hamburg - In unseren zentral gelegenen Locations erwartet Dich ein moderner und voll ausgestatteter Arbeitsplatz,  Wir erm\u00f6glichen Dir die Teilnahme an individuellen Coachings, Workshops oder (Online)-Trainings im Rahmen unserer FUNKE Akademie,  Wir leben ein hybrides Arbeitsmodell, weil uns Deine Work-Life-Balance wichtig ist,  Dich erwarten ein dynamisches Team, eine offene Feedbackkultur, kurze Kommunikationswege und ein herzliches Miteinander,  Wir bieten Dir ein Benefit-Portal mit attraktiven Rabatten und Abos, Profitiere von unseren Kooperationen mit verschiedensten Fitnessstudios und lasse Dich f\u00fcr Deine mentale und k\u00f6rperliche Gesundheit individuell beraten",
    "description": "<p>FUNKE geh\u00f6rt zu den f\u00fchrenden Arbeitgebern der Medienbranche. Von Online-Portalen \u00fcber Zeitungen und Zeitschriften bis hin zu Radio und Podcast - die Vielfalt unserer Titel, Marken und Genres ist einzigartig in der deutschen Medienlandschaft. Genauso vielf\u00e4ltig sind auch die Talente unserer rund 1.700 Journalist<em>innen und 3.800 Medienmacher</em>innen, die jeden Tag in ganz Deutschland mit Leidenschaft und Innovationskraft die Zukunft der Medien mitgestalten. #wirsindFUNKE</p><br><p>Standort: Berlin, DE Hamburg, DE</p><br><p><strong>Als Data Engineering Team der Regionalmedien entwickeln und betrieben wir eine Datenplattform der n\u00e4chsten Generation als Basis f\u00fcr Analysen, Dashboards, KI und Features in unserer Produktplattform. Zur Verst\u00e4rkung unseres Teams in Berlin oder Hamburg suchen wir Dich als</strong></p><br><p><strong>DATA SOLUTION ENGINEER (M/W/D)</strong></p><br><p><strong>DEINE AUFGABEN</strong></p><ul><li><br><strong>Datenaufbereitung f\u00fcr Dashboards und Analysen</strong>: Du liebst Daten und stellst sie f\u00fcr Dashboards, Analysen und Marketing-Automation unserer Regionalmedien wie die Berliner Morgenpost oder das Hamburger Abendblatt bereit</li><li><br><strong>Entwicklung eigener Datenverarbeitungsl\u00f6sungen</strong>: Du entwickelst eigene L\u00f6sungen der Datenverarbeitung mit den Services der Google Cloud Platform (GCP)</li><li><br><strong>Effiziente Nutzung der GCP-Services</strong>: Du nutzt die GCP-Services so, dass die Aufgaben der Datenverarbeitung effizient gel\u00f6st werden, ohne dass Du Dich um das Hosting und die Administration von Systemen k\u00fcmmern musst</li><li><br><strong>Container-Verwaltung mit Cloud Run</strong>: Du verwendest f\u00fcr unsere Docker-Container Cloud Run anstelle eines selbstverwalteten Kubernetes-Clusters</li><li><br><strong>Qualit\u00e4tssicherung des Codes</strong>: Du schreibst unseren Code in Python &amp; SQL wie ein gutes Buch, das Du immer wieder gerne liest</li><li><br><strong>Zusammenarbeit und Austausch</strong>: Du tauschst Dich gerne mit Deinen Kolleg*innen aus, optimierst Anforderungen und ber\u00e4tst im L\u00f6sungsdesign</li><li><br><strong>Arbeit mit dem aktuellen TechStack</strong>: Du nutzt zur Datenverarbeitung in der GCP BigQuery, Dataflow (Apache Beam), Pub/Sub, Cloud SQL (Postgres), BigTable, Cloud Composer (Apache Airflow), Cloud Run und zus\u00e4tzlich dbt</li></ul><p><strong>DEIN PROFIL</strong></p><ul><li>Idealerweise konntest Du bereits mindestens zwei Jahre Berufserfahrung im Data Engineering, Data Analytics, BI oder ML sammeln</li><li>Teamarbeit, innovative Ideen sowie die Leidenschaft zu Daten zeichnen Dich aus</li><li>Auf Dich kann man sich verlassen &amp; Du \u00fcbernimmst gerne Verantwortung</li><li>Du verf\u00fcgst \u00fcber sehr gute Deutsch- und Englischkenntnisse</li></ul><p><strong>DEINE BENEFITS</strong></p><ul><li><br><strong>Innovation trifft Tradition:</strong> Du gestaltest die digitale Transformation unserer Mediengruppe mit</li><li><br><strong>Top ausgestattet:</strong> Ob in Berlin oder Hamburg - In unseren zentral gelegenen Locations erwartet Dich ein moderner und voll ausgestatteter Arbeitsplatz</li><li><br><strong>Entwickle Dich mit uns:</strong> Wir erm\u00f6glichen Dir die Teilnahme an individuellen Coachings, Workshops oder (Online)-Trainings im Rahmen unserer FUNKE Akademie</li><li><br><strong>Flexibel arbeiten:</strong> Wir leben ein hybrides Arbeitsmodell, weil uns Deine Work-Life-Balance wichtig ist</li><li><br><strong>Teamwork:</strong> Dich erwarten ein dynamisches Team, eine offene Feedbackkultur, kurze Kommunikationswege und ein herzliches Miteinander</li><li><br><strong>Corporate Benefits:</strong> Wir bieten Dir ein Benefit-Portal mit attraktiven Rabatten und Abos</li><li><br><strong>Halte Dich fit und gesund:</strong> Profitiere von unseren Kooperationen mit verschiedensten Fitnessstudios und lasse Dich f\u00fcr Deine mentale und k\u00f6rperliche Gesundheit individuell beraten</li></ul><p><strong>Haben wir Dein Interesse geweckt? Dann gestalte mit uns die Zukunft und sende uns Deine Bewerbung an Jennifer Korreck.</strong></p><br><p><strong>Wir bei FUNKE sch\u00e4tzen Vielfalt und begr\u00fc\u00dfen daher alle Bewerbungen - unabh\u00e4ngig von Geschlecht, Nationalit\u00e4t, ethnischer oder sozialer Herkunft, Religion/Weltanschauung, Behinderung, Alter sowie sexueller Orientierung und Identit\u00e4t.</strong></p><br>"
  },
  {
    "id": 137,
    "title": "(Junior) Data Engineer (f/m/d)",
    "company": "re:cap",
    "locations": "Berlin",
    "skills": "Python, SQL, AWS, Data Analysis, Data Pipelines, GCP, Data Warehouse, BigQuery, DevOps, Docker, Terraform, GitHub, Orchestration, Looker, Go",
    "posted_at": "2024-06-28",
    "is_remote": "True",
    "snippet_fragments": "    Experience with our stack isn't a must ,    What you can expect Remote first, Our team is located all over Germany and Europe, However, if you are in Berlin you are more than welcome to come around the office and maybe even bring your furry friend, Every employee receives stocks, because our success is also your success, Because we care about your growth, Every new team member receives an Apple MacBook Air to guarantee smooth productivity , We offer flexible working hours and value asynchronous communication as well, On top we offer 25 vacation days , Meet the team at in-person on-sites, Prioritizing your well-being with comprehensive coverage, Experience the blend of work and leisure with our worldwide new benefit catering to your work-away-from-home needs , You will receive 1password family membership , You get a monthly budget to finance a benefit of your choice ,    Even if not all of these points fit 100% we encourage you to apply! We hire also for attitude,    What comes after you apply? \ufe0f ,     Easy steps for a smooth hiring process ",
    "description": "<p>remote - Germany, Spain, Czech Republic, Portugal, Slovakia or Austria | Full-time | Start ASAP</p><br><p><strong>ABOUT US</strong></p><br><p>We accelerate the growth of digital companies by providing tailored funding solutions and data-driven financial insights. Our mission is to refine capital for economies to come. We want to enable every company to access funding that'll help them to thrive.</p><br><p>As a product- and tech-driven company we are founded by a team of experienced fintech entrepreneurs. We are backed by Tier 1 venture capital investors that have also backed the likes of Stripe, Trade Republic, Telegram, Monday.com and Sorare.</p><br><p><strong>OUR VALUES</strong></p><br><p>We value flat hierarchies, full ownership and responsibility. Trust and open, honest communication are crucial to us, as it makes everything else easier. We work together and grow as a team.</p><br><p>Focus on Execution: We love and live off great ideas, but to create value we need to focus on execution.</p><br><p>Don't Fear Failure: We know that failure is an innate part of learning and success, so we value these experiences and take them as opportunities to try again and get better.</p><br><p>Trust Your Team: We trust our peers to do their best to achieve our shared goals, support each other and share their feedback so we can all grow and develop.</p><br><p><strong>YOUR CONTRIBUTION TO OUR SUCCESS</strong></p><ul><li>You will write production-grade Python code for data applications that will be directly integrated into re:cap's platform</li><li>You will collaborate with our backend team (working mostly with Go) to ensure our solutions are successfully implemented from end-to-end</li><li>You will interface with different teams to gather business requirements and prototype solutions (e.g., Streamlit applications or Python scripts)</li><li>You will build pipelines to move data from various third-party sources into re:cap's data warehouse in Google BigQuery</li><li>You will maintain our data warehouse and ensure our data transformations are efficient and well structured using dbt and SQL</li></ul><p><strong>WHO WE ARE LOOKING FOR</strong> \u200d\ufe0f</p><ul><li>You are quick to iterate on your solutions</li><li>Your attention to detail ensures that the data you provide supports critical business decisions accurately</li><li>You're comfortable wearing multiple hats, from supporting the finance department with data analysis to building data pipelines and deploying data applications</li><li>You can effectively communicate complex topics to non-technical audiences and translate their requirements into code</li><li>Experience with tech-driven and distributed companies is a plus</li><li>You have a valid EU work permit and reside within the EU. re:cap does not offer visa or relocation support at the moment</li></ul><p><strong>OUR TECH STACK</strong> \u200d</p><ul><li>Programming languages: Python, SQL and Go</li><li>Data ingestion: Airbyte</li><li>Data transformation: dbt</li><li>Data warehouse: Google BigQuery</li><li>Orchestration: Dagster</li><li>Analysis &amp; reporting: Looker Studio, Streamlit</li><li>DevOps: AWS, GCP, Docker, Terraform, GitHub</li><li>Experience with our stack isn't a must</li></ul><p><strong>WHAT YOU CAN EXPECT</strong><br> Remote first. Our team is located all over Germany and Europe, with the flexibility of 100% home office. However, if you are in Berlin you are more than welcome to come around the office and maybe even bring your furry friend</p><ul><li>Stock options. Every employee receives stocks, because our success is also your success</li><li>Development opportunities. Because we care about your growth, we have regular feedback talks as well as set paths for the development of each employee</li><li>The latest tech equipment. Every new team member receives an Apple MacBook Air to guarantee smooth productivity</li><li>Flexibility. We offer flexible working hours and value asynchronous communication as well. On top we offer 25 vacation days</li><li>Team building. Meet the team at in-person on-sites, get a buddy to fully integrate into the company and join other team events</li><li>International travel health insurance. Prioritizing your well-being with comprehensive coverage, we guarantee your peace of mind wherever your travels take you</li><li>Workation. Experience the blend of work and leisure with our worldwide new benefit catering to your work-away-from-home needs</li><li>We care about security. You will receive 1password family membership</li><li>Choice. You get a monthly budget to finance a benefit of your choice</li></ul><p>Even if not all of these points fit 100% we encourage you to apply! We hire also for attitude, not just for knowledge and are looking forward to hearing from you soon.</p><br><p><strong>WHAT COMES AFTER YOU APPLY?</strong> \u200d\ufe0f</p><br><p>Easy steps for a smooth hiring process</p><ul><li>Application Review</li><li>Get to know re:cap</li><li>Case study/Take home Assignment (depending on the position)</li><li>Role-specific Interview</li><li>Get to know the team</li><li>Offer</li></ul><p>We are committed to foster a diverse and inclusive workplace where we provide equal opportunities regardless of age, gender identity, disability status, ethnicity, sexual orientation, or religion. Therefore we encourage you to apply as all qualified applications will be taken into consideration.</p><br>"
  },
  {
    "id": 138,
    "title": "Senior / Lead Data Engineer (f/m/d)",
    "company": "Hive Technologies GmbH",
    "locations": "Berlin",
    "skills": "Python, SQL, AWS, Data Pipelines, Business Intelligence, Data Warehouse, ETL, Redshift, Flink, Dashboards, PostgreSQL, Terraform, Database Design, Tableau, Cloud Platforms, Shopify, Metabase, Hive, IaC, ELT",
    "posted_at": "2024-06-27",
    "is_remote": "False",
    "snippet_fragments": "Strong proficiency in SQL and significant experience with relational databases and data warehouse (e, Experience with (near) real-time data use-cases a plus, Proficiency in a programming language such as Python, Solid understanding of data warehousing concepts and best practices, Excellent problem-solving skills and high attention to detail, Strong communication skills and the ability to work collaboratively in a team environment, You will work with a highly driven team of exceptional and experienced people in all domains, People at Hive have worked at organizations such as McKinsey, We believe in a culture of trust,  Join a young company with an entrepreneurial culture operating at lightning speed  we want you to grow with us, We offer attractive compensation, including virtual employee stock options for all full-time team members plus your choice of hardware according to your preference",
    "description": "<p><strong>THE POSITION</strong></p><br><p>If you are excited about growing with Hive and love operations, this might be the right position for you!</p><br><p>You'll join as our first full-time data engineer, helping power our business, serve our customers better, and drive our data infrastructure.</p><br><p><strong>What you'll be responsible for:</strong></p><br><p>Some exemplary topics of what we expect a data engineer to cover is below - an important note is that we're not looking for someone that purely optimizes the technical aspects of what they're doing, but that they're doing it with their users (engineers, data analysts, PMs, ...) and our customers in mind.</p><ul><li>Design, develop, and maintain scalable ETL/ELT processes to support data ingestion, transformation, and storage using dbt, Python, and Redshift.</li><li>Optimize and manage our data warehouse (Redshift) to ensure high performance, reliability, and low latency.</li><li>Architect, create, and maintain data models that reflect the needs of the business.</li><li>Develop data products to be integrated across our entire operations platform, such as:</li><li>Merchant-facing analytics for dashboards and different views in our customer-facing applications</li><li>Operational analytics for data-driven decision making in our Warehouse Management Software</li><li>Delivery time prediction models to power our &quot;Delivery Promise&quot; functionality across applications, from the merchant's storefront to their tracking emails and customer-facing tracking portal.</li></ul><p>Hive is building the leading operations platform for independent commerce. It's time for us to take the next step and deeply invest in our data platform foundations as a key enabler to enhance the value of our multi-product offering. Better commerce operations for merchants, consumers, and our fulfillment network.</p><br><p><strong>What you'll be doing:</strong></p><ul><li><br><strong>Data pipeline optimization:</strong> Redesign, build, and optimize ETL processes to reduce latency and improve performance for real-time analytics use cases.</li><li><br><strong>Scalable Data Warehouse setup</strong>: Help shape and implement a scalable data warehousing solution (e.g., in Redshift) to handle increasing data volumes and complex queries efficiently.</li><li><br><strong>BI enhancement:</strong> Guide data analysts to develop new dashboards and reporting solutions in Metabase, providing actionable insights.</li><li><br><strong>Data quality and consistency:</strong> Ensure comprehensive data quality and accuracy across all pipelines.</li><li><br><strong>Integration with product infrastructure:</strong> Work with engineering teams to integrate data solutions with our product stack, enabling seamless data flow and enhancing our capabilities across the entire platform.<br> Collaboration across the business: Assess stakeholder needs across the Hive organization to drive decision-making and technical approaches proactively, ensuring different use cases are covered properly and thoroughly<br><strong>YOUR PROFILE</strong><br></li></ul><p>We know - sometimes, you can't tick every box. We would still love to hear from you if you think you're a good fit!</p><ul><li><br><strong>You have the skills.</strong> Strong proficiency in SQL and significant experience with relational databases and data warehouse (e.g. Postgres and Redshift). Experience with (near) real-time data use-cases a plus.</li><li><br><strong>You get into the details.</strong> Hands-on experience with ETL/ELT tools and processes, BI tools like Mode/Metabase/Tableau, and cloud platforms like AWS.</li><li><br><strong>You write code.</strong> Proficiency in a programming language such as Python, and are experienced in managing data infrastructure via IaC tools like Terraform</li><li><br><strong>You know the theory, and the practice.</strong> Solid understanding of data warehousing concepts and best practices.</li><li><br><strong>You care about the craft</strong>. Excellent problem-solving skills and high attention to detail.</li><li><br><strong>You bring people along.</strong> Strong communication skills and the ability to work collaboratively in a team environment.</li></ul><p><strong>OUR OFFERING</strong></p><ul><li><br><strong>Be part of the Hive</strong>. You will work with a highly driven team of exceptional and experienced people in all domains. People at Hive have worked at organizations such as McKinsey, Amazon, Shopify, Google, Flink, Blackstone, J.P. Morgan &amp; DHL before. We believe in a culture of trust, collaboration, empowerment and constructive feedback in a positive and inspiring work atmosphere</li><li><br><strong>Make an impact.</strong> Join a young company with an entrepreneurial culture operating at lightning speed - we want you to grow with us</li><li><br><strong>You will be valued</strong>. We offer attractive compensation, including virtual employee stock options for all full-time team members plus your choice of hardware according to your preference</li><li><br><strong>We support your well-being.</strong> Benefit from 30 vacation days annually, with the opportunity for a sabbatical after three years with us, alongside a dedicated monthly wellness and productivity budget.</li><li><br><strong>We will get you set up.</strong> Operating system and hardware of your choice, additional tech equipment that you need, screens, you name it - we want to enable you to do your best work</li><li><br><strong>There's more!</strong> Enjoy flexible working hours, free drinks and snacks in our office in Berlin, Paris, Milan &amp; Madrid and join regular team events such as off-sites and workcations</li></ul><p><strong>ABOUT US</strong></p><br><p><strong>We make better commerce operations for everyone.</strong></p><br><p>Hive's mission is to make commerce operations better - for brands, consumers and ops partners. Hive seamlessly combines powerful technology with a network of leading operations providers, saving commerce brands on average 17% on costs and generating up to 24% revenue uplift. All-in-one, through our Hive App. The Hive ecosystem spans the full operational chain. Started just in 2020, Hive already works with hundreds of the leading brands across Europe such as HOLY, mybacs and Inkster and has become the leading operations platform in Europe. Backed by acclaimed global investors including Tiger Global, Earlybird, Picus Capital, we are rapidly expanding our pan-European network with our newly opened fulfillment centers and offices in Berlin, Paris, Milan, Madrid and London.</p><br><p>At Hive, we believe fostering diversity in every team makes us a stronger company overall. We do not discriminate based on religion, skin color, nationality, gender, sexual orientation, age, marital status, or disability, and encourage applications from all backgrounds. We strive to create an inclusive workplace where everyone feels encouraged to be their true self and to grow professionally.</p><br>"
  },
  {
    "id": 139,
    "title": "Data Engineer (d/m/w) - befristet (Elternzeitvertretung)",
    "company": "Toll Collect GmbH",
    "locations": "Berlin",
    "skills": "SQL, Mathematik, Linux, Cognos, PL/SQL, Windows",
    "posted_at": "2024-06-27",
    "is_remote": "False",
    "snippet_fragments": "    Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics,      Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL),      Sie beherrschen den Umgang mit Windows und Linux einwandfrei,      Sie haben ein abgeschlossenes Studium in der Mathematik,      Sie haben Berufserfahrung im Bereich Data Engineering,     Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung,      Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung,  Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet,      Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung,     Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung,     Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu, Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen, Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt",
    "description": "<p>Referenznummer: 20728</p><br><p>Ihre Aufgaben</p><ul><li>Sie verantworten die Strukturierung und Weiterentwicklung von Datenmodellen und Datenfl\u00fcssen sowie der zugeh\u00f6rigen IT-gest\u00fctzten Prozesse</li><li>Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit</li><li>Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten</li><li>Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen</li><li>Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit, bringen eigene Ideen ein und setzen diese um</li><li>Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen<br> Ihr Profil</li><li>Sie haben Erfahrungen in IBM Infosphere Datastage und IBM Cognos Analytics</li><li>Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL).</li><li>Sie beherrschen den Umgang mit Windows und Linux einwandfrei</li><li>Sie haben ein abgeschlossenes Studium in der Mathematik, Informatik oder in einem vergleichbaren Studiengang</li><li>Sie haben Berufserfahrung im Bereich Data Engineering<br> Was bieten wir</li><li>Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung</li><li>Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung</li><li>Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet</li><li>Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung</li></ul><p>Interessiert?</p><br><p>Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen ohne Foto und mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung.</p><br><p>Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu. Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen. Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt.</p><br><p>Ihre Ansprechperson</p><br><p>Frau Silvia Barknecht, 030/74077-8214, karriere@toll-collect.de</p><br><p>Toll Collect GmbH * Personalmanagement * Linkstra\u00dfe 4, 10785 Berlin</p><br>"
  },
  {
    "id": 140,
    "title": "Senior Data Engineer",
    "company": "Flywheel Digital",
    "locations": "Berlin",
    "skills": "Python, SQL, AWS, Cloud, Data Pipelines, Data Modeling, ETL, Airflow, Agile, DynamoDB, Kafka, Spark, Lambda, Jira, Pair Programming, RabbitMQ, Version Control, GitHub, Cloud Platforms, Serverless, Kinesis, PySpark, RESTful APIs, Snowflake, AWS Glue, Distributed Computing, AWS EC2, CD, Continuous Integration, Git, AWS SQS, AWS S3, ELT",
    "posted_at": "2024-06-26",
    "is_remote": "False",
    "snippet_fragments": "AWS Serverless (lambda, eventbridge, step functions, sqs),      Experience working in an agile development environment ,      Experience with additional cloud platforms beyond AWS , Experience developing CI/CD, automations, and quality of life improvements for developers,     We are proud to offer all Flywheelers a competitive rewards package and unparalleled career growth opportunities and a supportive,     We have office hubs across the globe where team members can go to feel productive,     Benefits that help you live your best life ,     If you're looking to connect with teammates on a topic of inclusion and identity,    Every role starts the same, an introductory call with someone from our Talent Acquisition team, We will be looking for company and values-fit as well as your professional experience; there may be some technical role-specific questions during this call,    Every role is different after the initial call, In your initial call, we will walk you through exactly what to expect the process to be,    At Flywheel, our goal is to create a culture where individuals of all backgrounds feel comfortable in bringing their authentic selves to work, We want all Flywheel people to feel included and truly empowered to contribute fully to our vision and goals,    Flywheel is an Equal Opportunity Employer and participates in E-Verify, Everyone who applies will receive fair consideration for employment, We do not discriminate based upon race,    If you have any accessibility requirements that would make you more comfortable during the application and interview process",
    "description": "<p><strong>ABOUT FLYWHEEL</strong></p><br><p>Flywheel's suite of digital commerce solutions accelerate growth across all major digital marketplaces for the world's leading brands. We give clients access to near real-time performance measurement and improve sales, share, and profit. With teams across the Americas, Europe and APAC, we offer a career with real impact, endless growth opportunities and the support you need to be the best you can be.</p><br><p><strong>OPPORTUNITY</strong></p><br><p>We're looking for a Mid/Senior Data Engineer to join our team. The best candidates will hit the ground running and contribute to our data team as we develop and maintain necessary data automation, reports, ETL/ELT, and quality controls using leading-edge cloud technologies.</p><br><p>You will have a deep knowledge and understanding of all stages in the software development life cycle. The ability to self-start, mentor and manage less experienced data engineers, desire to learn new technology, manage multiple priorities, and strong communication are all in your wheelhouse!</p><br><p><strong>WHAT YOU'LL DO:</strong></p><ul><li>Write high-level, well-documented code in Python and SQL</li><li>Work with multiple TBs of data per day</li><li>Build data pipelines that range from simple to complex, using technologies like Apache Airflow, Apache Spark and various AWS Services</li><li>Build ETL pipelines with Databrics, Snowflake, AWS Glue, pyspark and other ETL tools</li><li>Work with a mix of structured and unstructured data across cloud-based batch and streaming architectures</li><li>Engage directly with technical analysts, project managers, and other technical teams to help build concise requirements and ensure timely completion of projects</li><li>Work with Git, CI/CD, and version control to maintain code and documentation</li><li>Design and vet solutions for technical problems, and solicit team feedback during the design process \u00b7 Mentor, manage, train, and participate in paired programming in a lead capacity</li></ul><p><strong>WHO YOU ARE:</strong></p><ul><li><strong>Hard Requirements</strong></li><li>Experience with version control, GitHub, and software development life cycle 4 years' experience with SQL and data modeling</li><li>4 years' experience developing distributed computing solution</li><li>Demonstrated experience interacting with RESTful APIs</li><li>Experience with data pipelines / batch automation in at least one major technology (e.g. Apache Airflow)</li><li>Experience with one of the major cloud providers (AWS-preferred)</li><li><strong>Nice to Have</strong></li><li>AWS Serverless (lambda, eventbridge, step functions, sqs)</li><li>Experience working in an agile development environment</li><li>Streaming experience (kafka, kinesis, etc.)</li><li>Familiarity with Jira</li><li>Experience with other AWS technologies: EC2, S3, DynamoDB, RabbitMQ etc.</li><li>Experience with additional cloud platforms beyond AWS</li><li>Experience developing CI/CD, automations, and quality of life improvements for developers</li></ul><p><strong>WORKING AT FLYWHEEL</strong></p><br><p>We are proud to offer all Flywheelers a competitive rewards package and unparalleled career growth opportunities and a supportive, fun and engaging culture.</p><ul><li>We have office hubs across the globe where team members can go to feel productive, inspired, and connected to others - team members go into Hub Offices 3x a week</li><li>Flexible vacation time</li><li>Great learning and development opportunities</li><li>Benefits that help you live your best life</li><li>Parental leave and benefits</li><li>Volunteering opportunities</li><li>If you're looking to connect with teammates on a topic of inclusion and identity, chances are there's an ERG for that.</li><li>Learn more about us here: Life at Flywheel</li></ul><p><strong>THE INTERVIEW PROCESS:</strong></p><br><p>Every role starts the same, an introductory call with someone from our Talent Acquisition team. We will be looking for company and values-fit as well as your professional experience; there may be some technical role-specific questions during this call.</p><br><p>Every role is different after the initial call, but you can expect to meet several people from the team 1:1 and there might be further skill assessments in the form of a Take Home Assignment/Case Study Presentation or Pair Programming/Live Coding exercise depending on the role. In your initial call, we will walk you through exactly what to expect the process to be.</p><br><p><strong>INCLUSIVE WORKFORCE</strong></p><br><p>At Flywheel, our goal is to create a culture where individuals of all backgrounds feel comfortable in bringing their authentic selves to work. We want all Flywheel people to feel included and truly empowered to contribute fully to our vision and goals.</p><br><p>Flywheel is an Equal Opportunity Employer and participates in E-Verify. Everyone who applies will receive fair consideration for employment. We do not discriminate based upon race, colour, religion, sex, sexual orientation, age, marital status, gender identity, national origin, disability, or any other applicable legally protected characteristics in the location in which the candidate is applying.</p><br><p>If you have any accessibility requirements that would make you more comfortable during the application and interview process, please let us know at recruitment@flywheeldigital.com so that we can support you.</p><br><p>Please note, we do not accept unsolicited resumes from 3rd party Recruitment Firms.</p><br><p>For more information about what data we collect and how we use it, please refer to our Privacy Policy.</p><br><p><strong>IMPORTANT ALERT:</strong> Please beware of fraudulent job communications from individuals falsely claiming to be from Flywheel. We've identified fraudulent activity through social media and messaging services purporting to be from Flywheel requesting payments for job- and recruitment-related expenses. Flywheel never asks candidates for personal information such as bank account data or tax IDs nor payments via social media or chat-based applications. Report suspected fraud to local authorities immediately. To learn more, click here.</p><br><p>#LI-HYBRID</p><br>"
  },
  {
    "id": 141,
    "title": "Senior/Expert Data Privacy Engineer (f/m/d): Data Privacy-Preserving AI",
    "company": "SAP",
    "locations": "Berlin",
    "skills": "Python, Machine Learning, Cloud, AI, TensorFlow, PyTorch, Integrity, SAP, Tabular, CRM",
    "posted_at": "2024-06-26",
    "is_remote": "False",
    "snippet_fragments": "   Contribute to thought leadership in a revolutionary new data modality for Foundation Models and Generative AI,    PhD or Masters degree in Computer Science, Extensive experience in data privacy, particularly in differential privacy, and its application in Foundation Models and Machine Learning.,    Strong technical vision on how to ensure data privacy for Foundation Models,    Deep understanding of issues and opportunities of applying Generative AI in a business context, Proficiency in Python, and experience with ML frameworks such as PyTorch, TensorFlow, or similar., Exceptional teamwork abilities, leadership and strategic thinking skills.,    Professional experience with Machine Learning on structured data,    Hands-on experience in developing and deploying secure and privacy-preserving ML solutions,   Meet your team SAP's AI organization is dedicated to seamlessly infusing AI into all enterprise applications, Join our international AI team where innovation thrives,   SAP innovations help more than four hundred thousand customers worldwide work together more efficiently and use business insight more effectively, Originally known for leadership in enterprise resource planning (ERP) software, As a cloud company with two hundred million users and more than one hundred thousand employees worldwide, Whether connecting global industries, people, or platforms, we help ensure every challenge gets the solution it deserves, At SAP, you can bring out your best.",
    "description": "<p><strong>We help the world run better</strong></p><br><p>At SAP, we enable you to bring out your best. Our company culture is focused on collaboration and a shared passion to help the world run better. How? We focus every day on building the foundation for tomorrow and creating a workplace that embraces differences, values flexibility, and is aligned to our purpose-driven and future-focused work. We offer a highly collaborative, caring team environment with a strong focus on learning and development, recognition for your individual contributions, and a variety of benefit options for you to choose from.</p><br><p><strong>What you`ll do</strong></p><br><p>Summary:</p><br><p>At SAP, we amplify the strength of AI technology, fusing it with our robust industry-focused data and profound process knowledge. Our vision is to infuse every SAP application with sophisticated AI capabilities, revolutionizing the way businesses operate. Large Language Models (LLMs) hold immense potential to change the way we work and develop products. They are reshaping the landscape of Machine Learning across various domains. However, their limited ability to leverage tabular data leaves a considerable share of enterprise data untapped. It is SAP's mission to overcome this challenge within the realm of Business AI. Our goal is to adapt Foundation Models to SAP data, enabling our clients to solve their business processes more effectively.</p><br><p>The Role:</p><ul><li>Unique opportunity to lead the engineering efforts in the area of data privacy for a newly established Foundation Model on structured business data.</li><li>Your primary objective is to design, develop, and execute technical solutions to safeguard our sensitive training data, focusing specifically on securing the models against potential threats and vulnerabilities.</li><li>Engineer and implement innovative methodologies to ensure the highest level of data integrity and security, as well as adhering to the highest ethical and regulatory standards with the Foundation Model.</li><li>Define processes, methods, and implement solutions from the ground up with an understanding to put them together for an End-to-End Foundational Model.</li><li>Collaborate with the legal department to ensure alignment between data privacy approaches and legal requirements.</li><li>Contribute to thought leadership in a revolutionary new data modality for Foundation Models and Generative AI.</li></ul><p><strong>What you bring</strong></p><ul><li>PhD or Master's degree in Computer Science, Artificial Intelligence, or other relevant disciplines.</li><li>Extensive experience in data privacy, particularly in differential privacy, and its application in Foundation Models and Machine Learning.</li><li>Strong technical vision on how to ensure data privacy for Foundation Models.</li><li>Deep understanding of issues and opportunities of applying Generative AI in a business context.</li><li>Proficiency in Python, and experience with ML frameworks such as PyTorch, TensorFlow, or similar.</li><li>Exceptional teamwork abilities, leadership and strategic thinking skills.</li><li>Professional experience with Machine Learning on structured data, preferably in the ERP or CRM domain.</li><li>Hands-on experience in developing and deploying secure and privacy-preserving ML solutions.</li></ul><p><strong>Meet your team</strong></p><br><p>SAP's AI organization is dedicated to seamlessly infusing AI into all enterprise applications, enabling customers, partners, and developers to enhance business processes and generate remarkable business value. Join our international AI team where innovation thrives, opportunities for personal development abound, and exceptional colleagues collaborate globally.</p><br><p>#SAPBusinessAICareers #SAPAICareers</p><br><p><strong>Bring out your best</strong></p><br><p>SAP innovations help more than four hundred thousand customers worldwide work together more efficiently and use business insight more effectively. Originally known for leadership in enterprise resource planning (ERP) software, SAP has evolved to become a market leader in end-to-end business application software and related services for database, analytics, intelligent technologies, and experience management. As a cloud company with two hundred million users and more than one hundred thousand employees worldwide, we are purpose-driven and future-focused, with a highly collaborative team ethic and commitment to personal development. Whether connecting global industries, people, or platforms, we help ensure every challenge gets the solution it deserves. At SAP, you can bring out your best.</p><br><p><strong>We win with inclusion</strong></p><br><p>SAP's culture of inclusion, focus on health and well-being, and flexible working models help ensure that everyone - regardless of background - feels included and can run at their best. At SAP, we believe we are made stronger by the unique capabilities and qualities that each person brings to our company, and we invest in our employees to inspire confidence and help everyone realize their full potential. We ultimately believe in unleashing all talent and creating a better and more equitable world.</p><br><p>SAP is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to the values of Equal Employment Opportunity and provide accessibility accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment with SAP and are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team: Careers@sap.com.</p><br><p>For SAP employees: Only permanent roles are eligible for the SAP Employee Referral Program, according to the eligibility rules set in the SAP Referral Policy. Specific conditions may apply for roles in Vocational Training.</p><br><p>Requisition ID: 395663 | Work Area: Software-Design and Development | Expected Travel: 0 - 10% | Career Status: Professional | Employment Type: Regular Full Time | #LI-Hybrid</p><br>"
  },
  {
    "id": 142,
    "title": "Data Scientist (Recommendations)",
    "company": "Knowunity",
    "locations": "Berlin",
    "skills": "Algorithms, Collaborative Filtering, Recommender Systems",
    "posted_at": "2024-06-26",
    "is_remote": "False",
    "snippet_fragments": "     Lead the building of large-scale recommendation algorithms and systems,      Productionise recommendation algorithms for over 12 Million students,      Extract relevant information from large amounts of various data and design algorithms to explore users' latent interests efficiently,      Closely collaborate with the search team to improve search relevance through recommendations,  This mission is awesome, because you will,      Shape the recommendation system at Knowunity and thereby helping students succeed,      Play an integral part in the expansion of Europe's fastest growing EdTech Startup,      Have direct impact with your decisions on millions of students from around the globe,      Experience in building recommendation systems at a bigger scale using Collaborative Filtering,      Ability and desire to rapidly learn new technologies and use different approaches to problem solving,      You believe in the power of speed and execution and love to get your hands dirty,      You are obsessed to serve the user and strive to deliver over sticking to processes, Team events, company events, sports & wellbeing events, Breakfast, fruits & snacks, coffee, tea & soft drinks, dog friendly, Hybrid work, travel budget, team workations",
    "description": "<p><strong>ABOUT US</strong></p><br><p>We are Knowunity, Europe's fastest growing EdTech app. Our goal is to create a future where every student can access, enjoy, and benefit from quality education. Since founding Knowunity in 2020, we have been committed to revolutionizing how students learn and consume education on a global scale. Today, we are the daily learning companion of over 12 million students across 9 countries in Europe and the U.S. We bring together a global peer-to-peer community that supports each other throughout school, and our mission is to grow this community to 20 million students in 2024 and beyond.</p><br><p>Backed with over $25 million in funding by leading VCs and angel investors, including Project A, Redalpine, Stride, Mario G\u00f6tze, Verena Pausder, and more, we are heavily focused on building the AI-driven daily learning companion for every student on the planet. Together, we are leading the transformation of making education accessible, social, and impactful for all.</p><br><p><strong>Become part of our educational revolution - we are ready to change the world!</strong></p><br><p><strong>YOUR MISSION</strong></p><br><p>We are looking for a motivated Data Scientist who will lead the building of recommendation algorithms that will further enhance the learning experience for our users. As Data Scientist, you will be part of our team of highly experienced developers and will report directly to Lucas Hild, Knowunity Co-Founder and CTO.</p><br><p><strong>Your mission will be to...</strong></p><ul><li>Lead the building of large-scale recommendation algorithms and systems, including content recommendations in Knowunity</li><li>Productionise recommendation algorithms for over 12 Million students</li><li>Extract relevant information from large amounts of various data and design algorithms to explore users' latent interests efficiently</li><li>Closely collaborate with the search team to improve search relevance through recommendations<br><strong>This mission is awesome, because you will...</strong><br></li><li>Shape the recommendation system at Knowunity and thereby helping students succeed</li><li>Play an integral part in the expansion of Europe's fastest growing EdTech Startup</li><li>Have direct impact with your decisions on millions of students from around the globe</li></ul><p><strong>YOUR STORY</strong></p><ul><li>5+ years of programming experience</li><li>Experience in building recommendation systems at a bigger scale using Collaborative Filtering, Matrix Factorization, Deep Neural Networks, etc.</li><li>Ability and desire to rapidly learn new technologies and use different approaches to problem solving</li><li>Business fluent in English</li><li>You believe in the power of speed and execution and love to get your hands dirty</li><li>You are obsessed to serve the user and strive to deliver over sticking to processes</li></ul><p><strong>WHAT WE OFFER</strong></p><br><p><strong>Memberships:</strong> Urban Sports Club, become.1, Likeminded</p><br><p><strong>Discounts:</strong> corporate benefits, FutureBens, Plantclub</p><br><p><strong>Events:</strong> Team events, company events, sports &amp; wellbeing events</p><br><p><strong>Development:</strong> Personal development budget, hackathons, mentoring</p><br><p><strong>Office:</strong> Breakfast, fruits &amp; snacks, coffee, tea &amp; soft drinks, dog friendly</p><br><p><strong>Remote:</strong> Hybrid work, travel budget, team workations</p><br><p><strong>Our Tech Stack</strong></p><br><p><strong>HOW TO APPLY</strong></p><br><p>Did we spark your interest to join our educational revolution? We encourage you to apply even if you do not meet all of the requirements.</p><br><p><strong>We can't wait to hear from you!</strong></p><br><p>At Knowunity, we actively foster an inclusive and diverse workplace that ensures equal opportunity for all qualified applicants, regardless of nationality, ethnic or national origin, skin color, religion, sex, gender identity or expression, sexual orientation, physical or mental disability, or marital status. Please refrain from including your picture and age with the application.</p><br>"
  },
  {
    "id": 143,
    "title": "Senior Data Engineer with focus on Generative AI",
    "company": "Contiamo",
    "locations": "Berlin",
    "skills": "Python, Mathematik, Data Science, AWS, Cloud, Data Pipelines, AI, Data Warehouse, Docker, Kubernetes, Excel, Algorithms, Cloud Platforms, PyTorch",
    "posted_at": "2024-06-24",
    "is_remote": "True",
    "snippet_fragments": "  We are seeking a highly skilled and experienced Senior Data Engineer with a focus on Generative AI to join our team, In this role, you will be responsible for designing and implementing data solutions that leverage Generative AI techniques to address our clients' complex data problems.,  In this role, you will be tasked with the development and implementation of algorithms and models for generating AI-driven content, This will involve leveraging advanced Generative AI techniques, You will also design and optimize data pipelines and distributed systems to handle large-scale data processing and storage, Staying abreast of the latest advancements in Generative AI and related technologies is crucial in this role,  As a technical leader, you will collaborate directly with a project management lead and engage with clients, effectively communicating technical issues and solutions to both technical and non-technical audiences, This collaboration ensures a comprehensive perspective and facilitates successful project outcomes, Using your experience and communication skills, Furthermore, your expertise will be key in comprehensively documenting projects and processes, enabling clients to understand and potentially take ownership of the solutions.,   This senior-level role demands not only technical proficiency but also robust problem-solving abilities, If you are ready to tackle challenging data problems,   You are a good fit if you,    Are passionate about new Generative AI techniques,    Have a strong proficiency in Python and experience with relevant libraries and frameworks for Generative AI,    Demonstrate proven experience in designing and implementing distributed systems and data pipelines,    Possess excellent research and communication skills to stay up-to-date with the rapidly evolving field of Generative AI and effectively share knowledge within the team,    Have strong problem-solving abilities and the ability to work independently,    Fit 80% of the above list and are ready to dive into the other items,    Currently live in Germany or you are considering a move, You must already have an EU work visa,    Are familiar with the usage and packaging of libraries like CatBoost,  Are familiar with containerized applications, such as Docker, and their maintenance,    Have experience with Kubernetes and the various cloud platforms,    A senior and highly qualified team to work with and learn from",
    "description": "<p><strong>ABOUT US</strong></p><br><p>Contiamo is a high quality consulting firm that brings together an interdisciplinary, senior team. We combine extensive experience in data science, data engineering, mathematics, business consulting, and change management.</p><br><p>We work with with leading companies like Mercedes Benz, CBRE or Deutsche Telekom to solve their business challenges through intelligent data usage. As a trusted partner we provide high-quality data solutions combined with deep business know-how.</p><br><p>We love to find elegant solutions for complex challenges every day. Our focus is on scalable cloud applications and the intensive use of open source tools.</p><br><p>Our culture thrives on fast iterations, relying on a high-trust environment where everyone is given significant responsibility. We work in a supportive atmosphere, valuing both individual contributions and the pleasure of working as a team.</p><br><p>Our projects are covering a wide range of exciting data use-cases, including cloud DWH migrations, data catalog implementations, building data intensive applications and algorithms / data science. We also are highly involved in Generative AI projects including the integration and implementation of LLM use-cases ( e.g. GPT-4 ).</p><br><p><strong>ABOUT THE ROLE</strong></p><br><p>We are seeking a highly skilled and experienced Senior Data Engineer with a focus on Generative AI to join our team. In this role, you will be responsible for designing and implementing data solutions that leverage Generative AI techniques to address our clients' complex data problems.</p><br><p>In this role, you will be tasked with the development and implementation of algorithms and models for generating AI-driven content. This will involve leveraging advanced Generative AI techniques, such as LLM's (Language Models), embeddings, and vector databases. You will also design and optimize data pipelines and distributed systems to handle large-scale data processing and storage, thereby enabling the practical application of generative AI. Staying abreast of the latest advancements in Generative AI and related technologies is crucial in this role, as you will be expected to effectively communicate and apply these advancements to solve our clients' data challenges.</p><br><p>As a technical leader, you will collaborate directly with a project management lead and engage with clients, effectively communicating technical issues and solutions to both technical and non-technical audiences. This collaboration ensures a comprehensive perspective and facilitates successful project outcomes. Using your experience and communication skills, you will identify essential requirements and priorities, carefully balancing project limitations and success. Furthermore, your expertise will be key in comprehensively documenting projects and processes, enabling clients to understand and potentially take ownership of the solutions.</p><br><p>This senior-level role demands not only technical proficiency but also robust problem-solving abilities, collaboration skills, and the wisdom to make informed decisions. If you are ready to tackle challenging data problems, eager to learn and leverage cutting-edge technology, and possess the qualities of an independent problem solver, we encourage you to apply.</p><br><p><strong>YOU ARE A GOOD FIT IF YOU</strong></p><ul><li>Are passionate about new Generative AI techniques, including LLM's, embeddings, and vector databases.</li><li>Have a strong proficiency in Python and experience with relevant libraries and frameworks for Generative AI.</li><li>Demonstrate proven experience in designing and implementing distributed systems and data pipelines</li><li>Possess excellent research and communication skills to stay up-to-date with the rapidly evolving field of Generative AI and effectively share knowledge within the team.</li><li>Have strong problem-solving abilities and the ability to work independently, take ownership of projects, and deliver high-quality results.</li><li>Fit 80% of the above list and are ready to dive into the other items</li><li>Currently live in Germany or you are considering a move. You must already have an EU work visa.</li></ul><p><strong>BONUS IF YOU</strong></p><ul><li>Are familiar with the usage and packaging of libraries like CatBoost, PyTorch, LangFuse, LangChain, Haystack, Ollama, and similar.</li><li>Are familiar with containerized applications, such as Docker, and their maintenance</li><li>Have experience with Kubernetes and the various cloud platforms, specifically Google Cloud Platform and AWS</li></ul><p><strong>BENEFITS</strong></p><ul><li>Flexible working hours (really!)</li><li>A senior and highly qualified team to work with and learn from</li><li>Competitive salary</li><li>Vacation up to 30 days, can be taken independently and flexible according to the own wishes</li><li>home office budget and choose the equipment you want to work on</li><li>remote work possible (also in other EU countries for a limited amount of time)</li><li>Beautiful office in the heart of Berlin, Team lunches and Events, paid train ticket and more...</li></ul><p>We value diversity and encourage applications from individuals of all backgrounds. If you have the skills and passion to excel in this role, we would love to hear from you.</p><br><p>Please note that this is a senior-level position, and we expect candidates to demonstrate their ability to be independent problem solvers and collaborate effectively with the team and clients. We highly value clear communication, both written and spoken.</p><br><p>If you have any questions contact us at careers@contiamo.com</p><br>"
  },
  {
    "id": 144,
    "title": "Profil Data Engineer (m/w/d)",
    "company": "CANCOM SE",
    "locations": "Berlin",
    "skills": "Python, SQL, Data Modeling, Java, Version Control, Git, SAP, Architektur",
    "posted_at": "2024-06-21",
    "is_remote": "True",
    "snippet_fragments": "       Bei CANCOM erwartet dich ein innovatives, Du hast Lust ein Teil davon zu sein und den n\u00e4chsten Karriereschritt zu gehen? Dann werde Teil unserer Digital Journey, Wir freuen uns auf Menschen aus den unterschiedlichsten Fachrichtungen, Unternehmensweite, system\u00fcbergreifende Erschlie\u00dfung und Aufbereitung von Daten und Bereitstellung auf einer zentralen Analyseplattform, Aufbau einer Dateninfrastruktur mit Datenpipelines, die einen reibungslosen Datenfluss von der Quelle bis zum Nutzer erm\u00f6glichen, inkl,         Entwicklung von ETL- und Datenintegrationsl\u00f6sungen unter Verwendung verschiedener Technologien und Datenquellen ,         Arbeiten mit Cloud-basierten Infrastrukturen f\u00fcr das Hosting von Datenl\u00f6sungen und Anwendungen , Aggregation, Bereinigung und Anreicherung der Daten f\u00fcr unterschiedliche Anwendungssituationen im Unternehmen, Performante Bereitstellung f\u00fcr Data Analysts, Data Scientists, fachliche Mitarbeiter und Unternehmenskunden,         Erstellung von Datenmodellen f\u00fcr analytische Anwendungen ,         Unterst\u00fctzung bei der Entwicklung von Analyse- und Berichtsl\u00f6sungen ,         Ausbildung im IT-Bereich oder ein Studium mit Schwerpunkt Informatik / Wirtschaftsinformatik ,         Erfahrung in der Arbeit mit Data-Warehouse-L\u00f6sungen und ETL-Prozessen , Erfahrung mit Datenbanken und Datenmodellierung, insb,         Gute Kenntnisse des SAP Data Architecture Stacks ,         Deutsch und Englisch in Wort und Schrift ,         Flexible Arbeitszeiten und Mobile Office in Abstimmung mit dem Vorgesetzten ,         Rabatte dank dem Portal Corporate Benefits ",
    "description": "<p><strong>PROFESSIONAL</strong></p><br><p><strong>PROFIL DATA ENGINEER (M/W/D)</strong></p><br><p>Berlin, Erfurt, Frankfurt am Main, Hamburg, Hannover, K\u00f6ln, Leipzig, M\u00fcnchen, N\u00fcrnberg, Stuttgart</p><br><p>JETZT BEWERBEN</p><br><p>Bei CANCOM erwartet dich ein innovatives, agiles und nachhaltiges Umfeld: Mehr als 5.600 Mitarbeiter arbeiten tagt\u00e4glich daran, mit Hilfe moderner IT-L\u00f6sungen die Zusammenarbeit und den Austausch in verschiedenen Lebensbereichen zu verbessern. Du hast Lust ein Teil davon zu sein und den n\u00e4chsten Karriereschritt zu gehen? Dann werde Teil unserer Digital Journey. Wir freuen uns auf Menschen aus den unterschiedlichsten Fachrichtungen, die aufgeschlossen f\u00fcr Neues sind, innovative Einf\u00e4lle haben und im Team gemeinsam Ziele voranbringen wollen.</p><br><p><strong>DEINE NEUEN AUFGABEN</strong></p><ul><li>Unternehmensweite, system\u00fcbergreifende Erschlie\u00dfung und Aufbereitung von Daten und Bereitstellung auf einer zentralen Analyseplattform</li><li>Aufbau einer Dateninfrastruktur mit Datenpipelines, die einen reibungslosen Datenfluss von der Quelle bis zum Nutzer erm\u00f6glichen, inkl. Datenqualit\u00e4t, Datensicherheit</li><li>Entwicklung von ETL- und Datenintegrationsl\u00f6sungen unter Verwendung verschiedener Technologien und Datenquellen</li><li>Arbeiten mit Cloud-basierten Infrastrukturen f\u00fcr das Hosting von Datenl\u00f6sungen und Anwendungen</li><li>Aggregation, Bereinigung und Anreicherung der Daten f\u00fcr unterschiedliche Anwendungssituationen im Unternehmen</li><li>Monitoring der Datenqualit\u00e4t und Prozesse</li><li>Performante Bereitstellung f\u00fcr Data Analysts, Data Scientists, fachliche Mitarbeiter und Unternehmenskunden</li><li>Erstellung von Datenmodellen f\u00fcr analytische Anwendungen</li><li>Unterst\u00fctzung bei der Entwicklung von Analyse- und Berichtsl\u00f6sungen</li></ul><p><strong>DAS BRINGST DU MIT</strong></p><ul><li>Ausbildung im IT-Bereich oder ein Studium mit Schwerpunkt Informatik / Wirtschaftsinformatik</li><li>Erfahrung in der Arbeit mit Data-Warehouse-L\u00f6sungen und ETL-Prozessen</li><li>Erfahrung mit Datenbanken und Datenmodellierung, insb. SQL</li><li>Gute Kenntnisse des SAP Data Architecture Stacks</li><li>Sehr gute Programmierkenntnisse (z.B. Python, Java)</li><li>Erfahrung in der Arbeit mit Versionskontrollsystemen (z.B. Git)</li><li>Deutsch und Englisch in Wort und Schrift</li></ul><p><strong>UNSERE BENEFITS</strong></p><ul><li>Flexible Arbeitszeiten und Mobile Office in Abstimmung mit dem Vorgesetzten</li><li>Rabatte dank dem Portal \u201eCorporate Benefits&quot;</li><li>Bike-Leasing</li><li>Kostenlose Getr\u00e4nke &amp; Obst</li><li>Weiterbildungsm\u00f6glichkeiten</li><li>Mitarbeiterevents</li></ul><p>Weitere Benefits f\u00fcr Deutschland</p><br><p><strong>KONTAKT</strong></p><br><p>Sascha Sturm</p><br><p>Team Leader Recruiting</p><br><p>+49 89 54054-5454</p><br>"
  },
  {
    "id": 145,
    "title": "Data Engineer (m/w/d)",
    "company": "Legalhero GmbH",
    "locations": "Berlin",
    "skills": "Python, AWS, Data Analysis, Azure, Data Modeling, Cassandra, Hadoop, NiFi, Java, MongoDB, MySQL, NoSQL, PostgreSQL, Tableau, Talend, Spark",
    "posted_at": "2024-06-21",
    "is_remote": "False",
    "snippet_fragments": " Programmierkenntnisse in Python, Java oder anderen relevanten Sprachen,    Erfahrung in der Entwicklung von skalierbaren und zuverl\u00e4ssigen Big-Data-L\u00f6sungen,    Kenntnisse in der Datenvisualisierung mit Tableau,    Uns interessiert dein Input wirklich und du kannst unsere Reise mitgestalten,  Sch\u00f6nes, klimatisiertes B\u00fcro mit viel Tageslicht zwischen Gleisdreieck und Potsdamer Platz, 100 % \u00dcbernahme eines Deutschlandtickets, freie Getr\u00e4nke und frisches Obst, Mitarbeiterrabatte, Firmenfeiern und weitere Benefits",
    "description": "<p><strong>WAS DICH ERWARTET</strong></p><ul><li>Konzeption, Design und Implementierung von Datenarchitekturen und Datenpipelines zur Unterst\u00fctzung von Produktfunktionen und Datenanalysen</li><li>Identifikation von Datenquellen, -anforderungen und -problemen und Entwicklung von L\u00f6sungen zur Datenintegration und -verarbeitung</li><li>Entwicklung und Implementierung von Datenbanken und Datenmodellen, einschlie\u00dflich Datenstrukturen und -standards, die die Integrit\u00e4t der Daten gew\u00e4hrleisten</li><li>Implementierung von Automatisierung, \u00dcberwachung und Optimierung von Datenpipelines und Datenintegrationsprozessen</li><li>Entwicklung von skalierbaren und zuverl\u00e4ssigen Big-Data-L\u00f6sungen</li><li>Kenntnisse in der Datenvisualisierung mit Tableau, um die Daten in unseren Plattformen zu visualisieren und unsere Partner zu unterst\u00fctzen</li></ul><p><strong>WAS DU MITBRINGST</strong></p><ul><li>Flie\u00dfende Deutschkenntnisse (C2)</li><li>Abgeschlossenes Studium im Bereich Informatik, Wirtschaftsinformatik oder vergleichbare Qualifikation</li><li>Mindestens 3 Jahre Erfahrung im Data Engineering oder einer \u00e4hnlichen Rolle</li><li>Erfahrung mit relationalen Datenbanken (z.B. PostgreSQL, MySQL), NoSQL-Datenbanken (z.B. MongoDB, Cassandra), Datenmodellierung und ETL-Tools (z.B. Talend, Apache NiFi)</li><li>Programmierkenntnisse in Python, Java oder anderen relevanten Sprachen</li><li>Erfahrung mit Cloud-Diensten (z.B. AWS, Azure, Google Cloud Platform)</li><li>Kenntnisse in Data-Warehousing, Big-Data-Technologien und -Tools (z.B. Hadoop, Spark)</li><li>Erfahrung in der Entwicklung von skalierbaren und zuverl\u00e4ssigen Big-Data-L\u00f6sungen</li><li>Kenntnisse in der Datenvisualisierung mit Tableau</li></ul><p><strong>WAS WIR VERSPRECHEN</strong></p><ul><li>Faire Verg\u00fctung, je nach Vorerfahrung</li><li>Interessante Themen: Du lernst viel praxistaugliches juristisches Wissen bei der Arbeit</li><li>Flexible Arbeitszeitmodelle</li><li>Freundlicher, kollegialer Umgang</li><li>Uns interessiert dein Input wirklich und du kannst unsere Reise mitgestalten</li><li>Sch\u00f6nes, klimatisiertes B\u00fcro mit viel Tageslicht zwischen Gleisdreieck und Potsdamer Platz</li><li>Mobilit\u00e4tsbudget inkl. 100 % \u00dcbernahme eines Deutschlandtickets, freie Getr\u00e4nke und frisches Obst, Mitarbeiterrabatte, Firmenfeiern und weitere Benefits</li><li>Arbeit hybrid oder im B\u00fcro</li></ul><p><strong>\u00dcBER UNS</strong></p><br><p>Legalhero ist die moderne Plattform f\u00fcr Rechtsschutzversicherungen und Anw\u00e4lte. Wir verfolgen das ehrgeizige Ziel, die Schadensfallabwicklung von Rechtsschutzversicherungen zu revolutionieren. Dazu integrieren wir uns direkt in die Systeme der Versicherer. Unsere Partneranw\u00e4lte wickeln die F\u00e4lle hocheffizient und kundenorientiert auf unserer Tech-Plattform mit Hilfe von KI ab. Legalhero wurde 2017 gegr\u00fcndet und hat bis heute hunderttausenden von Versicherungsnehmern geholfen. Unsere ca. 90 Kollegen sitzen in Berlin, nahe dem Gleisdreieck.</p><br><p>Ein inklusives, gleichberechtigtes und diskriminierungsfreies Arbeitsumfeld ist f\u00fcr uns selbstverst\u00e4ndlich. Wenn du eine Beeintr\u00e4chtigung oder spezielle Bed\u00fcrfnisse haben solltest und w\u00e4hrend des Bewerbungsprozesses spezielle Unterst\u00fctzung ben\u00f6tigst, teile es uns gerne mit.</p><br>"
  },
  {
    "id": 146,
    "title": "Customer Engineer, Data Analytics, Google Cloud",
    "company": "Google",
    "locations": "Berlin",
    "skills": "Python, Machine Learning, Data Analysis, Cloud, GCP, AI, Business Intelligence, ETL, Big Data, C++, Java, JavaScript, Scala, Data Lake, Go, R, Architektur",
    "posted_at": "2024-06-20",
    "is_remote": "False",
    "snippet_fragments": "Experience with developing data warehouses, data lakes, batch or real-time event processing, Business Intelligence (BI), and ETL solutions., Experience in writing code (e.g., Java, Python, JavaScript, C, Scala, R, Go)., Ability to learn, understand, and work with new and emerging technologies, methodologies, and solutions in the technology space.,    The Google Cloud Platform team helps customers transform and build what's next for their business  all with technology built in the cloud, Our products are developed for security, Our teams are dedicated to helping our customers  developers, As part of an entrepreneurial team in this rapidly growing business,    Google Cloud accelerates every organizations ability to digitally transform its business and industry, We deliver enterprise-grade solutions that leverage Googles cutting-edge technology, Customers in more than 200 countries and territories turn to Google Cloud as their trusted partner to enable growth and solve their most critical business problems,    Support local Sales teams in pursuit of key business opportunities, Identify business and technical requirements, conduct full technical discovery, and architect client solutions to meet gathered requirements., Lead technical projects, including such activities as technology advocacy, supporting bid responses, product and solution briefings, proof-of-concept work, and the coordination of supporting technical resources.,    Work directly with Google Cloud Platform products to demonstrate and prototype integrations in customer or partner environments",
    "description": "<p>Note: By applying to this position you will have an opportunity to share your preferred working location from the following: <strong>Munich, Germany; Berlin, Germany; Frankfurt, Germany; Hamburg, Germany</strong>.</p><br><p><strong>MINIMUM QUALIFICATIONS:</strong></p><ul><li>Bachelor's degree in Computer Science, a related technical field, or equivalent practical experience.</li><li>6 years of experience with Data Analytics and Gen AI/ Machine Learning.</li><li>Experience engaging with, and presenting to, technical stakeholders, and executive leaders.</li><li>Ability to communicate in English and German fluently in order to communicate in this customer-facing sales role.</li></ul><p><strong>PREFERRED QUALIFICATIONS:</strong></p><ul><li>Experience in technical business or professional consulting in the fields of cloud computing, data, information lifecycle management, and Big Data.</li><li>Experience in technical pre-sales (i.e., solution design and architecture, conducting proof of concepts, building MVPs, etc.).</li><li>Experience with developing data warehouses, data lakes, batch or real-time event processing, Business Intelligence (BI), and ETL solutions.</li><li>Experience in writing code (e.g., Java, Python, JavaScript, C++, Scala, R, Go).</li><li>Ability to learn, understand, and work with new and emerging technologies, methodologies, and solutions in the technology space.</li></ul><p><strong>ABOUT THE JOB</strong></p><br><p>The Google Cloud Platform team helps customers transform and build what's next for their business - all with technology built in the cloud. Our products are developed for security, reliability and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping our customers - developers, small and large businesses, educational institutions and government agencies - see the benefits of our technology come to life. As part of an entrepreneurial team in this rapidly growing business, you will play a key role in understanding the needs of our customers and help shape the future of businesses of all sizes use technology to connect with customers, employees and partners.</p><br><p>Google Cloud accelerates every organization's ability to digitally transform its business and industry. We deliver enterprise-grade solutions that leverage Google's cutting-edge technology, and tools that help developers build more sustainably. Customers in more than 200 countries and territories turn to Google Cloud as their trusted partner to enable growth and solve their most critical business problems.</p><br><p><strong>RESPONSIBILITIES</strong></p><ul><li>Support local Sales teams in pursuit of key business opportunities, engaging customers to address aspects of the data lifecycle.</li><li>Identify business and technical requirements, conduct full technical discovery, and architect client solutions to meet gathered requirements.</li><li>Lead technical projects, including such activities as technology advocacy, supporting bid responses, product and solution briefings, proof-of-concept work, and the coordination of supporting technical resources.</li><li>Work directly with Google Cloud Platform products to demonstrate and prototype integrations in customer or partner environments.</li><li>Prepare and deliver product messaging in an effort to highlight the Google Cloud Platform value proposition travel as required.<br> Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form.</li></ul><br>"
  },
  {
    "id": 147,
    "title": "Data Engineer (d/m/w)",
    "company": "Toll Collect GmbH",
    "locations": "Berlin",
    "skills": "",
    "posted_at": "2024-06-20",
    "is_remote": "False",
    "snippet_fragments": "     Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten,      Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen,      Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit,      Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen ,     Sie haben Erfahrungen IBM Infosphere Datastage und IBM Cognos Analytics,      Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL),      Sie Beherrscht einwandfrei den Umgang mit Windows und Linux,      Sie haben ein abgeschlossenes Studium in der Mathematik,      Sie haben Berufserfahrung im Bereich Data Engineering,     Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung,      Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung,  Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet,      Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung,     Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung, Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu, Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen, Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt",
    "description": "<p>Referenznummer: 20728</p><br><p>Ihre Aufgaben:</p><ul><li>Sie verantworten die Strukturierung und Weiterentwicklung von Datenmodellen und Datenfl\u00fcssen sowie der zugeh\u00f6rigen IT-gest\u00fctzten Prozesse</li><li>Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit</li><li>Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten</li><li>Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen</li><li>Sie wirken bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit, bringen eigene Ideen ein und setzen diese um</li><li>Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen<br> Ihr Profil</li><li>Sie haben Erfahrungen IBM Infosphere Datastage und IBM Cognos Analytics</li><li>Sie verf\u00fcgen \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL).</li><li>Sie Beherrscht einwandfrei den Umgang mit Windows und Linux</li><li>Sie haben ein abgeschlossenes Studium in der Mathematik, Informatik oder in einem vergleichbaren Studiengang</li><li>Sie haben Berufserfahrung im Bereich Data Engineering<br> Was bieten wir</li><li>Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung</li><li>Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung</li><li>Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet</li><li>Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung</li></ul><p>Interessiert?</p><br><p>Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung. Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu. Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen. Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt.</p><br><p>Ihre Ansprechperson</p><br><p>Frau Silvia Barknecht, 030/74077-8214, karriere@toll-collect.de</p><br><p>Toll Collect GmbH * Personalmanagement * Linkstra\u00dfe 4, 10785 Berlin</p><br>"
  },
  {
    "id": 148,
    "title": "Data Scientist",
    "company": "7Learnings",
    "locations": "Berlin",
    "skills": "SQL, Machine Learning, Mathematik, GCP, BigQuery, TensorFlow, Git, Physik, Wirtschaftsingenieurwesen",
    "posted_at": "2024-06-18",
    "is_remote": "True",
    "snippet_fragments": "   Erste praktische Erfahrung mit maschinellem Lernen und Datenwissenschaften durch Praktika oder Werkstudentent\u00e4tigkeit, GIT, Tensorflow, Google Cloud, SQL oder BigQuery ,    Flexible Arbeitszeiten sowie ein B\u00fcro in Berlin Kreuzberg & flexible M\u00f6glichkeiten f\u00fcr Home Office,    Kultur des Vertrauens und des regelm\u00e4\u00dfigen konstruktiven Feedbacks",
    "description": "<p><strong>DEINE ROLLE</strong></p><ul><li>Unterst\u00fctze Optimierungsprojekte im Handel mit analytischen F\u00e4higkeiten</li><li>Experimentiere mit Machine Learning Modellen f\u00fcr die Vorhersage von Absatz und Kosten</li><li>Kontakt mit H\u00e4ndlern zur Verbesserung der 7Learnings Software</li><li>Enge Zusammenarbeit mit unserem Ingenieurteam</li><li>Verbesserung unserer Pipeline und unseres Modellcodes</li><li>Unterst\u00fctzung der \u00dcberwachung, Messung und Erforschung gro\u00dfer Datenmengen</li></ul><p><strong>DAS BRINGST DU MIT</strong></p><ul><li><br><strong>Bachelor/Master</strong> in BWL, Informatik, Wirtschaftsingenieurwesen, Mathematik, Physik oder verwandten Studien</li><li>Ein <strong>ergebnis-orientierter</strong>, pragmatischer Geist</li><li>Erste <strong>praktische Erfahrung</strong> mit maschinellem Lernen und Datenwissenschaften durch Praktika oder Werkstudentent\u00e4tigkeit</li><li>Erfahrung mit <strong>GIT, Tensorflow, Google Cloud, SQL oder BigQuery</strong> sind hilfreich</li><li><br><strong>Deutsch</strong>: mindestens C1</li></ul><p><strong>DAS BIETEN WIR DIR</strong></p><ul><li>Flexible Arbeitszeiten sowie ein <strong>B\u00fcro in Berlin Kreuzberg &amp; flexible M\u00f6glichkeiten f\u00fcr Home Office</strong><br></li><li>Kultur des <strong>Vertrauens</strong> und des regelm\u00e4\u00dfigen <strong>konstruktiven Feedbacks</strong><br></li></ul><p><strong>\u00dcBER UNS</strong></p><br><p>7Learnings ist eine der f\u00fchrenden Optimierungsplattformen f\u00fcr H\u00e4ndler. Wir bieten einen Softwareservice zur Preis- und Marketingoptimierung f\u00fcr Onlineh\u00e4ndler an. Mit Hilfe unseres Algorithmus k\u00f6nnen bis zu 10% der Ausgaben f\u00fcr Rabatte bei gleichbleibenden Ums\u00e4tzen gespart werden. Dies wird dadurch erreicht, dass unn\u00f6tige Rabatte identifiziert und eliminiert werden. Gleichzeitig werden mehr Rabatte in Produkte mit h\u00f6herer Preiselastizit\u00e4t gelenkt. Unsere Methode erm\u00f6glicht es auch einem kleinen Team die Preise nach neuesten Erkenntnissen zu steuern und Geld zu sparen.</p><br>"
  },
  {
    "id": 149,
    "title": "Data Center Engineer",
    "company": "Sauce Labs Inc.",
    "locations": "Berlin",
    "skills": "Cloud, Linux, Android, Continuous Testing, DevOps, Routing, Virtual Machines, Saucelabs, TCP/IP, SAN, RAID, Optik, Elektronik",
    "posted_at": "2024-06-17",
    "is_remote": "False",
    "snippet_fragments": "  Assure sufficient supplies and hardware such as PDUs,   Troubleshoot and remedy dc hardware issues; document findings in tickets o Hands-on with infrastructure provisioning and server/network equipment deployments ,   Manage the mobile devices in our cloud , Purchase, configure and maintain mobile devices (iPhone, Android) in a Data Center environment,   Resolve tickets autonomously and in cooperation with Support,   Work with the Operations team and Developers to improve the stability of our mobile devices in a Data Center environment ,   Help to grow the real device cloud setup in line with increasing demands,   Participate in experiments with new hardware and software configurations ,   Periodic trips to other company sites in the US ,   2 years recent experience working as a Data Center Engineer or equivalent ,  Reliable, independent work ethic, with a history of seeing projects through to completion,   Excellent communication skills to work with vendors and other engineers ,   Knowledge of Layer 1 network technologies (optics,   Familiarity with Data Center power delivery and power standards ,   Experience with deployment and management of Linux based systems  Good command of spoken and written English ",
    "description": "<p><strong>ABOUT US:</strong></p><br><p>Sauce Labs is the leading provider of continuous test and error reporting solutions that give companies the confidence to develop, deliver and update high quality software at speed. The Sauce Labs Continuous Testing Cloud identifies quality signals in development and production, accelerating the ability to release and update web and mobile applications that look, function and perform exactly as they should on every browser, operating system and device, every single time. Sauce Labs is a privately held company funded by TPG and Riverwood Capital.</p><br><p><strong>The Role:</strong></p><br><p>On a daily basis, you will be working directly with our highly available systems which are the foundation of Sauce Labs. Becoming part of our growing multi-national team of DevOps professionals means you will have a direct, daily impact on improving our users' experience. You will contribute to the successful operation and scaling of the Data Center infrastructure that powers Sauce Labs. We launch over 10 million virtual machines a month and supply our customers with remote access to thousands of real mobile devices; one of the biggest public cloud of real mobile devices on the market.</p><br><p><strong>Responsibilities:</strong></p><ul><li>Work alongside an international and geographically distributed team of engineers/technicians</li><li>Apply best-practice methodology for maintaining a Data Center environment</li><li>Manage and maintain our data centers</li><li>Manage ordering, shipping and receiving with various vendors</li><li>Maintain an up-to-date inventory list of all equipment in our DCIM system</li><li>Assist with automated provisioning processes for streamlining hardware deployments</li><li>Assure sufficient supplies and hardware such as PDUs, cables, optics, storage drives, etc.</li><li>Troubleshoot and remedy dc hardware issues; document findings in tickets o Hands-on with infrastructure provisioning and server/network equipment deployments</li><li>Manage the mobile devices in our cloud</li><li>Purchase, configure and maintain mobile devices (iPhone, Android) in a Data Center environment</li><li>Resolve tickets autonomously and in cooperation with Support, Engineering and other teams</li><li>Work with the Operations team and Developers to improve the stability of our mobile devices in a Data Center environment</li><li>Help to grow the real device cloud setup in line with increasing demands, and constant technology adaptations in consumer electronics</li><li>Participate in experiments with new hardware and software configurations</li><li>On-Call Rotation 24x7</li><li>Periodic trips to other company sites in the US</li></ul><p><strong>Required Skills:</strong></p><ul><li>2+ years recent experience working as a Data Center Engineer or equivalent</li><li>Reliable, independent work ethic, with a history of seeing projects through to completion</li><li>Excellent communication skills to work with vendors and other engineers</li><li>Knowledge of enterprise and consumer hardware: CPU, RAM, SSD, Power, Mobile, etc.</li><li>Understanding of the following technologies: TCP/IP, Routing, Linux, SAN, RAID, etc.</li><li>Knowledge of Layer 1 network technologies (optics, network cable types, etc.)</li><li>Familiarity with Data Center power delivery and power standards</li><li>Experience with deployment and management of Linux based systems</p><br><p>Good command of spoken and written English</li><li>Ability to lift 25-75 lbs on a regular basis</li></ul><p>Please note our privacy terms when applying for a job at Sauce Labs.</p><br><p>Sauce Labs is proud to be an Equal Opportunity employer and values diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender identity/expression/status, sexual orientation, age, marital status, veteran status or disability status.</p><br><p><strong>Security responsibilities at Sauce</strong></p><br><p>At Sauce, we will commit to supporting the health and safety of employees and properties, partnering with internal stakeholders to learn and act on ever-evolving security protocols and procedures. You'll be expected to fully comply with all policies and procedures related to security at the department and org wide level and exercise a 'security first' approach to how we design, build &amp; run our products and services</p><br>"
  },
  {
    "id": 150,
    "title": "Data Engineer (d/m/w)",
    "company": "Toll Collect GmbH",
    "locations": "Berlin",
    "skills": "SQL, Mathematik, Linux, Cognos, PL/SQL, Windows",
    "posted_at": "2024-06-16",
    "is_remote": "False",
    "snippet_fragments": "     Sie arbeiten bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit,      Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen ,     Sie haben Erfahrungen IBM Infosphere Datastage und IBM Cognos Analytics,      Sie verf\u00fcgt \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL),      Sie haben abgeschlossenes Studium in der Mathematik,      Sie haben Berufserfahrung im Bereich Data Engineering,     Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung,      Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung,  Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet,      Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung,     Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung, Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu, Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen, Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt",
    "description": "<p>Referenznummer: 20728</p><br><p>Ihre Aufgaben:</p><ul><li>Sie verantworten die Strukturierung und Weiterentwicklung von Datenmodellen und Datenfl\u00fcssen sowie der zugeh\u00f6rigen IT-gest\u00fctzten Prozesse</li><li>Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit</li><li>Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten</li><li>Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen</li><li>Sie arbeiten bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit, bringen eigene Ideen ein und setzen diese um</li><li>Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen<br> Ihr Profil</li><li>Sie haben Erfahrungen IBM Infosphere Datastage und IBM Cognos Analytics</li><li>Sie verf\u00fcgt \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL).\uf03c Sie Beherrscht einwandfrei den Umgang mit Windows und Linux</li><li>Sie haben abgeschlossenes Studium in der Mathematik, Informatik oder in vergleichbaren Studieng\u00e4ngen</li><li>Sie haben Berufserfahrung im Bereich Data Engineering<br> Was bieten wir</li><li>Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung</li><li>Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung</li><li>Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet</li><li>Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung</li></ul><p>Interessiert?</p><br><p>Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung. Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu. Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen. Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt.</p><br><p>Ihre Ansprechperson</p><br><p>Frau Silvia Barknecht, 030/74077-8214, karriere@toll-collect.de</p><br><p>Toll Collect GmbH * Personalmanagement * Linkstra\u00dfe 4, 10785 Berlin</p><br>"
  },
  {
    "id": 151,
    "title": "Data Engineer - Business Intelligence / IT Beratung / SAP ERP / ABAP (m/w/d)",
    "company": "cimt ag",
    "locations": "Berlin",
    "skills": "Data Science, Cloud, Business Intelligence, ABAP, DevOps, Java, SAP, BW",
    "posted_at": "2024-06-16",
    "is_remote": "False",
    "snippet_fragments": "  Tolles Teamwork und \ufb02ache Hierarchien sichern kurze Kommunikationswege ,   Ein Mentoring und berufsbegleitendes Coaching liegen uns am Herzen ,   10 Tage f\u00fcr Weiterbildung pro Jahr plus kontinuierliche und individuelle Weiterbildungsm\u00f6glichkeiten ,   30 Urlaubstage pro Jahr plus weitere 10 freie Tage m\u00f6glich ,   Hybrides Arbeitszeitmodell / Verg\u00fctung der \u00dcberstunden ,   Du \u00fcbernimmst die Rolle als Berater (m/w/d) bei aufkommenden Fragen ,   Du hast ein Studium im Bereich Informatik oder eine Ausbildung mit IT-Hintergrund abgeschlossen ,   Du verf\u00fcgst \u00fcber solide SAP ERP Kenntnisse,   Du hattest bereits erste Ber\u00fchrungspunkte mit den g\u00e4ngigsten Modulen wie FI/CO,   Du bringst gute Grundkenntnisse in ABAP und der Java Entwicklung mit ,   Du bist in der Lage komplexe Sachverhalte zu verstehen und zu erkl\u00e4ren und f\u00fcr dich ist ein kontinuierlicher Wissensaufbau und Teamwork essenziell ,   Du verf\u00fcgst \u00fcber flie\u00dfende Sprachkenntnisse in Deutsch und Englisch ",
    "description": "<p><strong>\u00dcber cimt ag:</strong></p><br><p>Wir sind ein branchen\u00fcbergreifendes IT-Beratungsunternehmen. Mit mehr als 250 Mitarbeitern entwickeln wir innovative Software, moderne IT-Konzepte und zeitgem\u00e4\u00dfe Systemarchitekturen.</p><br><p>Schwerpunkte unserer Dienstleistungen: Data Science von der Business Analyse bis zu Visualisierungen und SAP-Beratung vom Betrieb bis zur Applikationsentwicklung. Dabei geh\u00f6ren Cloud Technologien ebenso wie moderne DevOps Technologien zu unserem Alltag sowie Entwicklung mittels ABAP und Java.</p><br><p><strong>WAS BIETEN WIR DIR?</strong></p><ul><li>Tolles Teamwork und \ufb02ache Hierarchien sichern kurze Kommunikationswege</li><li>Ein Mentoring und berufsbegleitendes Coaching liegen uns am Herzen</li><li>10 Tage f\u00fcr Weiterbildung pro Jahr plus kontinuierliche und individuelle Weiterbildungsm\u00f6glichkeiten</li><li>30 Urlaubstage pro Jahr plus weitere 10 freie Tage m\u00f6glich</li><li>Fahrkartenzuschuss / Firmenwagen Leasing</li><li>Hybrides Arbeitszeitmodell / Verg\u00fctung der \u00dcberstunden</li></ul><p><strong>WAS ERWARTET DICH?</strong></p><ul><li>Du arbeitest in hybriden Projekten mit SAP als Quellsystem und entwickelst ma\u00dfgeschneiderte L\u00f6sungen f\u00fcr unsere Kund:innen</li><li>Du unterst\u00fctzt gemeinsam mit deinen Kolleg:innen unsere Kundschaft in modernen Architekturen vorwiegend im Bereich Business Intelligence und Cloud</li><li>Du \u00fcbernimmst die Rolle als Berater (m/w/d) bei aufkommenden Fragen</li></ul><p><strong>WAS SOLLTEST DU MITBRINGEN?</strong></p><ul><li>Du hast ein Studium im Bereich Informatik oder eine Ausbildung mit IT-Hintergrund abgeschlossen</li><li>Du verf\u00fcgst \u00fcber solide SAP ERP Kenntnisse, idealerweise auch \u00fcber SAP BI und BW Kenntnisse</li><li>Du hattest bereits erste Ber\u00fchrungspunkte mit den g\u00e4ngigsten Modulen wie FI/CO, MM, CRM oder SD</li><li>Du bringst gute Grundkenntnisse in ABAP und der Java Entwicklung mit</li><li>Du bist in der Lage komplexe Sachverhalte zu verstehen und zu erkl\u00e4ren und f\u00fcr dich ist ein kontinuierlicher Wissensaufbau und Teamwork essenziell</li><li>Du verf\u00fcgst \u00fcber flie\u00dfende Sprachkenntnisse in Deutsch und Englisch</li></ul><p>Unser Jobangebot Data Engineer - Business Intelligence / IT Beratung / SAP ERP / ABAP (m/w/d) klingt vielversprechend?</p><br><p>Bei unserem Partner <strong>Workwise</strong> ist eine Bewerbung f\u00fcr diesen Job <strong>in nur wenigen Minuten</strong> und <strong>ohne Anschreiben</strong> m\u00f6glich. Anschlie\u00dfend kann der Status der Bewerbung live verfolgt werden. Wir freuen wir uns auf eine <strong>Bewerbung \u00fcber Workwise</strong>.</p><br><p>Mehr Informationen zu uns und unseren Jobangeboten findet man auf unserem Unternehmensprofil bei Workwise.</p><br>"
  },
  {
    "id": 152,
    "title": "Principal Data Scientist - Machine Learning (f/m/d)",
    "company": "Almedia",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Data Science, Cloud, A/B testing",
    "posted_at": "2024-06-14",
    "is_remote": "False",
    "snippet_fragments": " 6 years of work experience, with at least 4 years of industry experience in developing machine-learning models, and ideally leading projects and small teams.,  Expertise in building, deploying, measuring, and maintaining machine learning models to address real-world problems, Strong statistical knowledge (A/B tests, probability, regression), A combination of Python, SQL, and cloud experience is essential, Excellent communication skills, with the ability to present complex findings in a clear and concise manner, Preference for candidates with backgrounds in ad tech",
    "description": "<p>Almedia helps leading brands in the digital space to acquire new customers. Users can find and test the latest games, apps, and products for rewards via our platforms.</p><br><p>With more than 20 million users since our launch in 2020, Almedia's Freecash.com is one of the fastest-growing providers and a leader in our industry. Our mission is to provide a win-win experience for both users and advertisers.</p><br><p>We are looking for a Principal Data Scientist to join our rapidly growing team in Berlin.</p><br><p><strong>Responsibilities:</strong></p><ul><li>Lead the establishment of the organization's data science discipline and take ownership of the company's data science strategy.</li><li>Identify high-value ML business opportunities and work with both business and technical stakeholders to realize business benefit.</li><li>Deliver and deploy end-to-end machine-learning models, build measurement plans, learn and iterate to drive results.</li><li>Apply a solid statistical mindset and best practices, in the process of model development, deployment, and evolution.</li><li>Deeply understand the data and customer and business problems, in order to more closely align machine-learning model objectives and develop the best features and models to predict them.</li><li>Collaborate effectively with cross-functional teams, including product managers, engineers, business developers, and user acquisition channel managers.</li></ul><p><strong>Requirements:</strong></p><ul><li>6+ years of work experience, with at least 4 years of industry experience in developing machine-learning models, and ideally leading projects and small teams.</li><li>Expertise in building, deploying, measuring, and maintaining machine learning models to address real-world problems.</li><li>Strong statistical knowledge (A/B tests, probability, regression).</li><li>A combination of Python, SQL, and cloud experience is essential.</li><li>Excellent communication skills, with the ability to present complex findings in a clear and concise manner. Preference for candidates with backgrounds in ad tech, gaming, or marketing.</li></ul><p><strong>Benefits:</strong></p><ul><li>An opportunity to work in an innovative, high-growth startup that has been profitable from day one.</li><li>A fast-paced and inclusive work environment in a team of highly motivated professionals.</li><li>Continuous learning and development opportunities.</li><li>Flexible work arrangements and a modern office space in the heart of Berlin.</li><li>Work from abroad policy</li></ul><p>Almedia is an equal opportunity employer, we embrace and celebrate diversity and encourage individuals from all backgrounds to apply.</p><br>"
  },
  {
    "id": 153,
    "title": "Data Engineer (d/m/w)",
    "company": "Toll Collect GmbH",
    "locations": "Berlin",
    "skills": "SQL, Mathematik, Linux, Cognos, PL/SQL, Windows",
    "posted_at": "2024-06-14",
    "is_remote": "False",
    "snippet_fragments": "     Sie verf\u00fcgt \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL),      Sie haben abgeschlossenes Studium in der Mathematik,      Sie haben Berufserfahrung im Bereich Data Engineering,     Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung,      Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung,  Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet,      Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung,     Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung, Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu, Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen, Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt",
    "description": "<p>Referenznummer: 20728</p><br><p>Ihre Aufgaben:</p><ul><li>Sie verantworten die Strukturierung und Weiterentwicklung von Datenmodellen und Datenfl\u00fcssen sowie der zugeh\u00f6rigen IT-gest\u00fctzten Prozesse</li><li>Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit</li><li>Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten</li><li>Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen</li><li>Sie arbeiten bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit, bringen eigene Ideen ein und setzen diese um</li><li>Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen<br> Ihr Profil</li><li>Sie haben Erfahrungen IBM Infosphere Datastage und IBM Cognos Analytics</li><li>Sie verf\u00fcgt \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL).\uf03c Sie Beherrscht einwandfrei den Umgang mit Windows und Linux</li><li>Sie haben abgeschlossenes Studium in der Mathematik, Informatik oder in vergleichbaren Studieng\u00e4ngen</li><li>Sie haben Berufserfahrung im Bereich Data Engineering<br> Was bieten wir</li><li>Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung</li><li>Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung</li><li>Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet</li><li>Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung</li></ul><p>Interessiert?</p><br><p>Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung. Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu. Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen. Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt.</p><br><p>Ihre Ansprechperson</p><br><p>Frau Silvia Barknecht, 030/74077-8214, karriere@toll-collect.de</p><br><p>Toll Collect GmbH * Personalmanagement * Linkstra\u00dfe 4, 10785 Berlin</p><br>"
  },
  {
    "id": 154,
    "title": "Data Engineer (d/m/w)",
    "company": "Toll Collect GmbH",
    "locations": "Berlin",
    "skills": "SQL, Mathematik, Linux, Cognos, PL/SQL, Windows",
    "posted_at": "2024-06-14",
    "is_remote": "False",
    "snippet_fragments": "     Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen,      Sie arbeiten bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit,      Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen ,     Sie haben Erfahrungen IBM Infosphere Datastage und IBM Cognos Analytics,      Sie verf\u00fcgt \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL),      Sie haben abgeschlossenes Studium in der Mathematik,      Sie haben Berufserfahrung im Bereich Data Engineering,     Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung,      Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung,  Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet,      Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung,     Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung, Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu, Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen, Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt",
    "description": "<p>Referenznummer: 20728</p><br><p>Ihre Aufgaben:</p><ul><li>Sie verantworten die Strukturierung und Weiterentwicklung von Datenmodellen und Datenfl\u00fcssen sowie der zugeh\u00f6rigen IT-gest\u00fctzten Prozesse</li><li>Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit</li><li>Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten</li><li>Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen</li><li>Sie arbeiten bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit, bringen eigene Ideen ein und setzen diese um</li><li>Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen<br> Ihr Profil</li><li>Sie haben Erfahrungen IBM Infosphere Datastage und IBM Cognos Analytics</li><li>Sie verf\u00fcgt \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL).\uf03c Sie Beherrscht einwandfrei den Umgang mit Windows und Linux</li><li>Sie haben abgeschlossenes Studium in der Mathematik, Informatik oder in vergleichbaren Studieng\u00e4ngen</li><li>Sie haben Berufserfahrung im Bereich Data Engineering<br> Was bieten wir</li><li>Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung</li><li>Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung</li><li>Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet</li><li>Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung</li></ul><p>Interessiert?</p><br><p>Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung. Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu. Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen. Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt.</p><br><p>Ihre Ansprechperson</p><br><p>Frau Silvia Barknecht, 030/74077-8214, karriere@toll-collect.de</p><br><p>Toll Collect GmbH * Personalmanagement * Linkstra\u00dfe 4, 10785 Berlin</p><br>"
  },
  {
    "id": 155,
    "title": "Data Engineer (m/w/d)",
    "company": "Randstad Deutschland",
    "locations": "Berlin",
    "skills": "SQL, Elektrotechnik",
    "posted_at": "2024-06-14",
    "is_remote": "False",
    "snippet_fragments": "  Nutzung der Randstad App (Urlaubsantr\u00e4ge online,   Verantwortung f\u00fcr die Datenmodellerstellung f\u00fcr ein neues Netzleitsystem ,   Abgeschlossenen Hoch- oder Fachhochschulstudium in Elektrotechnik bzw,   Erfahrung mit der Erstellung und Pflege von Datenmodellen in Netzleitsystemen ",
    "description": "<p>Von Aachen bis Zwickau ist eines bei Randstad immer gleich: Sie werden in jeder unserer \u00fcber 500 Niederlassungen mit offenen Armen empfangen! So auch in <strong>Berlin</strong>: Hier m\u00f6chte unser Gesch\u00e4ftspartner, ein <strong>Energieunternehmen</strong>, sein Team verst\u00e4rken und sucht aktuell einen <strong>Dateningenieur</strong>. Bewerben Sie sich online oder kontaktieren Sie uns per E-Mail oder telefonisch. Bewerbungen von Menschen mit Handicap sind uns selbstverst\u00e4ndlich willkommen.</p><br><p><strong>DAS D\u00dcRFEN SIE ERWARTEN</strong></p><ul><li>Leistungsgerechte Verg\u00fctung gem\u00e4\u00df Tarifvertrag Zeitarbeit der BAP/DGB Tarifgemeinschaft</li><li>Interessenvertretung durch einen fl\u00e4chendeckenden Betriebsrat</li><li>Ein gro\u00dfes Angebot an Mitarbeiterverg\u00fcnstigungen</li><li>Nutzung der Randstad App (Urlaubsantr\u00e4ge online, Abrechnung jederzeit einsehbar und vieles mehr)</li><li>Kostenlose arbeitsmedizinische Vorsorge &amp; Beratung</li></ul><p><strong>IHRE AUFGABEN</strong></p><ul><li>Verantwortung f\u00fcr die Datenmodellerstellung f\u00fcr ein neues Netzleitsystem</li><li>Betreuung der Import- und Exportschnittstellen</li><li>Bearbeitung und Behebung von Softwarefehler</li><li>Zusammenarbeit mit dem Lieferanten</li><li>\u00dcberpr\u00fcfung und Aktualisierung der SCADA-Informationen</li><li>Erweiterungen und Ver\u00e4nderungen des Stromnetzes</li></ul><p><strong>UNSERE ANFORDERUNGEN</strong></p><ul><li>Abgeschlossenen Hoch- oder Fachhochschulstudium in Elektrotechnik bzw. einer vergleichbaren Fachrichtung</li><li>Erfahrung mit der Erstellung und Pflege von Datenmodellen in Netzleitsystemen</li><li>Gute Kenntnisse \u00fcber den Aufbau und den Betrieb elektrischer Verteilungsnetze</li><li>Kenntnisse \u00fcber die Erstellung von Auswertungen und Berichten mit SQL und Erfahrung in Projekten zur IT-Applikationsentwicklung.</li><li>Gute Englischkenntnisse in Wort und Schrift</li><li>Zuverl\u00e4ssige und selbstst\u00e4ndige Arbeitsweise</li></ul><br>"
  },
  {
    "id": 156,
    "title": "Senior Data Engineer",
    "company": "Xcede",
    "locations": "Berlin",
    "skills": "Python, Machine Learning, Linux, Airflow, Big Data, Agile, Continuous Integration, Docker, Kubernetes, Scala, Spark",
    "posted_at": "2024-06-13",
    "is_remote": "False",
    "snippet_fragments": "   Are you looking to join one of the most established,    This corporate giant Based in Berlin with over 20,000 employees with cross-functional data teams combined with state-of-the-art machine learning techniques, The ideal candidate would be passionate with a love of creativity and always looking to implement ideas to overcome business challenges, You would work in agile project teams on a variety of use cases such as image recognition",
    "description": "<p><strong>SENIOR DATA ENGINEER</strong></p><br><p>Location:</p><br><p>Berlin</p><br><p>Salary:</p><br><p>Up to \u20ac90000.00 per annum</p><br><p>Job Type:</p><br><p>Permanent</p><br><p>Date Posted:</p><br><p>about 7 hours ago</p><br><p>Expiry Date:</p><br><p>28/07/2024</p><br><p>Job Ref:</p><br><p>BBBH111042_1718272181</p><br><p>Start Date:</p><br><p>13/06/2024</p><br><p>Contact:</p><br><p>Mitchell Palmer</p><br><p>Contact Email:</p><br><p>mitchell.palmer@xcede.de</p><br><p>Specialism:</p><br><p>InternalData Engineering</p><br><p>Are you looking to join one of the most established, dynamic fashion companies in the world? Then this is for <strong>YOU!</strong></p><br><p>This corporate giant Based in Berlin with over 20,000 employees with cross-functional data teams combined with state-of-the-art machine learning techniques. The ideal candidate would be passionate with a love of creativity and always looking to implement ideas to overcome business challenges. You would work in agile project teams on a variety of use cases such as image recognition, logistics and pricing.</p><br><p>Tech stack &amp; Requirements:</p><ul><li><br><strong>Master's Degree</strong> in Computer Science or equivalent</li><li>5 Years of working experience as a data engineer or similar position</li><li>Experience with Big Data Processing and Data Storage e.g. <strong>Spark</strong> .</li><li>Ability to write efficient, well-tested code with a keen eye on scalability and maintainability in <strong>Python</strong> . <strong>Airflow</strong> and Scala experience is a plus.</li><li>Experience with <strong>Docker</strong> , <strong>Kubernetes</strong> and usage of continuous integration &amp; deployment is a plus</li><li>Good <strong>Linux</strong> knowledge</li><li>You are a relationship builder and strong communicator with a hands-on mentality</li><li><br><strong>Fluent English</strong> is a must-have</li></ul><p>A range of benefits are included along with <strong>relocation</strong> and <strong>market leading salary package</strong> .</p><br><p>Contact: mitchell.palmer@xcede.de</p><br>"
  },
  {
    "id": 157,
    "title": "Data Scientist Fraud Prevention (m/w/d)",
    "company": "dkb",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Mathematik, Data Science, AWS, Viya, Git, SAS, Physik",
    "posted_at": "2024-06-13",
    "is_remote": "False",
    "snippet_fragments": "",
    "description": "<p><strong>Data Scientist Fraud Prevention (m/w/d)</strong></p><br><p><strong>DKB AG</strong></p><br><p><strong>Standort: Berlin</strong></p><br><p><strong>befristet f\u00fcr ein Jahr</strong></p><br><p><strong>Teil- &amp; Vollzeit m\u00f6glich</strong></p><br><p><strong>ab sofort</strong></p><br><p><strong>DEIN PROFIL</strong></p><ul><li>Ein abgeschlossenes Studium der Mathematik, Physik, (Wirtschafts-)Informatik oder eines vergleichbaren quantitativen Studiengangs hast du in der Tasche</li><li>Seit mind. 2 Jahren setzt du Machine Learning Methoden in einer cloudbasierten Infrastruktur, idealerweise in SAS Viya, ein</li><li>Die Mehrwerte deiner Data Science Projekte kannst du sowohl den fachlichen als auch technischen Stakeholder*innen \u00fcberzeugend r\u00fcberbringen</li><li>Mit Python, SQL, AWS, GIT und idealerweise SAS kennst du dich bestens aus</li><li>Neue Ideen selbstst\u00e4ndig und eigenverantwortlich umzusetzen ist f\u00fcr dich selbstverst\u00e4ndlich</li></ul><p><strong>DEINE AUFGABEN</strong></p><ul><li>Du entwickelst leistungsf\u00e4hige Modelle, die unsere Kund*innen vor betr\u00fcgerischen Transaktionen sch\u00fctzen</li><li>Hierf\u00fcr analysierst du die unterschiedlichen Betrugsszenarien sowohl technisch wie auch fachlich</li><li>Du \u00fcbernimmst End-to-End-Verantwortung f\u00fcr die Entwicklung der Data Science Modelle vom Proof of Concept bis zum produktiven System</li><li>F\u00fcr deine Modelle erarbeitest du geeignete Testkonzepte, f\u00fchrst Tests durch und dokumentierst sie</li><li>Zusammen mit anderen Entwickler*innen bringst du unseren neuen cloud-basierten SAS Viya Toolstack voran</li><li>Deine Kenntnisse erweiterst du regelm\u00e4\u00dfig und setzt die jeweils besten verf\u00fcgbaren Methoden f\u00fcr die Modellentwicklung ein</li></ul><p>Die DKB steht f\u00fcr Vielfalt und Chancengerechtigkeit. Egal, woher du kommst, wie alt du bist, welches Geschlecht, welche Genderidentit\u00e4t, sexuelle Orientierung oder Religion du hast, ob mit oder ohne Behinderung - wir freuen uns auf deine Bewerbung!</p><br><p><strong>Deine Benefits und mehr</strong></p><br><p>Attraktive Verg\u00fctung</p><br><p>(tariflich oder</p><br><p>au\u00dfertariflich)</p><br><p>Flexibles und mobiles</p><br><p>Arbeiten - tempor\u00e4r auch</p><br><p>im EU-Ausland</p><br><p>Du hast die Wahl: Sodexo</p><br><p>Benefits Pass, Jobticket</p><br><p>oder Jobrad</p><br><p>Moderne Technik-</p><br><p>ausstattung und Tool</p><br><p>Stack.</p><br><p>Individuelle Qualifi-</p><br><p>zierungsm\u00f6glichkeiten</p><br><p>Duz-Kultur und kein</p><br><p>Dresscode</p><br><p>Externe</p><br><p>Mitarbeitenden-</p><br><p>beratung</p><br><p>Angebote zum</p><br><p>Gesundbleiben</p><br><p>Weitere Extras wie z.B.</p><br><p>betriebliche Altersvorsorge</p><br><p>und Versicherungsschutz</p><br><p><strong>Immer f\u00fcr dich ansprechbar</strong></p><br><p>Ute Dietzel</p><br><p>Expertise Lead</p><br><p>recruiting@dkb.de</p><br><p>Deutsche Kreditbank AG</p><br><p>Du m\u00f6chtest mehr zur DKB erfahren?</p><br><p>Dann schau auf unserer Karriereseite vorbei.</p><br>"
  },
  {
    "id": 158,
    "title": "Working Student Software Engineer (Data Scraping) (f/m/d)",
    "company": "Almedia",
    "locations": "Berlin",
    "skills": "Python, SQL, JavaScript, Database Design, Web Scraping",
    "posted_at": "2024-06-13",
    "is_remote": "False",
    "snippet_fragments": "  Generate regular reports and insights from the scraped data to support research and development projects and business decisions,    Work closely with the research and development teams to understand data requirements and provide actionable insights from the collected data, Maintain documentation for scraping scripts, processes, and data sources for knowledge sharing and future reference,   Adhere to legal and ethical guidelines regarding web scraping and data privacy,    Currently enrolled in a German university course,   Experience with web scraping and data extraction,   Proficiency in programming languages used in web scraping such as Python and JavaScript,   Knowledge of relational Databases and SQL,   Attention to detail and ability to ensure data accuracy,   An opportunity to work in an innovative",
    "description": "<p>Almedia helps leading brands in the digital space to acquire new customers. Users can find and test the latest games, apps, and products for rewards via our platforms.</p><br><p>With more than 20 million users since our launch in 2020, Almedia's Freecash.com is one of the fastest-growing providers and a leader in our industry. Our mission is to provide a win-win experience for both users and advertisers.</p><br><p>This year, we want to invest even further and scale our number of members in the Data Team at Almedia. For this, we are looking for a Working Student Software Engineer (Data Scraping) to join our rapidly growing team in Berlin.</p><br><p><strong>Responsibilities</strong>:</p><ul><li>Use web scraping tools and techniques to gather data from websites.</li><li>Develop and maintain web scraping scripts to extract and transform data into usable formats using SQL, and ensure data accuracy and completeness by implementing data validation and cleaning processes.</li><li>Continuously monitor target websites and online resources for updates and changes to adapt scraping scripts as needed.</li><li>Generate regular reports and insights from the scraped data to support research and development projects and business decisions.</li><li>Work closely with the research and development teams to understand data requirements and provide actionable insights from the collected data.</li><li>Maintain documentation for scraping scripts, processes, and data sources for knowledge sharing and future reference.</li><li>Adhere to legal and ethical guidelines regarding web scraping and data privacy.</li></ul><p><strong>Requirements</strong>:</p><ul><li>Currently enrolled in a German university course.</li><li>Experience with web scraping and data extraction.</li><li>Proficiency in programming languages used in web scraping such as Python and JavaScript.</li><li>Knowledge of relational Databases and SQL.</li><li>Strong analytical and problem-solving skills.</li><li>Attention to detail and ability to ensure data accuracy.</li><li>Strong communication and teamwork skills.</li></ul><p><strong>Benefits:</strong></p><ul><li>An opportunity to work in an innovative, high-growth startup that has been profitable from day one.</li><li>A fast-paced and inclusive work environment in a team of highly motivated professionals.</li><li>Continuous learning and development opportunities.</li><li>Flexible work arrangements and a modern office space in the heart of Berlin.</li><li>Work from abroad policy</li></ul><p>Almedia is an equal opportunity employer, we embrace and celebrate diversity and encourage individuals from all backgrounds to apply.</p><br>"
  },
  {
    "id": 159,
    "title": "Senior Data Engineer (f/m/d)",
    "company": "BMG RIGHTS MANAGEMENT GmbH - Corporate",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Cloud, Data Pipelines, GCP, AI, Business Intelligence, Airflow, Big Data, BigQuery, Swift, TensorFlow, Tableau, Looker, Dataproc, Data Visualization, PyTorch, Scripting Language, Data Lake, Cloud Security, Spark, Architektur",
    "posted_at": "2024-06-12",
    "is_remote": "False",
    "snippet_fragments": "   Bachelor's degree in computer science or equivalent technical education and work experience,  Hands-on experience in data engineering, particularly in the design and operation of data lakes, with a deep understanding of database systems and big data processing technologies, preferably on GCP,    Advanced knowledge of SQL for data manipulation and analysis, Experience with Airflow, Spark, dbt, BigQuery, and data visualization tools like Looker or Tableau,    Proven ability to maintain strong relationships with outsourced development teams, Capable of clear communication across diverse teams,    Demonstrated ability to bring new ideas to enhance BMG's data-driven decision-making and operational processes,    Commitment to staying updated with the latest developments in data engineering,   It's also a plus if you have,    A modern office in the heart of Berlin and flexible options for remote work,    Numerous benefits such as a free BVG job ticket,    Ongoing training opportunities on our internal platforms BMG Campus and Bertelsmann University,    Long-term career opportunities for all employees,    A collaborative work environment with an open,    Our unique corporate culture based on strong values and mutual support that make us a great team",
    "description": "<p>Founded in 2008, BMG has become the fourth-largest music publisher worldwide. Our success and competitive edge are rooted in our founding values of fairness, transparency, and service. Our mission is clear: to empower artists and songwriters to maximize the potential of their songs and recordings in the digital era.</p><br><p><strong>What you'll be doing</strong></p><ul><li>Develop and Maintain Data Pipelines: Design, develop, and maintain advanced data pipelines using Airflow and dbt, focusing on data ingestion and transformation, enabling analytics and business intelligence capabilities, particularly for Marketing and Sales Analytics</li><li>Implement Data Quality Monitoring: Establish data quality monitoring systems using Monte Carlo Data, dbt, and BigQuery to ensure data accuracy and consistency, fostering user and customer trust</li><li>Manage Data Platform: Oversee the data platform, including BigQuery, GCP Dataproc, Looker, Monte Carlo Data, and dbt, ensuring a reliable, state-of-the-art data infrastructure</li><li>Optimize Technical Infrastructure: Construct and continuously enhance a compliant technical infrastructure for analytics and AI, embedding ethical data practices as a core value</li><li>Optimize Cloud Costs: Identify and implement optimization opportunities to enhance cloud cost efficiency</li><li>Bridge Technical and Operational Domains: Translate business requirements into scalable technical architecture, bridging the gap between technical and operational domains</li><li>Collaborate and Educate: Work with other data engineers to improve existing solutions and lead global training initiatives to enhance user proficiency on our data stack and in the usage of the build data pipelines</li><li>Engage with Emerging Technologies: Proactively assess and integrate emerging technologies and tool, collaborate with industry experts to ensure state of the art data operations</li><li>Foster Innovation: Lead academic collaborations and organize hackathons to foster a culture of innovation</li><li>Internal Data Applications Knowledge: In-depth knowledge of BMG's internal data applications, including royalty processing engines and revenue assurance data pipelines</li></ul><p><strong>What you bring</strong></p><ul><li>Bachelor's degree in computer science or equivalent technical education and work experience, a master's degree is preferred</li><li>Hands-on experience in data engineering, particularly in the design and operation of data lakes, with a deep understanding of database systems and big data processing technologies, preferably on GCP</li><li>Advanced knowledge of SQL for data manipulation and analysis, and proficiency in Python for scripting and automation. Experience with Airflow, Spark, dbt, BigQuery, and data visualization tools like Looker or Tableau</li><li>Proven ability to maintain strong relationships with outsourced development teams, ensuring efficient communication and swift resolution of challenges. Capable of clear communication across diverse teams</li><li>Demonstrated ability to bring new ideas to enhance BMG's data-driven decision-making and operational processes</li><li>Commitment to staying updated with the latest developments in data engineering, machine learning, and relevant legal and compliance updates</li></ul><p><strong>It's also a plus if you have</strong></p><ul><li>ML Engineering: Experience with ML frameworks like TensorFlow or PyTorch and the ability to integrate and deploy ML models within data pipelines in cloud infrastructure</li><li>Cloud Security and Compliance: Advanced understanding of cloud security practices and data compliance protocols</li></ul><p><strong>What We offer</strong></p><ul><li>A modern office in the heart of Berlin and flexible options for remote work</li><li>Numerous benefits such as a free BVG job ticket, a reduced-price membership for Urban Sports, discounts for Bertelsmann employees etc.</li><li>Ongoing training opportunities on our internal platforms BMG Campus and Bertelsmann University</li><li>Long-term career opportunities for all employees</li><li>A collaborative work environment with an open, appreciative community of people who all share the same passion for working with artists and songwriters</li><li>Our unique corporate culture based on strong values and mutual support that make us a great team</li></ul><p><strong>This Is Us</strong></p><br><p>As the great Kurt Cobain once said, &quot;Come as you are.&quot; BMG is committed to providing equal employment opportunities for all employees. We value diversity in all forms. Equal opportunity is deeply rooted in our core value of fairness, and we are committed to creating a truly inclusive work environment where everyone can thrive. If you're good at what you do, come as you are! Whether you're an experienced professional or just starting out, we welcome you to join our team.</p><br><p>All applicants to BMG are treated equally - regardless of age, disability, gender identity or expression, sexual orientation, marital status, pregnancy or parenthood, ethnic origin, colour, nationality, religion or belief.</p><br><p>(BMG is publishing Kurt Cobain's catalog, including the 1992 single 'Come As You Are.')</p><br><p><strong>Unternehmen:</strong> BMG RIGHTS MANAGEMENT GmbH - Corporate</p><br><p><strong>Land:</strong> Germany</p><br><p><strong>Region:</strong> Berlin</p><br><p><strong>Stadt:</strong> Berlin</p><br><p><strong>Postleitzahl:</strong> 10117</p><br><p><strong>Job ID:</strong> 271025</p><br>"
  },
  {
    "id": 160,
    "title": "Lead Data Engineer (f/m/d)",
    "company": "Almedia",
    "locations": "Berlin",
    "skills": "Python, SQL, Data Science, Data Analysis, Data Pipelines, GCP, Data Warehouse, BigQuery, APIs, Orchestration, Scripting Language, Data Lake",
    "posted_at": "2024-06-12",
    "is_remote": "False",
    "snippet_fragments": "  Collaborate across teams to integrate data-driven insights into daily operations,   Handle the operational aspects of the data warehouse,    Experience in data engineering (4 years),    Expertise in SQL and experience with scripting languages (e,   Experience in building and optimising data pipelines,   Knowledge and competence within Data Science & Data Analytics,   Strong analytical skills related to working with unstructured datasets,   Ability to lead projects and collaborate effectively with diverse teams",
    "description": "<p>Almedia helps leading brands in the digital space to acquire new customers. Users can find and test the latest games, apps, and products for rewards via our platforms.</p><br><p>With more than 20 million users since our launch in 2020, Almedia's Freecash.com is one of the fastest-growing providers and a leader in our industry. Our mission is to provide a win-win experience for both users and advertisers.</p><br><p>We are seeking a a Lead Data Engineer to spearhead the development of our data warehouse in the Google Cloud Platform (GCP). This is a unique opportunity to join a forward-thinking company that is dedicated to revolutionising the way brands engage with their audience.</p><br><p>Collaborating with data scientists, analysts, and backend developers, you will drive the evolution of our data-driven culture, ensuring our infrastructure scales with our growth.</p><br><p><strong>Responsibilities:</strong></p><ul><li>Architect and maintain our BigQuery data warehouse and data lakes, aligning with both current and future business needs.</li><li>Manage the ingestion of data from diverse sources, optimizing for efficiency and reliability.</li><li>Lead complex data transformations and implement orchestration tools, turning raw data into refined datasets ready for analysis and operational use.</li><li>Create and maintain APIs for internal use, facilitating real-time data interactions that support critical business processes.</li><li>Implement robust data cataloging and quality frameworks, ensuring the warehouse remains a trusted source for insightful decision-making.</li><li>Provide guidance to junior engineers, promoting a culture of excellence in data management practices.</li><li>Collaborate across teams to integrate data-driven insights into daily operations.</li><li>Handle the operational aspects of the data warehouse, including performance tuning, disaster recovery planning, and capacity management, to support scalability and reliability.</li></ul><p><strong>Requirements:</strong></p><ul><li>Experience in data engineering (4 years+), with a strong understanding of data warehousing concepts.</li><li>Expertise in SQL and experience with scripting languages (e.g. Python).</li><li>Experience in building and optimising data pipelines, architectures, and data sets.</li><li>Knowledge and competence within Data Science &amp; Data Analytics.</li><li>Strong analytical skills related to working with unstructured datasets.</li><li>Ability to lead projects and collaborate effectively with diverse teams.</li><li>Excellent problem-solving and communication skills.</li></ul><p><strong>Benefits:</strong></p><ul><li>An opportunity to work in an innovative, high-growth startup that has been profitable from day one.</li><li>A fast-paced and inclusive work environment in a team of highly motivated professionals.</li><li>Continuous learning and development opportunities.</li><li>Flexible work arrangements and a modern office space in the heart of Berlin.</li><li>Work from abroad policy</li></ul><p>Almedia is an equal opportunity employer, we embrace and celebrate diversity and encourage individuals from all backgrounds to apply.</p><br>"
  },
  {
    "id": 161,
    "title": "Senior Software Engineer (Data Movement)",
    "company": "SumUp",
    "locations": "Berlin",
    "skills": "Python, Kafka, Grafana, Prometheus, Encryption, Go",
    "posted_at": "2024-06-12",
    "is_remote": "False",
    "snippet_fragments": "  7 years of experience as a Software Engineer and previous experience in maintaining critical data infrastructure ,   Comfortable with at least one of our other centre-of-gravity languages (Go,   Familiarity with our observability stack (Grafana,   Experience in Implementing Site Reliability Engineer (SRE) principles in daily work ,   Product-focused mindset with a strong emphasis on creating impactful solutions , Proven mentorship experience, guiding and developing other team members, Proactive in creating documentation, Request For Comments (RFC), Solutions Designs,   Opportunity to work with SumUppers globally on large-scale fintech products used by millions of businesses worldwide,   A dedicated annual L&D budget of 2,000 for attending conferences and/or advancing your career through further education,   A corporate pension scheme where we match up to 20% of your contributions ,   \ufe0f Numerous other benefits such as Urban Sports Club subsidy,   SumUp is a leading financial technology company, We're the financial partner of choice for more than 4 million merchants in over 35 markets, We collectively build, plan and fine-tune the technology that drives SumUp and empowers small businesses around the world.,   We believe in the everyday hero, Those who have the courage to follow their passion and who have the strength and determination to realise their dreams",
    "description": "<p><strong>About the team:</strong></p><br><p>Join the Data Platform Team at SumUp and help build the future of data infrastructure! We're building next-gen data infrastructure to support millions of businesses. Our mission is to develop automated, scalable, and reusable tools for distributed domains.</p><br><p>Our team consists of three key subteams:</p><br><p><strong>Data Streaming</strong> - Ensures a reliable Kafka and streaming infrastructure.</p><br><p><strong>Data Movement</strong> - Manages data ingestion and extraction across various storages.</p><br><p><strong>Data Gateway</strong> - Provides storage and access layers for diverse data needs.</p><br><p><strong>What's next?</strong> We will be focussing on ensuring data consistency, quality and SLAs are being achieved and are looking for a Senior Software Engineer to support our <strong>Data Movement Team</strong>.</p><br><p><strong>What you'll do</strong></p><ul><li>Contribute in shaping a holistic data ingestion infrastructure, from automating secrets management, monitoring data SLAs to creating a self-healing data ingestions</li><li>Help maintain our current Capture Data Capture (CDC) infrastructure based in Debezium</li><li>Support ongoing efforts on streamlining data encryption at scale</li><li>Collaborate with cross-functional teams to design, develop, and implement scalable and reliable solutions</li><li>Troubleshoot and resolve complex issues, ensuring the stability of critical data infrastructure</li></ul><p><strong>You'll be a great fit for this role if you have:</strong></p><ul><li>7+ years of experience as a Software Engineer and previous experience in maintaining critical data infrastructure</li><li>Comfortable with at least one of our other centre-of-gravity languages (Go, Python)</li><li>Familiarity with our observability stack (Grafana, Prometheus, Honeycomb)</li><li>Experience in Implementing Site Reliability Engineer (SRE) principles in daily work</li><li>Product-focused mindset with a strong emphasis on creating impactful solutions</li><li>Proven mentorship experience, guiding and developing other team members</li><li>Proactive in creating documentation, Request For Comments (RFC), Solutions Designs</li></ul><p><strong>Why you should join SumUp:</strong></p><br><p>Opportunity to work with SumUppers globally on large-scale fintech products used by millions of businesses worldwide, from our Berlin office. This involves an office-first setup.</p><br><p>Commitment to Diversity and Inclusion: Be part of a workplace that values and promotes diversity, fostering an inclusive environment where everyone's perspectives are respected and embraced</p><br><p>A dedicated annual L&amp;D budget of \u20ac2,000 for attending conferences and/or advancing your career through further education.</p><br><p>Enrolment onto our VSOP program: You will own a stake in SumUp's future success</p><br><p>A corporate pension scheme where we match up to 20% of your contributions</p><br><p>30 Days Sabbatical: Enjoy the unique opportunity to take a well-deserved break with our 30 days sabbatical benefit after completing 3 years of employment with SumUp.</p><br><p>Referral Bonus: Earn additional rewards by referring talented individuals to join the SumUp team.</p><ul><li>\ufe0f Numerous other benefits such as Urban Sports Club subsidy, Kita placement assistance, relocation assistance, subsidised office lunches.</li></ul><p><strong>About us:</strong></p><br><p>SumUp is a leading financial technology company, founded in 2012 with the goal of empowering small businesses around the globe. We're the financial partner of choice for more than 4 million merchants in over 35 markets. We collectively build, plan and fine-tune the technology that drives SumUp and empowers small businesses around the world.</p><br><p>We believe in the everyday hero. Those who have the courage to follow their passion and who have the strength and determination to realise their dreams. Small business owners are at the heart of all we do, so we're creating powerful, easy-to-use financial solutions to help them run their business. With a founders mentality and a 'team-first attitude' our diverse teams across Europe, South America, and the United States work together to ensure that small business owners can be successful doing what they love.</p><br><p>SumUp is an Equal Employment Opportunity employer that proudly pursues and hires a diverse workforce. SumUp does not make hiring or employment decisions on the basis of race, colour, religion or religious belief, ethnic or national origin, nationality, sex, gender, gender identity, sexual orientation, disability, age or any other basis protected by applicable laws or prohibited by Company policy. SumUp also strives for a healthy and safe workplace and strictly prohibits harassment of any kind.</p><br><p><strong>Job Application Tip</strong></p><br><p>We recognise that candidates feel they need to meet 100% of the job criteria in order to apply for a job. Please note that this is only a guide. If you don't tick every box, it's ok too because it means you have room to learn and develop your career at SumUp.</p><br>"
  },
  {
    "id": 162,
    "title": "Data Engineer (m/w/d)",
    "company": "dentolo Deutschland GmbH",
    "locations": "Berlin",
    "skills": "Python, SQL, AWS, Business Intelligence, Airflow, Agile, Terraform, Version Control, Data Structures, Git, Mac, Windows",
    "posted_at": "2024-06-11",
    "is_remote": "False",
    "snippet_fragments": " 2 years of experience in data engineering or business intelligence,  At least one year of experience with Terraform and AWS,  At least one year of experience with Airflow, Experience with writing complex queries and optimizing their performance, Handling of complex data structures, preferably with dbt.,  You have experience with Python and code versioning (Git),  We would love it if you already worked with Airbyte,  You have a strong interest in business-related topics and can have proven that you can connect the data you work with to real-world operative challenges and business questions posed,  Excellent communication skills and strong analytical thinking,  You have an eye for details and can break down complex problems,  You have great spoken and written English,  You are living in Berlin or planning to relocate here,  One of Europes fastest growing Insurtechs,  High level of collaboration and autonomy, Cutting-edge technologies, agile development practices, and a product-focused environment that tackles demanding technical and scaling challenges.,  6th floor office in the heart of Berlin (Mitte/ Prenzlauer Berg) with beautiful views over the city,  Quarterly team budget for various events,  Annual learning budget for your personal development,  Flexible work arrangements according to your needs,  Vacation entitlement starting with 28 days in your first year,  Free dental or pet insurance - to experience our products yourself,  Independent booking of monthly coaching sessions with nilo,  Transportation benefit - you can choose between a free Swapfiets bike or a BVG eco-ticket (with a dentolo allowance),  Work up to 60 days from outside of Germany! ,  Free choice of a Windows or Mac computer,  Sounds like the perfect job for you? , We look forward to receiving your application and getting to know you! ",
    "description": "<p>At dentolo, we don't just offer insurance, we create tailored solutions for individual customer needs.</p><br><p>Founded in 2015, the Insurtech develops and operates holistic insurance solutions that are affordable, understandable, and accessible to everyone. In doing so, we support our customers with prevention, the best customer support and relieve them of the worries about spontaneously arising costs or painful treatments for themselves or their pets.</p><br><p>The dentolo and petolo solutions offer everything from basic to full protection, so that our customers and their loved ones are covered in case of emergency and can enjoy a more carefree life. Thanks to in-depth discussions with customers, teams and market specialists, we are able to expand and improve our expertise in the field of dental &amp; pet health on a daily basis to provide an all-round service to our customers. The culture of dentolo is based on a shared vision, the joy of dynamic processes and courageous actions, whereby team spirit and the wishes of our customers always come first.</p><br><p>Currently, we are looking for a Data Engineer to join our Data Team. Your work will range from customer-focused development to workflow automation and internal tools to help our team and customers have a seamless experience.</p><br><p><strong>Your Role in our team:</strong></p><ul><li>You will take over responsibility for setting up a modern data infrastructure and migrating step by step from our current infrastructure to the new one.</li><li>This includes the setup of the environment in AWS (Airbyte, Airflow, dbt) with Terraform as well as the configuration of the three tools named.</li><li>You will support our Analytics Engineer / Data Analyst by providing them with the data they need by integration of data sources and writing raw data transformation in dbt.</li><li>You work together with our Engineering team to adapt infrastructure best practices.</li><li>You collaborate with our different teams (e.g. Product, Marketing, Sales, Operations) for the integration of domain related data sources.</li><li>You use your knowledge and ideas to contribute to our overall data strategy, especially with focus on our future data setup.</li><li>You initiate and take over your own projects in fields of your interest.</li><li>You use your passion for data to foster our dentolo data culture.<br><strong>What you need to be successful:</strong></li><li>2+ years of experience in data engineering or business intelligence.</li><li>At least one year of experience with Terraform and AWS.</li><li>At least one year of experience with Airflow.</li><li>Advanced knowledge of SQL. Experience with writing complex queries and optimizing their performance. Handling of complex data structures, preferably with dbt.</li><li>You have experience with Python and code versioning (Git).</li><li>We would love it if you already worked with Airbyte.</li><li>You have a strong interest in business-related topics and can have proven that you can connect the data you work with to real-world operative challenges and business questions posed.</li><li>Excellent communication skills and strong analytical thinking.</li><li>You have an eye for details and can break down complex problems.</li><li>You have great spoken and written English.</li><li>You are living in Berlin or planning to relocate here, or come to the office regularly.<br> Why dentolo?</li><li>One of Europe's fastest growing Insurtechs, backed long-term by one of the largest insurance powerhouses worldwide.</li><li>High level of collaboration and autonomy, working in a group of international colleagues in a small to medium sized startup with a getting-things-done attitude.</li><li>Cutting-edge technologies, agile development practices, and a product-focused environment that tackles demanding technical and scaling challenges.</li><li>6th floor office in the heart of Berlin (Mitte/ Prenzlauer Berg) with beautiful views over the city.</li><li>Quarterly team budget for various events, you decide : )</li><li>Annual learning budget for your personal development.</li><li>Flexible work arrangements according to your needs.</li><li>Vacation entitlement starting with 28 days in your first year, accumulating 1 day with every 2 years of affiliation to the max. 30 days.</li><li>Free dental or pet insurance - to experience our products yourself.</li><li>Independent booking of monthly coaching sessions with nilo.health, our mental health tool.</li><li>Transportation benefit - you can choose between a free Swapfiets bike or a BVG eco-ticket (with a dentolo allowance).</li><li>Work up to 60 days from outside of Germany!</li><li>Free choice of a Windows or Mac computer.<br> Sounds like the perfect job for you?</li></ul><p>We look forward to receiving your application and getting to know you!</p><br><p>dentolo is an equal opportunity and diversity employer. We strive to create a friendly, safe, and welcoming environment for all our team members, regardless of ethnicity, gender, gender identity and expression, sexual orientation, limitations and talents of any kind, physical appearance, social background, marital status, age, or religion (or lack thereof).</p><br><p>When you apply, we focus solely on your experience and motivation. You decide what additional information you want to disclose (photo, marital status, religion, gender, nationality, etc.). We value and treat all applications equally.</p><br><p><strong>Contact:</strong></p><br><p>Valeriia Vasko</p><br><p>Tech Recruiter</p><br><p>vvasko@dentolo.de</p><br>"
  },
  {
    "id": 163,
    "title": "(Senior) Data Scientist \u2013 Credit Risk & Risk Models (f/m/x)",
    "company": "ING Deutschland",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Mathematik, Unsupervised Learning, Statistik, Linear Models",
    "posted_at": "2024-06-11",
    "is_remote": "False",
    "snippet_fragments": "Problem-solving, motivational and communicative skills paired with reliability and a hands-on work-approach, Fluent in English, both written and spoken; fluency in German is preferred, Company pension plan, capital-building offers, free Deutschlandticket & bicycle leasING, company restaurant,    Remote working depending on the position and department and in line with the company,    Personal budget for continuing education and development as well as health; plus, We believe in substance over style,   This describes you to a T? ,   Simply apply online - your resume is all we need to get to know you",
    "description": "<p>Your models make sure that our &quot;risky business&quot; is anything but? With your analytical way of thinking, you not only see through complex issues, you can also explain and evaluate them? Perfect! At ING, we place great value on team spirit, a productive working atmosphere and further training for our employees. Do you think this suits you? Then apply, your CV is all you need! Our team in the Centre of Expertise &quot;Credit Risk&quot; is looking forward to meeting you.</p><br><p><strong>Your Tasks</strong></p><ul><li>Using your data expertise, you develop new risk scorecards and improve existing ones for credit decisions, helping us to keep our risk low and the value for our customers high.</li><li>Naturally, you ensure diligently that our models comply with group policies and requirements at all stages of their lifecycle.</li><li>You also keep a keen eye on our models and their performance through monitoring, evaluation, and reporting, keep them on track with gap analysis, risk assessments and mitigation and maintain detailed model documentation so they stay accessible and comprehensible.</li><li>Thanks to your clear and concise communication skills, you work seamlessly in a team with other risk model functions and are a valued and informative point of contact for internal and external auditors as well as regulators regarding model-related inquiries.</li></ul><p><strong>Your Profile</strong></p><ul><li>Master's degree in statistics, economics, engineering, finance, mathematics or a related quantitative field; a PhD is an advantage</li><li>Professional experience in credit risk modelling / model validation in financial institutions</li><li>Practised with machine learning techniques including regression, classification, clustering and ensemble methods</li><li>Familiarity with both supervised and unsupervised learning approaches as well as practical experience in solving real-world problems using machine learning models</li><li>Know-how in model building (cleaning data, dependent variable selection, investigation and understanding, variable reduction &amp; grouping, bivariate analysis, logistic / linear model building, model validation)</li><li>Proficient in Python and other analytical tools (SQL, etc.)</li><li>Problem-solving, motivational and communicative skills paired with reliability and a hands-on work-approach</li><li>Fluent in English, both written and spoken; fluency in German is preferred</li></ul><p><strong>We offer many benefits</strong></p><ul><li>Company pension plan, capital-building offers, free Deutschlandticket &amp; bicycle leasING, company restaurant</li><li>Remote working depending on the position and department and in line with the company, regulatory and legal requirements; individualized work schedule models, sabbatical, subsidization of nursing &amp; childcare costs</li><li>Personal budget for continuing education and development as well as health; plus, a personal budget to set up your mobile working space</li></ul><p><strong>Ready for a new job?</strong></p><br><p>At ING we are colorful and diverse: different personalities with different perspectives - an international culture where we value and appreciate each other. We believe in substance over style, people instead of labels.</p><br><p>This describes you to a T?</p><br><p>Simply apply online - <strong>your resume is all we need to get to know you, a cover letter is optional!</strong></p><br><p>ABOUT COMPANY</p><br><p>ING Deutschland</p><br><p>Frankfurt am Main, Germany<br> 6000 Employees Retail Banking<br> ING Deutschland: Digital, agil und pers\u00f6nlich \u201eIhr seht ja gar nicht aus wie Bankerinnen und Banker&quot;, h\u00f6ren wir oft. Das liegt vielleicht daran, dass...</p><br>"
  },
  {
    "id": 164,
    "title": "Senior Data Engineer - Data Warehouse/Analytics (f/m/d)*",
    "company": "Parloa",
    "locations": "Berlin",
    "skills": "Python, SQL, Cloud, Data Pipelines, AI, Azure, Data Modeling, Data Warehouse, Kafka, Docker, Kubernetes, MongoDB, MySQL, Redis, Terraform, Version Control, SaaS, CD, Continuous Integration, Git",
    "posted_at": "2024-06-10",
    "is_remote": "False",
    "snippet_fragments": "  Work closely with stakeholders in Customer Success and Product to define requirements and build data models that serve their needs ,   7 years of experience as data engineer or analytics engineer,   Strong expertise with data modeling and implementing data pipelines , Expert proficiency in SQL, proficiency in Python, experience with version control (git) and CI/CD,   Experience in working with cloud data platforms ,   Track record of building data warehouses and data products in accordance with legal requirements ,   Experience implementing data quality and governance frameworks ,   Experience in leading medium-sized technical projects (3-9 months roadmap) ,   Strong spoken and written communication skills in English , Be part of a dynamic, driven team of 20 nationalities with flat hierarchies and collaborative company culture.,   Hybrid work environment - we believe in hiring the best talent, However, we love to build real connections and want to welcome everyone in the office on certain days.,   Training and development budget which can be used for conferences and attending development courses to ensure continuous professional growth, Flexible working hours, 28 vacation days and workation opportunities.,   Enjoy unlimited access to a variety of fitness,   Leverage exclusive offers with our corporate benefits portal, Regular team events, game nights, and other social activities.,   Is something missing here? Reach out and let's talk about what else you need for your ideal next growth opportunity,   Recruiter video call Hiring Manager Interview Challenge Technical Interview Meeting the team,    Join Parloa in revolutionizing customer communication with Artificial Intelligence! We're a leading Conversational AI platform collaborating with industry giants, Our mission is to create a comprehensive customer solution for businesses worldwide,    We were founded in 2017 in Berlin, By leveraging our cutting-edge conversational AI platform, We're committed to achieving this by combining top-notch technical engineering with innovative leadership and the belief that every single team member can have a massive impact on our future",
    "description": "<p><strong>YOUR MISSION</strong></p><br><p>As a Senior Data Engineer - Data Warehouse/Analytics (f/m/d)*, you will build data marts that power customer-facing data products. As one of the founding members of the data team, your work will have a pivotal impact on the organization. You will empower company-wide stakeholders to work effectively with data by building Parloa's data warehouse from scratch. The data models and data pipelines you build will help to transform the entire customer service industry leveraging data and AI.</p><br><p><strong>IN THIS ROLE YOU WILL:</strong></p><ul><li>Design and implement the data pipelines that power our customer-facing analytics product together with your cross-functional team</li><li>Take ownership of designing, building and improving the data warehouse for Parloa and setting standards and conventions to enable us to scale</li><li>Build and optimize data models for performance, cost and usability</li><li>Lead and execute technical projects end-to-end: understanding user requirements, systems and model design, proof of concept, implementation &amp; scaling, maintenance and support, continuous improvement</li><li>Work closely with stakeholders in Customer Success and Product to define requirements and build data models that serve their needs</li></ul><p><strong>Our</strong> <strong>Tech stack (Data):</strong> Microsoft Azure, Python, Kubernetes, Docker, Terraform, MongoDB, MySQL, Redis, Kafka (more technologies to be added as we build our data platform)</p><br><p><strong>WHAT YOU BRING TO THE TABLE:</strong></p><ul><li>7+ years of experience as data engineer or analytics engineer, if less: experience with building up data warehouses/data products from ground up</li><li>Strong expertise with data modeling and implementing data pipelines</li><li>Expert proficiency in SQL, proficiency in Python, experience with version control (git) and CI/CD</li><li>Experience in working with cloud data platforms</li><li>Track record of building data warehouses and data products in accordance with legal requirements</li><li>Experience implementing data quality and governance frameworks</li><li>Experience in leading medium-sized technical projects (3-9 months roadmap)</li><li>Strong spoken and written communication skills in English</li></ul><p><strong>WHAT'S IN IT FOR YOU?</strong></p><ul><li>Be part of a dynamic, driven team of +20 nationalities with flat hierarchies and collaborative company culture.</li><li>Hybrid work environment - we believe in hiring the best talent, no matter where they are based. However, we love to build real connections and want to welcome everyone in the office on certain days.</li><li>Attractive compensation package.</li><li>Training and development budget which can be used for conferences and attending development courses to ensure continuous professional growth.</li><li>Flexible working hours, 28 vacation days and workation opportunities.</li><li>Enjoy unlimited access to a variety of fitness, yoga, and leisure activities via Wellpass.</li><li>Leverage exclusive offers with our corporate benefits portal, giving you access to compelling deals from leading brands.</li><li>Regular team events, game nights, and other social activities.</li><li>And last but not least: a beautiful office with flair in the heart of Berlin with all the conveniences, such as adjustable desks, social area, fresh fruits, cereals and drinks.</li><li>Is something missing here? Reach out and let's talk about what else you need for your ideal next growth opportunity.</li></ul><p><strong>Your recruiting process at Parloa:</strong></p><br><p>Recruiter video call Hiring Manager Interview Challenge Technical Interview Meeting the team</p><br><p><strong>WHY PARLOA?</strong></p><br><p>Join Parloa in revolutionizing customer communication with Artificial Intelligence! We're a leading Conversational AI platform collaborating with industry giants, both as partners and clients. Our mission is to create a comprehensive customer solution for businesses worldwide, and we're committed to achieving this by having people and AI join forces.</p><br><p>We were founded in 2017 in Berlin, and since then we've become one of the most innovative SaaS companies in the market. By leveraging our cutting-edge conversational AI platform, we are enabling businesses to have meaningful conversations with their customers. We're committed to achieving this by combining top-notch technical engineering with innovative leadership and the belief that every single team member can have a massive impact on our future.</p><br><p>By joining Parloa, you'll have the opportunity to be part of a dynamic and innovative team that's revolutionizing an entire industry. We're passionate about growing together and creating opportunities for personal and professional development. With our recent 20 million Series A investment, we're expanding globally and looking for talented individuals to join us on this exciting journey.</p><br><p>Do you have questions about Parloa, the role, or our team before you apply? Please feel free to get in touch with our Hiring Team.</p><br><p>Parloa is committed to upholding the highest data protection standards for our clients' and employees' data. All our employees are instrumental in ensuring the utmost care, GDPR, and ISO compliance, including ISO 27001, in handling sensitive information.</p><ul><li><br><strong>We provide equal opportunities to all qualified applicants regardless race, gender, sexual orientation, age, religion, national origin, disability status, socioeconomic background and other characteristics.</strong><br></li></ul><br>"
  },
  {
    "id": 165,
    "title": "Marketing Data Scientist",
    "company": "N26",
    "locations": "Berlin",
    "skills": "Python, SQL, Machine Learning, Mathematik, Data Science, Data Analysis, AI, A/B testing, Algorithms, Statistik",
    "posted_at": "2024-06-10",
    "is_remote": "True",
    "snippet_fragments": "  Professional experience with artificial intelligence and/or marketing data analysis ,   Strong understanding of common machine learning algorithms and Ability to translate complex data into actionable insights for non-technical stakeholders,   Strong programming skills in Python and SQL querying, You are able to write production-ready code,   Proven track record of delivering machine learning and AI projects end-to-end ,   Strong problem-solving skills and the ability to think critically and creatively, You give and receive open, direct and timely feedback,   Employee benefits that range from a competitive personal development budget,   As an N26 employee you will have access to a Premium subscription on your personal N26 bank account, As well as subscriptions for friends and family members,   Vacation days vary depending on your location of work, Additional day of annual leave for each year of service,   A high degree of autonomy and access to cutting edge technologies - all while working with a friendly team of peers of diverse nationalities,   A relocation package with visa support for those who need it",
    "description": "<p><strong>ABOUT THE OPPORTUNITY</strong></p><br><p>We are seeking a Marketing Data Scientist as part of our Marketing Data Science team to build production-ready solutions for our Marketing managers. As a Marketing Data Scientist you will play a crucial role in analysing marketing data to extract valuable insights, optimise marketing campaigns, and inform strategic decisions. You will work closely with the marketing and product teams to develop data models, run statistical analyses, and create visualisations that enhance our understanding of customer behaviour and market trends.</p><br><p><strong>IN THIS ROLE, YOU WILL:</strong></p><ul><li>Use statistical techniques and machine learning algorithms to interpret data and predict future trends.</li><li>Develop predictive models to forecast marketing outcomes and guide strategic planning.</li><li>Develop A/B testing frameworks to test and optimise marketing strategies and tactics.</li><li>Analyse customer data to segment audiences, understand behaviour, and identify opportunities for personalization and targeting.</li><li>Develop and enhance our customer lifetime value models and Marketing Mix Model.</li></ul><p><strong>WHAT YOU NEED TO BE SUCCESSFUL:</strong></p><br><p>Background:</p><ul><li>Bachelor's or Master's degree, ideally with a focus on quantitative disciplines including mathematics, statistics or computer science</li><li>3+ years of professional experience in the prototyping, development and productionizing of machine learning models and use cases</li><li>Professional experience with artificial intelligence and/or marketing data analysis</li></ul><p>Skills:</p><ul><li>Strong understanding of common machine learning algorithms and Ability to translate complex data into actionable insights for non-technical stakeholders.</li><li>Strong programming skills in Python and SQL querying. You are able to write production-ready code.</li><li>Proven track record of delivering machine learning and AI projects end-to-end</li><li>Strong problem-solving skills and the ability to think critically and creatively.</li><li>You give and receive open, direct and timely feedback</li><li>Language skills: English full professional proficiency;</li></ul><p><strong>WHAT'S IN IT FOR YOU:</strong><br> Accelerate your career growth by joining one of Europe's most talked about disruptors</p><ul><li>.</li><li>Employee benefits that range from a competitive personal development budget, work from home budget, discounts to fitness &amp; wellness memberships, language apps and public transportation.</li><li>As an N26 employee you will have access to a Premium subscription on your personal N26 bank account. As well as subscriptions for friends and family members.</li><li>Vacation days vary depending on your location of work. Additional day of annual leave for each year of service.</li><li>A high degree of autonomy and access to cutting edge technologies - all while working with a friendly team of peers of diverse nationalities, life experiences and family statuses.</li><li>A relocation package with visa support for those who need it.</li></ul><p><strong>WHO WE ARE</strong></p><br><p>N26 has reimagined banking for today's digital world. Technology and design empower everything we do and it's how we are building the global banking platform the world loves to use.</p><br><p>We've eliminated physical branches, paperwork, and hidden fees for an elegant digital experience and supreme savings. Giving people the power to live and bank their way is what gets us out of bed in the morning and inspires the work that we do.</p><br><p>Founded in 2013, N26 now has more than 8 million customers in 24 markets. We are headquartered in Berlin with offices in multiple cities across Europe, including Vienna and Barcelona, and a 1,500-strong team of more than 80 nationalities.</p><br><p>Sounds good? Apply now for this position.</p><br><p>N26 is an equal opportunity employer and values diversity. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status or disability status.</p><br>"
  },
  {
    "id": 166,
    "title": "Data Engineer",
    "company": "Toll Collect GmbH",
    "locations": "Berlin",
    "skills": "SQL, Mathematik, Linux, Cognos, PL/SQL, Windows",
    "posted_at": "2024-06-10",
    "is_remote": "False",
    "snippet_fragments": "    Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung,      Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung,  Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet,      Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung,     Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung, Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu, Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen, Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt",
    "description": "<p>Referenznummer: 20728</p><br><p>Ihre Aufgaben:</p><ul><li>Sie verantworten die Strukturierung und Weiterentwicklung von Datenmodellen und Datenfl\u00fcssen sowie der zugeh\u00f6rigen IT-gest\u00fctzten Prozesse</li><li>Sie erfassen fachliche Anforderungen und arbeiten bei der L\u00f6sungsbeschreibung mit</li><li>Sie unterst\u00fctzen bei der Erstellung von Analysen und Berichten</li><li>Sie analysieren und korrigieren Fehler und Auff\u00e4lligkeiten in den t\u00e4glichen Prozessen</li><li>Sie arbeiten bereichs- und unternehmens\u00fcbergreifend zur Weiterentwicklung von datengetriebenen Prozessen mit, bringen eigene Ideen ein und setzen diese um</li><li>Sie unterst\u00fctzen und beraten Systemanwender*innen bei operativen Fragestellungen<br> Ihr Profil</li><li>Sie haben Erfahrungen IBM Infosphere Datastage und IBM Cognos Analytics</li><li>Sie verf\u00fcgt \u00fcber Kenntnisse in SQL (PL/SQL / Postgres-SQL).\uf03c Sie Beherrscht einwandfrei den Umgang mit Windows und Linux</li><li>Sie haben abgeschlossenes Studium in der Mathematik, Informatik oder in vergleichbaren Studieng\u00e4ngen</li><li>Sie haben Berufserfahrung im Bereich Data Engineering<br> Was bieten wir</li><li>Breites Qualifizierungsangebot zur fachlichen und pers\u00f6nlichen Weiterentwicklung</li><li>Arbeitsplatz direkt am Potsdamer Platz im Herzen Berlins mit guter Verkehrsanbindung</li><li>Interdisziplin\u00e4res, motiviertes und dynamisches Team, das Fortschritt gestaltet</li><li>Attraktive Verg\u00fctung sowie umfangreiche Sozialleistungen vom Job-Ticket \u00fcber einen Zuschuss zum Mittagessen bis zur betrieblichen Altersversorgung</li></ul><p>Interessiert?</p><br><p>Wir freuen uns auf Ihre aussagekr\u00e4ftigen Bewerbungsunterlagen mit Angabe des fr\u00fchestm\u00f6glichen Eintrittstermins und Ihrer Gehaltsvorstellung. Bitte senden Sie uns Ihre Unterlagen ausschlie\u00dflich als PDF-Datei mit insgesamt maximal 3 MB zu. Die Verarbeitung Ihrer personenbezogenen Daten erfolgt entsprechend unserer Datenschutzerkl\u00e4rung f\u00fcr Bewerbungen. Bewerber*innen mit einer Schwerbehinderung (d/m/w) werden bei gleicher Eignung bevorzugt eingestellt.</p><br><p>Ihre Ansprechperson</p><br><p>Frau Silvia Barknecht, 030/74077-8214, karriere@toll-collect.de</p><br><p>Toll Collect GmbH * Personalmanagement * Linkstra\u00dfe 4, 10785 Berlin</p><br>"
  },
  {
    "id": 167,
    "title": "Data Engineer (m/f/d)",
    "company": "Project A Ventures",
    "locations": "Berlin",
    "skills": "Data Science, Linux, Agile, Slack, Version Control, Algorithms, Windows",
    "posted_at": "2024-06-10",
    "is_remote": "False",
    "snippet_fragments": "Build high-quality data warehouses, marketing automations, recommendation engines, etc.,  Integrate data from various systems into flexible and consistent representations ,  Explore and evaluate the lasting impact of AI use cases and their implementation ,  Ensure that all people and IT systems in the organisation have easy access to data,  Work in an agile software development process and collaborate closely with the Analytics team ,  Impact the business while working in an amazing cross-functional team environment ,  Genuine interest in data and algorithms, Knowledge of version control systems, web technologies, software engineering best practices, and the inner workings of database systems,  The ability to turn data science into something that creates business value - is a plus ,  Desire to learn new things (we know you can fly at least one type of plane,  Good communication skills in English (native/full working proficiency) ,  A degree in computer science or a comparable qualification ,  Please note that were looking for support in our Berlin office, Eligibility to work in the EU is required,  Remote-friendly  Work anywhere in Germany or take advantage of our beautiful and well-equipped office at the heart of Berlin ,  Choose your tech  Macbook/Windows/Linux laptop and optional screen,  Career growth  Access to internal workshops, Subsidised products and services, including meal vouchers, German language classes, a bike leasing program, and discounts on services of our portfolio companies and various other brands",
    "description": "<p>About the Job</p><br><p>We're looking for a motivated Data Engineer (m/f/d) to join our Data &amp; Analytics team and support its Data strategies.</p><br><p>In your day-to-day work, you'll focus on building data-driven applications and get the opportunity to contribute to various projects.</p><br><p>Our Data and Analytics team enables our portfolio companies and external partners to grow sustainably as they shift from intuitive to objective decision-making through reliable data collection, proper data infrastructure implementation, and effective data initiatives.</p><br><p><strong>We firmly believe that the decade of data has begun:</strong> Powerful technologies are readily accessible to turn raw data into real insights, products, features and more. We are looking for capable talents from various backgrounds to tag along on our journey to utilise data to create real impact via scalable Data / ML infrastructure, thorough analyses &amp; meaningful relationships to ensure proper application.</p><br><p><strong>In this role, you'll:</strong></p><ul><li>Build high-quality data warehouses, marketing automations, recommendation engines, etc.</li><li>Integrate data from various systems into flexible and consistent representations</li><li>Explore and evaluate the lasting impact of AI use cases and their implementation</li><li>Ensure that all people and IT systems in the organisation have easy access to data, through various front-ends and interfaces</li><li>Work in an agile software development process and collaborate closely with the Analytics team</li><li>Impact the business while working in an amazing cross-functional team environment<br> Your Profile</li><li>Genuine interest in data and algorithms, and an excitement for solving difficult business problems through scalable data products</li><li>Knowledge of version control systems, web technologies, software engineering best practices, and the inner workings of database systems</li><li>The ability to turn data science into something that creates business value - is a plus</li><li>Desire to learn new things (we know you can &quot;fly at least one type of plane&quot;, and we will provide you with many types and variations of said plane)</li><li>Good communication skills in English (native/full working proficiency)</li><li>A degree in computer science or a comparable qualification<br> Please note that we're looking for support in our Berlin office. Eligibility to work in the EU is required.</li></ul><p><strong>Benefits and Perks:</strong></p><ul><li>Remote-friendly - Work anywhere in Germany or take advantage of our beautiful and well-equipped office at the heart of Berlin</li><li>Choose your tech - Macbook/Windows/Linux laptop and optional screen.</li><li>Career growth - Access to internal workshops, knowledge-sharing meetups, PAV Academy professional training opportunities, industry conferences, and other personal development possibilities</li><li>Subsidised products and services, including meal vouchers, German language classes, a bike leasing program, and discounts on services of our portfolio companies and various other brands</li><li>Wellness - 24/7 access to counseling specialists, free subscription to workplace wellbeing platform Unmind, weekly online yoga classes</li><li>Paid team and company events</li><li>Social activities - Hang out with co-workers during and after-hours (Slack or IRL, you decide), grab lunch or coffee with randomly assigned teammates, and disconnect from everything to spend quality time in outdoor activities</li><li>Visa application support and relocation package<br> Apply below and become a part of our success story!</li></ul><p>Our Commitment to Diversity and Inclusion</p><br><p>Project A is committed to diverse and equal opportunities hiring for all - applicants, candidates, and employees alike. We value humans - with all our glorious multifaceted backgrounds, perspectives, and experiences - and look forward to your application.</p><br>"
  }
]